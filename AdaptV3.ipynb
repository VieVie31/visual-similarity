{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdaptV3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d70d484b2524bff961da9e5d7ae8d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5f178bc1db864dce8515b2bb952681ee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb08618769a94a2e9a6ec2718cf9c2d4",
              "IPY_MODEL_e74ff61ffb02417fb0abd5a6a1f3d886"
            ]
          }
        },
        "5f178bc1db864dce8515b2bb952681ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb08618769a94a2e9a6ec2718cf9c2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_48e24fe46b554f15b5f52f0108894e00",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22e9ca83f9754132ad00b1c54fbc8d5b"
          }
        },
        "e74ff61ffb02417fb0abd5a6a1f3d886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e1fbbdecb8b44bfb8dcacd788bf8a06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [09:41&lt;00:00,  2.91s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d007b853dd374d89b5a558f558a87537"
          }
        },
        "48e24fe46b554f15b5f52f0108894e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22e9ca83f9754132ad00b1c54fbc8d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e1fbbdecb8b44bfb8dcacd788bf8a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d007b853dd374d89b5a558f558a87537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1f55bca394e4a20bf6cad5b8e9e2554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d24f78e8d80f4bf6912638930da0c35f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff621910fcce4033aa47fabbd1e3166e",
              "IPY_MODEL_df5dda73b6ae421b8313ebc697f0a191"
            ]
          }
        },
        "d24f78e8d80f4bf6912638930da0c35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff621910fcce4033aa47fabbd1e3166e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9214690265b54e708a47e3a5c6c2927b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca51f7d70cd14188bde47ac62089f669"
          }
        },
        "df5dda73b6ae421b8313ebc697f0a191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a7bbc00882344c78f2eb1e7fde6058a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [56:36&lt;00:00, 33.96s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b218a7929e944b0cad2f82c44a480d5f"
          }
        },
        "9214690265b54e708a47e3a5c6c2927b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca51f7d70cd14188bde47ac62089f669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a7bbc00882344c78f2eb1e7fde6058a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b218a7929e944b0cad2f82c44a480d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d633b84d794c47ddaa369c0794242eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aef3a722302a4566b712e6c2b75c46c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_038ac82035d947acb29d5c677b692a04",
              "IPY_MODEL_16838130593f41719943a41d5127b873"
            ]
          }
        },
        "aef3a722302a4566b712e6c2b75c46c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "038ac82035d947acb29d5c677b692a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f112e3d9a1214526b4e23a06ff451e2d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f503c767253847f7b5548a0aa0db56cc"
          }
        },
        "16838130593f41719943a41d5127b873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0da10926a68e45cb925f78615a53e5d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [10:32&lt;00:00,  1.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70775fd8c63f4901a456eca94124c459"
          }
        },
        "f112e3d9a1214526b4e23a06ff451e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f503c767253847f7b5548a0aa0db56cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0da10926a68e45cb925f78615a53e5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70775fd8c63f4901a456eca94124c459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97b41246367b4c0da708b6fabf4a50a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b058d8d90234813b2a9f5192fa4b762",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_310310cd37d440d29cbcf4209070e5eb",
              "IPY_MODEL_83bb22a903054cf2a3aad044a2c354a9"
            ]
          }
        },
        "9b058d8d90234813b2a9f5192fa4b762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "310310cd37d440d29cbcf4209070e5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0106063654f4ea18082ef93c4b653d1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e422bf8a7f024c22b5d9e4921ce2e91e"
          }
        },
        "83bb22a903054cf2a3aad044a2c354a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95cccd4d9dbb4a80acd7cc680d986f46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [08:01&lt;00:00,  1.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e8149154b024b27941e57ec3f1dd1b1"
          }
        },
        "b0106063654f4ea18082ef93c4b653d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e422bf8a7f024c22b5d9e4921ce2e91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95cccd4d9dbb4a80acd7cc680d986f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e8149154b024b27941e57ec3f1dd1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff6b1dab425541d0ab96ad8dffdeeefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c22866bde0a84898bf1bc71d8de3d4e7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e04b7897170944789f178ab1462b50d0",
              "IPY_MODEL_b8f1a47694b8461eb164bfc41a2a2f3c"
            ]
          }
        },
        "c22866bde0a84898bf1bc71d8de3d4e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e04b7897170944789f178ab1462b50d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7175536afef1490ca8e62d145e4e09cc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3ede31572344efaa2590ee1829b360f"
          }
        },
        "b8f1a47694b8461eb164bfc41a2a2f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69d1d50d6108494cbc81c17db31b5161",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [03:01&lt;00:00,  1.81s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c1de452cdb8431580c73b4101e2177c"
          }
        },
        "7175536afef1490ca8e62d145e4e09cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3ede31572344efaa2590ee1829b360f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69d1d50d6108494cbc81c17db31b5161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c1de452cdb8431580c73b4101e2177c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "553693c3d2784b62940cd2a830e9c778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9eaf98d108df45fdbc67bbb52939f7d7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b7cbefe266e486482bae6332c97ee25",
              "IPY_MODEL_7efc9c34277448119995fcc87e853224"
            ]
          }
        },
        "9eaf98d108df45fdbc67bbb52939f7d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b7cbefe266e486482bae6332c97ee25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_605b0e4961514d42925fe7ed41b787ae",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83a17f5962d34dc8acd55fce8de172d1"
          }
        },
        "7efc9c34277448119995fcc87e853224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d90c5cadcbaf45d0873c0c520a2d63d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [36:54&lt;00:00,  3.16s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4dd6bfe992dd4ecaac0c292c02091cc2"
          }
        },
        "605b0e4961514d42925fe7ed41b787ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83a17f5962d34dc8acd55fce8de172d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d90c5cadcbaf45d0873c0c520a2d63d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4dd6bfe992dd4ecaac0c292c02091cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d9b7855ed6c4e5680f680ca79c828ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ffa89f3b6b841ddad3fbfc276837e5d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e93cac7a83044673a2a8f1675797da60",
              "IPY_MODEL_8732dc5f0f1d4740afdfc6f98479e467"
            ]
          }
        },
        "5ffa89f3b6b841ddad3fbfc276837e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e93cac7a83044673a2a8f1675797da60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf4bbf6ce1bb40ce8df2ec9e49d5da8e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3abd886811c641e19395c75c9a6f1065"
          }
        },
        "8732dc5f0f1d4740afdfc6f98479e467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3babc9816288458eb16c031edb367097",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [35:26&lt;00:00,  3.04s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a599039147f474baf4511fee59b5e91"
          }
        },
        "bf4bbf6ce1bb40ce8df2ec9e49d5da8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3abd886811c641e19395c75c9a6f1065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3babc9816288458eb16c031edb367097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a599039147f474baf4511fee59b5e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4beff6f038d4441dbe98b244b46648c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7644deabebd4fc2a8de3b197454530f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f623de6e514414eae7907fe799e56a5",
              "IPY_MODEL_23a53e44747e40db9cbbcd999ff2a8c4"
            ]
          }
        },
        "c7644deabebd4fc2a8de3b197454530f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f623de6e514414eae7907fe799e56a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f2a38a801aab4a4397f0b7d6e02e9501",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20cc24100080430683940fe8c95b2db0"
          }
        },
        "23a53e44747e40db9cbbcd999ff2a8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6620f36b2ee549bbbe87bf85816a506a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [34:00&lt;00:00,  2.91s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bbd2910ebce47959a0960882981b462"
          }
        },
        "f2a38a801aab4a4397f0b7d6e02e9501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20cc24100080430683940fe8c95b2db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6620f36b2ee549bbbe87bf85816a506a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bbd2910ebce47959a0960882981b462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6cd7a171ab248d1afb33773894e045d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b58d2c734d734c53a5e6b16334bd6b21",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e6395d244d404122ae329d486f2de8c0",
              "IPY_MODEL_eec873c5b0574da2b6ce617cbaf43478"
            ]
          }
        },
        "b58d2c734d734c53a5e6b16334bd6b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6395d244d404122ae329d486f2de8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_297efd08d7464baf8f9cb4002c5d66c3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6387627745de47ada80c8320c8c1d14b"
          }
        },
        "eec873c5b0574da2b6ce617cbaf43478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6212c0008df74b6aa55a6cb64f2fa006",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [32:33&lt;00:00,  2.79s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_644b037e60d34861877ccf757ecc1a69"
          }
        },
        "297efd08d7464baf8f9cb4002c5d66c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6387627745de47ada80c8320c8c1d14b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6212c0008df74b6aa55a6cb64f2fa006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "644b037e60d34861877ccf757ecc1a69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f657c56072f43bbb9a1bba86dde9ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f8b9bfd6404e4fb7b8da48e1012b00d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8c660cd311114afe9bd0a8a5fc875c85",
              "IPY_MODEL_6e7cc47893e742f983b7c726f9c47a84"
            ]
          }
        },
        "f8b9bfd6404e4fb7b8da48e1012b00d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c660cd311114afe9bd0a8a5fc875c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8e955622679942ff975d75b013d39472",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8828340c2fb44249ed8e7f2f44f176e"
          }
        },
        "6e7cc47893e742f983b7c726f9c47a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bfd641d2255f4ae1835c7a31e5c77cd5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [20:47&lt;00:00,  1.78s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dcea2a747cc47e8acb78e83aa0fbb23"
          }
        },
        "8e955622679942ff975d75b013d39472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8828340c2fb44249ed8e7f2f44f176e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfd641d2255f4ae1835c7a31e5c77cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dcea2a747cc47e8acb78e83aa0fbb23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8b5c563ae0a41d48344646efa6944a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f8484db479e40e8b95dd8d9b3433798",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_057ab59ef19e454a9ee3da401dd49e82",
              "IPY_MODEL_f5ed57283e5e48378630adfb8f186da2"
            ]
          }
        },
        "1f8484db479e40e8b95dd8d9b3433798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "057ab59ef19e454a9ee3da401dd49e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3fb87713508044239033661b70881392",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aea5d4202dc94e6f94d820636ecb3eac"
          }
        },
        "f5ed57283e5e48378630adfb8f186da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63098e9858524743845e41bf86ba8ca4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [17:07&lt;00:00,  1.47s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a7cb606dd0649e6a6cb5535b676e592"
          }
        },
        "3fb87713508044239033661b70881392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aea5d4202dc94e6f94d820636ecb3eac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63098e9858524743845e41bf86ba8ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a7cb606dd0649e6a6cb5535b676e592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcb8ce3fec734f17a02a8d8a1086b8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3385243b20d5438a810f7b423601a4cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31abb6f8f00d461da73196901dd05702",
              "IPY_MODEL_9073d12e24d74f0cb9be9ced76bb21db"
            ]
          }
        },
        "3385243b20d5438a810f7b423601a4cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31abb6f8f00d461da73196901dd05702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_323c4c4efffe4ac196642fcf53fd2083",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dcb92620fe6d4d2d8f147edcddeaff57"
          }
        },
        "9073d12e24d74f0cb9be9ced76bb21db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fad12bf5044a4196ab87356ff0f0270f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [15:39&lt;00:00,  1.34s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe608ab4998f4ef8815b075488a359d0"
          }
        },
        "323c4c4efffe4ac196642fcf53fd2083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dcb92620fe6d4d2d8f147edcddeaff57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fad12bf5044a4196ab87356ff0f0270f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe608ab4998f4ef8815b075488a359d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d70e5edad5684fe3b353a88a62c4345c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_baad53051f0940cfb30a35e881345366",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_829cb304f4a44153bf848e4597becf4c",
              "IPY_MODEL_8ed039f72fd14db98475ff58941c2ba4"
            ]
          }
        },
        "baad53051f0940cfb30a35e881345366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "829cb304f4a44153bf848e4597becf4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_970a9f83209c4a3e98f5523b4363d205",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f372c6e9bc14eeaaf57242d7b05fd4c"
          }
        },
        "8ed039f72fd14db98475ff58941c2ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea9a0eaab10b4399802f9fd58ef4290d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [1:32:16&lt;00:00,  7.91s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_598d4317644842fb9cb3829fd0fa36e5"
          }
        },
        "970a9f83209c4a3e98f5523b4363d205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f372c6e9bc14eeaaf57242d7b05fd4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea9a0eaab10b4399802f9fd58ef4290d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "598d4317644842fb9cb3829fd0fa36e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e75d65960a8246f5ae9a762643f8b199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9db6d3d082ed4a329b60d4858eed62a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63df5cc5563545518375ad54a2665089",
              "IPY_MODEL_5da98f0018c84d32847bafea2293d3a2"
            ]
          }
        },
        "9db6d3d082ed4a329b60d4858eed62a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63df5cc5563545518375ad54a2665089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82fe0d135850418181ae3cb9a0c9fd54",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e013e4437314817be3cdaea9b9fb6c2"
          }
        },
        "5da98f0018c84d32847bafea2293d3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70115ceeaa4f432382ffc78a4765378e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700/700 [1:29:36&lt;00:00,  7.68s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f998a9fa2e3455d95a3df7097910088"
          }
        },
        "82fe0d135850418181ae3cb9a0c9fd54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e013e4437314817be3cdaea9b9fb6c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70115ceeaa4f432382ffc78a4765378e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f998a9fa2e3455d95a3df7097910088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8emOXBPZuWk_"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "from tqdm.auto import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "class Adaptation (nn.Module):\n",
        "    def __init__(self,input):\n",
        "        super().__init__()\n",
        "        self.weight_matrix = nn.Linear(input,1024,bias=False)\n",
        "  \n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.weight_matrix(x)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "def sim_matrix(a, b, eps=1e-8):\n",
        "    \"\"\"\n",
        "    added eps for numerical stability\n",
        "    \"\"\"\n",
        "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
        "    a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
        "    b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
        "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
        "    return sim_mt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwWThQfyrJMu"
      },
      "source": [
        "**Fonction de calcul de la loss**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hASB3j0smg5u"
      },
      "source": [
        "def calc_loss(left,right,temp):\n",
        "  sim1 = sim_matrix(left, right)\n",
        "  sim2 = sim1.t()\n",
        "  loss_left2right= F.cross_entropy(sim1* temp, torch.arange(len(sim1)).long().to(device)).to(device)\n",
        "  loss_right2left= F.cross_entropy(sim2* temp, torch.arange(len(sim2)).long().to(device)).to(device)\n",
        "  loss = loss_left2right* 0.5 + loss_right2left * 0.5\n",
        "  return loss"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBcLy0yyrw1y"
      },
      "source": [
        "**Calcul top K**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79lAhkXSjA8g"
      },
      "source": [
        "def get_topk2(left,right, k):\n",
        "  sim = -sim_matrix(left, right)\n",
        "  \n",
        "  sorted_idx = sim.argsort(1)\n",
        "  \n",
        " \n",
        "  sens1 = np.array([lbl in sorted_idx[lbl][:k] for lbl in range(len(left))])    \n",
        "  sim = sim.t()\n",
        "  sorted_idx = sim.argsort(1)\n",
        "  sens2 = np.array([lbl in sorted_idx[lbl][:k] for lbl in range(len(left))])\n",
        "\n",
        "  return ((sens1 | sens2).mean())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8p3tO784XvT"
      },
      "source": [
        "def load_embeddings (path): \n",
        "  data = np.load(path, allow_pickle=True).reshape(-1)[0]\n",
        "  return data\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrYj2QWSCyWZ"
      },
      "source": [
        "from sklearn.preprocessing import normalize as l2"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U96RmPIOC56s"
      },
      "source": [
        "left = l2(left)\n",
        "right = l2(right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhHScUzKlLRD"
      },
      "source": [
        "Train avec zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSfCgeyEBOTA"
      },
      "source": [
        "def train1(left_train, right_train, left_tst, right_tst,epochs,adaptation, optimizer,k,temp):\n",
        "\n",
        "   \n",
        "    score =0\n",
        "    recall = []\n",
        "    train_losses =[]\n",
        "    test_losses=[]\n",
        "    total_train = len(left_train)\n",
        "    total_test = len(left_tst)\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "  \n",
        "        adaptation.train()\n",
        "        running_loss =0.0\n",
        "        optimizer.zero_grad()\n",
        "        left_adapted = adaptation(left_train)\n",
        "        right_adapted = adaptation(right_train)\n",
        "        loss = calc_loss(left_adapted,right_adapted,temp)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss = loss.item()    \n",
        "        with torch.no_grad():\n",
        "          adaptation.eval()\n",
        "          test_loss=0.0\n",
        "          left_adapted_test = adaptation(left_tst)\n",
        "          right_adapted_test = adaptation(right_tst)\n",
        "          loss = calc_loss(left_adapted_test,right_adapted_test,temp)\n",
        "          test_loss = loss.item()\n",
        "\n",
        "        \n",
        "        recall.append(get_topk2(left_adapted_test,right_adapted_test,k))\n",
        "        train_losses.append(running_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        print(\"Epoch \" , (epoch+1))\n",
        "        print(\"Train Loss: \",running_loss)\n",
        "        print(\"Test Loss: \",test_loss)\n",
        "        print(\"Recall :\", recall[epoch])\n",
        "        \n",
        "        \n",
        "    \n",
        "    plt.plot(train_losses, label='Training loss')\n",
        "    plt.plot(test_losses, label='Testing loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.figure(1)\n",
        "    plt.plot(recall,label ='Recall' )\n",
        "    plt.legend()\n",
        "    plt.show\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEjAYmtFlP2x"
      },
      "source": [
        "Train en accumulant le gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcxVITeEved7"
      },
      "source": [
        "def train2(left_train, right_train, left_tst, right_tst,epochs,adaptation, optimizer,k,temp):\n",
        "\n",
        "   \n",
        "    score =0\n",
        "    recall = []    \n",
        "    train_losses =[]\n",
        "    test_losses=[]\n",
        "    total_train = len(left_train)\n",
        "    total_test = len(left_tst)\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "  \n",
        "        adaptation.train()\n",
        "        running_loss =0.0\n",
        "       \n",
        "        left_adapted = adaptation(left_train)\n",
        "        right_adapted = adaptation(right_train)\n",
        "        loss = calc_loss(left_adapted,right_adapted,temp)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss = loss.item()    \n",
        "        with torch.no_grad():\n",
        "          adaptation.eval()\n",
        "          test_loss=0.0\n",
        "          left_adapted_test = adaptation(left_tst)\n",
        "          right_adapted_test = adaptation(right_tst)\n",
        "          loss = calc_loss(left_adapted_test,right_adapted_test,temp)\n",
        "          test_loss = loss.item()\n",
        "\n",
        "        \n",
        "        recall.append(get_topk2(left_adapted_test,right_adapted_test,k))\n",
        "        train_losses.append(running_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        print(\"Epoch \" , (epoch+1))\n",
        "        print(\"Train Loss: \",running_loss)\n",
        "        print(\"Test Loss: \",test_loss)\n",
        "        print(\"Recall :\", recall[epoch])\n",
        "        \n",
        "        \n",
        "    print(sum(recall)/len(recall))\n",
        "    plt.plot(train_losses, label='Training loss')\n",
        "    plt.plot(test_losses, label='Testing loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.figure(1)\n",
        "    plt.plot(recall,label ='Recall' )\n",
        "    plt.legend()\n",
        "    plt.show"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubGBEKycl6w9"
      },
      "source": [
        "def run(path,runs,epochs, k,temp,type,spl):\n",
        "\n",
        "  \"\"\"\n",
        "  runs : number of experiments \n",
        "  left, right : embeddings\n",
        "  epochs : number of epochs \n",
        "  k : aR@k\n",
        "  temp : temperature\n",
        "  type : gradient accumulation =>2 \n",
        "          else => 1 \n",
        "  spl : train size\n",
        "  \"\"\"\n",
        "  data = load_embeddings (path)\n",
        "  if not check_embeddings(data):\n",
        "    return\n",
        "  left = data['left']\n",
        "  right = data['right']\n",
        "  left = torch.FloatTensor(left).to(device)\n",
        "  right = torch.FloatTensor(right).to(device)\n",
        "  #pca = PCA(256).fit(np.concatenate([left, right]))\n",
        "  #left = pca.transform(left)\n",
        "  #right = pca.transform(right)\n",
        "  for i in range(runs):\n",
        "\n",
        "    \n",
        "    N = len(left)\n",
        "    sample = int(spl*N)\n",
        "    idx = np.random.permutation(left.shape[0])  \n",
        "    train_idx, test_idx = idx[:sample], idx[sample:]\n",
        "\n",
        "    model = Adaptation(256)\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr =0.0005,weight_decay=1e-5)\n",
        "\n",
        "\n",
        "\n",
        "    left_train, left_test, right_train, right_test = left[train_idx,:], left[test_idx,:], right[train_idx,], right[test_idx,]\n",
        "    if type==1:\n",
        "      train1(left_train,right_train,left_test, right_test,epochs, model, optimizer,k,temp)\n",
        "    else:\n",
        "      train2(left_train,right_train,left_test, right_test,epochs, model, optimizer,k,temp) \n",
        "  \n",
        "\n",
        "  return{\"left_train\": model(left_train), \"right_train\" : model(right_train), \"left_test\": model(left_test), \"right_test\": model(right_test)}\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9d70d484b2524bff961da9e5d7ae8d87",
            "5f178bc1db864dce8515b2bb952681ee",
            "cb08618769a94a2e9a6ec2718cf9c2d4",
            "e74ff61ffb02417fb0abd5a6a1f3d886",
            "48e24fe46b554f15b5f52f0108894e00",
            "22e9ca83f9754132ad00b1c54fbc8d5b",
            "1e1fbbdecb8b44bfb8dcacd788bf8a06",
            "d007b853dd374d89b5a558f558a87537"
          ]
        },
        "id": "2YmjILMnsyh2",
        "outputId": "10b82f62-67f0-4d06-c5f2-38197aac12f3"
      },
      "source": [
        "run(path=\"pairs_ebds.npy\",runs=1,epochs=200,k=1,temp=15,type=1,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d70d484b2524bff961da9e5d7ae8d87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  6.895463466644287\n",
            "Test Loss:  5.575901031494141\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  2\n",
            "Train Loss:  6.815420627593994\n",
            "Test Loss:  5.532136917114258\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  3\n",
            "Train Loss:  6.736627578735352\n",
            "Test Loss:  5.489441871643066\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  4\n",
            "Train Loss:  6.659130096435547\n",
            "Test Loss:  5.447847366333008\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  5\n",
            "Train Loss:  6.5829572677612305\n",
            "Test Loss:  5.40738582611084\n",
            "Recall : 0.18\n",
            "Epoch  6\n",
            "Train Loss:  6.508173942565918\n",
            "Test Loss:  5.368088722229004\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  7\n",
            "Train Loss:  6.4348015785217285\n",
            "Test Loss:  5.329928398132324\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  8\n",
            "Train Loss:  6.36283540725708\n",
            "Test Loss:  5.292901039123535\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  9\n",
            "Train Loss:  6.292285442352295\n",
            "Test Loss:  5.256989479064941\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  10\n",
            "Train Loss:  6.223156929016113\n",
            "Test Loss:  5.222175598144531\n",
            "Recall : 0.1961904761904762\n",
            "Epoch  11\n",
            "Train Loss:  6.155444145202637\n",
            "Test Loss:  5.188424110412598\n",
            "Recall : 0.1980952380952381\n",
            "Epoch  12\n",
            "Train Loss:  6.089142799377441\n",
            "Test Loss:  5.155784606933594\n",
            "Recall : 0.2038095238095238\n",
            "Epoch  13\n",
            "Train Loss:  6.024222373962402\n",
            "Test Loss:  5.1241960525512695\n",
            "Recall : 0.21047619047619048\n",
            "Epoch  14\n",
            "Train Loss:  5.960671424865723\n",
            "Test Loss:  5.093664646148682\n",
            "Recall : 0.21428571428571427\n",
            "Epoch  15\n",
            "Train Loss:  5.898470878601074\n",
            "Test Loss:  5.064126968383789\n",
            "Recall : 0.21904761904761905\n",
            "Epoch  16\n",
            "Train Loss:  5.837591171264648\n",
            "Test Loss:  5.035547256469727\n",
            "Recall : 0.22380952380952382\n",
            "Epoch  17\n",
            "Train Loss:  5.77798318862915\n",
            "Test Loss:  5.00787878036499\n",
            "Recall : 0.2257142857142857\n",
            "Epoch  18\n",
            "Train Loss:  5.7196173667907715\n",
            "Test Loss:  4.981127738952637\n",
            "Recall : 0.22952380952380952\n",
            "Epoch  19\n",
            "Train Loss:  5.662471771240234\n",
            "Test Loss:  4.955236911773682\n",
            "Recall : 0.23238095238095238\n",
            "Epoch  20\n",
            "Train Loss:  5.606511116027832\n",
            "Test Loss:  4.930147171020508\n",
            "Recall : 0.24\n",
            "Epoch  21\n",
            "Train Loss:  5.5517072677612305\n",
            "Test Loss:  4.905815124511719\n",
            "Recall : 0.24\n",
            "Epoch  22\n",
            "Train Loss:  5.498041152954102\n",
            "Test Loss:  4.882261276245117\n",
            "Recall : 0.2438095238095238\n",
            "Epoch  23\n",
            "Train Loss:  5.445483207702637\n",
            "Test Loss:  4.859466075897217\n",
            "Recall : 0.24761904761904763\n",
            "Epoch  24\n",
            "Train Loss:  5.3939971923828125\n",
            "Test Loss:  4.837406158447266\n",
            "Recall : 0.24857142857142858\n",
            "Epoch  25\n",
            "Train Loss:  5.343566417694092\n",
            "Test Loss:  4.816066741943359\n",
            "Recall : 0.2523809523809524\n",
            "Epoch  26\n",
            "Train Loss:  5.294159889221191\n",
            "Test Loss:  4.795442581176758\n",
            "Recall : 0.2561904761904762\n",
            "Epoch  27\n",
            "Train Loss:  5.245735168457031\n",
            "Test Loss:  4.775482654571533\n",
            "Recall : 0.26095238095238094\n",
            "Epoch  28\n",
            "Train Loss:  5.198276996612549\n",
            "Test Loss:  4.75615930557251\n",
            "Recall : 0.26476190476190475\n",
            "Epoch  29\n",
            "Train Loss:  5.151758193969727\n",
            "Test Loss:  4.737453460693359\n",
            "Recall : 0.26571428571428574\n",
            "Epoch  30\n",
            "Train Loss:  5.106153964996338\n",
            "Test Loss:  4.719365119934082\n",
            "Recall : 0.26857142857142857\n",
            "Epoch  31\n",
            "Train Loss:  5.061441421508789\n",
            "Test Loss:  4.701860427856445\n",
            "Recall : 0.2723809523809524\n",
            "Epoch  32\n",
            "Train Loss:  5.017597675323486\n",
            "Test Loss:  4.684879302978516\n",
            "Recall : 0.2723809523809524\n",
            "Epoch  33\n",
            "Train Loss:  4.974596977233887\n",
            "Test Loss:  4.668415069580078\n",
            "Recall : 0.2742857142857143\n",
            "Epoch  34\n",
            "Train Loss:  4.932413101196289\n",
            "Test Loss:  4.652457237243652\n",
            "Recall : 0.27714285714285714\n",
            "Epoch  35\n",
            "Train Loss:  4.891024589538574\n",
            "Test Loss:  4.637024879455566\n",
            "Recall : 0.2819047619047619\n",
            "Epoch  36\n",
            "Train Loss:  4.8504180908203125\n",
            "Test Loss:  4.622142791748047\n",
            "Recall : 0.2838095238095238\n",
            "Epoch  37\n",
            "Train Loss:  4.810573577880859\n",
            "Test Loss:  4.607753753662109\n",
            "Recall : 0.28476190476190477\n",
            "Epoch  38\n",
            "Train Loss:  4.771486282348633\n",
            "Test Loss:  4.593835830688477\n",
            "Recall : 0.28476190476190477\n",
            "Epoch  39\n",
            "Train Loss:  4.733131408691406\n",
            "Test Loss:  4.580360412597656\n",
            "Recall : 0.2914285714285714\n",
            "Epoch  40\n",
            "Train Loss:  4.695469856262207\n",
            "Test Loss:  4.5673322677612305\n",
            "Recall : 0.2923809523809524\n",
            "Epoch  41\n",
            "Train Loss:  4.658497333526611\n",
            "Test Loss:  4.554714679718018\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  42\n",
            "Train Loss:  4.622196197509766\n",
            "Test Loss:  4.542484283447266\n",
            "Recall : 0.2980952380952381\n",
            "Epoch  43\n",
            "Train Loss:  4.5865559577941895\n",
            "Test Loss:  4.530624866485596\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  44\n",
            "Train Loss:  4.551571846008301\n",
            "Test Loss:  4.519161701202393\n",
            "Recall : 0.3057142857142857\n",
            "Epoch  45\n",
            "Train Loss:  4.517247200012207\n",
            "Test Loss:  4.508098602294922\n",
            "Recall : 0.30666666666666664\n",
            "Epoch  46\n",
            "Train Loss:  4.483558177947998\n",
            "Test Loss:  4.497409820556641\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  47\n",
            "Train Loss:  4.450479507446289\n",
            "Test Loss:  4.487088203430176\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  48\n",
            "Train Loss:  4.418022155761719\n",
            "Test Loss:  4.477118015289307\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  49\n",
            "Train Loss:  4.3861589431762695\n",
            "Test Loss:  4.4674882888793945\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  50\n",
            "Train Loss:  4.354875564575195\n",
            "Test Loss:  4.458196640014648\n",
            "Recall : 0.32\n",
            "Epoch  51\n",
            "Train Loss:  4.324153423309326\n",
            "Test Loss:  4.4492387771606445\n",
            "Recall : 0.319047619047619\n",
            "Epoch  52\n",
            "Train Loss:  4.293982028961182\n",
            "Test Loss:  4.440593719482422\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  53\n",
            "Train Loss:  4.26435661315918\n",
            "Test Loss:  4.432250022888184\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  54\n",
            "Train Loss:  4.235265731811523\n",
            "Test Loss:  4.424195289611816\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  55\n",
            "Train Loss:  4.206678867340088\n",
            "Test Loss:  4.416414260864258\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  56\n",
            "Train Loss:  4.178589820861816\n",
            "Test Loss:  4.408909320831299\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  57\n",
            "Train Loss:  4.150996208190918\n",
            "Test Loss:  4.401658058166504\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  58\n",
            "Train Loss:  4.123883247375488\n",
            "Test Loss:  4.394647598266602\n",
            "Recall : 0.3238095238095238\n",
            "Epoch  59\n",
            "Train Loss:  4.09724235534668\n",
            "Test Loss:  4.387885093688965\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  60\n",
            "Train Loss:  4.071072578430176\n",
            "Test Loss:  4.3813557624816895\n",
            "Recall : 0.32857142857142857\n",
            "Epoch  61\n",
            "Train Loss:  4.045363426208496\n",
            "Test Loss:  4.375055313110352\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  62\n",
            "Train Loss:  4.020105838775635\n",
            "Test Loss:  4.368985176086426\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  63\n",
            "Train Loss:  3.995284080505371\n",
            "Test Loss:  4.36312198638916\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  64\n",
            "Train Loss:  3.970895290374756\n",
            "Test Loss:  4.3574981689453125\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  65\n",
            "Train Loss:  3.946930408477783\n",
            "Test Loss:  4.352087020874023\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  66\n",
            "Train Loss:  3.9233856201171875\n",
            "Test Loss:  4.3469038009643555\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  67\n",
            "Train Loss:  3.9002437591552734\n",
            "Test Loss:  4.341914653778076\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  68\n",
            "Train Loss:  3.877498149871826\n",
            "Test Loss:  4.337137699127197\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  69\n",
            "Train Loss:  3.8551321029663086\n",
            "Test Loss:  4.332553863525391\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  70\n",
            "Train Loss:  3.8331475257873535\n",
            "Test Loss:  4.328149318695068\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  71\n",
            "Train Loss:  3.811537742614746\n",
            "Test Loss:  4.323925495147705\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  72\n",
            "Train Loss:  3.790294647216797\n",
            "Test Loss:  4.319870948791504\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  73\n",
            "Train Loss:  3.7694129943847656\n",
            "Test Loss:  4.315988540649414\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  74\n",
            "Train Loss:  3.7488818168640137\n",
            "Test Loss:  4.312255382537842\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  75\n",
            "Train Loss:  3.728694438934326\n",
            "Test Loss:  4.308658123016357\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  76\n",
            "Train Loss:  3.708850860595703\n",
            "Test Loss:  4.305185317993164\n",
            "Recall : 0.34\n",
            "Epoch  77\n",
            "Train Loss:  3.6893463134765625\n",
            "Test Loss:  4.301863670349121\n",
            "Recall : 0.34\n",
            "Epoch  78\n",
            "Train Loss:  3.6701712608337402\n",
            "Test Loss:  4.298684597015381\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  79\n",
            "Train Loss:  3.651313543319702\n",
            "Test Loss:  4.295636177062988\n",
            "Recall : 0.34\n",
            "Epoch  80\n",
            "Train Loss:  3.6327695846557617\n",
            "Test Loss:  4.292697906494141\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  81\n",
            "Train Loss:  3.6145386695861816\n",
            "Test Loss:  4.28986120223999\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  82\n",
            "Train Loss:  3.5966124534606934\n",
            "Test Loss:  4.287137031555176\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  83\n",
            "Train Loss:  3.5789895057678223\n",
            "Test Loss:  4.284520149230957\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  84\n",
            "Train Loss:  3.561655044555664\n",
            "Test Loss:  4.282007217407227\n",
            "Recall : 0.3495238095238095\n",
            "Epoch  85\n",
            "Train Loss:  3.5446014404296875\n",
            "Test Loss:  4.2796125411987305\n",
            "Recall : 0.3495238095238095\n",
            "Epoch  86\n",
            "Train Loss:  3.527825355529785\n",
            "Test Loss:  4.277343273162842\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  87\n",
            "Train Loss:  3.511309862136841\n",
            "Test Loss:  4.275184631347656\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  88\n",
            "Train Loss:  3.4950549602508545\n",
            "Test Loss:  4.273129940032959\n",
            "Recall : 0.3495238095238095\n",
            "Epoch  89\n",
            "Train Loss:  3.479062557220459\n",
            "Test Loss:  4.271183490753174\n",
            "Recall : 0.3495238095238095\n",
            "Epoch  90\n",
            "Train Loss:  3.463334321975708\n",
            "Test Loss:  4.269335746765137\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  91\n",
            "Train Loss:  3.4478585720062256\n",
            "Test Loss:  4.267576217651367\n",
            "Recall : 0.3514285714285714\n",
            "Epoch  92\n",
            "Train Loss:  3.4326281547546387\n",
            "Test Loss:  4.265899658203125\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  93\n",
            "Train Loss:  3.417647361755371\n",
            "Test Loss:  4.264301776885986\n",
            "Recall : 0.3514285714285714\n",
            "Epoch  94\n",
            "Train Loss:  3.4029057025909424\n",
            "Test Loss:  4.262779235839844\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  95\n",
            "Train Loss:  3.388399124145508\n",
            "Test Loss:  4.261346817016602\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  96\n",
            "Train Loss:  3.3741190433502197\n",
            "Test Loss:  4.260004043579102\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  97\n",
            "Train Loss:  3.3600597381591797\n",
            "Test Loss:  4.258753776550293\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  98\n",
            "Train Loss:  3.346220016479492\n",
            "Test Loss:  4.2575883865356445\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  99\n",
            "Train Loss:  3.332599401473999\n",
            "Test Loss:  4.2564897537231445\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  100\n",
            "Train Loss:  3.319187641143799\n",
            "Test Loss:  4.255461692810059\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  101\n",
            "Train Loss:  3.3059816360473633\n",
            "Test Loss:  4.254507064819336\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  102\n",
            "Train Loss:  3.2929744720458984\n",
            "Test Loss:  4.253617286682129\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  103\n",
            "Train Loss:  3.280163288116455\n",
            "Test Loss:  4.252797603607178\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  104\n",
            "Train Loss:  3.2675416469573975\n",
            "Test Loss:  4.25205135345459\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  105\n",
            "Train Loss:  3.2551066875457764\n",
            "Test Loss:  4.251373291015625\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  106\n",
            "Train Loss:  3.2428550720214844\n",
            "Test Loss:  4.250748634338379\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  107\n",
            "Train Loss:  3.230785846710205\n",
            "Test Loss:  4.250184535980225\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  108\n",
            "Train Loss:  3.2188942432403564\n",
            "Test Loss:  4.249671936035156\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  109\n",
            "Train Loss:  3.2071757316589355\n",
            "Test Loss:  4.249204635620117\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  110\n",
            "Train Loss:  3.1956300735473633\n",
            "Test Loss:  4.248788833618164\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  111\n",
            "Train Loss:  3.184262275695801\n",
            "Test Loss:  4.2484025955200195\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  112\n",
            "Train Loss:  3.173067092895508\n",
            "Test Loss:  4.248052597045898\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  113\n",
            "Train Loss:  3.1620383262634277\n",
            "Test Loss:  4.2477521896362305\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  114\n",
            "Train Loss:  3.151169776916504\n",
            "Test Loss:  4.247501373291016\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  115\n",
            "Train Loss:  3.1404542922973633\n",
            "Test Loss:  4.247296333312988\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  116\n",
            "Train Loss:  3.129887104034424\n",
            "Test Loss:  4.247129917144775\n",
            "Recall : 0.36\n",
            "Epoch  117\n",
            "Train Loss:  3.1194658279418945\n",
            "Test Loss:  4.246992111206055\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  118\n",
            "Train Loss:  3.1091856956481934\n",
            "Test Loss:  4.24688720703125\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  119\n",
            "Train Loss:  3.099048376083374\n",
            "Test Loss:  4.246817111968994\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  120\n",
            "Train Loss:  3.089048385620117\n",
            "Test Loss:  4.24677848815918\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  121\n",
            "Train Loss:  3.079188823699951\n",
            "Test Loss:  4.246774673461914\n",
            "Recall : 0.36\n",
            "Epoch  122\n",
            "Train Loss:  3.0694680213928223\n",
            "Test Loss:  4.246803283691406\n",
            "Recall : 0.36\n",
            "Epoch  123\n",
            "Train Loss:  3.0598878860473633\n",
            "Test Loss:  4.2468671798706055\n",
            "Recall : 0.36\n",
            "Epoch  124\n",
            "Train Loss:  3.0504417419433594\n",
            "Test Loss:  4.246967315673828\n",
            "Recall : 0.36\n",
            "Epoch  125\n",
            "Train Loss:  3.0411319732666016\n",
            "Test Loss:  4.247092247009277\n",
            "Recall : 0.36\n",
            "Epoch  126\n",
            "Train Loss:  3.0319571495056152\n",
            "Test Loss:  4.24722957611084\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  127\n",
            "Train Loss:  3.0229132175445557\n",
            "Test Loss:  4.247379302978516\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  128\n",
            "Train Loss:  3.013995409011841\n",
            "Test Loss:  4.247544288635254\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  129\n",
            "Train Loss:  3.0051984786987305\n",
            "Test Loss:  4.247739791870117\n",
            "Recall : 0.36\n",
            "Epoch  130\n",
            "Train Loss:  2.996520519256592\n",
            "Test Loss:  4.247944355010986\n",
            "Recall : 0.36\n",
            "Epoch  131\n",
            "Train Loss:  2.9879629611968994\n",
            "Test Loss:  4.2481689453125\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  132\n",
            "Train Loss:  2.9795169830322266\n",
            "Test Loss:  4.248411655426025\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  133\n",
            "Train Loss:  2.971184730529785\n",
            "Test Loss:  4.248662948608398\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  134\n",
            "Train Loss:  2.962963104248047\n",
            "Test Loss:  4.248929977416992\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  135\n",
            "Train Loss:  2.954845905303955\n",
            "Test Loss:  4.249203681945801\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  136\n",
            "Train Loss:  2.9468398094177246\n",
            "Test Loss:  4.249486923217773\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  137\n",
            "Train Loss:  2.938941717147827\n",
            "Test Loss:  4.2497758865356445\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  138\n",
            "Train Loss:  2.93115234375\n",
            "Test Loss:  4.250080108642578\n",
            "Recall : 0.3638095238095238\n",
            "Epoch  139\n",
            "Train Loss:  2.9234728813171387\n",
            "Test Loss:  4.250378608703613\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  140\n",
            "Train Loss:  2.9158976078033447\n",
            "Test Loss:  4.250687122344971\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  141\n",
            "Train Loss:  2.9084200859069824\n",
            "Test Loss:  4.251010894775391\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  142\n",
            "Train Loss:  2.901036262512207\n",
            "Test Loss:  4.251343727111816\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  143\n",
            "Train Loss:  2.8937442302703857\n",
            "Test Loss:  4.251691818237305\n",
            "Recall : 0.3638095238095238\n",
            "Epoch  144\n",
            "Train Loss:  2.886542320251465\n",
            "Test Loss:  4.25206184387207\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  145\n",
            "Train Loss:  2.879424571990967\n",
            "Test Loss:  4.2524542808532715\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  146\n",
            "Train Loss:  2.872394561767578\n",
            "Test Loss:  4.252871990203857\n",
            "Recall : 0.3647619047619048\n",
            "Epoch  147\n",
            "Train Loss:  2.865457057952881\n",
            "Test Loss:  4.253294467926025\n",
            "Recall : 0.3647619047619048\n",
            "Epoch  148\n",
            "Train Loss:  2.8586034774780273\n",
            "Test Loss:  4.253730773925781\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  149\n",
            "Train Loss:  2.851834535598755\n",
            "Test Loss:  4.254182815551758\n",
            "Recall : 0.3638095238095238\n",
            "Epoch  150\n",
            "Train Loss:  2.8451485633850098\n",
            "Test Loss:  4.25464391708374\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  151\n",
            "Train Loss:  2.838540554046631\n",
            "Test Loss:  4.255122184753418\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  152\n",
            "Train Loss:  2.8320045471191406\n",
            "Test Loss:  4.255621910095215\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  153\n",
            "Train Loss:  2.82554292678833\n",
            "Test Loss:  4.25614070892334\n",
            "Recall : 0.36\n",
            "Epoch  154\n",
            "Train Loss:  2.819152355194092\n",
            "Test Loss:  4.25669002532959\n",
            "Recall : 0.36\n",
            "Epoch  155\n",
            "Train Loss:  2.8128347396850586\n",
            "Test Loss:  4.257266998291016\n",
            "Recall : 0.36\n",
            "Epoch  156\n",
            "Train Loss:  2.806589126586914\n",
            "Test Loss:  4.257879257202148\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  157\n",
            "Train Loss:  2.80041766166687\n",
            "Test Loss:  4.258516311645508\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  158\n",
            "Train Loss:  2.794318675994873\n",
            "Test Loss:  4.259171485900879\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  159\n",
            "Train Loss:  2.7882885932922363\n",
            "Test Loss:  4.2598395347595215\n",
            "Recall : 0.3638095238095238\n",
            "Epoch  160\n",
            "Train Loss:  2.7823269367218018\n",
            "Test Loss:  4.2605180740356445\n",
            "Recall : 0.3638095238095238\n",
            "Epoch  161\n",
            "Train Loss:  2.7764315605163574\n",
            "Test Loss:  4.261203765869141\n",
            "Recall : 0.3638095238095238\n",
            "Epoch  162\n",
            "Train Loss:  2.770606279373169\n",
            "Test Loss:  4.261900901794434\n",
            "Recall : 0.3628571428571429\n",
            "Epoch  163\n",
            "Train Loss:  2.764848470687866\n",
            "Test Loss:  4.2626142501831055\n",
            "Recall : 0.3647619047619048\n",
            "Epoch  164\n",
            "Train Loss:  2.759159564971924\n",
            "Test Loss:  4.263348579406738\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  165\n",
            "Train Loss:  2.753532886505127\n",
            "Test Loss:  4.264096260070801\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  166\n",
            "Train Loss:  2.7479684352874756\n",
            "Test Loss:  4.264851093292236\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  167\n",
            "Train Loss:  2.7424659729003906\n",
            "Test Loss:  4.2656145095825195\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  168\n",
            "Train Loss:  2.7370262145996094\n",
            "Test Loss:  4.266385078430176\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  169\n",
            "Train Loss:  2.731649875640869\n",
            "Test Loss:  4.267152309417725\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  170\n",
            "Train Loss:  2.726332664489746\n",
            "Test Loss:  4.267923355102539\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  171\n",
            "Train Loss:  2.721072196960449\n",
            "Test Loss:  4.2686967849731445\n",
            "Recall : 0.3619047619047619\n",
            "Epoch  172\n",
            "Train Loss:  2.715865135192871\n",
            "Test Loss:  4.269474983215332\n",
            "Recall : 0.36\n",
            "Epoch  173\n",
            "Train Loss:  2.710710048675537\n",
            "Test Loss:  4.27025032043457\n",
            "Recall : 0.36\n",
            "Epoch  174\n",
            "Train Loss:  2.705608367919922\n",
            "Test Loss:  4.271015644073486\n",
            "Recall : 0.36\n",
            "Epoch  175\n",
            "Train Loss:  2.7005581855773926\n",
            "Test Loss:  4.27177619934082\n",
            "Recall : 0.36\n",
            "Epoch  176\n",
            "Train Loss:  2.6955583095550537\n",
            "Test Loss:  4.272529602050781\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  177\n",
            "Train Loss:  2.690608501434326\n",
            "Test Loss:  4.273294448852539\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  178\n",
            "Train Loss:  2.6857094764709473\n",
            "Test Loss:  4.274056434631348\n",
            "Recall : 0.36\n",
            "Epoch  179\n",
            "Train Loss:  2.6808648109436035\n",
            "Test Loss:  4.274813175201416\n",
            "Recall : 0.36\n",
            "Epoch  180\n",
            "Train Loss:  2.6760659217834473\n",
            "Test Loss:  4.27556037902832\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  181\n",
            "Train Loss:  2.6713197231292725\n",
            "Test Loss:  4.276309013366699\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  182\n",
            "Train Loss:  2.6666207313537598\n",
            "Test Loss:  4.277070999145508\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  183\n",
            "Train Loss:  2.6619679927825928\n",
            "Test Loss:  4.277864456176758\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  184\n",
            "Train Loss:  2.657362222671509\n",
            "Test Loss:  4.278679370880127\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  185\n",
            "Train Loss:  2.652801036834717\n",
            "Test Loss:  4.279502868652344\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  186\n",
            "Train Loss:  2.6482839584350586\n",
            "Test Loss:  4.280350685119629\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  187\n",
            "Train Loss:  2.6438119411468506\n",
            "Test Loss:  4.281217575073242\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  188\n",
            "Train Loss:  2.639387607574463\n",
            "Test Loss:  4.282093048095703\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  189\n",
            "Train Loss:  2.6350088119506836\n",
            "Test Loss:  4.28296422958374\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  190\n",
            "Train Loss:  2.630673885345459\n",
            "Test Loss:  4.283839225769043\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  191\n",
            "Train Loss:  2.6263842582702637\n",
            "Test Loss:  4.284717559814453\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  192\n",
            "Train Loss:  2.6221377849578857\n",
            "Test Loss:  4.285602569580078\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  193\n",
            "Train Loss:  2.617933988571167\n",
            "Test Loss:  4.286487579345703\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  194\n",
            "Train Loss:  2.6137757301330566\n",
            "Test Loss:  4.2873735427856445\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  195\n",
            "Train Loss:  2.6096582412719727\n",
            "Test Loss:  4.288258075714111\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  196\n",
            "Train Loss:  2.6055784225463867\n",
            "Test Loss:  4.289153575897217\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  197\n",
            "Train Loss:  2.601539134979248\n",
            "Test Loss:  4.2900543212890625\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  198\n",
            "Train Loss:  2.5975403785705566\n",
            "Test Loss:  4.290966987609863\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  199\n",
            "Train Loss:  2.5935821533203125\n",
            "Test Loss:  4.291891098022461\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  200\n",
            "Train Loss:  2.5896620750427246\n",
            "Test Loss:  4.2928361892700195\n",
            "Recall : 0.35523809523809524\n",
            "\n",
            "0.3272714285714288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pAl72ZWL3WO"
      },
      "source": [
        "Sans pca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b1f55bca394e4a20bf6cad5b8e9e2554",
            "d24f78e8d80f4bf6912638930da0c35f",
            "ff621910fcce4033aa47fabbd1e3166e",
            "df5dda73b6ae421b8313ebc697f0a191",
            "9214690265b54e708a47e3a5c6c2927b",
            "ca51f7d70cd14188bde47ac62089f669",
            "5a7bbc00882344c78f2eb1e7fde6058a",
            "b218a7929e944b0cad2f82c44a480d5f"
          ]
        },
        "id": "UkM9vIEfh2HT",
        "outputId": "83ebf2f6-6a32-495f-b94e-9ff13fe7e0b3"
      },
      "source": [
        "run(path=\"pairs_ebds.npy\",runs=1,epochs=100,k=1,temp=15,type=1,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1f55bca394e4a20bf6cad5b8e9e2554",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.194338798522949\n",
            "Test Loss:  6.0058393478393555\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  2\n",
            "Train Loss:  7.039216995239258\n",
            "Test Loss:  5.875629425048828\n",
            "Recall : 0.16\n",
            "Epoch  3\n",
            "Train Loss:  6.882340431213379\n",
            "Test Loss:  5.750176429748535\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  4\n",
            "Train Loss:  6.727581977844238\n",
            "Test Loss:  5.632506370544434\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  5\n",
            "Train Loss:  6.578578948974609\n",
            "Test Loss:  5.52464485168457\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  6\n",
            "Train Loss:  6.4367265701293945\n",
            "Test Loss:  5.427233695983887\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  7\n",
            "Train Loss:  6.302309989929199\n",
            "Test Loss:  5.339616775512695\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  8\n",
            "Train Loss:  6.174553871154785\n",
            "Test Loss:  5.260492324829102\n",
            "Recall : 0.1980952380952381\n",
            "Epoch  9\n",
            "Train Loss:  6.052165508270264\n",
            "Test Loss:  5.188616752624512\n",
            "Recall : 0.20285714285714285\n",
            "Epoch  10\n",
            "Train Loss:  5.933440208435059\n",
            "Test Loss:  5.123050689697266\n",
            "Recall : 0.20857142857142857\n",
            "Epoch  11\n",
            "Train Loss:  5.817107200622559\n",
            "Test Loss:  5.063051223754883\n",
            "Recall : 0.21619047619047618\n",
            "Epoch  12\n",
            "Train Loss:  5.7021164894104\n",
            "Test Loss:  5.008131504058838\n",
            "Recall : 0.2219047619047619\n",
            "Epoch  13\n",
            "Train Loss:  5.587582111358643\n",
            "Test Loss:  4.957915306091309\n",
            "Recall : 0.22666666666666666\n",
            "Epoch  14\n",
            "Train Loss:  5.473212242126465\n",
            "Test Loss:  4.911874771118164\n",
            "Recall : 0.23142857142857143\n",
            "Epoch  15\n",
            "Train Loss:  5.358857154846191\n",
            "Test Loss:  4.87008810043335\n",
            "Recall : 0.2361904761904762\n",
            "Epoch  16\n",
            "Train Loss:  5.244754791259766\n",
            "Test Loss:  4.832578182220459\n",
            "Recall : 0.2361904761904762\n",
            "Epoch  17\n",
            "Train Loss:  5.1307148933410645\n",
            "Test Loss:  4.79917049407959\n",
            "Recall : 0.24\n",
            "Epoch  18\n",
            "Train Loss:  5.016594886779785\n",
            "Test Loss:  4.768426418304443\n",
            "Recall : 0.24285714285714285\n",
            "Epoch  19\n",
            "Train Loss:  4.902652740478516\n",
            "Test Loss:  4.7409772872924805\n",
            "Recall : 0.24761904761904763\n",
            "Epoch  20\n",
            "Train Loss:  4.788476467132568\n",
            "Test Loss:  4.7168684005737305\n",
            "Recall : 0.25047619047619046\n",
            "Epoch  21\n",
            "Train Loss:  4.673351287841797\n",
            "Test Loss:  4.69558048248291\n",
            "Recall : 0.2523809523809524\n",
            "Epoch  22\n",
            "Train Loss:  4.5568718910217285\n",
            "Test Loss:  4.677426815032959\n",
            "Recall : 0.25523809523809526\n",
            "Epoch  23\n",
            "Train Loss:  4.439028263092041\n",
            "Test Loss:  4.6619157791137695\n",
            "Recall : 0.2523809523809524\n",
            "Epoch  24\n",
            "Train Loss:  4.319350719451904\n",
            "Test Loss:  4.649410247802734\n",
            "Recall : 0.2561904761904762\n",
            "Epoch  25\n",
            "Train Loss:  4.197470664978027\n",
            "Test Loss:  4.639291286468506\n",
            "Recall : 0.26285714285714284\n",
            "Epoch  26\n",
            "Train Loss:  4.073393821716309\n",
            "Test Loss:  4.631545066833496\n",
            "Recall : 0.26095238095238094\n",
            "Epoch  27\n",
            "Train Loss:  3.9464941024780273\n",
            "Test Loss:  4.626989364624023\n",
            "Recall : 0.2561904761904762\n",
            "Epoch  28\n",
            "Train Loss:  3.8171403408050537\n",
            "Test Loss:  4.625088691711426\n",
            "Recall : 0.26\n",
            "Epoch  29\n",
            "Train Loss:  3.684953451156616\n",
            "Test Loss:  4.625707149505615\n",
            "Recall : 0.2619047619047619\n",
            "Epoch  30\n",
            "Train Loss:  3.549701690673828\n",
            "Test Loss:  4.627834320068359\n",
            "Recall : 0.26476190476190475\n",
            "Epoch  31\n",
            "Train Loss:  3.4113128185272217\n",
            "Test Loss:  4.632081508636475\n",
            "Recall : 0.26285714285714284\n",
            "Epoch  32\n",
            "Train Loss:  3.269537925720215\n",
            "Test Loss:  4.638519763946533\n",
            "Recall : 0.26857142857142857\n",
            "Epoch  33\n",
            "Train Loss:  3.1244759559631348\n",
            "Test Loss:  4.647871017456055\n",
            "Recall : 0.2619047619047619\n",
            "Epoch  34\n",
            "Train Loss:  2.976573944091797\n",
            "Test Loss:  4.662164688110352\n",
            "Recall : 0.2619047619047619\n",
            "Epoch  35\n",
            "Train Loss:  2.825526714324951\n",
            "Test Loss:  4.680591583251953\n",
            "Recall : 0.259047619047619\n",
            "Epoch  36\n",
            "Train Loss:  2.6716437339782715\n",
            "Test Loss:  4.702266693115234\n",
            "Recall : 0.2523809523809524\n",
            "Epoch  37\n",
            "Train Loss:  2.5146913528442383\n",
            "Test Loss:  4.725877285003662\n",
            "Recall : 0.24666666666666667\n",
            "Epoch  38\n",
            "Train Loss:  2.354220390319824\n",
            "Test Loss:  4.752504348754883\n",
            "Recall : 0.24285714285714285\n",
            "Epoch  39\n",
            "Train Loss:  2.1903305053710938\n",
            "Test Loss:  4.782479763031006\n",
            "Recall : 0.24095238095238095\n",
            "Epoch  40\n",
            "Train Loss:  2.023703098297119\n",
            "Test Loss:  4.815120697021484\n",
            "Recall : 0.24285714285714285\n",
            "Epoch  41\n",
            "Train Loss:  1.8564366102218628\n",
            "Test Loss:  4.852504253387451\n",
            "Recall : 0.23714285714285716\n",
            "Epoch  42\n",
            "Train Loss:  1.689201831817627\n",
            "Test Loss:  4.893851280212402\n",
            "Recall : 0.2342857142857143\n",
            "Epoch  43\n",
            "Train Loss:  1.523399829864502\n",
            "Test Loss:  4.940130233764648\n",
            "Recall : 0.22857142857142856\n",
            "Epoch  44\n",
            "Train Loss:  1.360959768295288\n",
            "Test Loss:  4.986276626586914\n",
            "Recall : 0.22476190476190477\n",
            "Epoch  45\n",
            "Train Loss:  1.204392433166504\n",
            "Test Loss:  5.0361785888671875\n",
            "Recall : 0.22380952380952382\n",
            "Epoch  46\n",
            "Train Loss:  1.0561308860778809\n",
            "Test Loss:  5.091385841369629\n",
            "Recall : 0.2180952380952381\n",
            "Epoch  47\n",
            "Train Loss:  0.9173249006271362\n",
            "Test Loss:  5.144571304321289\n",
            "Recall : 0.20952380952380953\n",
            "Epoch  48\n",
            "Train Loss:  0.7894293665885925\n",
            "Test Loss:  5.199152946472168\n",
            "Recall : 0.20761904761904762\n",
            "Epoch  49\n",
            "Train Loss:  0.6736531257629395\n",
            "Test Loss:  5.25736141204834\n",
            "Recall : 0.19523809523809524\n",
            "Epoch  50\n",
            "Train Loss:  0.5691813230514526\n",
            "Test Loss:  5.314943313598633\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  51\n",
            "Train Loss:  0.47931185364723206\n",
            "Test Loss:  5.3705267906188965\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  52\n",
            "Train Loss:  0.4069974720478058\n",
            "Test Loss:  5.422996520996094\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  53\n",
            "Train Loss:  0.3467090129852295\n",
            "Test Loss:  5.472482681274414\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  54\n",
            "Train Loss:  0.29575371742248535\n",
            "Test Loss:  5.523125648498535\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  55\n",
            "Train Loss:  0.25259098410606384\n",
            "Test Loss:  5.566779613494873\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  56\n",
            "Train Loss:  0.21798273921012878\n",
            "Test Loss:  5.606547832489014\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  57\n",
            "Train Loss:  0.18984386324882507\n",
            "Test Loss:  5.64130163192749\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  58\n",
            "Train Loss:  0.16778384149074554\n",
            "Test Loss:  5.670861721038818\n",
            "Recall : 0.16\n",
            "Epoch  59\n",
            "Train Loss:  0.14869870245456696\n",
            "Test Loss:  5.706762313842773\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  60\n",
            "Train Loss:  0.13550153374671936\n",
            "Test Loss:  5.738221168518066\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  61\n",
            "Train Loss:  0.12148666381835938\n",
            "Test Loss:  5.769134521484375\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  62\n",
            "Train Loss:  0.11012820899486542\n",
            "Test Loss:  5.803879737854004\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  63\n",
            "Train Loss:  0.10093877464532852\n",
            "Test Loss:  5.839303970336914\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  64\n",
            "Train Loss:  0.09345504641532898\n",
            "Test Loss:  5.872406005859375\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  65\n",
            "Train Loss:  0.08610527217388153\n",
            "Test Loss:  5.90377140045166\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  66\n",
            "Train Loss:  0.08216487616300583\n",
            "Test Loss:  5.930895805358887\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  67\n",
            "Train Loss:  0.07570386677980423\n",
            "Test Loss:  5.957142353057861\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  68\n",
            "Train Loss:  0.07141643762588501\n",
            "Test Loss:  5.980988502502441\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  69\n",
            "Train Loss:  0.06684345006942749\n",
            "Test Loss:  6.013462066650391\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  70\n",
            "Train Loss:  0.0637378916144371\n",
            "Test Loss:  6.0375542640686035\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  71\n",
            "Train Loss:  0.060936830937862396\n",
            "Test Loss:  6.054192543029785\n",
            "Recall : 0.14\n",
            "Epoch  72\n",
            "Train Loss:  0.057887714356184006\n",
            "Test Loss:  6.076326370239258\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  73\n",
            "Train Loss:  0.05514128506183624\n",
            "Test Loss:  6.093137264251709\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  74\n",
            "Train Loss:  0.052962616086006165\n",
            "Test Loss:  6.114764213562012\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  75\n",
            "Train Loss:  0.05097401887178421\n",
            "Test Loss:  6.136157512664795\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  76\n",
            "Train Loss:  0.04921437054872513\n",
            "Test Loss:  6.15675163269043\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  77\n",
            "Train Loss:  0.0475764125585556\n",
            "Test Loss:  6.17411994934082\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  78\n",
            "Train Loss:  0.046067509800195694\n",
            "Test Loss:  6.191739082336426\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  79\n",
            "Train Loss:  0.044714704155921936\n",
            "Test Loss:  6.210030555725098\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  80\n",
            "Train Loss:  0.043520066887140274\n",
            "Test Loss:  6.227856636047363\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  81\n",
            "Train Loss:  0.042422883212566376\n",
            "Test Loss:  6.244729518890381\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  82\n",
            "Train Loss:  0.04141150414943695\n",
            "Test Loss:  6.261429309844971\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  83\n",
            "Train Loss:  0.04047016426920891\n",
            "Test Loss:  6.278299331665039\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  84\n",
            "Train Loss:  0.039614081382751465\n",
            "Test Loss:  6.289811134338379\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  85\n",
            "Train Loss:  0.038812246173620224\n",
            "Test Loss:  6.307002067565918\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  86\n",
            "Train Loss:  0.03807148337364197\n",
            "Test Loss:  6.3241095542907715\n",
            "Recall : 0.12571428571428572\n",
            "Epoch  87\n",
            "Train Loss:  0.03738422691822052\n",
            "Test Loss:  6.339593887329102\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  88\n",
            "Train Loss:  0.036726824939250946\n",
            "Test Loss:  6.354842662811279\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  89\n",
            "Train Loss:  0.03611814230680466\n",
            "Test Loss:  6.370275497436523\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  90\n",
            "Train Loss:  0.03554969280958176\n",
            "Test Loss:  6.3863701820373535\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  91\n",
            "Train Loss:  0.03501521423459053\n",
            "Test Loss:  6.401642799377441\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  92\n",
            "Train Loss:  0.034505486488342285\n",
            "Test Loss:  6.416727066040039\n",
            "Recall : 0.12285714285714286\n",
            "Epoch  93\n",
            "Train Loss:  0.03402981907129288\n",
            "Test Loss:  6.429055213928223\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  94\n",
            "Train Loss:  0.033598095178604126\n",
            "Test Loss:  6.442776679992676\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  95\n",
            "Train Loss:  0.03330057114362717\n",
            "Test Loss:  6.44968843460083\n",
            "Recall : 0.12285714285714286\n",
            "Epoch  96\n",
            "Train Loss:  0.032875001430511475\n",
            "Test Loss:  6.462521553039551\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  97\n",
            "Train Loss:  0.032428059726953506\n",
            "Test Loss:  6.46873140335083\n",
            "Recall : 0.12\n",
            "Epoch  98\n",
            "Train Loss:  0.03205128014087677\n",
            "Test Loss:  6.478488922119141\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  99\n",
            "Train Loss:  0.03662172704935074\n",
            "Test Loss:  6.489716529846191\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  100\n",
            "Train Loss:  0.03697824105620384\n",
            "Test Loss:  6.507979393005371\n",
            "Recall : 0.1180952380952381\n",
            "\n",
            "0.18480952380952378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d633b84d794c47ddaa369c0794242eb4",
            "aef3a722302a4566b712e6c2b75c46c2",
            "038ac82035d947acb29d5c677b692a04",
            "16838130593f41719943a41d5127b873",
            "f112e3d9a1214526b4e23a06ff451e2d",
            "f503c767253847f7b5548a0aa0db56cc",
            "0da10926a68e45cb925f78615a53e5d1",
            "70775fd8c63f4901a456eca94124c459"
          ]
        },
        "id": "jUMJjk66Og3q",
        "outputId": "d29babcf-ebb6-4700-ad8e-3c02b330fb88"
      },
      "source": [
        "run(path=\"pairs_ebds.npy\",runs=1,epochs=700,k=1,temp=15,type=1,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d633b84d794c47ddaa369c0794242eb4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  6.885959625244141\n",
            "Test Loss:  5.815744400024414\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  2\n",
            "Train Loss:  6.806159019470215\n",
            "Test Loss:  5.768312454223633\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  3\n",
            "Train Loss:  6.727612495422363\n",
            "Test Loss:  5.721988201141357\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  4\n",
            "Train Loss:  6.650341033935547\n",
            "Test Loss:  5.676858425140381\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  5\n",
            "Train Loss:  6.574367523193359\n",
            "Test Loss:  5.632936477661133\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  6\n",
            "Train Loss:  6.499733924865723\n",
            "Test Loss:  5.590239524841309\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  7\n",
            "Train Loss:  6.426479339599609\n",
            "Test Loss:  5.548733711242676\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  8\n",
            "Train Loss:  6.354615211486816\n",
            "Test Loss:  5.508426666259766\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  9\n",
            "Train Loss:  6.2841291427612305\n",
            "Test Loss:  5.469315528869629\n",
            "Recall : 0.16\n",
            "Epoch  10\n",
            "Train Loss:  6.215026378631592\n",
            "Test Loss:  5.431362628936768\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  11\n",
            "Train Loss:  6.147305011749268\n",
            "Test Loss:  5.394585609436035\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  12\n",
            "Train Loss:  6.080964088439941\n",
            "Test Loss:  5.358922004699707\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  13\n",
            "Train Loss:  6.015995025634766\n",
            "Test Loss:  5.324395179748535\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  14\n",
            "Train Loss:  5.952376365661621\n",
            "Test Loss:  5.290959358215332\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  15\n",
            "Train Loss:  5.890066146850586\n",
            "Test Loss:  5.2586188316345215\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  16\n",
            "Train Loss:  5.829034328460693\n",
            "Test Loss:  5.227331161499023\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  17\n",
            "Train Loss:  5.769261360168457\n",
            "Test Loss:  5.19706916809082\n",
            "Recall : 0.19428571428571428\n",
            "Epoch  18\n",
            "Train Loss:  5.710705757141113\n",
            "Test Loss:  5.1677937507629395\n",
            "Recall : 0.20095238095238097\n",
            "Epoch  19\n",
            "Train Loss:  5.653347969055176\n",
            "Test Loss:  5.139480113983154\n",
            "Recall : 0.2038095238095238\n",
            "Epoch  20\n",
            "Train Loss:  5.597167015075684\n",
            "Test Loss:  5.112083911895752\n",
            "Recall : 0.20761904761904762\n",
            "Epoch  21\n",
            "Train Loss:  5.542119979858398\n",
            "Test Loss:  5.085606575012207\n",
            "Recall : 0.21333333333333335\n",
            "Epoch  22\n",
            "Train Loss:  5.488170623779297\n",
            "Test Loss:  5.060012340545654\n",
            "Recall : 0.21428571428571427\n",
            "Epoch  23\n",
            "Train Loss:  5.435308456420898\n",
            "Test Loss:  5.035239219665527\n",
            "Recall : 0.2180952380952381\n",
            "Epoch  24\n",
            "Train Loss:  5.383483409881592\n",
            "Test Loss:  5.011247634887695\n",
            "Recall : 0.22095238095238096\n",
            "Epoch  25\n",
            "Train Loss:  5.3326921463012695\n",
            "Test Loss:  4.988016605377197\n",
            "Recall : 0.22380952380952382\n",
            "Epoch  26\n",
            "Train Loss:  5.282904624938965\n",
            "Test Loss:  4.965539932250977\n",
            "Recall : 0.2257142857142857\n",
            "Epoch  27\n",
            "Train Loss:  5.234104633331299\n",
            "Test Loss:  4.943816184997559\n",
            "Recall : 0.22666666666666666\n",
            "Epoch  28\n",
            "Train Loss:  5.186262130737305\n",
            "Test Loss:  4.9228034019470215\n",
            "Recall : 0.22857142857142856\n",
            "Epoch  29\n",
            "Train Loss:  5.139339447021484\n",
            "Test Loss:  4.902482032775879\n",
            "Recall : 0.23333333333333334\n",
            "Epoch  30\n",
            "Train Loss:  5.093320846557617\n",
            "Test Loss:  4.882813453674316\n",
            "Recall : 0.2361904761904762\n",
            "Epoch  31\n",
            "Train Loss:  5.04817008972168\n",
            "Test Loss:  4.863816261291504\n",
            "Recall : 0.24\n",
            "Epoch  32\n",
            "Train Loss:  5.003861427307129\n",
            "Test Loss:  4.8454508781433105\n",
            "Recall : 0.2419047619047619\n",
            "Epoch  33\n",
            "Train Loss:  4.960407257080078\n",
            "Test Loss:  4.827680587768555\n",
            "Recall : 0.24571428571428572\n",
            "Epoch  34\n",
            "Train Loss:  4.917768478393555\n",
            "Test Loss:  4.810480117797852\n",
            "Recall : 0.24952380952380954\n",
            "Epoch  35\n",
            "Train Loss:  4.87592887878418\n",
            "Test Loss:  4.793835639953613\n",
            "Recall : 0.2523809523809524\n",
            "Epoch  36\n",
            "Train Loss:  4.834871292114258\n",
            "Test Loss:  4.777721881866455\n",
            "Recall : 0.2561904761904762\n",
            "Epoch  37\n",
            "Train Loss:  4.794588088989258\n",
            "Test Loss:  4.762142181396484\n",
            "Recall : 0.2571428571428571\n",
            "Epoch  38\n",
            "Train Loss:  4.755071640014648\n",
            "Test Loss:  4.747076988220215\n",
            "Recall : 0.2580952380952381\n",
            "Epoch  39\n",
            "Train Loss:  4.716291427612305\n",
            "Test Loss:  4.732515335083008\n",
            "Recall : 0.2619047619047619\n",
            "Epoch  40\n",
            "Train Loss:  4.67823600769043\n",
            "Test Loss:  4.718439102172852\n",
            "Recall : 0.2638095238095238\n",
            "Epoch  41\n",
            "Train Loss:  4.640893936157227\n",
            "Test Loss:  4.704828262329102\n",
            "Recall : 0.26666666666666666\n",
            "Epoch  42\n",
            "Train Loss:  4.6042561531066895\n",
            "Test Loss:  4.691662788391113\n",
            "Recall : 0.26761904761904765\n",
            "Epoch  43\n",
            "Train Loss:  4.568314552307129\n",
            "Test Loss:  4.67894172668457\n",
            "Recall : 0.26857142857142857\n",
            "Epoch  44\n",
            "Train Loss:  4.5330352783203125\n",
            "Test Loss:  4.6666412353515625\n",
            "Recall : 0.2704761904761905\n",
            "Epoch  45\n",
            "Train Loss:  4.498420715332031\n",
            "Test Loss:  4.654762268066406\n",
            "Recall : 0.2733333333333333\n",
            "Epoch  46\n",
            "Train Loss:  4.4644389152526855\n",
            "Test Loss:  4.643292427062988\n",
            "Recall : 0.2761904761904762\n",
            "Epoch  47\n",
            "Train Loss:  4.4310760498046875\n",
            "Test Loss:  4.6322126388549805\n",
            "Recall : 0.2819047619047619\n",
            "Epoch  48\n",
            "Train Loss:  4.398323059082031\n",
            "Test Loss:  4.621503829956055\n",
            "Recall : 0.2838095238095238\n",
            "Epoch  49\n",
            "Train Loss:  4.366170883178711\n",
            "Test Loss:  4.6111555099487305\n",
            "Recall : 0.2866666666666667\n",
            "Epoch  50\n",
            "Train Loss:  4.334601402282715\n",
            "Test Loss:  4.601180076599121\n",
            "Recall : 0.2885714285714286\n",
            "Epoch  51\n",
            "Train Loss:  4.303609848022461\n",
            "Test Loss:  4.591550827026367\n",
            "Recall : 0.2895238095238095\n",
            "Epoch  52\n",
            "Train Loss:  4.273172378540039\n",
            "Test Loss:  4.5822672843933105\n",
            "Recall : 0.2923809523809524\n",
            "Epoch  53\n",
            "Train Loss:  4.243286609649658\n",
            "Test Loss:  4.573272705078125\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  54\n",
            "Train Loss:  4.2139387130737305\n",
            "Test Loss:  4.564583778381348\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  55\n",
            "Train Loss:  4.185120582580566\n",
            "Test Loss:  4.556212425231934\n",
            "Recall : 0.3\n",
            "Epoch  56\n",
            "Train Loss:  4.156830787658691\n",
            "Test Loss:  4.5481462478637695\n",
            "Recall : 0.3\n",
            "Epoch  57\n",
            "Train Loss:  4.1290435791015625\n",
            "Test Loss:  4.54036808013916\n",
            "Recall : 0.3\n",
            "Epoch  58\n",
            "Train Loss:  4.101747035980225\n",
            "Test Loss:  4.532855987548828\n",
            "Recall : 0.30095238095238097\n",
            "Epoch  59\n",
            "Train Loss:  4.074933052062988\n",
            "Test Loss:  4.525608062744141\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  60\n",
            "Train Loss:  4.048589706420898\n",
            "Test Loss:  4.518611907958984\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  61\n",
            "Train Loss:  4.022700786590576\n",
            "Test Loss:  4.511858940124512\n",
            "Recall : 0.30666666666666664\n",
            "Epoch  62\n",
            "Train Loss:  3.9972620010375977\n",
            "Test Loss:  4.50533390045166\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  63\n",
            "Train Loss:  3.9722681045532227\n",
            "Test Loss:  4.499061107635498\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  64\n",
            "Train Loss:  3.9477059841156006\n",
            "Test Loss:  4.493041038513184\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  65\n",
            "Train Loss:  3.923563003540039\n",
            "Test Loss:  4.487251281738281\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  66\n",
            "Train Loss:  3.8998231887817383\n",
            "Test Loss:  4.481695175170898\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  67\n",
            "Train Loss:  3.8764843940734863\n",
            "Test Loss:  4.476329803466797\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  68\n",
            "Train Loss:  3.8535373210906982\n",
            "Test Loss:  4.471165657043457\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  69\n",
            "Train Loss:  3.830984115600586\n",
            "Test Loss:  4.4662065505981445\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  70\n",
            "Train Loss:  3.8088226318359375\n",
            "Test Loss:  4.461441993713379\n",
            "Recall : 0.3180952380952381\n",
            "Epoch  71\n",
            "Train Loss:  3.7870399951934814\n",
            "Test Loss:  4.456831932067871\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  72\n",
            "Train Loss:  3.765620231628418\n",
            "Test Loss:  4.452376365661621\n",
            "Recall : 0.32285714285714284\n",
            "Epoch  73\n",
            "Train Loss:  3.744560718536377\n",
            "Test Loss:  4.448097229003906\n",
            "Recall : 0.3238095238095238\n",
            "Epoch  74\n",
            "Train Loss:  3.7238636016845703\n",
            "Test Loss:  4.444014549255371\n",
            "Recall : 0.32476190476190475\n",
            "Epoch  75\n",
            "Train Loss:  3.7035233974456787\n",
            "Test Loss:  4.440074920654297\n",
            "Recall : 0.32571428571428573\n",
            "Epoch  76\n",
            "Train Loss:  3.6835241317749023\n",
            "Test Loss:  4.436285495758057\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  77\n",
            "Train Loss:  3.6638646125793457\n",
            "Test Loss:  4.432652473449707\n",
            "Recall : 0.32857142857142857\n",
            "Epoch  78\n",
            "Train Loss:  3.644536256790161\n",
            "Test Loss:  4.429190635681152\n",
            "Recall : 0.32857142857142857\n",
            "Epoch  79\n",
            "Train Loss:  3.625533103942871\n",
            "Test Loss:  4.425890922546387\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  80\n",
            "Train Loss:  3.6068434715270996\n",
            "Test Loss:  4.4227495193481445\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  81\n",
            "Train Loss:  3.588459014892578\n",
            "Test Loss:  4.419750213623047\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  82\n",
            "Train Loss:  3.570387363433838\n",
            "Test Loss:  4.416893005371094\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  83\n",
            "Train Loss:  3.5526108741760254\n",
            "Test Loss:  4.41417121887207\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  84\n",
            "Train Loss:  3.5351247787475586\n",
            "Test Loss:  4.411565780639648\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  85\n",
            "Train Loss:  3.5179262161254883\n",
            "Test Loss:  4.409069061279297\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  86\n",
            "Train Loss:  3.5010108947753906\n",
            "Test Loss:  4.406676292419434\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  87\n",
            "Train Loss:  3.4843711853027344\n",
            "Test Loss:  4.4043779373168945\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  88\n",
            "Train Loss:  3.468000650405884\n",
            "Test Loss:  4.402176856994629\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  89\n",
            "Train Loss:  3.4518959522247314\n",
            "Test Loss:  4.400067329406738\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  90\n",
            "Train Loss:  3.4360475540161133\n",
            "Test Loss:  4.3980607986450195\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  91\n",
            "Train Loss:  3.4204530715942383\n",
            "Test Loss:  4.396145820617676\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  92\n",
            "Train Loss:  3.405109405517578\n",
            "Test Loss:  4.394311904907227\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  93\n",
            "Train Loss:  3.3900094032287598\n",
            "Test Loss:  4.39256477355957\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  94\n",
            "Train Loss:  3.3751580715179443\n",
            "Test Loss:  4.39091682434082\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  95\n",
            "Train Loss:  3.3605456352233887\n",
            "Test Loss:  4.38934850692749\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  96\n",
            "Train Loss:  3.3461732864379883\n",
            "Test Loss:  4.387859344482422\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  97\n",
            "Train Loss:  3.33203387260437\n",
            "Test Loss:  4.386447906494141\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  98\n",
            "Train Loss:  3.318114757537842\n",
            "Test Loss:  4.3851094245910645\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  99\n",
            "Train Loss:  3.304403781890869\n",
            "Test Loss:  4.383829593658447\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  100\n",
            "Train Loss:  3.2909023761749268\n",
            "Test Loss:  4.382607460021973\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  101\n",
            "Train Loss:  3.2776098251342773\n",
            "Test Loss:  4.381448745727539\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  102\n",
            "Train Loss:  3.264523983001709\n",
            "Test Loss:  4.380364418029785\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  103\n",
            "Train Loss:  3.2516415119171143\n",
            "Test Loss:  4.379329681396484\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  104\n",
            "Train Loss:  3.238955497741699\n",
            "Test Loss:  4.37834358215332\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  105\n",
            "Train Loss:  3.226463794708252\n",
            "Test Loss:  4.377407550811768\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  106\n",
            "Train Loss:  3.2141642570495605\n",
            "Test Loss:  4.376523017883301\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  107\n",
            "Train Loss:  3.2020537853240967\n",
            "Test Loss:  4.375693321228027\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  108\n",
            "Train Loss:  3.1901321411132812\n",
            "Test Loss:  4.374930381774902\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  109\n",
            "Train Loss:  3.1783957481384277\n",
            "Test Loss:  4.374228477478027\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  110\n",
            "Train Loss:  3.1668388843536377\n",
            "Test Loss:  4.373594284057617\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  111\n",
            "Train Loss:  3.1554532051086426\n",
            "Test Loss:  4.373007297515869\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  112\n",
            "Train Loss:  3.144232749938965\n",
            "Test Loss:  4.372450351715088\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  113\n",
            "Train Loss:  3.133172035217285\n",
            "Test Loss:  4.371934413909912\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  114\n",
            "Train Loss:  3.1222620010375977\n",
            "Test Loss:  4.3714599609375\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  115\n",
            "Train Loss:  3.111501693725586\n",
            "Test Loss:  4.371020317077637\n",
            "Recall : 0.34\n",
            "Epoch  116\n",
            "Train Loss:  3.1008903980255127\n",
            "Test Loss:  4.37061071395874\n",
            "Recall : 0.34\n",
            "Epoch  117\n",
            "Train Loss:  3.0904362201690674\n",
            "Test Loss:  4.370236396789551\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  118\n",
            "Train Loss:  3.080138683319092\n",
            "Test Loss:  4.369912147521973\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  119\n",
            "Train Loss:  3.0699915885925293\n",
            "Test Loss:  4.369633674621582\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  120\n",
            "Train Loss:  3.0599913597106934\n",
            "Test Loss:  4.369403839111328\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  121\n",
            "Train Loss:  3.0501303672790527\n",
            "Test Loss:  4.369217395782471\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  122\n",
            "Train Loss:  3.040408134460449\n",
            "Test Loss:  4.369077682495117\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  123\n",
            "Train Loss:  3.030817985534668\n",
            "Test Loss:  4.368974685668945\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  124\n",
            "Train Loss:  3.021357536315918\n",
            "Test Loss:  4.368906497955322\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  125\n",
            "Train Loss:  3.0120301246643066\n",
            "Test Loss:  4.368881702423096\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  126\n",
            "Train Loss:  3.002833366394043\n",
            "Test Loss:  4.368906021118164\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  127\n",
            "Train Loss:  2.9937634468078613\n",
            "Test Loss:  4.368978023529053\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  128\n",
            "Train Loss:  2.9848275184631348\n",
            "Test Loss:  4.369090557098389\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  129\n",
            "Train Loss:  2.976015329360962\n",
            "Test Loss:  4.3692474365234375\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  130\n",
            "Train Loss:  2.9673242568969727\n",
            "Test Loss:  4.3694329261779785\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  131\n",
            "Train Loss:  2.9587507247924805\n",
            "Test Loss:  4.369646072387695\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  132\n",
            "Train Loss:  2.950295925140381\n",
            "Test Loss:  4.369881629943848\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  133\n",
            "Train Loss:  2.9419543743133545\n",
            "Test Loss:  4.370138168334961\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  134\n",
            "Train Loss:  2.9337267875671387\n",
            "Test Loss:  4.37041711807251\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  135\n",
            "Train Loss:  2.9256062507629395\n",
            "Test Loss:  4.370706558227539\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  136\n",
            "Train Loss:  2.917588949203491\n",
            "Test Loss:  4.371002197265625\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  137\n",
            "Train Loss:  2.9096779823303223\n",
            "Test Loss:  4.37130069732666\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  138\n",
            "Train Loss:  2.901876449584961\n",
            "Test Loss:  4.371610164642334\n",
            "Recall : 0.34\n",
            "Epoch  139\n",
            "Train Loss:  2.8941783905029297\n",
            "Test Loss:  4.371930122375488\n",
            "Recall : 0.34\n",
            "Epoch  140\n",
            "Train Loss:  2.8865745067596436\n",
            "Test Loss:  4.372257709503174\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  141\n",
            "Train Loss:  2.879066228866577\n",
            "Test Loss:  4.372614860534668\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  142\n",
            "Train Loss:  2.8716506958007812\n",
            "Test Loss:  4.373020172119141\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  143\n",
            "Train Loss:  2.864328622817993\n",
            "Test Loss:  4.37346076965332\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  144\n",
            "Train Loss:  2.857093334197998\n",
            "Test Loss:  4.373929023742676\n",
            "Recall : 0.34\n",
            "Epoch  145\n",
            "Train Loss:  2.8499467372894287\n",
            "Test Loss:  4.374418258666992\n",
            "Recall : 0.34\n",
            "Epoch  146\n",
            "Train Loss:  2.8428878784179688\n",
            "Test Loss:  4.374927997589111\n",
            "Recall : 0.34\n",
            "Epoch  147\n",
            "Train Loss:  2.835916519165039\n",
            "Test Loss:  4.375453948974609\n",
            "Recall : 0.34\n",
            "Epoch  148\n",
            "Train Loss:  2.8290276527404785\n",
            "Test Loss:  4.376000881195068\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  149\n",
            "Train Loss:  2.8222274780273438\n",
            "Test Loss:  4.376579284667969\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  150\n",
            "Train Loss:  2.8155200481414795\n",
            "Test Loss:  4.377170085906982\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  151\n",
            "Train Loss:  2.8088951110839844\n",
            "Test Loss:  4.377774238586426\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  152\n",
            "Train Loss:  2.802351951599121\n",
            "Test Loss:  4.378379821777344\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  153\n",
            "Train Loss:  2.7958879470825195\n",
            "Test Loss:  4.378978729248047\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  154\n",
            "Train Loss:  2.789506435394287\n",
            "Test Loss:  4.379590034484863\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  155\n",
            "Train Loss:  2.783200740814209\n",
            "Test Loss:  4.380214691162109\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  156\n",
            "Train Loss:  2.7769718170166016\n",
            "Test Loss:  4.380850791931152\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  157\n",
            "Train Loss:  2.770817279815674\n",
            "Test Loss:  4.381504058837891\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  158\n",
            "Train Loss:  2.7647409439086914\n",
            "Test Loss:  4.382177352905273\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  159\n",
            "Train Loss:  2.7587406635284424\n",
            "Test Loss:  4.382871627807617\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  160\n",
            "Train Loss:  2.7528185844421387\n",
            "Test Loss:  4.383577823638916\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  161\n",
            "Train Loss:  2.7469637393951416\n",
            "Test Loss:  4.384291648864746\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  162\n",
            "Train Loss:  2.7411751747131348\n",
            "Test Loss:  4.385014533996582\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  163\n",
            "Train Loss:  2.7354555130004883\n",
            "Test Loss:  4.385756492614746\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  164\n",
            "Train Loss:  2.729801893234253\n",
            "Test Loss:  4.386499404907227\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  165\n",
            "Train Loss:  2.724215030670166\n",
            "Test Loss:  4.387238502502441\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  166\n",
            "Train Loss:  2.7186946868896484\n",
            "Test Loss:  4.387979984283447\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  167\n",
            "Train Loss:  2.7132439613342285\n",
            "Test Loss:  4.388724327087402\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  168\n",
            "Train Loss:  2.7078590393066406\n",
            "Test Loss:  4.389482021331787\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  169\n",
            "Train Loss:  2.702538013458252\n",
            "Test Loss:  4.390254974365234\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  170\n",
            "Train Loss:  2.6972763538360596\n",
            "Test Loss:  4.39103364944458\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  171\n",
            "Train Loss:  2.692075252532959\n",
            "Test Loss:  4.3918137550354\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  172\n",
            "Train Loss:  2.6869335174560547\n",
            "Test Loss:  4.392611503601074\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  173\n",
            "Train Loss:  2.681851863861084\n",
            "Test Loss:  4.393423080444336\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  174\n",
            "Train Loss:  2.676827907562256\n",
            "Test Loss:  4.3942437171936035\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  175\n",
            "Train Loss:  2.6718549728393555\n",
            "Test Loss:  4.395071029663086\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  176\n",
            "Train Loss:  2.6669411659240723\n",
            "Test Loss:  4.3959174156188965\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  177\n",
            "Train Loss:  2.662086248397827\n",
            "Test Loss:  4.396763801574707\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  178\n",
            "Train Loss:  2.657284736633301\n",
            "Test Loss:  4.397607803344727\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  179\n",
            "Train Loss:  2.652534246444702\n",
            "Test Loss:  4.398441314697266\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  180\n",
            "Train Loss:  2.647834300994873\n",
            "Test Loss:  4.399270057678223\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  181\n",
            "Train Loss:  2.64318585395813\n",
            "Test Loss:  4.400112152099609\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  182\n",
            "Train Loss:  2.6385867595672607\n",
            "Test Loss:  4.400962829589844\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  183\n",
            "Train Loss:  2.6340386867523193\n",
            "Test Loss:  4.401824951171875\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  184\n",
            "Train Loss:  2.6295371055603027\n",
            "Test Loss:  4.402702808380127\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  185\n",
            "Train Loss:  2.62508487701416\n",
            "Test Loss:  4.403583526611328\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  186\n",
            "Train Loss:  2.6206841468811035\n",
            "Test Loss:  4.40445613861084\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  187\n",
            "Train Loss:  2.616330623626709\n",
            "Test Loss:  4.405326843261719\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  188\n",
            "Train Loss:  2.6120240688323975\n",
            "Test Loss:  4.406193733215332\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  189\n",
            "Train Loss:  2.6077606678009033\n",
            "Test Loss:  4.407062530517578\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  190\n",
            "Train Loss:  2.6035408973693848\n",
            "Test Loss:  4.407922744750977\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  191\n",
            "Train Loss:  2.5993661880493164\n",
            "Test Loss:  4.408791542053223\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  192\n",
            "Train Loss:  2.5952329635620117\n",
            "Test Loss:  4.409675598144531\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  193\n",
            "Train Loss:  2.5911383628845215\n",
            "Test Loss:  4.410588264465332\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  194\n",
            "Train Loss:  2.587082624435425\n",
            "Test Loss:  4.411526679992676\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  195\n",
            "Train Loss:  2.5830678939819336\n",
            "Test Loss:  4.412476062774658\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  196\n",
            "Train Loss:  2.579094886779785\n",
            "Test Loss:  4.413430213928223\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  197\n",
            "Train Loss:  2.5751655101776123\n",
            "Test Loss:  4.414377689361572\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  198\n",
            "Train Loss:  2.571277618408203\n",
            "Test Loss:  4.415319919586182\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  199\n",
            "Train Loss:  2.5674328804016113\n",
            "Test Loss:  4.416256904602051\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  200\n",
            "Train Loss:  2.563631296157837\n",
            "Test Loss:  4.417189598083496\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  201\n",
            "Train Loss:  2.559868812561035\n",
            "Test Loss:  4.418118953704834\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  202\n",
            "Train Loss:  2.5561442375183105\n",
            "Test Loss:  4.419051170349121\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  203\n",
            "Train Loss:  2.552455425262451\n",
            "Test Loss:  4.419967174530029\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  204\n",
            "Train Loss:  2.5488033294677734\n",
            "Test Loss:  4.420873641967773\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  205\n",
            "Train Loss:  2.5451908111572266\n",
            "Test Loss:  4.4217681884765625\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  206\n",
            "Train Loss:  2.5416154861450195\n",
            "Test Loss:  4.422675132751465\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  207\n",
            "Train Loss:  2.5380733013153076\n",
            "Test Loss:  4.423595428466797\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  208\n",
            "Train Loss:  2.534562110900879\n",
            "Test Loss:  4.424541473388672\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  209\n",
            "Train Loss:  2.5310847759246826\n",
            "Test Loss:  4.4255146980285645\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  210\n",
            "Train Loss:  2.5276384353637695\n",
            "Test Loss:  4.426491737365723\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  211\n",
            "Train Loss:  2.5242228507995605\n",
            "Test Loss:  4.427464962005615\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  212\n",
            "Train Loss:  2.520838737487793\n",
            "Test Loss:  4.428443908691406\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  213\n",
            "Train Loss:  2.5174851417541504\n",
            "Test Loss:  4.429416656494141\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  214\n",
            "Train Loss:  2.514164686203003\n",
            "Test Loss:  4.430405616760254\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  215\n",
            "Train Loss:  2.510876178741455\n",
            "Test Loss:  4.431401252746582\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  216\n",
            "Train Loss:  2.5076162815093994\n",
            "Test Loss:  4.432407379150391\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  217\n",
            "Train Loss:  2.5043859481811523\n",
            "Test Loss:  4.433407783508301\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  218\n",
            "Train Loss:  2.5011887550354004\n",
            "Test Loss:  4.4344024658203125\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  219\n",
            "Train Loss:  2.498018980026245\n",
            "Test Loss:  4.43538761138916\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  220\n",
            "Train Loss:  2.494882583618164\n",
            "Test Loss:  4.436373710632324\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  221\n",
            "Train Loss:  2.4917755126953125\n",
            "Test Loss:  4.437371730804443\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  222\n",
            "Train Loss:  2.488692283630371\n",
            "Test Loss:  4.438377380371094\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  223\n",
            "Train Loss:  2.4856393337249756\n",
            "Test Loss:  4.439385890960693\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  224\n",
            "Train Loss:  2.482614040374756\n",
            "Test Loss:  4.440396308898926\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  225\n",
            "Train Loss:  2.479616165161133\n",
            "Test Loss:  4.44140100479126\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  226\n",
            "Train Loss:  2.4766438007354736\n",
            "Test Loss:  4.442401885986328\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  227\n",
            "Train Loss:  2.473698616027832\n",
            "Test Loss:  4.443390846252441\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  228\n",
            "Train Loss:  2.4707813262939453\n",
            "Test Loss:  4.444365978240967\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  229\n",
            "Train Loss:  2.4678902626037598\n",
            "Test Loss:  4.445343017578125\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  230\n",
            "Train Loss:  2.465024471282959\n",
            "Test Loss:  4.4463348388671875\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  231\n",
            "Train Loss:  2.462183713912964\n",
            "Test Loss:  4.44732666015625\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  232\n",
            "Train Loss:  2.459367036819458\n",
            "Test Loss:  4.448300838470459\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  233\n",
            "Train Loss:  2.4565703868865967\n",
            "Test Loss:  4.449284553527832\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  234\n",
            "Train Loss:  2.453787326812744\n",
            "Test Loss:  4.450283050537109\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  235\n",
            "Train Loss:  2.4510245323181152\n",
            "Test Loss:  4.451295852661133\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  236\n",
            "Train Loss:  2.4482898712158203\n",
            "Test Loss:  4.452311038970947\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  237\n",
            "Train Loss:  2.445582866668701\n",
            "Test Loss:  4.453320026397705\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  238\n",
            "Train Loss:  2.4428999423980713\n",
            "Test Loss:  4.454320430755615\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  239\n",
            "Train Loss:  2.440243721008301\n",
            "Test Loss:  4.455331802368164\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  240\n",
            "Train Loss:  2.437610626220703\n",
            "Test Loss:  4.4563493728637695\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  241\n",
            "Train Loss:  2.4349989891052246\n",
            "Test Loss:  4.457354545593262\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  242\n",
            "Train Loss:  2.4324069023132324\n",
            "Test Loss:  4.45835018157959\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  243\n",
            "Train Loss:  2.4298324584960938\n",
            "Test Loss:  4.459346771240234\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  244\n",
            "Train Loss:  2.4272828102111816\n",
            "Test Loss:  4.4603590965271\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  245\n",
            "Train Loss:  2.424750804901123\n",
            "Test Loss:  4.4613800048828125\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  246\n",
            "Train Loss:  2.4222378730773926\n",
            "Test Loss:  4.462372303009033\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  247\n",
            "Train Loss:  2.419748306274414\n",
            "Test Loss:  4.463335037231445\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  248\n",
            "Train Loss:  2.4172821044921875\n",
            "Test Loss:  4.464301109313965\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  249\n",
            "Train Loss:  2.414842367172241\n",
            "Test Loss:  4.465261936187744\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  250\n",
            "Train Loss:  2.4124159812927246\n",
            "Test Loss:  4.466230392456055\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  251\n",
            "Train Loss:  2.4100117683410645\n",
            "Test Loss:  4.467190742492676\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  252\n",
            "Train Loss:  2.4076294898986816\n",
            "Test Loss:  4.468168258666992\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  253\n",
            "Train Loss:  2.4052679538726807\n",
            "Test Loss:  4.469178676605225\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  254\n",
            "Train Loss:  2.402923107147217\n",
            "Test Loss:  4.470207214355469\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  255\n",
            "Train Loss:  2.400595188140869\n",
            "Test Loss:  4.471244812011719\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  256\n",
            "Train Loss:  2.3982880115509033\n",
            "Test Loss:  4.472280502319336\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  257\n",
            "Train Loss:  2.395998477935791\n",
            "Test Loss:  4.473293304443359\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  258\n",
            "Train Loss:  2.393726348876953\n",
            "Test Loss:  4.47432279586792\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  259\n",
            "Train Loss:  2.3914713859558105\n",
            "Test Loss:  4.475351333618164\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  260\n",
            "Train Loss:  2.3892295360565186\n",
            "Test Loss:  4.476389408111572\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  261\n",
            "Train Loss:  2.3870038986206055\n",
            "Test Loss:  4.47743558883667\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  262\n",
            "Train Loss:  2.384798526763916\n",
            "Test Loss:  4.478480815887451\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  263\n",
            "Train Loss:  2.3826065063476562\n",
            "Test Loss:  4.479516506195068\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  264\n",
            "Train Loss:  2.380427837371826\n",
            "Test Loss:  4.480550765991211\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  265\n",
            "Train Loss:  2.3782668113708496\n",
            "Test Loss:  4.481579780578613\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  266\n",
            "Train Loss:  2.376121997833252\n",
            "Test Loss:  4.48260498046875\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  267\n",
            "Train Loss:  2.373987913131714\n",
            "Test Loss:  4.483635902404785\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  268\n",
            "Train Loss:  2.371870517730713\n",
            "Test Loss:  4.484677791595459\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  269\n",
            "Train Loss:  2.3697690963745117\n",
            "Test Loss:  4.485708713531494\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  270\n",
            "Train Loss:  2.367684841156006\n",
            "Test Loss:  4.486741065979004\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  271\n",
            "Train Loss:  2.3656132221221924\n",
            "Test Loss:  4.4877777099609375\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  272\n",
            "Train Loss:  2.3635571002960205\n",
            "Test Loss:  4.488809585571289\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  273\n",
            "Train Loss:  2.361520528793335\n",
            "Test Loss:  4.489835262298584\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  274\n",
            "Train Loss:  2.359499454498291\n",
            "Test Loss:  4.490856170654297\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  275\n",
            "Train Loss:  2.3574934005737305\n",
            "Test Loss:  4.491872787475586\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  276\n",
            "Train Loss:  2.355499505996704\n",
            "Test Loss:  4.492890357971191\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  277\n",
            "Train Loss:  2.3535232543945312\n",
            "Test Loss:  4.493927955627441\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  278\n",
            "Train Loss:  2.3515586853027344\n",
            "Test Loss:  4.494970321655273\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  279\n",
            "Train Loss:  2.3496055603027344\n",
            "Test Loss:  4.495973587036133\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  280\n",
            "Train Loss:  2.3476667404174805\n",
            "Test Loss:  4.496922492980957\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  281\n",
            "Train Loss:  2.34574031829834\n",
            "Test Loss:  4.497860908508301\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  282\n",
            "Train Loss:  2.3438291549682617\n",
            "Test Loss:  4.498836517333984\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  283\n",
            "Train Loss:  2.3419322967529297\n",
            "Test Loss:  4.499810695648193\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  284\n",
            "Train Loss:  2.3400461673736572\n",
            "Test Loss:  4.500772476196289\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  285\n",
            "Train Loss:  2.33817720413208\n",
            "Test Loss:  4.501745223999023\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  286\n",
            "Train Loss:  2.33632230758667\n",
            "Test Loss:  4.502723217010498\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  287\n",
            "Train Loss:  2.334479331970215\n",
            "Test Loss:  4.503686904907227\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  288\n",
            "Train Loss:  2.3326494693756104\n",
            "Test Loss:  4.504639625549316\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  289\n",
            "Train Loss:  2.3308329582214355\n",
            "Test Loss:  4.505589485168457\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  290\n",
            "Train Loss:  2.3290252685546875\n",
            "Test Loss:  4.506526947021484\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  291\n",
            "Train Loss:  2.3272271156311035\n",
            "Test Loss:  4.507495880126953\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  292\n",
            "Train Loss:  2.3254411220550537\n",
            "Test Loss:  4.508504867553711\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  293\n",
            "Train Loss:  2.3236632347106934\n",
            "Test Loss:  4.5095062255859375\n",
            "Recall : 0.3361904761904762\n",
            "Epoch  294\n",
            "Train Loss:  2.3218984603881836\n",
            "Test Loss:  4.510510444641113\n",
            "Recall : 0.3352380952380952\n",
            "Epoch  295\n",
            "Train Loss:  2.3201422691345215\n",
            "Test Loss:  4.511456489562988\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  296\n",
            "Train Loss:  2.3183960914611816\n",
            "Test Loss:  4.51239538192749\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  297\n",
            "Train Loss:  2.3166589736938477\n",
            "Test Loss:  4.513384819030762\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  298\n",
            "Train Loss:  2.314929485321045\n",
            "Test Loss:  4.514362335205078\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  299\n",
            "Train Loss:  2.3132033348083496\n",
            "Test Loss:  4.515316009521484\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  300\n",
            "Train Loss:  2.3115198612213135\n",
            "Test Loss:  4.516264915466309\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  301\n",
            "Train Loss:  2.3098270893096924\n",
            "Test Loss:  4.517213344573975\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  302\n",
            "Train Loss:  2.3081488609313965\n",
            "Test Loss:  4.5181379318237305\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  303\n",
            "Train Loss:  2.3064932823181152\n",
            "Test Loss:  4.51906681060791\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  304\n",
            "Train Loss:  2.3048477172851562\n",
            "Test Loss:  4.520082473754883\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  305\n",
            "Train Loss:  2.3032033443450928\n",
            "Test Loss:  4.521076202392578\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  306\n",
            "Train Loss:  2.301584243774414\n",
            "Test Loss:  4.521998882293701\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  307\n",
            "Train Loss:  2.299968719482422\n",
            "Test Loss:  4.5229597091674805\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  308\n",
            "Train Loss:  2.298353672027588\n",
            "Test Loss:  4.523957252502441\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  309\n",
            "Train Loss:  2.2967724800109863\n",
            "Test Loss:  4.524979591369629\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  310\n",
            "Train Loss:  2.295173168182373\n",
            "Test Loss:  4.525986671447754\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  311\n",
            "Train Loss:  2.293625831604004\n",
            "Test Loss:  4.5270094871521\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  312\n",
            "Train Loss:  2.29205322265625\n",
            "Test Loss:  4.528013229370117\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  313\n",
            "Train Loss:  2.2905054092407227\n",
            "Test Loss:  4.529029846191406\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  314\n",
            "Train Loss:  2.2889697551727295\n",
            "Test Loss:  4.530080795288086\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  315\n",
            "Train Loss:  2.287431240081787\n",
            "Test Loss:  4.531033992767334\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  316\n",
            "Train Loss:  2.2859232425689697\n",
            "Test Loss:  4.532009601593018\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  317\n",
            "Train Loss:  2.284389019012451\n",
            "Test Loss:  4.5329790115356445\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  318\n",
            "Train Loss:  2.2828917503356934\n",
            "Test Loss:  4.533943176269531\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  319\n",
            "Train Loss:  2.2814111709594727\n",
            "Test Loss:  4.535015106201172\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  320\n",
            "Train Loss:  2.2799339294433594\n",
            "Test Loss:  4.535895347595215\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  321\n",
            "Train Loss:  2.2784624099731445\n",
            "Test Loss:  4.536904811859131\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  322\n",
            "Train Loss:  2.276975154876709\n",
            "Test Loss:  4.537851333618164\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  323\n",
            "Train Loss:  2.2755625247955322\n",
            "Test Loss:  4.538802146911621\n",
            "Recall : 0.3333333333333333\n",
            "Epoch  324\n",
            "Train Loss:  2.2741341590881348\n",
            "Test Loss:  4.53987979888916\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  325\n",
            "Train Loss:  2.2727279663085938\n",
            "Test Loss:  4.540901184082031\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  326\n",
            "Train Loss:  2.271275043487549\n",
            "Test Loss:  4.542036056518555\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  327\n",
            "Train Loss:  2.269853115081787\n",
            "Test Loss:  4.54299259185791\n",
            "Recall : 0.3323809523809524\n",
            "Epoch  328\n",
            "Train Loss:  2.268430471420288\n",
            "Test Loss:  4.543947219848633\n",
            "Recall : 0.3314285714285714\n",
            "Epoch  329\n",
            "Train Loss:  2.267068386077881\n",
            "Test Loss:  4.544954299926758\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  330\n",
            "Train Loss:  2.2656235694885254\n",
            "Test Loss:  4.546063423156738\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  331\n",
            "Train Loss:  2.2642602920532227\n",
            "Test Loss:  4.546962738037109\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  332\n",
            "Train Loss:  2.2629618644714355\n",
            "Test Loss:  4.548032283782959\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  333\n",
            "Train Loss:  2.2614755630493164\n",
            "Test Loss:  4.549098491668701\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  334\n",
            "Train Loss:  2.260125160217285\n",
            "Test Loss:  4.550057411193848\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  335\n",
            "Train Loss:  2.2587900161743164\n",
            "Test Loss:  4.551135063171387\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  336\n",
            "Train Loss:  2.257483959197998\n",
            "Test Loss:  4.552038192749023\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  337\n",
            "Train Loss:  2.256065607070923\n",
            "Test Loss:  4.552978515625\n",
            "Recall : 0.32857142857142857\n",
            "Epoch  338\n",
            "Train Loss:  2.2547621726989746\n",
            "Test Loss:  4.5540595054626465\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  339\n",
            "Train Loss:  2.2533645629882812\n",
            "Test Loss:  4.555147647857666\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  340\n",
            "Train Loss:  2.2520198822021484\n",
            "Test Loss:  4.556077003479004\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  341\n",
            "Train Loss:  2.2507662773132324\n",
            "Test Loss:  4.556963920593262\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  342\n",
            "Train Loss:  2.2493836879730225\n",
            "Test Loss:  4.557894229888916\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  343\n",
            "Train Loss:  2.248081922531128\n",
            "Test Loss:  4.558990478515625\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  344\n",
            "Train Loss:  2.2467525005340576\n",
            "Test Loss:  4.560115814208984\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  345\n",
            "Train Loss:  2.2454569339752197\n",
            "Test Loss:  4.56120491027832\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  346\n",
            "Train Loss:  2.2442550659179688\n",
            "Test Loss:  4.562074184417725\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  347\n",
            "Train Loss:  2.2431108951568604\n",
            "Test Loss:  4.562981605529785\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  348\n",
            "Train Loss:  2.241830825805664\n",
            "Test Loss:  4.563913345336914\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  349\n",
            "Train Loss:  2.2405407428741455\n",
            "Test Loss:  4.564853668212891\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  350\n",
            "Train Loss:  2.239225387573242\n",
            "Test Loss:  4.565925121307373\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  351\n",
            "Train Loss:  2.237934112548828\n",
            "Test Loss:  4.567031383514404\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  352\n",
            "Train Loss:  2.2367122173309326\n",
            "Test Loss:  4.567972183227539\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  353\n",
            "Train Loss:  2.23543119430542\n",
            "Test Loss:  4.568925857543945\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  354\n",
            "Train Loss:  2.2342143058776855\n",
            "Test Loss:  4.569864273071289\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  355\n",
            "Train Loss:  2.2329392433166504\n",
            "Test Loss:  4.570748805999756\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  356\n",
            "Train Loss:  2.231687545776367\n",
            "Test Loss:  4.571772575378418\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  357\n",
            "Train Loss:  2.230456829071045\n",
            "Test Loss:  4.572806358337402\n",
            "Recall : 0.32666666666666666\n",
            "Epoch  358\n",
            "Train Loss:  2.229250431060791\n",
            "Test Loss:  4.573722839355469\n",
            "Recall : 0.32571428571428573\n",
            "Epoch  359\n",
            "Train Loss:  2.228076934814453\n",
            "Test Loss:  4.574741363525391\n",
            "Recall : 0.32571428571428573\n",
            "Epoch  360\n",
            "Train Loss:  2.226870536804199\n",
            "Test Loss:  4.575754165649414\n",
            "Recall : 0.32571428571428573\n",
            "Epoch  361\n",
            "Train Loss:  2.225673198699951\n",
            "Test Loss:  4.576750755310059\n",
            "Recall : 0.32476190476190475\n",
            "Epoch  362\n",
            "Train Loss:  2.2245163917541504\n",
            "Test Loss:  4.577722549438477\n",
            "Recall : 0.3238095238095238\n",
            "Epoch  363\n",
            "Train Loss:  2.2233386039733887\n",
            "Test Loss:  4.578768730163574\n",
            "Recall : 0.3238095238095238\n",
            "Epoch  364\n",
            "Train Loss:  2.222136974334717\n",
            "Test Loss:  4.579730987548828\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  365\n",
            "Train Loss:  2.220993995666504\n",
            "Test Loss:  4.580616474151611\n",
            "Recall : 0.3238095238095238\n",
            "Epoch  366\n",
            "Train Loss:  2.2198691368103027\n",
            "Test Loss:  4.581547260284424\n",
            "Recall : 0.32285714285714284\n",
            "Epoch  367\n",
            "Train Loss:  2.218737840652466\n",
            "Test Loss:  4.582390308380127\n",
            "Recall : 0.32285714285714284\n",
            "Epoch  368\n",
            "Train Loss:  2.2175545692443848\n",
            "Test Loss:  4.5832929611206055\n",
            "Recall : 0.32285714285714284\n",
            "Epoch  369\n",
            "Train Loss:  2.216461420059204\n",
            "Test Loss:  4.584377288818359\n",
            "Recall : 0.32285714285714284\n",
            "Epoch  370\n",
            "Train Loss:  2.2152464389801025\n",
            "Test Loss:  4.585399627685547\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  371\n",
            "Train Loss:  2.2142066955566406\n",
            "Test Loss:  4.586292266845703\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  372\n",
            "Train Loss:  2.213097095489502\n",
            "Test Loss:  4.587038516998291\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  373\n",
            "Train Loss:  2.2119626998901367\n",
            "Test Loss:  4.5878682136535645\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  374\n",
            "Train Loss:  2.2108969688415527\n",
            "Test Loss:  4.588890075683594\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  375\n",
            "Train Loss:  2.209843635559082\n",
            "Test Loss:  4.5898942947387695\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  376\n",
            "Train Loss:  2.208649158477783\n",
            "Test Loss:  4.590850830078125\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  377\n",
            "Train Loss:  2.2076406478881836\n",
            "Test Loss:  4.591928958892822\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  378\n",
            "Train Loss:  2.206584930419922\n",
            "Test Loss:  4.592823028564453\n",
            "Recall : 0.32\n",
            "Epoch  379\n",
            "Train Loss:  2.205519199371338\n",
            "Test Loss:  4.593527793884277\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  380\n",
            "Train Loss:  2.204440116882324\n",
            "Test Loss:  4.594370365142822\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  381\n",
            "Train Loss:  2.203354835510254\n",
            "Test Loss:  4.595210075378418\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  382\n",
            "Train Loss:  2.202317714691162\n",
            "Test Loss:  4.5962138175964355\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  383\n",
            "Train Loss:  2.2012622356414795\n",
            "Test Loss:  4.597296714782715\n",
            "Recall : 0.32\n",
            "Epoch  384\n",
            "Train Loss:  2.200240135192871\n",
            "Test Loss:  4.598266124725342\n",
            "Recall : 0.32\n",
            "Epoch  385\n",
            "Train Loss:  2.1991782188415527\n",
            "Test Loss:  4.599149703979492\n",
            "Recall : 0.32\n",
            "Epoch  386\n",
            "Train Loss:  2.198157787322998\n",
            "Test Loss:  4.599963188171387\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  387\n",
            "Train Loss:  2.1970810890197754\n",
            "Test Loss:  4.60084867477417\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  388\n",
            "Train Loss:  2.196086883544922\n",
            "Test Loss:  4.601814270019531\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  389\n",
            "Train Loss:  2.1950793266296387\n",
            "Test Loss:  4.6028337478637695\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  390\n",
            "Train Loss:  2.1940765380859375\n",
            "Test Loss:  4.6037983894348145\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  391\n",
            "Train Loss:  2.193037509918213\n",
            "Test Loss:  4.604597568511963\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  392\n",
            "Train Loss:  2.1920528411865234\n",
            "Test Loss:  4.605546951293945\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  393\n",
            "Train Loss:  2.191038131713867\n",
            "Test Loss:  4.606390953063965\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  394\n",
            "Train Loss:  2.1900672912597656\n",
            "Test Loss:  4.607093811035156\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  395\n",
            "Train Loss:  2.1891188621520996\n",
            "Test Loss:  4.607961177825928\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  396\n",
            "Train Loss:  2.1880502700805664\n",
            "Test Loss:  4.608938217163086\n",
            "Recall : 0.32285714285714284\n",
            "Epoch  397\n",
            "Train Loss:  2.187070369720459\n",
            "Test Loss:  4.6099042892456055\n",
            "Recall : 0.32285714285714284\n",
            "Epoch  398\n",
            "Train Loss:  2.186147689819336\n",
            "Test Loss:  4.610837936401367\n",
            "Recall : 0.3238095238095238\n",
            "Epoch  399\n",
            "Train Loss:  2.185288429260254\n",
            "Test Loss:  4.611522197723389\n",
            "Recall : 0.3238095238095238\n",
            "Epoch  400\n",
            "Train Loss:  2.184220314025879\n",
            "Test Loss:  4.6123528480529785\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  401\n",
            "Train Loss:  2.1832404136657715\n",
            "Test Loss:  4.613259315490723\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  402\n",
            "Train Loss:  2.1821510791778564\n",
            "Test Loss:  4.614121913909912\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  403\n",
            "Train Loss:  2.181354284286499\n",
            "Test Loss:  4.615007400512695\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  404\n",
            "Train Loss:  2.1804065704345703\n",
            "Test Loss:  4.6157331466674805\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  405\n",
            "Train Loss:  2.1794276237487793\n",
            "Test Loss:  4.616655349731445\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  406\n",
            "Train Loss:  2.178473949432373\n",
            "Test Loss:  4.617657661437988\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  407\n",
            "Train Loss:  2.1774685382843018\n",
            "Test Loss:  4.618584632873535\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  408\n",
            "Train Loss:  2.1764822006225586\n",
            "Test Loss:  4.619550704956055\n",
            "Recall : 0.32095238095238093\n",
            "Epoch  409\n",
            "Train Loss:  2.175612449645996\n",
            "Test Loss:  4.6203789710998535\n",
            "Recall : 0.32\n",
            "Epoch  410\n",
            "Train Loss:  2.174740791320801\n",
            "Test Loss:  4.621014595031738\n",
            "Recall : 0.319047619047619\n",
            "Epoch  411\n",
            "Train Loss:  2.173760175704956\n",
            "Test Loss:  4.62172269821167\n",
            "Recall : 0.319047619047619\n",
            "Epoch  412\n",
            "Train Loss:  2.1729273796081543\n",
            "Test Loss:  4.622539520263672\n",
            "Recall : 0.319047619047619\n",
            "Epoch  413\n",
            "Train Loss:  2.1719422340393066\n",
            "Test Loss:  4.623424530029297\n",
            "Recall : 0.319047619047619\n",
            "Epoch  414\n",
            "Train Loss:  2.170992136001587\n",
            "Test Loss:  4.624512195587158\n",
            "Recall : 0.319047619047619\n",
            "Epoch  415\n",
            "Train Loss:  2.1700305938720703\n",
            "Test Loss:  4.625444412231445\n",
            "Recall : 0.319047619047619\n",
            "Epoch  416\n",
            "Train Loss:  2.169203281402588\n",
            "Test Loss:  4.626087188720703\n",
            "Recall : 0.3180952380952381\n",
            "Epoch  417\n",
            "Train Loss:  2.168339252471924\n",
            "Test Loss:  4.626813888549805\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  418\n",
            "Train Loss:  2.1673150062561035\n",
            "Test Loss:  4.627445220947266\n",
            "Recall : 0.3180952380952381\n",
            "Epoch  419\n",
            "Train Loss:  2.1664648056030273\n",
            "Test Loss:  4.628068447113037\n",
            "Recall : 0.3180952380952381\n",
            "Epoch  420\n",
            "Train Loss:  2.1654775142669678\n",
            "Test Loss:  4.628955364227295\n",
            "Recall : 0.3180952380952381\n",
            "Epoch  421\n",
            "Train Loss:  2.164581298828125\n",
            "Test Loss:  4.629900932312012\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  422\n",
            "Train Loss:  2.1636948585510254\n",
            "Test Loss:  4.630764961242676\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  423\n",
            "Train Loss:  2.162789821624756\n",
            "Test Loss:  4.631587028503418\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  424\n",
            "Train Loss:  2.161905527114868\n",
            "Test Loss:  4.632306098937988\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  425\n",
            "Train Loss:  2.161045551300049\n",
            "Test Loss:  4.6329569816589355\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  426\n",
            "Train Loss:  2.1602821350097656\n",
            "Test Loss:  4.633683204650879\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  427\n",
            "Train Loss:  2.1593806743621826\n",
            "Test Loss:  4.63444709777832\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  428\n",
            "Train Loss:  2.158508777618408\n",
            "Test Loss:  4.63521671295166\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  429\n",
            "Train Loss:  2.1576921939849854\n",
            "Test Loss:  4.635961532592773\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  430\n",
            "Train Loss:  2.156733512878418\n",
            "Test Loss:  4.636841773986816\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  431\n",
            "Train Loss:  2.156008720397949\n",
            "Test Loss:  4.637467861175537\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  432\n",
            "Train Loss:  2.1552422046661377\n",
            "Test Loss:  4.638236999511719\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  433\n",
            "Train Loss:  2.1543641090393066\n",
            "Test Loss:  4.639062881469727\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  434\n",
            "Train Loss:  2.153573513031006\n",
            "Test Loss:  4.639787673950195\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  435\n",
            "Train Loss:  2.152719020843506\n",
            "Test Loss:  4.640610218048096\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  436\n",
            "Train Loss:  2.1518735885620117\n",
            "Test Loss:  4.641551494598389\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  437\n",
            "Train Loss:  2.1510493755340576\n",
            "Test Loss:  4.642366409301758\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  438\n",
            "Train Loss:  2.150237560272217\n",
            "Test Loss:  4.643138885498047\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  439\n",
            "Train Loss:  2.149475574493408\n",
            "Test Loss:  4.64395809173584\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  440\n",
            "Train Loss:  2.148683547973633\n",
            "Test Loss:  4.644577503204346\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  441\n",
            "Train Loss:  2.1478514671325684\n",
            "Test Loss:  4.645401477813721\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  442\n",
            "Train Loss:  2.1470799446105957\n",
            "Test Loss:  4.646316051483154\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  443\n",
            "Train Loss:  2.146261692047119\n",
            "Test Loss:  4.6472063064575195\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  444\n",
            "Train Loss:  2.145508050918579\n",
            "Test Loss:  4.6480913162231445\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  445\n",
            "Train Loss:  2.144777774810791\n",
            "Test Loss:  4.648760795593262\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  446\n",
            "Train Loss:  2.143988609313965\n",
            "Test Loss:  4.6495208740234375\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  447\n",
            "Train Loss:  2.1432981491088867\n",
            "Test Loss:  4.650252819061279\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  448\n",
            "Train Loss:  2.1425747871398926\n",
            "Test Loss:  4.6510233879089355\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  449\n",
            "Train Loss:  2.141745090484619\n",
            "Test Loss:  4.651950836181641\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  450\n",
            "Train Loss:  2.1409177780151367\n",
            "Test Loss:  4.652959823608398\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  451\n",
            "Train Loss:  2.140131950378418\n",
            "Test Loss:  4.653820037841797\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  452\n",
            "Train Loss:  2.1394572257995605\n",
            "Test Loss:  4.654541969299316\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  453\n",
            "Train Loss:  2.138847827911377\n",
            "Test Loss:  4.655179023742676\n",
            "Recall : 0.3142857142857143\n",
            "Epoch  454\n",
            "Train Loss:  2.1380887031555176\n",
            "Test Loss:  4.655979156494141\n",
            "Recall : 0.3142857142857143\n",
            "Epoch  455\n",
            "Train Loss:  2.137260913848877\n",
            "Test Loss:  4.656960487365723\n",
            "Recall : 0.3142857142857143\n",
            "Epoch  456\n",
            "Train Loss:  2.136399269104004\n",
            "Test Loss:  4.657689094543457\n",
            "Recall : 0.31333333333333335\n",
            "Epoch  457\n",
            "Train Loss:  2.135699510574341\n",
            "Test Loss:  4.658443927764893\n",
            "Recall : 0.31333333333333335\n",
            "Epoch  458\n",
            "Train Loss:  2.1349778175354004\n",
            "Test Loss:  4.6591596603393555\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  459\n",
            "Train Loss:  2.134246826171875\n",
            "Test Loss:  4.65983772277832\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  460\n",
            "Train Loss:  2.133650302886963\n",
            "Test Loss:  4.6605377197265625\n",
            "Recall : 0.31333333333333335\n",
            "Epoch  461\n",
            "Train Loss:  2.1326987743377686\n",
            "Test Loss:  4.661481857299805\n",
            "Recall : 0.31333333333333335\n",
            "Epoch  462\n",
            "Train Loss:  2.1320323944091797\n",
            "Test Loss:  4.662400245666504\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  463\n",
            "Train Loss:  2.1312994956970215\n",
            "Test Loss:  4.663102149963379\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  464\n",
            "Train Loss:  2.130535125732422\n",
            "Test Loss:  4.663945198059082\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  465\n",
            "Train Loss:  2.129873752593994\n",
            "Test Loss:  4.66484260559082\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  466\n",
            "Train Loss:  2.1291191577911377\n",
            "Test Loss:  4.665596008300781\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  467\n",
            "Train Loss:  2.128464460372925\n",
            "Test Loss:  4.666216850280762\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  468\n",
            "Train Loss:  2.1276745796203613\n",
            "Test Loss:  4.6669416427612305\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  469\n",
            "Train Loss:  2.1268959045410156\n",
            "Test Loss:  4.667902946472168\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  470\n",
            "Train Loss:  2.12624454498291\n",
            "Test Loss:  4.668806076049805\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  471\n",
            "Train Loss:  2.1255431175231934\n",
            "Test Loss:  4.669623374938965\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  472\n",
            "Train Loss:  2.124863386154175\n",
            "Test Loss:  4.67033052444458\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  473\n",
            "Train Loss:  2.1242527961730957\n",
            "Test Loss:  4.671104907989502\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  474\n",
            "Train Loss:  2.123469352722168\n",
            "Test Loss:  4.671904563903809\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  475\n",
            "Train Loss:  2.122812271118164\n",
            "Test Loss:  4.6725969314575195\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  476\n",
            "Train Loss:  2.1222124099731445\n",
            "Test Loss:  4.6734466552734375\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  477\n",
            "Train Loss:  2.121610641479492\n",
            "Test Loss:  4.674116611480713\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  478\n",
            "Train Loss:  2.120893716812134\n",
            "Test Loss:  4.674814224243164\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  479\n",
            "Train Loss:  2.1202592849731445\n",
            "Test Loss:  4.675503253936768\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  480\n",
            "Train Loss:  2.119640350341797\n",
            "Test Loss:  4.676156997680664\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  481\n",
            "Train Loss:  2.1191766262054443\n",
            "Test Loss:  4.677121639251709\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  482\n",
            "Train Loss:  2.1184184551239014\n",
            "Test Loss:  4.677994728088379\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  483\n",
            "Train Loss:  2.1176300048828125\n",
            "Test Loss:  4.67877721786499\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  484\n",
            "Train Loss:  2.1169281005859375\n",
            "Test Loss:  4.679584980010986\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  485\n",
            "Train Loss:  2.1163861751556396\n",
            "Test Loss:  4.6802778244018555\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  486\n",
            "Train Loss:  2.115844249725342\n",
            "Test Loss:  4.680930137634277\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  487\n",
            "Train Loss:  2.115121364593506\n",
            "Test Loss:  4.681702136993408\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  488\n",
            "Train Loss:  2.114509105682373\n",
            "Test Loss:  4.682507514953613\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  489\n",
            "Train Loss:  2.1138086318969727\n",
            "Test Loss:  4.683122634887695\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  490\n",
            "Train Loss:  2.113196849822998\n",
            "Test Loss:  4.6840057373046875\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  491\n",
            "Train Loss:  2.112457275390625\n",
            "Test Loss:  4.684871673583984\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  492\n",
            "Train Loss:  2.111889123916626\n",
            "Test Loss:  4.685511112213135\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  493\n",
            "Train Loss:  2.1111865043640137\n",
            "Test Loss:  4.686043739318848\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  494\n",
            "Train Loss:  2.1104986667633057\n",
            "Test Loss:  4.686463356018066\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  495\n",
            "Train Loss:  2.109905958175659\n",
            "Test Loss:  4.687042236328125\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  496\n",
            "Train Loss:  2.1091971397399902\n",
            "Test Loss:  4.6879191398620605\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  497\n",
            "Train Loss:  2.1084794998168945\n",
            "Test Loss:  4.6888508796691895\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  498\n",
            "Train Loss:  2.1078379154205322\n",
            "Test Loss:  4.6895904541015625\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  499\n",
            "Train Loss:  2.107203960418701\n",
            "Test Loss:  4.690239906311035\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  500\n",
            "Train Loss:  2.1066854000091553\n",
            "Test Loss:  4.69074821472168\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  501\n",
            "Train Loss:  2.1059393882751465\n",
            "Test Loss:  4.691352844238281\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  502\n",
            "Train Loss:  2.105417251586914\n",
            "Test Loss:  4.692055702209473\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  503\n",
            "Train Loss:  2.1047167778015137\n",
            "Test Loss:  4.692811965942383\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  504\n",
            "Train Loss:  2.1041104793548584\n",
            "Test Loss:  4.693634033203125\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  505\n",
            "Train Loss:  2.1035122871398926\n",
            "Test Loss:  4.694316387176514\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  506\n",
            "Train Loss:  2.1029787063598633\n",
            "Test Loss:  4.694884300231934\n",
            "Recall : 0.31142857142857144\n",
            "Epoch  507\n",
            "Train Loss:  2.1024460792541504\n",
            "Test Loss:  4.695558547973633\n",
            "Recall : 0.31142857142857144\n",
            "Epoch  508\n",
            "Train Loss:  2.1020212173461914\n",
            "Test Loss:  4.696065902709961\n",
            "Recall : 0.31047619047619046\n",
            "Epoch  509\n",
            "Train Loss:  2.1013102531433105\n",
            "Test Loss:  4.696701526641846\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  510\n",
            "Train Loss:  2.1007778644561768\n",
            "Test Loss:  4.697423934936523\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  511\n",
            "Train Loss:  2.10016131401062\n",
            "Test Loss:  4.698182106018066\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  512\n",
            "Train Loss:  2.099578857421875\n",
            "Test Loss:  4.698967456817627\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  513\n",
            "Train Loss:  2.099116086959839\n",
            "Test Loss:  4.699709892272949\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  514\n",
            "Train Loss:  2.0985653400421143\n",
            "Test Loss:  4.7002692222595215\n",
            "Recall : 0.30952380952380953\n",
            "Epoch  515\n",
            "Train Loss:  2.0979373455047607\n",
            "Test Loss:  4.700942039489746\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  516\n",
            "Train Loss:  2.097321033477783\n",
            "Test Loss:  4.701651573181152\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  517\n",
            "Train Loss:  2.0967257022857666\n",
            "Test Loss:  4.7024736404418945\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  518\n",
            "Train Loss:  2.0961220264434814\n",
            "Test Loss:  4.703248977661133\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  519\n",
            "Train Loss:  2.0955288410186768\n",
            "Test Loss:  4.703765869140625\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  520\n",
            "Train Loss:  2.09489107131958\n",
            "Test Loss:  4.704357147216797\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  521\n",
            "Train Loss:  2.0943660736083984\n",
            "Test Loss:  4.705084800720215\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  522\n",
            "Train Loss:  2.0937278270721436\n",
            "Test Loss:  4.705866813659668\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  523\n",
            "Train Loss:  2.093224048614502\n",
            "Test Loss:  4.70662260055542\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  524\n",
            "Train Loss:  2.092550277709961\n",
            "Test Loss:  4.707425117492676\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  525\n",
            "Train Loss:  2.092052936553955\n",
            "Test Loss:  4.708067893981934\n",
            "Recall : 0.30666666666666664\n",
            "Epoch  526\n",
            "Train Loss:  2.091507911682129\n",
            "Test Loss:  4.7087554931640625\n",
            "Recall : 0.30666666666666664\n",
            "Epoch  527\n",
            "Train Loss:  2.0909361839294434\n",
            "Test Loss:  4.709298610687256\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  528\n",
            "Train Loss:  2.0903444290161133\n",
            "Test Loss:  4.709925651550293\n",
            "Recall : 0.30666666666666664\n",
            "Epoch  529\n",
            "Train Loss:  2.089816093444824\n",
            "Test Loss:  4.710641860961914\n",
            "Recall : 0.30666666666666664\n",
            "Epoch  530\n",
            "Train Loss:  2.0892248153686523\n",
            "Test Loss:  4.71140193939209\n",
            "Recall : 0.3057142857142857\n",
            "Epoch  531\n",
            "Train Loss:  2.0887866020202637\n",
            "Test Loss:  4.71201753616333\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  532\n",
            "Train Loss:  2.0882725715637207\n",
            "Test Loss:  4.712610244750977\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  533\n",
            "Train Loss:  2.087754249572754\n",
            "Test Loss:  4.713276386260986\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  534\n",
            "Train Loss:  2.0872902870178223\n",
            "Test Loss:  4.713822364807129\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  535\n",
            "Train Loss:  2.0868465900421143\n",
            "Test Loss:  4.714397430419922\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  536\n",
            "Train Loss:  2.0862202644348145\n",
            "Test Loss:  4.715058326721191\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  537\n",
            "Train Loss:  2.0856947898864746\n",
            "Test Loss:  4.7158613204956055\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  538\n",
            "Train Loss:  2.085146903991699\n",
            "Test Loss:  4.7163848876953125\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  539\n",
            "Train Loss:  2.0845534801483154\n",
            "Test Loss:  4.716967582702637\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  540\n",
            "Train Loss:  2.084028959274292\n",
            "Test Loss:  4.717820167541504\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  541\n",
            "Train Loss:  2.083444595336914\n",
            "Test Loss:  4.718350410461426\n",
            "Recall : 0.30095238095238097\n",
            "Epoch  542\n",
            "Train Loss:  2.08294677734375\n",
            "Test Loss:  4.7188897132873535\n",
            "Recall : 0.30095238095238097\n",
            "Epoch  543\n",
            "Train Loss:  2.0823464393615723\n",
            "Test Loss:  4.719636917114258\n",
            "Recall : 0.30095238095238097\n",
            "Epoch  544\n",
            "Train Loss:  2.0819220542907715\n",
            "Test Loss:  4.720168113708496\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  545\n",
            "Train Loss:  2.081385850906372\n",
            "Test Loss:  4.720871925354004\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  546\n",
            "Train Loss:  2.080873489379883\n",
            "Test Loss:  4.721465110778809\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  547\n",
            "Train Loss:  2.080300807952881\n",
            "Test Loss:  4.722028732299805\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  548\n",
            "Train Loss:  2.079888343811035\n",
            "Test Loss:  4.7226457595825195\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  549\n",
            "Train Loss:  2.0794057846069336\n",
            "Test Loss:  4.723204612731934\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  550\n",
            "Train Loss:  2.078967571258545\n",
            "Test Loss:  4.723650932312012\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  551\n",
            "Train Loss:  2.078460931777954\n",
            "Test Loss:  4.724244594573975\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  552\n",
            "Train Loss:  2.0779190063476562\n",
            "Test Loss:  4.725015640258789\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  553\n",
            "Train Loss:  2.0773985385894775\n",
            "Test Loss:  4.725848197937012\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  554\n",
            "Train Loss:  2.076991319656372\n",
            "Test Loss:  4.726382255554199\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  555\n",
            "Train Loss:  2.0765273571014404\n",
            "Test Loss:  4.726861953735352\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  556\n",
            "Train Loss:  2.076111316680908\n",
            "Test Loss:  4.727393627166748\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  557\n",
            "Train Loss:  2.075641632080078\n",
            "Test Loss:  4.727951526641846\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  558\n",
            "Train Loss:  2.075190782546997\n",
            "Test Loss:  4.728481769561768\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  559\n",
            "Train Loss:  2.074550151824951\n",
            "Test Loss:  4.7290754318237305\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  560\n",
            "Train Loss:  2.0741078853607178\n",
            "Test Loss:  4.72980260848999\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  561\n",
            "Train Loss:  2.0735785961151123\n",
            "Test Loss:  4.730682849884033\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  562\n",
            "Train Loss:  2.0731565952301025\n",
            "Test Loss:  4.731184482574463\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  563\n",
            "Train Loss:  2.072659969329834\n",
            "Test Loss:  4.731493949890137\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  564\n",
            "Train Loss:  2.0721633434295654\n",
            "Test Loss:  4.732216835021973\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  565\n",
            "Train Loss:  2.07163667678833\n",
            "Test Loss:  4.732978820800781\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  566\n",
            "Train Loss:  2.0711357593536377\n",
            "Test Loss:  4.733678817749023\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  567\n",
            "Train Loss:  2.070725202560425\n",
            "Test Loss:  4.734279632568359\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  568\n",
            "Train Loss:  2.0702061653137207\n",
            "Test Loss:  4.734921455383301\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  569\n",
            "Train Loss:  2.069840431213379\n",
            "Test Loss:  4.735416889190674\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  570\n",
            "Train Loss:  2.069337844848633\n",
            "Test Loss:  4.735871315002441\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  571\n",
            "Train Loss:  2.0688326358795166\n",
            "Test Loss:  4.736527919769287\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  572\n",
            "Train Loss:  2.0682945251464844\n",
            "Test Loss:  4.737293243408203\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  573\n",
            "Train Loss:  2.0679047107696533\n",
            "Test Loss:  4.737818717956543\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  574\n",
            "Train Loss:  2.067502021789551\n",
            "Test Loss:  4.738315582275391\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  575\n",
            "Train Loss:  2.0670166015625\n",
            "Test Loss:  4.7388811111450195\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  576\n",
            "Train Loss:  2.066500663757324\n",
            "Test Loss:  4.739475250244141\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  577\n",
            "Train Loss:  2.0660324096679688\n",
            "Test Loss:  4.739956855773926\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  578\n",
            "Train Loss:  2.0655808448791504\n",
            "Test Loss:  4.740464210510254\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  579\n",
            "Train Loss:  2.0651259422302246\n",
            "Test Loss:  4.741118431091309\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  580\n",
            "Train Loss:  2.064729928970337\n",
            "Test Loss:  4.74155855178833\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  581\n",
            "Train Loss:  2.0644075870513916\n",
            "Test Loss:  4.742217063903809\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  582\n",
            "Train Loss:  2.0638198852539062\n",
            "Test Loss:  4.7426652908325195\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  583\n",
            "Train Loss:  2.063349723815918\n",
            "Test Loss:  4.7433271408081055\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  584\n",
            "Train Loss:  2.0630502700805664\n",
            "Test Loss:  4.743869304656982\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  585\n",
            "Train Loss:  2.0625710487365723\n",
            "Test Loss:  4.744475364685059\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  586\n",
            "Train Loss:  2.0621418952941895\n",
            "Test Loss:  4.745155334472656\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  587\n",
            "Train Loss:  2.0616650581359863\n",
            "Test Loss:  4.745737075805664\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  588\n",
            "Train Loss:  2.0612151622772217\n",
            "Test Loss:  4.746295928955078\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  589\n",
            "Train Loss:  2.0607175827026367\n",
            "Test Loss:  4.746903419494629\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  590\n",
            "Train Loss:  2.0602688789367676\n",
            "Test Loss:  4.747570037841797\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  591\n",
            "Train Loss:  2.0598866939544678\n",
            "Test Loss:  4.748003959655762\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  592\n",
            "Train Loss:  2.059622287750244\n",
            "Test Loss:  4.748502731323242\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  593\n",
            "Train Loss:  2.0591139793395996\n",
            "Test Loss:  4.749074935913086\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  594\n",
            "Train Loss:  2.0587146282196045\n",
            "Test Loss:  4.749780654907227\n",
            "Recall : 0.3047619047619048\n",
            "Epoch  595\n",
            "Train Loss:  2.0584464073181152\n",
            "Test Loss:  4.750505447387695\n",
            "Recall : 0.3038095238095238\n",
            "Epoch  596\n",
            "Train Loss:  2.0578393936157227\n",
            "Test Loss:  4.751101016998291\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  597\n",
            "Train Loss:  2.057413101196289\n",
            "Test Loss:  4.751617431640625\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  598\n",
            "Train Loss:  2.0570666790008545\n",
            "Test Loss:  4.752186298370361\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  599\n",
            "Train Loss:  2.056584596633911\n",
            "Test Loss:  4.75269889831543\n",
            "Recall : 0.3028571428571429\n",
            "Epoch  600\n",
            "Train Loss:  2.056151866912842\n",
            "Test Loss:  4.753243446350098\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  601\n",
            "Train Loss:  2.0557451248168945\n",
            "Test Loss:  4.753639221191406\n",
            "Recall : 0.30095238095238097\n",
            "Epoch  602\n",
            "Train Loss:  2.055253267288208\n",
            "Test Loss:  4.754283428192139\n",
            "Recall : 0.3\n",
            "Epoch  603\n",
            "Train Loss:  2.054826498031616\n",
            "Test Loss:  4.754912376403809\n",
            "Recall : 0.3\n",
            "Epoch  604\n",
            "Train Loss:  2.0544347763061523\n",
            "Test Loss:  4.755465984344482\n",
            "Recall : 0.3\n",
            "Epoch  605\n",
            "Train Loss:  2.0540976524353027\n",
            "Test Loss:  4.755987167358398\n",
            "Recall : 0.3\n",
            "Epoch  606\n",
            "Train Loss:  2.053657293319702\n",
            "Test Loss:  4.756374359130859\n",
            "Recall : 0.3\n",
            "Epoch  607\n",
            "Train Loss:  2.053166389465332\n",
            "Test Loss:  4.757007122039795\n",
            "Recall : 0.3\n",
            "Epoch  608\n",
            "Train Loss:  2.0527424812316895\n",
            "Test Loss:  4.757565021514893\n",
            "Recall : 0.3\n",
            "Epoch  609\n",
            "Train Loss:  2.0523533821105957\n",
            "Test Loss:  4.75807523727417\n",
            "Recall : 0.3\n",
            "Epoch  610\n",
            "Train Loss:  2.051976203918457\n",
            "Test Loss:  4.758674621582031\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  611\n",
            "Train Loss:  2.051522731781006\n",
            "Test Loss:  4.759110927581787\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  612\n",
            "Train Loss:  2.051053524017334\n",
            "Test Loss:  4.7596235275268555\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  613\n",
            "Train Loss:  2.050701856613159\n",
            "Test Loss:  4.760106086730957\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  614\n",
            "Train Loss:  2.050302028656006\n",
            "Test Loss:  4.760677337646484\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  615\n",
            "Train Loss:  2.049877643585205\n",
            "Test Loss:  4.761450290679932\n",
            "Recall : 0.3\n",
            "Epoch  616\n",
            "Train Loss:  2.0494437217712402\n",
            "Test Loss:  4.761819362640381\n",
            "Recall : 0.3\n",
            "Epoch  617\n",
            "Train Loss:  2.0491034984588623\n",
            "Test Loss:  4.762274742126465\n",
            "Recall : 0.3\n",
            "Epoch  618\n",
            "Train Loss:  2.048619270324707\n",
            "Test Loss:  4.762979507446289\n",
            "Recall : 0.3\n",
            "Epoch  619\n",
            "Train Loss:  2.0482587814331055\n",
            "Test Loss:  4.763422012329102\n",
            "Recall : 0.3\n",
            "Epoch  620\n",
            "Train Loss:  2.047867774963379\n",
            "Test Loss:  4.763812065124512\n",
            "Recall : 0.3\n",
            "Epoch  621\n",
            "Train Loss:  2.04746150970459\n",
            "Test Loss:  4.764470100402832\n",
            "Recall : 0.3\n",
            "Epoch  622\n",
            "Train Loss:  2.046976089477539\n",
            "Test Loss:  4.765138626098633\n",
            "Recall : 0.3\n",
            "Epoch  623\n",
            "Train Loss:  2.0465264320373535\n",
            "Test Loss:  4.765676498413086\n",
            "Recall : 0.3\n",
            "Epoch  624\n",
            "Train Loss:  2.0462701320648193\n",
            "Test Loss:  4.76622200012207\n",
            "Recall : 0.3\n",
            "Epoch  625\n",
            "Train Loss:  2.046201705932617\n",
            "Test Loss:  4.7662811279296875\n",
            "Recall : 0.3\n",
            "Epoch  626\n",
            "Train Loss:  2.0455822944641113\n",
            "Test Loss:  4.766641139984131\n",
            "Recall : 0.30095238095238097\n",
            "Epoch  627\n",
            "Train Loss:  2.045294761657715\n",
            "Test Loss:  4.767471790313721\n",
            "Recall : 0.30095238095238097\n",
            "Epoch  628\n",
            "Train Loss:  2.044731616973877\n",
            "Test Loss:  4.768080234527588\n",
            "Recall : 0.3\n",
            "Epoch  629\n",
            "Train Loss:  2.0443100929260254\n",
            "Test Loss:  4.768566608428955\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  630\n",
            "Train Loss:  2.04400897026062\n",
            "Test Loss:  4.769158363342285\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  631\n",
            "Train Loss:  2.0436582565307617\n",
            "Test Loss:  4.769589424133301\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  632\n",
            "Train Loss:  2.0431580543518066\n",
            "Test Loss:  4.770078182220459\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  633\n",
            "Train Loss:  2.0427794456481934\n",
            "Test Loss:  4.770708084106445\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  634\n",
            "Train Loss:  2.04233980178833\n",
            "Test Loss:  4.771430015563965\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  635\n",
            "Train Loss:  2.0419631004333496\n",
            "Test Loss:  4.772040843963623\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  636\n",
            "Train Loss:  2.0415053367614746\n",
            "Test Loss:  4.77268123626709\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  637\n",
            "Train Loss:  2.0412795543670654\n",
            "Test Loss:  4.773198127746582\n",
            "Recall : 0.2980952380952381\n",
            "Epoch  638\n",
            "Train Loss:  2.040908098220825\n",
            "Test Loss:  4.773566246032715\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  639\n",
            "Train Loss:  2.040541172027588\n",
            "Test Loss:  4.774092197418213\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  640\n",
            "Train Loss:  2.040130615234375\n",
            "Test Loss:  4.774585723876953\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  641\n",
            "Train Loss:  2.039736270904541\n",
            "Test Loss:  4.775123596191406\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  642\n",
            "Train Loss:  2.0393381118774414\n",
            "Test Loss:  4.775840759277344\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  643\n",
            "Train Loss:  2.039017677307129\n",
            "Test Loss:  4.776270389556885\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  644\n",
            "Train Loss:  2.0386438369750977\n",
            "Test Loss:  4.776708602905273\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  645\n",
            "Train Loss:  2.038254737854004\n",
            "Test Loss:  4.777200698852539\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  646\n",
            "Train Loss:  2.037870407104492\n",
            "Test Loss:  4.777728080749512\n",
            "Recall : 0.29619047619047617\n",
            "Epoch  647\n",
            "Train Loss:  2.037531852722168\n",
            "Test Loss:  4.7782392501831055\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  648\n",
            "Train Loss:  2.0370941162109375\n",
            "Test Loss:  4.77879524230957\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  649\n",
            "Train Loss:  2.036825180053711\n",
            "Test Loss:  4.779341697692871\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  650\n",
            "Train Loss:  2.0365586280822754\n",
            "Test Loss:  4.779688835144043\n",
            "Recall : 0.29714285714285715\n",
            "Epoch  651\n",
            "Train Loss:  2.036417007446289\n",
            "Test Loss:  4.780200481414795\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  652\n",
            "Train Loss:  2.036121368408203\n",
            "Test Loss:  4.780751705169678\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  653\n",
            "Train Loss:  2.0357508659362793\n",
            "Test Loss:  4.781299591064453\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  654\n",
            "Train Loss:  2.035451889038086\n",
            "Test Loss:  4.781682014465332\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  655\n",
            "Train Loss:  2.0352351665496826\n",
            "Test Loss:  4.781929016113281\n",
            "Recall : 0.29619047619047617\n",
            "Epoch  656\n",
            "Train Loss:  2.0348706245422363\n",
            "Test Loss:  4.782284259796143\n",
            "Recall : 0.29619047619047617\n",
            "Epoch  657\n",
            "Train Loss:  2.0344579219818115\n",
            "Test Loss:  4.782737731933594\n",
            "Recall : 0.29619047619047617\n",
            "Epoch  658\n",
            "Train Loss:  2.034057140350342\n",
            "Test Loss:  4.783455848693848\n",
            "Recall : 0.29619047619047617\n",
            "Epoch  659\n",
            "Train Loss:  2.0337305068969727\n",
            "Test Loss:  4.7839813232421875\n",
            "Recall : 0.29619047619047617\n",
            "Epoch  660\n",
            "Train Loss:  2.0334086418151855\n",
            "Test Loss:  4.784472465515137\n",
            "Recall : 0.29619047619047617\n",
            "Epoch  661\n",
            "Train Loss:  2.033038854598999\n",
            "Test Loss:  4.785024166107178\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  662\n",
            "Train Loss:  2.0327231884002686\n",
            "Test Loss:  4.785233497619629\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  663\n",
            "Train Loss:  2.0323143005371094\n",
            "Test Loss:  4.785513877868652\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  664\n",
            "Train Loss:  2.032022714614868\n",
            "Test Loss:  4.786033630371094\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  665\n",
            "Train Loss:  2.0316102504730225\n",
            "Test Loss:  4.7864274978637695\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  666\n",
            "Train Loss:  2.0311648845672607\n",
            "Test Loss:  4.787064552307129\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  667\n",
            "Train Loss:  2.0308797359466553\n",
            "Test Loss:  4.787507057189941\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  668\n",
            "Train Loss:  2.030562400817871\n",
            "Test Loss:  4.787924766540527\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  669\n",
            "Train Loss:  2.030259609222412\n",
            "Test Loss:  4.788365364074707\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  670\n",
            "Train Loss:  2.030158519744873\n",
            "Test Loss:  4.788780689239502\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  671\n",
            "Train Loss:  2.0300393104553223\n",
            "Test Loss:  4.789050102233887\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  672\n",
            "Train Loss:  2.02994966506958\n",
            "Test Loss:  4.789516448974609\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  673\n",
            "Train Loss:  2.029590129852295\n",
            "Test Loss:  4.790044784545898\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  674\n",
            "Train Loss:  2.0291519165039062\n",
            "Test Loss:  4.790559768676758\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  675\n",
            "Train Loss:  2.028883457183838\n",
            "Test Loss:  4.791280746459961\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  676\n",
            "Train Loss:  2.028547763824463\n",
            "Test Loss:  4.791694641113281\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  677\n",
            "Train Loss:  2.0282769203186035\n",
            "Test Loss:  4.791987419128418\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  678\n",
            "Train Loss:  2.0277833938598633\n",
            "Test Loss:  4.79231071472168\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  679\n",
            "Train Loss:  2.0274665355682373\n",
            "Test Loss:  4.792703151702881\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  680\n",
            "Train Loss:  2.0270373821258545\n",
            "Test Loss:  4.79310417175293\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  681\n",
            "Train Loss:  2.0266504287719727\n",
            "Test Loss:  4.79364538192749\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  682\n",
            "Train Loss:  2.026343822479248\n",
            "Test Loss:  4.794311046600342\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  683\n",
            "Train Loss:  2.02590274810791\n",
            "Test Loss:  4.794598579406738\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  684\n",
            "Train Loss:  2.0255799293518066\n",
            "Test Loss:  4.795156002044678\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  685\n",
            "Train Loss:  2.0252530574798584\n",
            "Test Loss:  4.795405387878418\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  686\n",
            "Train Loss:  2.0250792503356934\n",
            "Test Loss:  4.795915603637695\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  687\n",
            "Train Loss:  2.0247888565063477\n",
            "Test Loss:  4.796278953552246\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  688\n",
            "Train Loss:  2.0243711471557617\n",
            "Test Loss:  4.796626091003418\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  689\n",
            "Train Loss:  2.0240116119384766\n",
            "Test Loss:  4.797307968139648\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  690\n",
            "Train Loss:  2.023715019226074\n",
            "Test Loss:  4.797828197479248\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  691\n",
            "Train Loss:  2.023341417312622\n",
            "Test Loss:  4.7980499267578125\n",
            "Recall : 0.2914285714285714\n",
            "Epoch  692\n",
            "Train Loss:  2.022923469543457\n",
            "Test Loss:  4.798349857330322\n",
            "Recall : 0.2923809523809524\n",
            "Epoch  693\n",
            "Train Loss:  2.0226199626922607\n",
            "Test Loss:  4.799068450927734\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  694\n",
            "Train Loss:  2.0222935676574707\n",
            "Test Loss:  4.799487113952637\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  695\n",
            "Train Loss:  2.0221142768859863\n",
            "Test Loss:  4.799691200256348\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  696\n",
            "Train Loss:  2.021780490875244\n",
            "Test Loss:  4.8003153800964355\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  697\n",
            "Train Loss:  2.021393299102783\n",
            "Test Loss:  4.800932884216309\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  698\n",
            "Train Loss:  2.021087408065796\n",
            "Test Loss:  4.801329612731934\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  699\n",
            "Train Loss:  2.0207841396331787\n",
            "Test Loss:  4.801921844482422\n",
            "Recall : 0.29428571428571426\n",
            "Epoch  700\n",
            "Train Loss:  2.020482301712036\n",
            "Test Loss:  4.802480697631836\n",
            "Recall : 0.29428571428571426\n",
            "\n",
            "0.3122802721088428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "97b41246367b4c0da708b6fabf4a50a8",
            "9b058d8d90234813b2a9f5192fa4b762",
            "310310cd37d440d29cbcf4209070e5eb",
            "83bb22a903054cf2a3aad044a2c354a9",
            "b0106063654f4ea18082ef93c4b653d1",
            "e422bf8a7f024c22b5d9e4921ce2e91e",
            "95cccd4d9dbb4a80acd7cc680d986f46",
            "4e8149154b024b27941e57ec3f1dd1b1"
          ]
        },
        "id": "hlYZao3SOzed",
        "outputId": "8891a8ee-e19b-47cc-b81f-e9d96f707c79"
      },
      "source": [
        "run(path=\"pairs_ebds.npy\",runs=1,epochs=700,k=1,temp=15,type=2,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97b41246367b4c0da708b6fabf4a50a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  6.87333869934082\n",
            "Test Loss:  5.691632270812988\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  2\n",
            "Train Loss:  6.793310165405273\n",
            "Test Loss:  5.648541450500488\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  3\n",
            "Train Loss:  6.717205047607422\n",
            "Test Loss:  5.606600761413574\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  4\n",
            "Train Loss:  6.642841339111328\n",
            "Test Loss:  5.565454006195068\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  5\n",
            "Train Loss:  6.569545745849609\n",
            "Test Loss:  5.52495813369751\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  6\n",
            "Train Loss:  6.497056007385254\n",
            "Test Loss:  5.485079288482666\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  7\n",
            "Train Loss:  6.425285816192627\n",
            "Test Loss:  5.445823669433594\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  8\n",
            "Train Loss:  6.354207992553711\n",
            "Test Loss:  5.407211780548096\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  9\n",
            "Train Loss:  6.283816337585449\n",
            "Test Loss:  5.369265556335449\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  10\n",
            "Train Loss:  6.214180946350098\n",
            "Test Loss:  5.332015514373779\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  11\n",
            "Train Loss:  6.1453657150268555\n",
            "Test Loss:  5.295454978942871\n",
            "Recall : 0.19523809523809524\n",
            "Epoch  12\n",
            "Train Loss:  6.077451705932617\n",
            "Test Loss:  5.2596588134765625\n",
            "Recall : 0.1980952380952381\n",
            "Epoch  13\n",
            "Train Loss:  6.010499954223633\n",
            "Test Loss:  5.224643707275391\n",
            "Recall : 0.20095238095238097\n",
            "Epoch  14\n",
            "Train Loss:  5.9445695877075195\n",
            "Test Loss:  5.190382480621338\n",
            "Recall : 0.2057142857142857\n",
            "Epoch  15\n",
            "Train Loss:  5.879703998565674\n",
            "Test Loss:  5.156920909881592\n",
            "Recall : 0.20857142857142857\n",
            "Epoch  16\n",
            "Train Loss:  5.815961837768555\n",
            "Test Loss:  5.12429666519165\n",
            "Recall : 0.21142857142857144\n",
            "Epoch  17\n",
            "Train Loss:  5.753425598144531\n",
            "Test Loss:  5.092521667480469\n",
            "Recall : 0.21333333333333335\n",
            "Epoch  18\n",
            "Train Loss:  5.692157745361328\n",
            "Test Loss:  5.061574935913086\n",
            "Recall : 0.21714285714285714\n",
            "Epoch  19\n",
            "Train Loss:  5.6321916580200195\n",
            "Test Loss:  5.031487464904785\n",
            "Recall : 0.22285714285714286\n",
            "Epoch  20\n",
            "Train Loss:  5.573556423187256\n",
            "Test Loss:  5.002301216125488\n",
            "Recall : 0.22666666666666666\n",
            "Epoch  21\n",
            "Train Loss:  5.516268730163574\n",
            "Test Loss:  4.974002361297607\n",
            "Recall : 0.22857142857142856\n",
            "Epoch  22\n",
            "Train Loss:  5.46035099029541\n",
            "Test Loss:  4.94658088684082\n",
            "Recall : 0.23047619047619047\n",
            "Epoch  23\n",
            "Train Loss:  5.4058613777160645\n",
            "Test Loss:  4.920044898986816\n",
            "Recall : 0.23333333333333334\n",
            "Epoch  24\n",
            "Train Loss:  5.35279655456543\n",
            "Test Loss:  4.894405364990234\n",
            "Recall : 0.2361904761904762\n",
            "Epoch  25\n",
            "Train Loss:  5.301170349121094\n",
            "Test Loss:  4.869599342346191\n",
            "Recall : 0.23714285714285716\n",
            "Epoch  26\n",
            "Train Loss:  5.2510175704956055\n",
            "Test Loss:  4.845627784729004\n",
            "Recall : 0.24285714285714285\n",
            "Epoch  27\n",
            "Train Loss:  5.202322006225586\n",
            "Test Loss:  4.8225250244140625\n",
            "Recall : 0.24666666666666667\n",
            "Epoch  28\n",
            "Train Loss:  5.155076026916504\n",
            "Test Loss:  4.800312042236328\n",
            "Recall : 0.24857142857142858\n",
            "Epoch  29\n",
            "Train Loss:  5.109281539916992\n",
            "Test Loss:  4.778923034667969\n",
            "Recall : 0.2523809523809524\n",
            "Epoch  30\n",
            "Train Loss:  5.064919948577881\n",
            "Test Loss:  4.758385181427002\n",
            "Recall : 0.25523809523809526\n",
            "Epoch  31\n",
            "Train Loss:  5.021960258483887\n",
            "Test Loss:  4.738657474517822\n",
            "Recall : 0.2580952380952381\n",
            "Epoch  32\n",
            "Train Loss:  4.980387210845947\n",
            "Test Loss:  4.719707489013672\n",
            "Recall : 0.259047619047619\n",
            "Epoch  33\n",
            "Train Loss:  4.940183639526367\n",
            "Test Loss:  4.70150089263916\n",
            "Recall : 0.26666666666666666\n",
            "Epoch  34\n",
            "Train Loss:  4.901338577270508\n",
            "Test Loss:  4.684050559997559\n",
            "Recall : 0.2704761904761905\n",
            "Epoch  35\n",
            "Train Loss:  4.863802433013916\n",
            "Test Loss:  4.667401313781738\n",
            "Recall : 0.2742857142857143\n",
            "Epoch  36\n",
            "Train Loss:  4.82757568359375\n",
            "Test Loss:  4.651485443115234\n",
            "Recall : 0.28\n",
            "Epoch  37\n",
            "Train Loss:  4.792608261108398\n",
            "Test Loss:  4.6362433433532715\n",
            "Recall : 0.2819047619047619\n",
            "Epoch  38\n",
            "Train Loss:  4.758861541748047\n",
            "Test Loss:  4.621678829193115\n",
            "Recall : 0.28285714285714286\n",
            "Epoch  39\n",
            "Train Loss:  4.726287841796875\n",
            "Test Loss:  4.607744216918945\n",
            "Recall : 0.2876190476190476\n",
            "Epoch  40\n",
            "Train Loss:  4.694880485534668\n",
            "Test Loss:  4.594407081604004\n",
            "Recall : 0.2923809523809524\n",
            "Epoch  41\n",
            "Train Loss:  4.6645708084106445\n",
            "Test Loss:  4.581691741943359\n",
            "Recall : 0.29333333333333333\n",
            "Epoch  42\n",
            "Train Loss:  4.635331153869629\n",
            "Test Loss:  4.569523811340332\n",
            "Recall : 0.29523809523809524\n",
            "Epoch  43\n",
            "Train Loss:  4.607117652893066\n",
            "Test Loss:  4.5578837394714355\n",
            "Recall : 0.29904761904761906\n",
            "Epoch  44\n",
            "Train Loss:  4.579890251159668\n",
            "Test Loss:  4.546784400939941\n",
            "Recall : 0.30095238095238097\n",
            "Epoch  45\n",
            "Train Loss:  4.553609848022461\n",
            "Test Loss:  4.536160469055176\n",
            "Recall : 0.3019047619047619\n",
            "Epoch  46\n",
            "Train Loss:  4.528236389160156\n",
            "Test Loss:  4.5259809494018555\n",
            "Recall : 0.3057142857142857\n",
            "Epoch  47\n",
            "Train Loss:  4.503747940063477\n",
            "Test Loss:  4.516213417053223\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  48\n",
            "Train Loss:  4.480093479156494\n",
            "Test Loss:  4.50688362121582\n",
            "Recall : 0.3076190476190476\n",
            "Epoch  49\n",
            "Train Loss:  4.457248210906982\n",
            "Test Loss:  4.497950077056885\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  50\n",
            "Train Loss:  4.435166835784912\n",
            "Test Loss:  4.489384651184082\n",
            "Recall : 0.30857142857142855\n",
            "Epoch  51\n",
            "Train Loss:  4.413817405700684\n",
            "Test Loss:  4.481138706207275\n",
            "Recall : 0.31142857142857144\n",
            "Epoch  52\n",
            "Train Loss:  4.393129348754883\n",
            "Test Loss:  4.4731903076171875\n",
            "Recall : 0.31142857142857144\n",
            "Epoch  53\n",
            "Train Loss:  4.373109340667725\n",
            "Test Loss:  4.465551853179932\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  54\n",
            "Train Loss:  4.353714466094971\n",
            "Test Loss:  4.458198547363281\n",
            "Recall : 0.31238095238095237\n",
            "Epoch  55\n",
            "Train Loss:  4.33491325378418\n",
            "Test Loss:  4.451106548309326\n",
            "Recall : 0.31142857142857144\n",
            "Epoch  56\n",
            "Train Loss:  4.316677570343018\n",
            "Test Loss:  4.444287300109863\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  57\n",
            "Train Loss:  4.299003601074219\n",
            "Test Loss:  4.437695503234863\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  58\n",
            "Train Loss:  4.2818522453308105\n",
            "Test Loss:  4.431347846984863\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  59\n",
            "Train Loss:  4.265213489532471\n",
            "Test Loss:  4.4252238273620605\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  60\n",
            "Train Loss:  4.249061584472656\n",
            "Test Loss:  4.419290542602539\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  61\n",
            "Train Loss:  4.23337459564209\n",
            "Test Loss:  4.413532257080078\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  62\n",
            "Train Loss:  4.218121528625488\n",
            "Test Loss:  4.4079742431640625\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  63\n",
            "Train Loss:  4.203285217285156\n",
            "Test Loss:  4.40262508392334\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  64\n",
            "Train Loss:  4.188863754272461\n",
            "Test Loss:  4.3974609375\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  65\n",
            "Train Loss:  4.174823760986328\n",
            "Test Loss:  4.39245080947876\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  66\n",
            "Train Loss:  4.1611480712890625\n",
            "Test Loss:  4.387591361999512\n",
            "Recall : 0.3180952380952381\n",
            "Epoch  67\n",
            "Train Loss:  4.147825717926025\n",
            "Test Loss:  4.3828935623168945\n",
            "Recall : 0.3161904761904762\n",
            "Epoch  68\n",
            "Train Loss:  4.134847164154053\n",
            "Test Loss:  4.378351211547852\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  69\n",
            "Train Loss:  4.122206211090088\n",
            "Test Loss:  4.373987197875977\n",
            "Recall : 0.3142857142857143\n",
            "Epoch  70\n",
            "Train Loss:  4.109877109527588\n",
            "Test Loss:  4.36977481842041\n",
            "Recall : 0.3142857142857143\n",
            "Epoch  71\n",
            "Train Loss:  4.09786319732666\n",
            "Test Loss:  4.365720748901367\n",
            "Recall : 0.3171428571428571\n",
            "Epoch  72\n",
            "Train Loss:  4.086147308349609\n",
            "Test Loss:  4.361814975738525\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  73\n",
            "Train Loss:  4.0747270584106445\n",
            "Test Loss:  4.358037948608398\n",
            "Recall : 0.31523809523809526\n",
            "Epoch  74\n",
            "Train Loss:  4.063572883605957\n",
            "Test Loss:  4.354422569274902\n",
            "Recall : 0.3180952380952381\n",
            "Epoch  75\n",
            "Train Loss:  4.052678108215332\n",
            "Test Loss:  4.350943565368652\n",
            "Recall : 0.319047619047619\n",
            "Epoch  76\n",
            "Train Loss:  4.042032241821289\n",
            "Test Loss:  4.34757137298584\n",
            "Recall : 0.32\n",
            "Epoch  77\n",
            "Train Loss:  4.031634330749512\n",
            "Test Loss:  4.344320297241211\n",
            "Recall : 0.3238095238095238\n",
            "Epoch  78\n",
            "Train Loss:  4.02147102355957\n",
            "Test Loss:  4.341203212738037\n",
            "Recall : 0.32\n",
            "Epoch  79\n",
            "Train Loss:  4.011532783508301\n",
            "Test Loss:  4.338212013244629\n",
            "Recall : 0.3219047619047619\n",
            "Epoch  80\n",
            "Train Loss:  4.001810073852539\n",
            "Test Loss:  4.335329055786133\n",
            "Recall : 0.3238095238095238\n",
            "Epoch  81\n",
            "Train Loss:  3.992292881011963\n",
            "Test Loss:  4.3325605392456055\n",
            "Recall : 0.32571428571428573\n",
            "Epoch  82\n",
            "Train Loss:  3.982980489730835\n",
            "Test Loss:  4.329903602600098\n",
            "Recall : 0.32761904761904764\n",
            "Epoch  83\n",
            "Train Loss:  3.973862648010254\n",
            "Test Loss:  4.327338218688965\n",
            "Recall : 0.3295238095238095\n",
            "Epoch  84\n",
            "Train Loss:  3.964938163757324\n",
            "Test Loss:  4.324883937835693\n",
            "Recall : 0.3304761904761905\n",
            "Epoch  85\n",
            "Train Loss:  3.95619797706604\n",
            "Test Loss:  4.322521209716797\n",
            "Recall : 0.3342857142857143\n",
            "Epoch  86\n",
            "Train Loss:  3.947632312774658\n",
            "Test Loss:  4.320240497589111\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  87\n",
            "Train Loss:  3.9392306804656982\n",
            "Test Loss:  4.318036079406738\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  88\n",
            "Train Loss:  3.930992364883423\n",
            "Test Loss:  4.315927982330322\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  89\n",
            "Train Loss:  3.9229178428649902\n",
            "Test Loss:  4.313899040222168\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  90\n",
            "Train Loss:  3.914985179901123\n",
            "Test Loss:  4.311938285827637\n",
            "Recall : 0.33714285714285713\n",
            "Epoch  91\n",
            "Train Loss:  3.907197952270508\n",
            "Test Loss:  4.310061454772949\n",
            "Recall : 0.3380952380952381\n",
            "Epoch  92\n",
            "Train Loss:  3.899547576904297\n",
            "Test Loss:  4.30824089050293\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  93\n",
            "Train Loss:  3.89203143119812\n",
            "Test Loss:  4.306475639343262\n",
            "Recall : 0.34\n",
            "Epoch  94\n",
            "Train Loss:  3.8846452236175537\n",
            "Test Loss:  4.304770469665527\n",
            "Recall : 0.34\n",
            "Epoch  95\n",
            "Train Loss:  3.877377510070801\n",
            "Test Loss:  4.3031182289123535\n",
            "Recall : 0.34\n",
            "Epoch  96\n",
            "Train Loss:  3.8702280521392822\n",
            "Test Loss:  4.301540374755859\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  97\n",
            "Train Loss:  3.8631980419158936\n",
            "Test Loss:  4.300029754638672\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  98\n",
            "Train Loss:  3.856274127960205\n",
            "Test Loss:  4.2985711097717285\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  99\n",
            "Train Loss:  3.8494510650634766\n",
            "Test Loss:  4.297168254852295\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  100\n",
            "Train Loss:  3.8427305221557617\n",
            "Test Loss:  4.295809268951416\n",
            "Recall : 0.34\n",
            "Epoch  101\n",
            "Train Loss:  3.8361117839813232\n",
            "Test Loss:  4.294497489929199\n",
            "Recall : 0.34\n",
            "Epoch  102\n",
            "Train Loss:  3.8295891284942627\n",
            "Test Loss:  4.293240547180176\n",
            "Recall : 0.34\n",
            "Epoch  103\n",
            "Train Loss:  3.823153495788574\n",
            "Test Loss:  4.2920331954956055\n",
            "Recall : 0.34\n",
            "Epoch  104\n",
            "Train Loss:  3.816805124282837\n",
            "Test Loss:  4.290857791900635\n",
            "Recall : 0.34\n",
            "Epoch  105\n",
            "Train Loss:  3.8105452060699463\n",
            "Test Loss:  4.289731025695801\n",
            "Recall : 0.34\n",
            "Epoch  106\n",
            "Train Loss:  3.804370403289795\n",
            "Test Loss:  4.288640975952148\n",
            "Recall : 0.34\n",
            "Epoch  107\n",
            "Train Loss:  3.798274040222168\n",
            "Test Loss:  4.287599563598633\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  108\n",
            "Train Loss:  3.7922475337982178\n",
            "Test Loss:  4.286592483520508\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  109\n",
            "Train Loss:  3.7862954139709473\n",
            "Test Loss:  4.285611152648926\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  110\n",
            "Train Loss:  3.780414342880249\n",
            "Test Loss:  4.284655570983887\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  111\n",
            "Train Loss:  3.7746074199676514\n",
            "Test Loss:  4.283740043640137\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  112\n",
            "Train Loss:  3.768861770629883\n",
            "Test Loss:  4.282864570617676\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  113\n",
            "Train Loss:  3.763166904449463\n",
            "Test Loss:  4.282005310058594\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  114\n",
            "Train Loss:  3.757537841796875\n",
            "Test Loss:  4.2811713218688965\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  115\n",
            "Train Loss:  3.751967430114746\n",
            "Test Loss:  4.280346870422363\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  116\n",
            "Train Loss:  3.746453285217285\n",
            "Test Loss:  4.279535293579102\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  117\n",
            "Train Loss:  3.7409896850585938\n",
            "Test Loss:  4.278736114501953\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  118\n",
            "Train Loss:  3.735574722290039\n",
            "Test Loss:  4.277933597564697\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  119\n",
            "Train Loss:  3.730205535888672\n",
            "Test Loss:  4.277132987976074\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  120\n",
            "Train Loss:  3.724879264831543\n",
            "Test Loss:  4.276324272155762\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  121\n",
            "Train Loss:  3.7195987701416016\n",
            "Test Loss:  4.275527000427246\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  122\n",
            "Train Loss:  3.714362144470215\n",
            "Test Loss:  4.274723052978516\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  123\n",
            "Train Loss:  3.7091667652130127\n",
            "Test Loss:  4.273923873901367\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  124\n",
            "Train Loss:  3.704011917114258\n",
            "Test Loss:  4.273128509521484\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  125\n",
            "Train Loss:  3.6988930702209473\n",
            "Test Loss:  4.272336959838867\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  126\n",
            "Train Loss:  3.6938061714172363\n",
            "Test Loss:  4.271567344665527\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  127\n",
            "Train Loss:  3.6887528896331787\n",
            "Test Loss:  4.270811080932617\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  128\n",
            "Train Loss:  3.683734893798828\n",
            "Test Loss:  4.270059585571289\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  129\n",
            "Train Loss:  3.6787490844726562\n",
            "Test Loss:  4.269314765930176\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  130\n",
            "Train Loss:  3.673790454864502\n",
            "Test Loss:  4.268561363220215\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  131\n",
            "Train Loss:  3.668869972229004\n",
            "Test Loss:  4.2678117752075195\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  132\n",
            "Train Loss:  3.6639809608459473\n",
            "Test Loss:  4.267066478729248\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  133\n",
            "Train Loss:  3.659118175506592\n",
            "Test Loss:  4.266331672668457\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  134\n",
            "Train Loss:  3.6542916297912598\n",
            "Test Loss:  4.265612602233887\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  135\n",
            "Train Loss:  3.6494946479797363\n",
            "Test Loss:  4.264908790588379\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  136\n",
            "Train Loss:  3.6447298526763916\n",
            "Test Loss:  4.264214515686035\n",
            "Recall : 0.3495238095238095\n",
            "Epoch  137\n",
            "Train Loss:  3.6399917602539062\n",
            "Test Loss:  4.263525485992432\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  138\n",
            "Train Loss:  3.6352782249450684\n",
            "Test Loss:  4.262840270996094\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  139\n",
            "Train Loss:  3.6305923461914062\n",
            "Test Loss:  4.2621588706970215\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  140\n",
            "Train Loss:  3.625934600830078\n",
            "Test Loss:  4.26149845123291\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  141\n",
            "Train Loss:  3.6213083267211914\n",
            "Test Loss:  4.260842323303223\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  142\n",
            "Train Loss:  3.6167097091674805\n",
            "Test Loss:  4.260196685791016\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  143\n",
            "Train Loss:  3.61214017868042\n",
            "Test Loss:  4.259556293487549\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  144\n",
            "Train Loss:  3.6076035499572754\n",
            "Test Loss:  4.258927345275879\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  145\n",
            "Train Loss:  3.6031007766723633\n",
            "Test Loss:  4.258308410644531\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  146\n",
            "Train Loss:  3.5986273288726807\n",
            "Test Loss:  4.257711410522461\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  147\n",
            "Train Loss:  3.594188690185547\n",
            "Test Loss:  4.257132530212402\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  148\n",
            "Train Loss:  3.589785099029541\n",
            "Test Loss:  4.256572246551514\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  149\n",
            "Train Loss:  3.5854105949401855\n",
            "Test Loss:  4.2560224533081055\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  150\n",
            "Train Loss:  3.5810656547546387\n",
            "Test Loss:  4.2554755210876465\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  151\n",
            "Train Loss:  3.5767548084259033\n",
            "Test Loss:  4.2549285888671875\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  152\n",
            "Train Loss:  3.5724680423736572\n",
            "Test Loss:  4.254395484924316\n",
            "Recall : 0.34\n",
            "Epoch  153\n",
            "Train Loss:  3.56821346282959\n",
            "Test Loss:  4.253868103027344\n",
            "Recall : 0.34\n",
            "Epoch  154\n",
            "Train Loss:  3.5639877319335938\n",
            "Test Loss:  4.253354072570801\n",
            "Recall : 0.34\n",
            "Epoch  155\n",
            "Train Loss:  3.5597894191741943\n",
            "Test Loss:  4.2528557777404785\n",
            "Recall : 0.34\n",
            "Epoch  156\n",
            "Train Loss:  3.5556230545043945\n",
            "Test Loss:  4.252373218536377\n",
            "Recall : 0.34\n",
            "Epoch  157\n",
            "Train Loss:  3.551485061645508\n",
            "Test Loss:  4.25190544128418\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  158\n",
            "Train Loss:  3.5473814010620117\n",
            "Test Loss:  4.251458168029785\n",
            "Recall : 0.34\n",
            "Epoch  159\n",
            "Train Loss:  3.5433053970336914\n",
            "Test Loss:  4.251023292541504\n",
            "Recall : 0.34\n",
            "Epoch  160\n",
            "Train Loss:  3.539259910583496\n",
            "Test Loss:  4.250603675842285\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  161\n",
            "Train Loss:  3.5352418422698975\n",
            "Test Loss:  4.2501935958862305\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  162\n",
            "Train Loss:  3.5312557220458984\n",
            "Test Loss:  4.24977970123291\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  163\n",
            "Train Loss:  3.5272951126098633\n",
            "Test Loss:  4.249379634857178\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  164\n",
            "Train Loss:  3.5233635902404785\n",
            "Test Loss:  4.248995304107666\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  165\n",
            "Train Loss:  3.5194573402404785\n",
            "Test Loss:  4.248627185821533\n",
            "Recall : 0.34\n",
            "Epoch  166\n",
            "Train Loss:  3.5155811309814453\n",
            "Test Loss:  4.248275279998779\n",
            "Recall : 0.33904761904761904\n",
            "Epoch  167\n",
            "Train Loss:  3.511733055114746\n",
            "Test Loss:  4.247934341430664\n",
            "Recall : 0.34\n",
            "Epoch  168\n",
            "Train Loss:  3.5079147815704346\n",
            "Test Loss:  4.247607231140137\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  169\n",
            "Train Loss:  3.504124164581299\n",
            "Test Loss:  4.247293472290039\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  170\n",
            "Train Loss:  3.500361680984497\n",
            "Test Loss:  4.246990203857422\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  171\n",
            "Train Loss:  3.4966278076171875\n",
            "Test Loss:  4.246694564819336\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  172\n",
            "Train Loss:  3.4929211139678955\n",
            "Test Loss:  4.2464094161987305\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  173\n",
            "Train Loss:  3.489248752593994\n",
            "Test Loss:  4.246138572692871\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  174\n",
            "Train Loss:  3.485607624053955\n",
            "Test Loss:  4.245868682861328\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  175\n",
            "Train Loss:  3.481999635696411\n",
            "Test Loss:  4.245607376098633\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  176\n",
            "Train Loss:  3.4784188270568848\n",
            "Test Loss:  4.245364189147949\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  177\n",
            "Train Loss:  3.474863052368164\n",
            "Test Loss:  4.245141506195068\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  178\n",
            "Train Loss:  3.4713377952575684\n",
            "Test Loss:  4.244929313659668\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  179\n",
            "Train Loss:  3.4678447246551514\n",
            "Test Loss:  4.244720935821533\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  180\n",
            "Train Loss:  3.4643847942352295\n",
            "Test Loss:  4.244520664215088\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  181\n",
            "Train Loss:  3.4609525203704834\n",
            "Test Loss:  4.244330406188965\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  182\n",
            "Train Loss:  3.457547903060913\n",
            "Test Loss:  4.244143486022949\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  183\n",
            "Train Loss:  3.4541711807250977\n",
            "Test Loss:  4.2439703941345215\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  184\n",
            "Train Loss:  3.450822591781616\n",
            "Test Loss:  4.243806838989258\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  185\n",
            "Train Loss:  3.447502851486206\n",
            "Test Loss:  4.243647575378418\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  186\n",
            "Train Loss:  3.4442124366760254\n",
            "Test Loss:  4.243500709533691\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  187\n",
            "Train Loss:  3.4409523010253906\n",
            "Test Loss:  4.243366241455078\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  188\n",
            "Train Loss:  3.437720537185669\n",
            "Test Loss:  4.243231773376465\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  189\n",
            "Train Loss:  3.4345157146453857\n",
            "Test Loss:  4.243104934692383\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  190\n",
            "Train Loss:  3.4313340187072754\n",
            "Test Loss:  4.242982864379883\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  191\n",
            "Train Loss:  3.4281816482543945\n",
            "Test Loss:  4.242865085601807\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  192\n",
            "Train Loss:  3.4250569343566895\n",
            "Test Loss:  4.2427473068237305\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  193\n",
            "Train Loss:  3.421959400177002\n",
            "Test Loss:  4.242632865905762\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  194\n",
            "Train Loss:  3.4188876152038574\n",
            "Test Loss:  4.242517471313477\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  195\n",
            "Train Loss:  3.4158411026000977\n",
            "Test Loss:  4.242399215698242\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  196\n",
            "Train Loss:  3.412818193435669\n",
            "Test Loss:  4.242284774780273\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  197\n",
            "Train Loss:  3.409820556640625\n",
            "Test Loss:  4.2421770095825195\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  198\n",
            "Train Loss:  3.4068474769592285\n",
            "Test Loss:  4.242079734802246\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  199\n",
            "Train Loss:  3.403895854949951\n",
            "Test Loss:  4.241987705230713\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  200\n",
            "Train Loss:  3.400966167449951\n",
            "Test Loss:  4.2419023513793945\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  201\n",
            "Train Loss:  3.3980584144592285\n",
            "Test Loss:  4.241825103759766\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  202\n",
            "Train Loss:  3.395171880722046\n",
            "Test Loss:  4.241756439208984\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  203\n",
            "Train Loss:  3.392307758331299\n",
            "Test Loss:  4.241690635681152\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  204\n",
            "Train Loss:  3.38946533203125\n",
            "Test Loss:  4.24162483215332\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  205\n",
            "Train Loss:  3.386644124984741\n",
            "Test Loss:  4.241567134857178\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  206\n",
            "Train Loss:  3.3838424682617188\n",
            "Test Loss:  4.241511344909668\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  207\n",
            "Train Loss:  3.381060838699341\n",
            "Test Loss:  4.24144983291626\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  208\n",
            "Train Loss:  3.3783016204833984\n",
            "Test Loss:  4.2413835525512695\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  209\n",
            "Train Loss:  3.375558853149414\n",
            "Test Loss:  4.241321563720703\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  210\n",
            "Train Loss:  3.372833251953125\n",
            "Test Loss:  4.2412614822387695\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  211\n",
            "Train Loss:  3.3701272010803223\n",
            "Test Loss:  4.241202354431152\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  212\n",
            "Train Loss:  3.367438316345215\n",
            "Test Loss:  4.241147041320801\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  213\n",
            "Train Loss:  3.364767551422119\n",
            "Test Loss:  4.241086959838867\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  214\n",
            "Train Loss:  3.3621160984039307\n",
            "Test Loss:  4.241024971008301\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  215\n",
            "Train Loss:  3.3594839572906494\n",
            "Test Loss:  4.240960121154785\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  216\n",
            "Train Loss:  3.356870651245117\n",
            "Test Loss:  4.240893363952637\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  217\n",
            "Train Loss:  3.3542709350585938\n",
            "Test Loss:  4.240832328796387\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  218\n",
            "Train Loss:  3.351686477661133\n",
            "Test Loss:  4.240773677825928\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  219\n",
            "Train Loss:  3.3491156101226807\n",
            "Test Loss:  4.240719795227051\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  220\n",
            "Train Loss:  3.346559524536133\n",
            "Test Loss:  4.240660667419434\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  221\n",
            "Train Loss:  3.3440141677856445\n",
            "Test Loss:  4.240599632263184\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  222\n",
            "Train Loss:  3.3414835929870605\n",
            "Test Loss:  4.240544319152832\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  223\n",
            "Train Loss:  3.338968276977539\n",
            "Test Loss:  4.2404937744140625\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  224\n",
            "Train Loss:  3.3364667892456055\n",
            "Test Loss:  4.240442276000977\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  225\n",
            "Train Loss:  3.333977699279785\n",
            "Test Loss:  4.240391731262207\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  226\n",
            "Train Loss:  3.3315021991729736\n",
            "Test Loss:  4.2403388023376465\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  227\n",
            "Train Loss:  3.3290367126464844\n",
            "Test Loss:  4.240283012390137\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  228\n",
            "Train Loss:  3.3265838623046875\n",
            "Test Loss:  4.24022102355957\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  229\n",
            "Train Loss:  3.324141025543213\n",
            "Test Loss:  4.240156173706055\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  230\n",
            "Train Loss:  3.3217077255249023\n",
            "Test Loss:  4.240086555480957\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  231\n",
            "Train Loss:  3.3192873001098633\n",
            "Test Loss:  4.240018844604492\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  232\n",
            "Train Loss:  3.316877841949463\n",
            "Test Loss:  4.239947319030762\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  233\n",
            "Train Loss:  3.3144803047180176\n",
            "Test Loss:  4.239873886108398\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  234\n",
            "Train Loss:  3.312096118927002\n",
            "Test Loss:  4.2397966384887695\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  235\n",
            "Train Loss:  3.309725284576416\n",
            "Test Loss:  4.239713668823242\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  236\n",
            "Train Loss:  3.3073654174804688\n",
            "Test Loss:  4.239628314971924\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  237\n",
            "Train Loss:  3.3050169944763184\n",
            "Test Loss:  4.239538669586182\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  238\n",
            "Train Loss:  3.302678108215332\n",
            "Test Loss:  4.239442348480225\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  239\n",
            "Train Loss:  3.300351619720459\n",
            "Test Loss:  4.239346027374268\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  240\n",
            "Train Loss:  3.29803729057312\n",
            "Test Loss:  4.239255905151367\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  241\n",
            "Train Loss:  3.2957353591918945\n",
            "Test Loss:  4.239168167114258\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  242\n",
            "Train Loss:  3.2934446334838867\n",
            "Test Loss:  4.239082336425781\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  243\n",
            "Train Loss:  3.2911648750305176\n",
            "Test Loss:  4.23898983001709\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  244\n",
            "Train Loss:  3.288893699645996\n",
            "Test Loss:  4.238895416259766\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  245\n",
            "Train Loss:  3.286633253097534\n",
            "Test Loss:  4.238794803619385\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  246\n",
            "Train Loss:  3.2843809127807617\n",
            "Test Loss:  4.2386932373046875\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  247\n",
            "Train Loss:  3.282139778137207\n",
            "Test Loss:  4.238593101501465\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  248\n",
            "Train Loss:  3.2799103260040283\n",
            "Test Loss:  4.238492012023926\n",
            "Recall : 0.34\n",
            "Epoch  249\n",
            "Train Loss:  3.277689218521118\n",
            "Test Loss:  4.2383856773376465\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  250\n",
            "Train Loss:  3.275479555130005\n",
            "Test Loss:  4.238272666931152\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  251\n",
            "Train Loss:  3.273280620574951\n",
            "Test Loss:  4.238157749176025\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  252\n",
            "Train Loss:  3.2710928916931152\n",
            "Test Loss:  4.23804235458374\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  253\n",
            "Train Loss:  3.2689154148101807\n",
            "Test Loss:  4.237924575805664\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  254\n",
            "Train Loss:  3.266749858856201\n",
            "Test Loss:  4.2378034591674805\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  255\n",
            "Train Loss:  3.2645959854125977\n",
            "Test Loss:  4.237678050994873\n",
            "Recall : 0.34095238095238095\n",
            "Epoch  256\n",
            "Train Loss:  3.2624521255493164\n",
            "Test Loss:  4.237548351287842\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  257\n",
            "Train Loss:  3.260319232940674\n",
            "Test Loss:  4.237417221069336\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  258\n",
            "Train Loss:  3.2581968307495117\n",
            "Test Loss:  4.237283706665039\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  259\n",
            "Train Loss:  3.2560853958129883\n",
            "Test Loss:  4.237153053283691\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  260\n",
            "Train Loss:  3.2539849281311035\n",
            "Test Loss:  4.237020492553711\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  261\n",
            "Train Loss:  3.251894950866699\n",
            "Test Loss:  4.236886501312256\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  262\n",
            "Train Loss:  3.24981689453125\n",
            "Test Loss:  4.236756324768066\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  263\n",
            "Train Loss:  3.2477517127990723\n",
            "Test Loss:  4.236626625061035\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  264\n",
            "Train Loss:  3.245695114135742\n",
            "Test Loss:  4.23649787902832\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  265\n",
            "Train Loss:  3.243650436401367\n",
            "Test Loss:  4.236367702484131\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  266\n",
            "Train Loss:  3.241614818572998\n",
            "Test Loss:  4.236240386962891\n",
            "Recall : 0.3419047619047619\n",
            "Epoch  267\n",
            "Train Loss:  3.2395896911621094\n",
            "Test Loss:  4.236114501953125\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  268\n",
            "Train Loss:  3.2375757694244385\n",
            "Test Loss:  4.235996246337891\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  269\n",
            "Train Loss:  3.2355709075927734\n",
            "Test Loss:  4.2358784675598145\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  270\n",
            "Train Loss:  3.233576774597168\n",
            "Test Loss:  4.2357635498046875\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  271\n",
            "Train Loss:  3.231593608856201\n",
            "Test Loss:  4.235648155212402\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  272\n",
            "Train Loss:  3.2296221256256104\n",
            "Test Loss:  4.235538005828857\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  273\n",
            "Train Loss:  3.227659225463867\n",
            "Test Loss:  4.23543119430542\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  274\n",
            "Train Loss:  3.2257065773010254\n",
            "Test Loss:  4.235328674316406\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  275\n",
            "Train Loss:  3.223764657974243\n",
            "Test Loss:  4.235230445861816\n",
            "Recall : 0.34285714285714286\n",
            "Epoch  276\n",
            "Train Loss:  3.221832275390625\n",
            "Test Loss:  4.235137939453125\n",
            "Recall : 0.3438095238095238\n",
            "Epoch  277\n",
            "Train Loss:  3.2199079990386963\n",
            "Test Loss:  4.235045433044434\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  278\n",
            "Train Loss:  3.2179956436157227\n",
            "Test Loss:  4.234958648681641\n",
            "Recall : 0.34476190476190477\n",
            "Epoch  279\n",
            "Train Loss:  3.2160942554473877\n",
            "Test Loss:  4.2348785400390625\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  280\n",
            "Train Loss:  3.2142035961151123\n",
            "Test Loss:  4.234799385070801\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  281\n",
            "Train Loss:  3.212322950363159\n",
            "Test Loss:  4.23471736907959\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  282\n",
            "Train Loss:  3.210451126098633\n",
            "Test Loss:  4.234639644622803\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  283\n",
            "Train Loss:  3.208588123321533\n",
            "Test Loss:  4.234567642211914\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  284\n",
            "Train Loss:  3.206733226776123\n",
            "Test Loss:  4.234494686126709\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  285\n",
            "Train Loss:  3.204887866973877\n",
            "Test Loss:  4.234421730041504\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  286\n",
            "Train Loss:  3.203052520751953\n",
            "Test Loss:  4.234349250793457\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  287\n",
            "Train Loss:  3.2012271881103516\n",
            "Test Loss:  4.234278202056885\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  288\n",
            "Train Loss:  3.1994130611419678\n",
            "Test Loss:  4.234206676483154\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  289\n",
            "Train Loss:  3.1976094245910645\n",
            "Test Loss:  4.234139442443848\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  290\n",
            "Train Loss:  3.1958136558532715\n",
            "Test Loss:  4.234074592590332\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  291\n",
            "Train Loss:  3.1940267086029053\n",
            "Test Loss:  4.234017372131348\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  292\n",
            "Train Loss:  3.1922502517700195\n",
            "Test Loss:  4.233962059020996\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  293\n",
            "Train Loss:  3.1904845237731934\n",
            "Test Loss:  4.233905792236328\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  294\n",
            "Train Loss:  3.1887264251708984\n",
            "Test Loss:  4.233854293823242\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  295\n",
            "Train Loss:  3.186978816986084\n",
            "Test Loss:  4.23380184173584\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  296\n",
            "Train Loss:  3.18524169921875\n",
            "Test Loss:  4.233746528625488\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  297\n",
            "Train Loss:  3.18351411819458\n",
            "Test Loss:  4.233695030212402\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  298\n",
            "Train Loss:  3.181797981262207\n",
            "Test Loss:  4.233644485473633\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  299\n",
            "Train Loss:  3.180089235305786\n",
            "Test Loss:  4.233593940734863\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  300\n",
            "Train Loss:  3.1783900260925293\n",
            "Test Loss:  4.233545303344727\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  301\n",
            "Train Loss:  3.1767008304595947\n",
            "Test Loss:  4.23349666595459\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  302\n",
            "Train Loss:  3.175020217895508\n",
            "Test Loss:  4.233448505401611\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  303\n",
            "Train Loss:  3.1733503341674805\n",
            "Test Loss:  4.233403205871582\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  304\n",
            "Train Loss:  3.171687126159668\n",
            "Test Loss:  4.233360290527344\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  305\n",
            "Train Loss:  3.1700329780578613\n",
            "Test Loss:  4.233321189880371\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  306\n",
            "Train Loss:  3.1683878898620605\n",
            "Test Loss:  4.233285903930664\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  307\n",
            "Train Loss:  3.166752338409424\n",
            "Test Loss:  4.233255863189697\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  308\n",
            "Train Loss:  3.1651272773742676\n",
            "Test Loss:  4.233229637145996\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  309\n",
            "Train Loss:  3.1635117530822754\n",
            "Test Loss:  4.233203887939453\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  310\n",
            "Train Loss:  3.1619057655334473\n",
            "Test Loss:  4.233185768127441\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  311\n",
            "Train Loss:  3.1603071689605713\n",
            "Test Loss:  4.23316764831543\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  312\n",
            "Train Loss:  3.1587185859680176\n",
            "Test Loss:  4.233147621154785\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  313\n",
            "Train Loss:  3.1571383476257324\n",
            "Test Loss:  4.233132362365723\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  314\n",
            "Train Loss:  3.1555659770965576\n",
            "Test Loss:  4.233119964599609\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  315\n",
            "Train Loss:  3.1540026664733887\n",
            "Test Loss:  4.233107566833496\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  316\n",
            "Train Loss:  3.1524486541748047\n",
            "Test Loss:  4.233095645904541\n",
            "Recall : 0.3457142857142857\n",
            "Epoch  317\n",
            "Train Loss:  3.1509037017822266\n",
            "Test Loss:  4.233089447021484\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  318\n",
            "Train Loss:  3.149367094039917\n",
            "Test Loss:  4.233085632324219\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  319\n",
            "Train Loss:  3.147838592529297\n",
            "Test Loss:  4.233081817626953\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  320\n",
            "Train Loss:  3.1463193893432617\n",
            "Test Loss:  4.233076572418213\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  321\n",
            "Train Loss:  3.1448092460632324\n",
            "Test Loss:  4.233072280883789\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  322\n",
            "Train Loss:  3.1433069705963135\n",
            "Test Loss:  4.233072280883789\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  323\n",
            "Train Loss:  3.141812801361084\n",
            "Test Loss:  4.233074188232422\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  324\n",
            "Train Loss:  3.1403274536132812\n",
            "Test Loss:  4.233079433441162\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  325\n",
            "Train Loss:  3.1388494968414307\n",
            "Test Loss:  4.233084678649902\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  326\n",
            "Train Loss:  3.1373796463012695\n",
            "Test Loss:  4.233091354370117\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  327\n",
            "Train Loss:  3.1359171867370605\n",
            "Test Loss:  4.233102798461914\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  328\n",
            "Train Loss:  3.134460926055908\n",
            "Test Loss:  4.233116149902344\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  329\n",
            "Train Loss:  3.133009910583496\n",
            "Test Loss:  4.233131408691406\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  330\n",
            "Train Loss:  3.1315650939941406\n",
            "Test Loss:  4.23314905166626\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  331\n",
            "Train Loss:  3.130126714706421\n",
            "Test Loss:  4.233165740966797\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  332\n",
            "Train Loss:  3.1286964416503906\n",
            "Test Loss:  4.233180999755859\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  333\n",
            "Train Loss:  3.127272605895996\n",
            "Test Loss:  4.233195781707764\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  334\n",
            "Train Loss:  3.1258559226989746\n",
            "Test Loss:  4.233212471008301\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  335\n",
            "Train Loss:  3.1244454383850098\n",
            "Test Loss:  4.233232498168945\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  336\n",
            "Train Loss:  3.123042583465576\n",
            "Test Loss:  4.233254432678223\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  337\n",
            "Train Loss:  3.121645927429199\n",
            "Test Loss:  4.233275413513184\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  338\n",
            "Train Loss:  3.1202573776245117\n",
            "Test Loss:  4.233297824859619\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  339\n",
            "Train Loss:  3.1188745498657227\n",
            "Test Loss:  4.233321189880371\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  340\n",
            "Train Loss:  3.117499828338623\n",
            "Test Loss:  4.233346939086914\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  341\n",
            "Train Loss:  3.116130828857422\n",
            "Test Loss:  4.2333784103393555\n",
            "Recall : 0.3466666666666667\n",
            "Epoch  342\n",
            "Train Loss:  3.114769458770752\n",
            "Test Loss:  4.233410835266113\n",
            "Recall : 0.3476190476190476\n",
            "Epoch  343\n",
            "Train Loss:  3.113414764404297\n",
            "Test Loss:  4.233443737030029\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  344\n",
            "Train Loss:  3.1120686531066895\n",
            "Test Loss:  4.2334794998168945\n",
            "Recall : 0.3485714285714286\n",
            "Epoch  345\n",
            "Train Loss:  3.1107282638549805\n",
            "Test Loss:  4.233517646789551\n",
            "Recall : 0.3495238095238095\n",
            "Epoch  346\n",
            "Train Loss:  3.1093950271606445\n",
            "Test Loss:  4.233556747436523\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  347\n",
            "Train Loss:  3.10806941986084\n",
            "Test Loss:  4.233595848083496\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  348\n",
            "Train Loss:  3.1067490577697754\n",
            "Test Loss:  4.233631610870361\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  349\n",
            "Train Loss:  3.105436325073242\n",
            "Test Loss:  4.233667373657227\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  350\n",
            "Train Loss:  3.1041293144226074\n",
            "Test Loss:  4.233706474304199\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  351\n",
            "Train Loss:  3.102827310562134\n",
            "Test Loss:  4.233748435974121\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  352\n",
            "Train Loss:  3.1015305519104004\n",
            "Test Loss:  4.23379373550415\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  353\n",
            "Train Loss:  3.10024094581604\n",
            "Test Loss:  4.2338409423828125\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  354\n",
            "Train Loss:  3.098957061767578\n",
            "Test Loss:  4.233892440795898\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  355\n",
            "Train Loss:  3.0976786613464355\n",
            "Test Loss:  4.233944892883301\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  356\n",
            "Train Loss:  3.096405267715454\n",
            "Test Loss:  4.2339982986450195\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  357\n",
            "Train Loss:  3.0951385498046875\n",
            "Test Loss:  4.234052658081055\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  358\n",
            "Train Loss:  3.093876600265503\n",
            "Test Loss:  4.234109878540039\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  359\n",
            "Train Loss:  3.092620849609375\n",
            "Test Loss:  4.234167098999023\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  360\n",
            "Train Loss:  3.0913710594177246\n",
            "Test Loss:  4.2342209815979\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  361\n",
            "Train Loss:  3.090125799179077\n",
            "Test Loss:  4.234274864196777\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  362\n",
            "Train Loss:  3.0888848304748535\n",
            "Test Loss:  4.234328269958496\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  363\n",
            "Train Loss:  3.0876498222351074\n",
            "Test Loss:  4.234382629394531\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  364\n",
            "Train Loss:  3.0864198207855225\n",
            "Test Loss:  4.234438419342041\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  365\n",
            "Train Loss:  3.0851941108703613\n",
            "Test Loss:  4.234495162963867\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  366\n",
            "Train Loss:  3.083972454071045\n",
            "Test Loss:  4.234552383422852\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  367\n",
            "Train Loss:  3.0827560424804688\n",
            "Test Loss:  4.2346086502075195\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  368\n",
            "Train Loss:  3.0815446376800537\n",
            "Test Loss:  4.234665870666504\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  369\n",
            "Train Loss:  3.080338478088379\n",
            "Test Loss:  4.234726428985596\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  370\n",
            "Train Loss:  3.0791358947753906\n",
            "Test Loss:  4.23478889465332\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  371\n",
            "Train Loss:  3.077937602996826\n",
            "Test Loss:  4.2348527908325195\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  372\n",
            "Train Loss:  3.076744318008423\n",
            "Test Loss:  4.234915256500244\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  373\n",
            "Train Loss:  3.075556993484497\n",
            "Test Loss:  4.234978675842285\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  374\n",
            "Train Loss:  3.0743727684020996\n",
            "Test Loss:  4.235042572021484\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  375\n",
            "Train Loss:  3.073192596435547\n",
            "Test Loss:  4.235109329223633\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  376\n",
            "Train Loss:  3.0720157623291016\n",
            "Test Loss:  4.235177516937256\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  377\n",
            "Train Loss:  3.070842742919922\n",
            "Test Loss:  4.235248565673828\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  378\n",
            "Train Loss:  3.0696732997894287\n",
            "Test Loss:  4.235322952270508\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  379\n",
            "Train Loss:  3.068507671356201\n",
            "Test Loss:  4.235396385192871\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  380\n",
            "Train Loss:  3.0673460960388184\n",
            "Test Loss:  4.235471725463867\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  381\n",
            "Train Loss:  3.0661892890930176\n",
            "Test Loss:  4.235547065734863\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  382\n",
            "Train Loss:  3.065037727355957\n",
            "Test Loss:  4.235622406005859\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  383\n",
            "Train Loss:  3.063890218734741\n",
            "Test Loss:  4.2356977462768555\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  384\n",
            "Train Loss:  3.0627455711364746\n",
            "Test Loss:  4.235772132873535\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  385\n",
            "Train Loss:  3.061605930328369\n",
            "Test Loss:  4.235846519470215\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  386\n",
            "Train Loss:  3.0604701042175293\n",
            "Test Loss:  4.235918998718262\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  387\n",
            "Train Loss:  3.059337615966797\n",
            "Test Loss:  4.235990524291992\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  388\n",
            "Train Loss:  3.058208465576172\n",
            "Test Loss:  4.2360639572143555\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  389\n",
            "Train Loss:  3.057084083557129\n",
            "Test Loss:  4.236142158508301\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  390\n",
            "Train Loss:  3.055964231491089\n",
            "Test Loss:  4.236218452453613\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  391\n",
            "Train Loss:  3.0548479557037354\n",
            "Test Loss:  4.236294746398926\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  392\n",
            "Train Loss:  3.053736448287964\n",
            "Test Loss:  4.236371040344238\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  393\n",
            "Train Loss:  3.052628517150879\n",
            "Test Loss:  4.236446380615234\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  394\n",
            "Train Loss:  3.051525831222534\n",
            "Test Loss:  4.236520767211914\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  395\n",
            "Train Loss:  3.050426721572876\n",
            "Test Loss:  4.236598968505859\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  396\n",
            "Train Loss:  3.049330711364746\n",
            "Test Loss:  4.236675262451172\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  397\n",
            "Train Loss:  3.0482378005981445\n",
            "Test Loss:  4.236751079559326\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  398\n",
            "Train Loss:  3.0471489429473877\n",
            "Test Loss:  4.236827850341797\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  399\n",
            "Train Loss:  3.046064615249634\n",
            "Test Loss:  4.236905097961426\n",
            "Recall : 0.3514285714285714\n",
            "Epoch  400\n",
            "Train Loss:  3.044985055923462\n",
            "Test Loss:  4.236980438232422\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  401\n",
            "Train Loss:  3.0439090728759766\n",
            "Test Loss:  4.237057685852051\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  402\n",
            "Train Loss:  3.0428361892700195\n",
            "Test Loss:  4.237135887145996\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  403\n",
            "Train Loss:  3.041767120361328\n",
            "Test Loss:  4.237212181091309\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  404\n",
            "Train Loss:  3.040700912475586\n",
            "Test Loss:  4.237288475036621\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  405\n",
            "Train Loss:  3.0396389961242676\n",
            "Test Loss:  4.237364768981934\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  406\n",
            "Train Loss:  3.0385804176330566\n",
            "Test Loss:  4.237443923950195\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  407\n",
            "Train Loss:  3.0375258922576904\n",
            "Test Loss:  4.237524509429932\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  408\n",
            "Train Loss:  3.0364737510681152\n",
            "Test Loss:  4.237605094909668\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  409\n",
            "Train Loss:  3.03542423248291\n",
            "Test Loss:  4.237685203552246\n",
            "Recall : 0.3514285714285714\n",
            "Epoch  410\n",
            "Train Loss:  3.034377098083496\n",
            "Test Loss:  4.237764358520508\n",
            "Recall : 0.3514285714285714\n",
            "Epoch  411\n",
            "Train Loss:  3.0333333015441895\n",
            "Test Loss:  4.237845420837402\n",
            "Recall : 0.3514285714285714\n",
            "Epoch  412\n",
            "Train Loss:  3.0322933197021484\n",
            "Test Loss:  4.237929344177246\n",
            "Recall : 0.3514285714285714\n",
            "Epoch  413\n",
            "Train Loss:  3.031256675720215\n",
            "Test Loss:  4.23801326751709\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  414\n",
            "Train Loss:  3.030223846435547\n",
            "Test Loss:  4.238096714019775\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  415\n",
            "Train Loss:  3.029193162918091\n",
            "Test Loss:  4.2381792068481445\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  416\n",
            "Train Loss:  3.028165340423584\n",
            "Test Loss:  4.238262176513672\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  417\n",
            "Train Loss:  3.0271410942077637\n",
            "Test Loss:  4.238345146179199\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  418\n",
            "Train Loss:  3.0261192321777344\n",
            "Test Loss:  4.238429069519043\n",
            "Recall : 0.3504761904761905\n",
            "Epoch  419\n",
            "Train Loss:  3.0251011848449707\n",
            "Test Loss:  4.2385125160217285\n",
            "Recall : 0.3514285714285714\n",
            "Epoch  420\n",
            "Train Loss:  3.0240871906280518\n",
            "Test Loss:  4.238595962524414\n",
            "Recall : 0.3514285714285714\n",
            "Epoch  421\n",
            "Train Loss:  3.0230770111083984\n",
            "Test Loss:  4.238677978515625\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  422\n",
            "Train Loss:  3.0220696926116943\n",
            "Test Loss:  4.238757133483887\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  423\n",
            "Train Loss:  3.0210652351379395\n",
            "Test Loss:  4.238836288452148\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  424\n",
            "Train Loss:  3.020063877105713\n",
            "Test Loss:  4.238914489746094\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  425\n",
            "Train Loss:  3.01906681060791\n",
            "Test Loss:  4.238991737365723\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  426\n",
            "Train Loss:  3.018073558807373\n",
            "Test Loss:  4.239068031311035\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  427\n",
            "Train Loss:  3.017083168029785\n",
            "Test Loss:  4.239142417907715\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  428\n",
            "Train Loss:  3.0160951614379883\n",
            "Test Loss:  4.239214897155762\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  429\n",
            "Train Loss:  3.015110492706299\n",
            "Test Loss:  4.239288330078125\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  430\n",
            "Train Loss:  3.0141282081604004\n",
            "Test Loss:  4.239360809326172\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  431\n",
            "Train Loss:  3.013151168823242\n",
            "Test Loss:  4.2394304275512695\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  432\n",
            "Train Loss:  3.012176513671875\n",
            "Test Loss:  4.239499092102051\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  433\n",
            "Train Loss:  3.011207103729248\n",
            "Test Loss:  4.239568710327148\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  434\n",
            "Train Loss:  3.0102410316467285\n",
            "Test Loss:  4.2396392822265625\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  435\n",
            "Train Loss:  3.00927734375\n",
            "Test Loss:  4.239710807800293\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  436\n",
            "Train Loss:  3.0083165168762207\n",
            "Test Loss:  4.239779472351074\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  437\n",
            "Train Loss:  3.007359743118286\n",
            "Test Loss:  4.23984956741333\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  438\n",
            "Train Loss:  3.006405830383301\n",
            "Test Loss:  4.239919185638428\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  439\n",
            "Train Loss:  3.00545597076416\n",
            "Test Loss:  4.239988327026367\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  440\n",
            "Train Loss:  3.004509925842285\n",
            "Test Loss:  4.240059852600098\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  441\n",
            "Train Loss:  3.0035674571990967\n",
            "Test Loss:  4.240129470825195\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  442\n",
            "Train Loss:  3.0026276111602783\n",
            "Test Loss:  4.240199089050293\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  443\n",
            "Train Loss:  3.0016915798187256\n",
            "Test Loss:  4.240272045135498\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  444\n",
            "Train Loss:  3.000758647918701\n",
            "Test Loss:  4.240345001220703\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  445\n",
            "Train Loss:  2.9998297691345215\n",
            "Test Loss:  4.240418434143066\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  446\n",
            "Train Loss:  2.9989047050476074\n",
            "Test Loss:  4.2404937744140625\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  447\n",
            "Train Loss:  2.997983455657959\n",
            "Test Loss:  4.240567684173584\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  448\n",
            "Train Loss:  2.9970643520355225\n",
            "Test Loss:  4.240640640258789\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  449\n",
            "Train Loss:  2.9961485862731934\n",
            "Test Loss:  4.240715026855469\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  450\n",
            "Train Loss:  2.995236396789551\n",
            "Test Loss:  4.240788459777832\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  451\n",
            "Train Loss:  2.9943270683288574\n",
            "Test Loss:  4.240861892700195\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  452\n",
            "Train Loss:  2.9934210777282715\n",
            "Test Loss:  4.240936279296875\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  453\n",
            "Train Loss:  2.992518901824951\n",
            "Test Loss:  4.24100923538208\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  454\n",
            "Train Loss:  2.99161958694458\n",
            "Test Loss:  4.241082668304443\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  455\n",
            "Train Loss:  2.9907240867614746\n",
            "Test Loss:  4.241157531738281\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  456\n",
            "Train Loss:  2.9898312091827393\n",
            "Test Loss:  4.241232872009277\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  457\n",
            "Train Loss:  2.9889419078826904\n",
            "Test Loss:  4.241307258605957\n",
            "Recall : 0.3523809523809524\n",
            "Epoch  458\n",
            "Train Loss:  2.9880547523498535\n",
            "Test Loss:  4.241384506225586\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  459\n",
            "Train Loss:  2.987170696258545\n",
            "Test Loss:  4.241461753845215\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  460\n",
            "Train Loss:  2.9862899780273438\n",
            "Test Loss:  4.241539478302002\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  461\n",
            "Train Loss:  2.985413074493408\n",
            "Test Loss:  4.241617679595947\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  462\n",
            "Train Loss:  2.984539031982422\n",
            "Test Loss:  4.241696834564209\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  463\n",
            "Train Loss:  2.983668565750122\n",
            "Test Loss:  4.241774559020996\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  464\n",
            "Train Loss:  2.9828011989593506\n",
            "Test Loss:  4.241851806640625\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  465\n",
            "Train Loss:  2.9819374084472656\n",
            "Test Loss:  4.241928577423096\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  466\n",
            "Train Loss:  2.981076240539551\n",
            "Test Loss:  4.24200439453125\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  467\n",
            "Train Loss:  2.980217695236206\n",
            "Test Loss:  4.24207878112793\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  468\n",
            "Train Loss:  2.9793624877929688\n",
            "Test Loss:  4.242155075073242\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  469\n",
            "Train Loss:  2.9785099029541016\n",
            "Test Loss:  4.2422332763671875\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  470\n",
            "Train Loss:  2.9776611328125\n",
            "Test Loss:  4.242311000823975\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  471\n",
            "Train Loss:  2.9768166542053223\n",
            "Test Loss:  4.242387771606445\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  472\n",
            "Train Loss:  2.9759745597839355\n",
            "Test Loss:  4.242465019226074\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  473\n",
            "Train Loss:  2.975135326385498\n",
            "Test Loss:  4.242542266845703\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  474\n",
            "Train Loss:  2.974299430847168\n",
            "Test Loss:  4.242621421813965\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  475\n",
            "Train Loss:  2.973466634750366\n",
            "Test Loss:  4.242703437805176\n",
            "Recall : 0.35333333333333333\n",
            "Epoch  476\n",
            "Train Loss:  2.9726366996765137\n",
            "Test Loss:  4.242786407470703\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  477\n",
            "Train Loss:  2.9718096256256104\n",
            "Test Loss:  4.242870330810547\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  478\n",
            "Train Loss:  2.9709856510162354\n",
            "Test Loss:  4.242954254150391\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  479\n",
            "Train Loss:  2.9701647758483887\n",
            "Test Loss:  4.243038177490234\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  480\n",
            "Train Loss:  2.969346284866333\n",
            "Test Loss:  4.243122100830078\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  481\n",
            "Train Loss:  2.968531608581543\n",
            "Test Loss:  4.243206977844238\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  482\n",
            "Train Loss:  2.967719554901123\n",
            "Test Loss:  4.243291854858398\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  483\n",
            "Train Loss:  2.966909646987915\n",
            "Test Loss:  4.2433762550354\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  484\n",
            "Train Loss:  2.966102123260498\n",
            "Test Loss:  4.243460655212402\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  485\n",
            "Train Loss:  2.9652984142303467\n",
            "Test Loss:  4.2435407638549805\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  486\n",
            "Train Loss:  2.96449613571167\n",
            "Test Loss:  4.243619441986084\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  487\n",
            "Train Loss:  2.9636969566345215\n",
            "Test Loss:  4.243698596954346\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  488\n",
            "Train Loss:  2.9629011154174805\n",
            "Test Loss:  4.243778228759766\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  489\n",
            "Train Loss:  2.9621095657348633\n",
            "Test Loss:  4.243856906890869\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  490\n",
            "Train Loss:  2.9613213539123535\n",
            "Test Loss:  4.243939399719238\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  491\n",
            "Train Loss:  2.9605348110198975\n",
            "Test Loss:  4.244021415710449\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  492\n",
            "Train Loss:  2.959751605987549\n",
            "Test Loss:  4.244102954864502\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  493\n",
            "Train Loss:  2.958970785140991\n",
            "Test Loss:  4.244184970855713\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  494\n",
            "Train Loss:  2.95819091796875\n",
            "Test Loss:  4.244263648986816\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  495\n",
            "Train Loss:  2.9574155807495117\n",
            "Test Loss:  4.244342803955078\n",
            "Recall : 0.35428571428571426\n",
            "Epoch  496\n",
            "Train Loss:  2.9566423892974854\n",
            "Test Loss:  4.244421005249023\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  497\n",
            "Train Loss:  2.955872058868408\n",
            "Test Loss:  4.244498252868652\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  498\n",
            "Train Loss:  2.955104351043701\n",
            "Test Loss:  4.244575500488281\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  499\n",
            "Train Loss:  2.954339027404785\n",
            "Test Loss:  4.244653701782227\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  500\n",
            "Train Loss:  2.9535770416259766\n",
            "Test Loss:  4.244732856750488\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  501\n",
            "Train Loss:  2.9528164863586426\n",
            "Test Loss:  4.24481201171875\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  502\n",
            "Train Loss:  2.9520578384399414\n",
            "Test Loss:  4.244892120361328\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  503\n",
            "Train Loss:  2.9513015747070312\n",
            "Test Loss:  4.244970321655273\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  504\n",
            "Train Loss:  2.9505457878112793\n",
            "Test Loss:  4.245048999786377\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  505\n",
            "Train Loss:  2.9497928619384766\n",
            "Test Loss:  4.2451276779174805\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  506\n",
            "Train Loss:  2.9490418434143066\n",
            "Test Loss:  4.245207786560059\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  507\n",
            "Train Loss:  2.9482932090759277\n",
            "Test Loss:  4.245287895202637\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  508\n",
            "Train Loss:  2.947547435760498\n",
            "Test Loss:  4.245368003845215\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  509\n",
            "Train Loss:  2.946803569793701\n",
            "Test Loss:  4.245449066162109\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  510\n",
            "Train Loss:  2.946061611175537\n",
            "Test Loss:  4.245530128479004\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  511\n",
            "Train Loss:  2.945321559906006\n",
            "Test Loss:  4.245610237121582\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  512\n",
            "Train Loss:  2.944582462310791\n",
            "Test Loss:  4.245689868927002\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  513\n",
            "Train Loss:  2.943845272064209\n",
            "Test Loss:  4.245769500732422\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  514\n",
            "Train Loss:  2.9431099891662598\n",
            "Test Loss:  4.245850563049316\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  515\n",
            "Train Loss:  2.9423770904541016\n",
            "Test Loss:  4.245929718017578\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  516\n",
            "Train Loss:  2.9416465759277344\n",
            "Test Loss:  4.24600887298584\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  517\n",
            "Train Loss:  2.940918207168579\n",
            "Test Loss:  4.246087074279785\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  518\n",
            "Train Loss:  2.9401917457580566\n",
            "Test Loss:  4.246164321899414\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  519\n",
            "Train Loss:  2.939467430114746\n",
            "Test Loss:  4.246240615844727\n",
            "Recall : 0.35523809523809524\n",
            "Epoch  520\n",
            "Train Loss:  2.9387450218200684\n",
            "Test Loss:  4.246315956115723\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  521\n",
            "Train Loss:  2.9380249977111816\n",
            "Test Loss:  4.246392250061035\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  522\n",
            "Train Loss:  2.937307119369507\n",
            "Test Loss:  4.246470928192139\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  523\n",
            "Train Loss:  2.936591148376465\n",
            "Test Loss:  4.246548652648926\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  524\n",
            "Train Loss:  2.935878276824951\n",
            "Test Loss:  4.246626853942871\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  525\n",
            "Train Loss:  2.9351682662963867\n",
            "Test Loss:  4.246706008911133\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  526\n",
            "Train Loss:  2.934459686279297\n",
            "Test Loss:  4.246786117553711\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  527\n",
            "Train Loss:  2.933753490447998\n",
            "Test Loss:  4.246866703033447\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  528\n",
            "Train Loss:  2.933049440383911\n",
            "Test Loss:  4.246947765350342\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  529\n",
            "Train Loss:  2.9323463439941406\n",
            "Test Loss:  4.247026443481445\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  530\n",
            "Train Loss:  2.9316468238830566\n",
            "Test Loss:  4.247104644775391\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  531\n",
            "Train Loss:  2.9309496879577637\n",
            "Test Loss:  4.247180461883545\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  532\n",
            "Train Loss:  2.930253744125366\n",
            "Test Loss:  4.247256755828857\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  533\n",
            "Train Loss:  2.9295597076416016\n",
            "Test Loss:  4.247335433959961\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  534\n",
            "Train Loss:  2.928867816925049\n",
            "Test Loss:  4.24741268157959\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  535\n",
            "Train Loss:  2.928177833557129\n",
            "Test Loss:  4.247489929199219\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  536\n",
            "Train Loss:  2.9274892807006836\n",
            "Test Loss:  4.247567176818848\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  537\n",
            "Train Loss:  2.9268033504486084\n",
            "Test Loss:  4.247644424438477\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  538\n",
            "Train Loss:  2.926119089126587\n",
            "Test Loss:  4.247720718383789\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  539\n",
            "Train Loss:  2.9254374504089355\n",
            "Test Loss:  4.247798919677734\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  540\n",
            "Train Loss:  2.9247565269470215\n",
            "Test Loss:  4.2478742599487305\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  541\n",
            "Train Loss:  2.9240779876708984\n",
            "Test Loss:  4.247947692871094\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  542\n",
            "Train Loss:  2.9234018325805664\n",
            "Test Loss:  4.248022079467773\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  543\n",
            "Train Loss:  2.922727108001709\n",
            "Test Loss:  4.248095989227295\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  544\n",
            "Train Loss:  2.9220545291900635\n",
            "Test Loss:  4.2481689453125\n",
            "Recall : 0.35619047619047617\n",
            "Epoch  545\n",
            "Train Loss:  2.9213831424713135\n",
            "Test Loss:  4.248242378234863\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  546\n",
            "Train Loss:  2.920714855194092\n",
            "Test Loss:  4.24831485748291\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  547\n",
            "Train Loss:  2.9200477600097656\n",
            "Test Loss:  4.248389720916748\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  548\n",
            "Train Loss:  2.9193837642669678\n",
            "Test Loss:  4.248464584350586\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  549\n",
            "Train Loss:  2.9187216758728027\n",
            "Test Loss:  4.248539924621582\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  550\n",
            "Train Loss:  2.9180612564086914\n",
            "Test Loss:  4.248616695404053\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  551\n",
            "Train Loss:  2.917402744293213\n",
            "Test Loss:  4.24869441986084\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  552\n",
            "Train Loss:  2.916746139526367\n",
            "Test Loss:  4.248773097991943\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  553\n",
            "Train Loss:  2.9160919189453125\n",
            "Test Loss:  4.248851776123047\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  554\n",
            "Train Loss:  2.9154391288757324\n",
            "Test Loss:  4.248930931091309\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  555\n",
            "Train Loss:  2.9147887229919434\n",
            "Test Loss:  4.249007225036621\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  556\n",
            "Train Loss:  2.914140224456787\n",
            "Test Loss:  4.249083995819092\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  557\n",
            "Train Loss:  2.9134938716888428\n",
            "Test Loss:  4.249159812927246\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  558\n",
            "Train Loss:  2.9128506183624268\n",
            "Test Loss:  4.249236106872559\n",
            "Recall : 0.36\n",
            "Epoch  559\n",
            "Train Loss:  2.9122090339660645\n",
            "Test Loss:  4.2493109703063965\n",
            "Recall : 0.36\n",
            "Epoch  560\n",
            "Train Loss:  2.9115688800811768\n",
            "Test Loss:  4.249387741088867\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  561\n",
            "Train Loss:  2.910930633544922\n",
            "Test Loss:  4.249463081359863\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  562\n",
            "Train Loss:  2.9102940559387207\n",
            "Test Loss:  4.249537467956543\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  563\n",
            "Train Loss:  2.9096598625183105\n",
            "Test Loss:  4.249608993530273\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  564\n",
            "Train Loss:  2.909027099609375\n",
            "Test Loss:  4.249678611755371\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  565\n",
            "Train Loss:  2.9083967208862305\n",
            "Test Loss:  4.249748229980469\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  566\n",
            "Train Loss:  2.9077675342559814\n",
            "Test Loss:  4.249817848205566\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  567\n",
            "Train Loss:  2.9071412086486816\n",
            "Test Loss:  4.2498860359191895\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  568\n",
            "Train Loss:  2.9065158367156982\n",
            "Test Loss:  4.2499542236328125\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  569\n",
            "Train Loss:  2.905892848968506\n",
            "Test Loss:  4.250022888183594\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  570\n",
            "Train Loss:  2.9052720069885254\n",
            "Test Loss:  4.250091552734375\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  571\n",
            "Train Loss:  2.9046530723571777\n",
            "Test Loss:  4.25015926361084\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  572\n",
            "Train Loss:  2.9040350914001465\n",
            "Test Loss:  4.250227928161621\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  573\n",
            "Train Loss:  2.903419017791748\n",
            "Test Loss:  4.250295639038086\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  574\n",
            "Train Loss:  2.9028053283691406\n",
            "Test Loss:  4.250362873077393\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  575\n",
            "Train Loss:  2.9021921157836914\n",
            "Test Loss:  4.250431060791016\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  576\n",
            "Train Loss:  2.901580810546875\n",
            "Test Loss:  4.2504987716674805\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  577\n",
            "Train Loss:  2.900970697402954\n",
            "Test Loss:  4.250566482543945\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  578\n",
            "Train Loss:  2.900362014770508\n",
            "Test Loss:  4.2506327629089355\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  579\n",
            "Train Loss:  2.899754762649536\n",
            "Test Loss:  4.2507004737854\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  580\n",
            "Train Loss:  2.899148941040039\n",
            "Test Loss:  4.250767707824707\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  581\n",
            "Train Loss:  2.8985438346862793\n",
            "Test Loss:  4.250835418701172\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  582\n",
            "Train Loss:  2.8979411125183105\n",
            "Test Loss:  4.250904083251953\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  583\n",
            "Train Loss:  2.897338628768921\n",
            "Test Loss:  4.250971794128418\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  584\n",
            "Train Loss:  2.8967385292053223\n",
            "Test Loss:  4.251040935516357\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  585\n",
            "Train Loss:  2.896138906478882\n",
            "Test Loss:  4.251108646392822\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  586\n",
            "Train Loss:  2.8955416679382324\n",
            "Test Loss:  4.25117826461792\n",
            "Recall : 0.35714285714285715\n",
            "Epoch  587\n",
            "Train Loss:  2.8949451446533203\n",
            "Test Loss:  4.251249313354492\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  588\n",
            "Train Loss:  2.89435076713562\n",
            "Test Loss:  4.2513203620910645\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  589\n",
            "Train Loss:  2.8937575817108154\n",
            "Test Loss:  4.251391887664795\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  590\n",
            "Train Loss:  2.8931655883789062\n",
            "Test Loss:  4.251464366912842\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  591\n",
            "Train Loss:  2.892575740814209\n",
            "Test Loss:  4.251538276672363\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  592\n",
            "Train Loss:  2.89198637008667\n",
            "Test Loss:  4.251612663269043\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  593\n",
            "Train Loss:  2.8913984298706055\n",
            "Test Loss:  4.251687049865723\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  594\n",
            "Train Loss:  2.8908119201660156\n",
            "Test Loss:  4.251760482788086\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  595\n",
            "Train Loss:  2.890225410461426\n",
            "Test Loss:  4.251835823059082\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  596\n",
            "Train Loss:  2.8896405696868896\n",
            "Test Loss:  4.251911163330078\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  597\n",
            "Train Loss:  2.8890559673309326\n",
            "Test Loss:  4.251988410949707\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  598\n",
            "Train Loss:  2.8884739875793457\n",
            "Test Loss:  4.252065658569336\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  599\n",
            "Train Loss:  2.887892484664917\n",
            "Test Loss:  4.252144813537598\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  600\n",
            "Train Loss:  2.887312889099121\n",
            "Test Loss:  4.252223968505859\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  601\n",
            "Train Loss:  2.8867344856262207\n",
            "Test Loss:  4.2523040771484375\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  602\n",
            "Train Loss:  2.8861565589904785\n",
            "Test Loss:  4.252384185791016\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  603\n",
            "Train Loss:  2.885580539703369\n",
            "Test Loss:  4.25246524810791\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  604\n",
            "Train Loss:  2.8850045204162598\n",
            "Test Loss:  4.2525458335876465\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  605\n",
            "Train Loss:  2.884430408477783\n",
            "Test Loss:  4.252629280090332\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  606\n",
            "Train Loss:  2.883857250213623\n",
            "Test Loss:  4.252712249755859\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  607\n",
            "Train Loss:  2.8832855224609375\n",
            "Test Loss:  4.252796173095703\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  608\n",
            "Train Loss:  2.88271427154541\n",
            "Test Loss:  4.252880096435547\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  609\n",
            "Train Loss:  2.8821444511413574\n",
            "Test Loss:  4.252964019775391\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  610\n",
            "Train Loss:  2.881574869155884\n",
            "Test Loss:  4.253050327301025\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  611\n",
            "Train Loss:  2.881007671356201\n",
            "Test Loss:  4.253137588500977\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  612\n",
            "Train Loss:  2.880441188812256\n",
            "Test Loss:  4.253226280212402\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  613\n",
            "Train Loss:  2.8798768520355225\n",
            "Test Loss:  4.2533159255981445\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  614\n",
            "Train Loss:  2.8793139457702637\n",
            "Test Loss:  4.2534074783325195\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  615\n",
            "Train Loss:  2.8787522315979004\n",
            "Test Loss:  4.253499507904053\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  616\n",
            "Train Loss:  2.8781909942626953\n",
            "Test Loss:  4.253592014312744\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  617\n",
            "Train Loss:  2.877631187438965\n",
            "Test Loss:  4.25368595123291\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  618\n",
            "Train Loss:  2.87707257270813\n",
            "Test Loss:  4.253780841827393\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  619\n",
            "Train Loss:  2.8765149116516113\n",
            "Test Loss:  4.253873825073242\n",
            "Recall : 0.35904761904761906\n",
            "Epoch  620\n",
            "Train Loss:  2.8759586811065674\n",
            "Test Loss:  4.253967761993408\n",
            "Recall : 0.36\n",
            "Epoch  621\n",
            "Train Loss:  2.875403881072998\n",
            "Test Loss:  4.254062175750732\n",
            "Recall : 0.36\n",
            "Epoch  622\n",
            "Train Loss:  2.874850273132324\n",
            "Test Loss:  4.25415563583374\n",
            "Recall : 0.36\n",
            "Epoch  623\n",
            "Train Loss:  2.874298095703125\n",
            "Test Loss:  4.254250526428223\n",
            "Recall : 0.36\n",
            "Epoch  624\n",
            "Train Loss:  2.8737473487854004\n",
            "Test Loss:  4.25434684753418\n",
            "Recall : 0.36\n",
            "Epoch  625\n",
            "Train Loss:  2.873197078704834\n",
            "Test Loss:  4.25444221496582\n",
            "Recall : 0.36\n",
            "Epoch  626\n",
            "Train Loss:  2.8726491928100586\n",
            "Test Loss:  4.254538536071777\n",
            "Recall : 0.36\n",
            "Epoch  627\n",
            "Train Loss:  2.8721017837524414\n",
            "Test Loss:  4.254635810852051\n",
            "Recall : 0.36\n",
            "Epoch  628\n",
            "Train Loss:  2.871556282043457\n",
            "Test Loss:  4.254733085632324\n",
            "Recall : 0.36\n",
            "Epoch  629\n",
            "Train Loss:  2.871011734008789\n",
            "Test Loss:  4.254830837249756\n",
            "Recall : 0.36\n",
            "Epoch  630\n",
            "Train Loss:  2.8704676628112793\n",
            "Test Loss:  4.25493049621582\n",
            "Recall : 0.36\n",
            "Epoch  631\n",
            "Train Loss:  2.869925022125244\n",
            "Test Loss:  4.255030632019043\n",
            "Recall : 0.36\n",
            "Epoch  632\n",
            "Train Loss:  2.869384765625\n",
            "Test Loss:  4.255132675170898\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  633\n",
            "Train Loss:  2.868844747543335\n",
            "Test Loss:  4.25523567199707\n",
            "Recall : 0.36\n",
            "Epoch  634\n",
            "Train Loss:  2.8683061599731445\n",
            "Test Loss:  4.255339622497559\n",
            "Recall : 0.36\n",
            "Epoch  635\n",
            "Train Loss:  2.867769718170166\n",
            "Test Loss:  4.2554426193237305\n",
            "Recall : 0.36\n",
            "Epoch  636\n",
            "Train Loss:  2.8672337532043457\n",
            "Test Loss:  4.255545139312744\n",
            "Recall : 0.36\n",
            "Epoch  637\n",
            "Train Loss:  2.86669921875\n",
            "Test Loss:  4.255647659301758\n",
            "Recall : 0.36\n",
            "Epoch  638\n",
            "Train Loss:  2.8661651611328125\n",
            "Test Loss:  4.255751609802246\n",
            "Recall : 0.36\n",
            "Epoch  639\n",
            "Train Loss:  2.8656320571899414\n",
            "Test Loss:  4.255857467651367\n",
            "Recall : 0.36\n",
            "Epoch  640\n",
            "Train Loss:  2.865100860595703\n",
            "Test Loss:  4.255965232849121\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  641\n",
            "Train Loss:  2.8645713329315186\n",
            "Test Loss:  4.256070137023926\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  642\n",
            "Train Loss:  2.8640429973602295\n",
            "Test Loss:  4.256175994873047\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  643\n",
            "Train Loss:  2.8635168075561523\n",
            "Test Loss:  4.256281852722168\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  644\n",
            "Train Loss:  2.8629918098449707\n",
            "Test Loss:  4.256389141082764\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  645\n",
            "Train Loss:  2.8624682426452637\n",
            "Test Loss:  4.256496429443359\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  646\n",
            "Train Loss:  2.8619461059570312\n",
            "Test Loss:  4.256604194641113\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  647\n",
            "Train Loss:  2.8614249229431152\n",
            "Test Loss:  4.256711959838867\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  648\n",
            "Train Loss:  2.860905170440674\n",
            "Test Loss:  4.2568206787109375\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  649\n",
            "Train Loss:  2.860386371612549\n",
            "Test Loss:  4.256929397583008\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  650\n",
            "Train Loss:  2.859868049621582\n",
            "Test Loss:  4.257038116455078\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  651\n",
            "Train Loss:  2.8593506813049316\n",
            "Test Loss:  4.257148742675781\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  652\n",
            "Train Loss:  2.858835220336914\n",
            "Test Loss:  4.257260322570801\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  653\n",
            "Train Loss:  2.85832142829895\n",
            "Test Loss:  4.25737190246582\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  654\n",
            "Train Loss:  2.857809543609619\n",
            "Test Loss:  4.257482528686523\n",
            "Recall : 0.36\n",
            "Epoch  655\n",
            "Train Loss:  2.8572983741760254\n",
            "Test Loss:  4.257593154907227\n",
            "Recall : 0.36\n",
            "Epoch  656\n",
            "Train Loss:  2.8567886352539062\n",
            "Test Loss:  4.2577056884765625\n",
            "Recall : 0.36\n",
            "Epoch  657\n",
            "Train Loss:  2.8562800884246826\n",
            "Test Loss:  4.25781774520874\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  658\n",
            "Train Loss:  2.8557729721069336\n",
            "Test Loss:  4.257931709289551\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  659\n",
            "Train Loss:  2.85526704788208\n",
            "Test Loss:  4.258047580718994\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  660\n",
            "Train Loss:  2.854762315750122\n",
            "Test Loss:  4.2581634521484375\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  661\n",
            "Train Loss:  2.854259490966797\n",
            "Test Loss:  4.258279800415039\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  662\n",
            "Train Loss:  2.853757858276367\n",
            "Test Loss:  4.258398056030273\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  663\n",
            "Train Loss:  2.853257656097412\n",
            "Test Loss:  4.258516788482666\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  664\n",
            "Train Loss:  2.8527588844299316\n",
            "Test Loss:  4.258635520935059\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  665\n",
            "Train Loss:  2.8522613048553467\n",
            "Test Loss:  4.258756637573242\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  666\n",
            "Train Loss:  2.8517656326293945\n",
            "Test Loss:  4.258877277374268\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  667\n",
            "Train Loss:  2.851271629333496\n",
            "Test Loss:  4.25899600982666\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  668\n",
            "Train Loss:  2.850778579711914\n",
            "Test Loss:  4.25911808013916\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  669\n",
            "Train Loss:  2.8502869606018066\n",
            "Test Loss:  4.2592387199401855\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  670\n",
            "Train Loss:  2.8497958183288574\n",
            "Test Loss:  4.259361743927002\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  671\n",
            "Train Loss:  2.8493056297302246\n",
            "Test Loss:  4.25948429107666\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  672\n",
            "Train Loss:  2.848816394805908\n",
            "Test Loss:  4.259609699249268\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  673\n",
            "Train Loss:  2.8483290672302246\n",
            "Test Loss:  4.259735107421875\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  674\n",
            "Train Loss:  2.8478431701660156\n",
            "Test Loss:  4.259861946105957\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  675\n",
            "Train Loss:  2.847358226776123\n",
            "Test Loss:  4.259988307952881\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  676\n",
            "Train Loss:  2.8468756675720215\n",
            "Test Loss:  4.260114669799805\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  677\n",
            "Train Loss:  2.8463940620422363\n",
            "Test Loss:  4.260241508483887\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  678\n",
            "Train Loss:  2.8459134101867676\n",
            "Test Loss:  4.260366916656494\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  679\n",
            "Train Loss:  2.8454339504241943\n",
            "Test Loss:  4.260492324829102\n",
            "Recall : 0.36\n",
            "Epoch  680\n",
            "Train Loss:  2.8449554443359375\n",
            "Test Loss:  4.260618209838867\n",
            "Recall : 0.36\n",
            "Epoch  681\n",
            "Train Loss:  2.844477415084839\n",
            "Test Loss:  4.260744094848633\n",
            "Recall : 0.36\n",
            "Epoch  682\n",
            "Train Loss:  2.8440005779266357\n",
            "Test Loss:  4.2608723640441895\n",
            "Recall : 0.36\n",
            "Epoch  683\n",
            "Train Loss:  2.8435258865356445\n",
            "Test Loss:  4.261000633239746\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  684\n",
            "Train Loss:  2.8430516719818115\n",
            "Test Loss:  4.2611284255981445\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  685\n",
            "Train Loss:  2.842578887939453\n",
            "Test Loss:  4.261257171630859\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  686\n",
            "Train Loss:  2.8421072959899902\n",
            "Test Loss:  4.261387348175049\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  687\n",
            "Train Loss:  2.8416366577148438\n",
            "Test Loss:  4.261516571044922\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  688\n",
            "Train Loss:  2.841167449951172\n",
            "Test Loss:  4.261645793914795\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  689\n",
            "Train Loss:  2.840700626373291\n",
            "Test Loss:  4.261775016784668\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  690\n",
            "Train Loss:  2.8402347564697266\n",
            "Test Loss:  4.261906623840332\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  691\n",
            "Train Loss:  2.8397696018218994\n",
            "Test Loss:  4.26203727722168\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  692\n",
            "Train Loss:  2.839306354522705\n",
            "Test Loss:  4.262168884277344\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  693\n",
            "Train Loss:  2.83884334564209\n",
            "Test Loss:  4.262299537658691\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  694\n",
            "Train Loss:  2.8383820056915283\n",
            "Test Loss:  4.262430667877197\n",
            "Recall : 0.36095238095238097\n",
            "Epoch  695\n",
            "Train Loss:  2.837921619415283\n",
            "Test Loss:  4.262561321258545\n",
            "Recall : 0.36\n",
            "Epoch  696\n",
            "Train Loss:  2.8374621868133545\n",
            "Test Loss:  4.262690544128418\n",
            "Recall : 0.36\n",
            "Epoch  697\n",
            "Train Loss:  2.8370041847229004\n",
            "Test Loss:  4.262821197509766\n",
            "Recall : 0.36\n",
            "Epoch  698\n",
            "Train Loss:  2.8365468978881836\n",
            "Test Loss:  4.262951850891113\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  699\n",
            "Train Loss:  2.8360908031463623\n",
            "Test Loss:  4.263082504272461\n",
            "Recall : 0.3580952380952381\n",
            "Epoch  700\n",
            "Train Loss:  2.8356356620788574\n",
            "Test Loss:  4.26321268081665\n",
            "Recall : 0.3580952380952381\n",
            "\n",
            "0.3416367346938771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ff6b1dab425541d0ab96ad8dffdeeefa",
            "c22866bde0a84898bf1bc71d8de3d4e7",
            "e04b7897170944789f178ab1462b50d0",
            "b8f1a47694b8461eb164bfc41a2a2f3c",
            "7175536afef1490ca8e62d145e4e09cc",
            "f3ede31572344efaa2590ee1829b360f",
            "69d1d50d6108494cbc81c17db31b5161",
            "9c1de452cdb8431580c73b4101e2177c"
          ]
        },
        "id": "EDqQzOLSHsSx",
        "outputId": "6fcf601a-9cab-4455-e56a-54136741a8c7"
      },
      "source": [
        "run(path=\"resnet18.npy\",runs=1,epochs=100,k=1,temp=15,k=1,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff6b1dab425541d0ab96ad8dffdeeefa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.439766883850098\n",
            "Test Loss:  6.2475361824035645\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  2\n",
            "Train Loss:  7.370005130767822\n",
            "Test Loss:  6.216598987579346\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  3\n",
            "Train Loss:  7.301321506500244\n",
            "Test Loss:  6.186524391174316\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  4\n",
            "Train Loss:  7.233725547790527\n",
            "Test Loss:  6.1573872566223145\n",
            "Recall : 0.1219047619047619\n",
            "Epoch  5\n",
            "Train Loss:  7.167269706726074\n",
            "Test Loss:  6.1291656494140625\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  6\n",
            "Train Loss:  7.101993083953857\n",
            "Test Loss:  6.1018595695495605\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  7\n",
            "Train Loss:  7.03794002532959\n",
            "Test Loss:  6.075542449951172\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  8\n",
            "Train Loss:  6.975141525268555\n",
            "Test Loss:  6.0502142906188965\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  9\n",
            "Train Loss:  6.9136199951171875\n",
            "Test Loss:  6.025838851928711\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  10\n",
            "Train Loss:  6.853377342224121\n",
            "Test Loss:  6.0024003982543945\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  11\n",
            "Train Loss:  6.79440975189209\n",
            "Test Loss:  5.979909896850586\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  12\n",
            "Train Loss:  6.736724376678467\n",
            "Test Loss:  5.95836067199707\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  13\n",
            "Train Loss:  6.6803059577941895\n",
            "Test Loss:  5.937719345092773\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  14\n",
            "Train Loss:  6.625123977661133\n",
            "Test Loss:  5.917935371398926\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  15\n",
            "Train Loss:  6.571161270141602\n",
            "Test Loss:  5.8990373611450195\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  16\n",
            "Train Loss:  6.518409252166748\n",
            "Test Loss:  5.8809814453125\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  17\n",
            "Train Loss:  6.466839790344238\n",
            "Test Loss:  5.863744258880615\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  18\n",
            "Train Loss:  6.416408061981201\n",
            "Test Loss:  5.8473005294799805\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  19\n",
            "Train Loss:  6.367092132568359\n",
            "Test Loss:  5.831618309020996\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  20\n",
            "Train Loss:  6.318824291229248\n",
            "Test Loss:  5.8166704177856445\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  21\n",
            "Train Loss:  6.271588325500488\n",
            "Test Loss:  5.802413463592529\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  22\n",
            "Train Loss:  6.225353240966797\n",
            "Test Loss:  5.788821220397949\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  23\n",
            "Train Loss:  6.18006706237793\n",
            "Test Loss:  5.7758378982543945\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  24\n",
            "Train Loss:  6.1356916427612305\n",
            "Test Loss:  5.763452529907227\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  25\n",
            "Train Loss:  6.092206001281738\n",
            "Test Loss:  5.751640319824219\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  26\n",
            "Train Loss:  6.049577713012695\n",
            "Test Loss:  5.740349769592285\n",
            "Recall : 0.14\n",
            "Epoch  27\n",
            "Train Loss:  6.007770538330078\n",
            "Test Loss:  5.729524612426758\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  28\n",
            "Train Loss:  5.966752529144287\n",
            "Test Loss:  5.719161033630371\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  29\n",
            "Train Loss:  5.926496982574463\n",
            "Test Loss:  5.709254264831543\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  30\n",
            "Train Loss:  5.886957168579102\n",
            "Test Loss:  5.699812889099121\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  31\n",
            "Train Loss:  5.848100185394287\n",
            "Test Loss:  5.690807342529297\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  32\n",
            "Train Loss:  5.809921741485596\n",
            "Test Loss:  5.682165145874023\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  33\n",
            "Train Loss:  5.772398471832275\n",
            "Test Loss:  5.673880100250244\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  34\n",
            "Train Loss:  5.735507965087891\n",
            "Test Loss:  5.665934085845947\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  35\n",
            "Train Loss:  5.699243068695068\n",
            "Test Loss:  5.658327102661133\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  36\n",
            "Train Loss:  5.663578987121582\n",
            "Test Loss:  5.651043891906738\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  37\n",
            "Train Loss:  5.628495693206787\n",
            "Test Loss:  5.644076347351074\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  38\n",
            "Train Loss:  5.593976020812988\n",
            "Test Loss:  5.637402534484863\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  39\n",
            "Train Loss:  5.559996604919434\n",
            "Test Loss:  5.631013870239258\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  40\n",
            "Train Loss:  5.526535987854004\n",
            "Test Loss:  5.624899864196777\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  41\n",
            "Train Loss:  5.493578910827637\n",
            "Test Loss:  5.6190290451049805\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  42\n",
            "Train Loss:  5.461127281188965\n",
            "Test Loss:  5.613385200500488\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  43\n",
            "Train Loss:  5.429170608520508\n",
            "Test Loss:  5.607958793640137\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  44\n",
            "Train Loss:  5.397678375244141\n",
            "Test Loss:  5.6027374267578125\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  45\n",
            "Train Loss:  5.366642951965332\n",
            "Test Loss:  5.597702503204346\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  46\n",
            "Train Loss:  5.33607292175293\n",
            "Test Loss:  5.592866897583008\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  47\n",
            "Train Loss:  5.305952072143555\n",
            "Test Loss:  5.588208198547363\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  48\n",
            "Train Loss:  5.276272296905518\n",
            "Test Loss:  5.583748817443848\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  49\n",
            "Train Loss:  5.247030258178711\n",
            "Test Loss:  5.579464912414551\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  50\n",
            "Train Loss:  5.218209266662598\n",
            "Test Loss:  5.575347900390625\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  51\n",
            "Train Loss:  5.189797401428223\n",
            "Test Loss:  5.571403503417969\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  52\n",
            "Train Loss:  5.161798477172852\n",
            "Test Loss:  5.567636489868164\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  53\n",
            "Train Loss:  5.134203910827637\n",
            "Test Loss:  5.564029693603516\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  54\n",
            "Train Loss:  5.106998920440674\n",
            "Test Loss:  5.560596942901611\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  55\n",
            "Train Loss:  5.080185890197754\n",
            "Test Loss:  5.5573320388793945\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  56\n",
            "Train Loss:  5.053757190704346\n",
            "Test Loss:  5.554200649261475\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  57\n",
            "Train Loss:  5.027700424194336\n",
            "Test Loss:  5.551228046417236\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  58\n",
            "Train Loss:  5.002007484436035\n",
            "Test Loss:  5.548400402069092\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  59\n",
            "Train Loss:  4.976682662963867\n",
            "Test Loss:  5.545733451843262\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  60\n",
            "Train Loss:  4.951725006103516\n",
            "Test Loss:  5.543220520019531\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  61\n",
            "Train Loss:  4.9271159172058105\n",
            "Test Loss:  5.540831565856934\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  62\n",
            "Train Loss:  4.902853488922119\n",
            "Test Loss:  5.538541316986084\n",
            "Recall : 0.16\n",
            "Epoch  63\n",
            "Train Loss:  4.878932952880859\n",
            "Test Loss:  5.536325454711914\n",
            "Recall : 0.16\n",
            "Epoch  64\n",
            "Train Loss:  4.855341911315918\n",
            "Test Loss:  5.534207344055176\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  65\n",
            "Train Loss:  4.832079887390137\n",
            "Test Loss:  5.5321784019470215\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  66\n",
            "Train Loss:  4.809148788452148\n",
            "Test Loss:  5.530251502990723\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  67\n",
            "Train Loss:  4.786550998687744\n",
            "Test Loss:  5.528423309326172\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  68\n",
            "Train Loss:  4.764264106750488\n",
            "Test Loss:  5.526681423187256\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  69\n",
            "Train Loss:  4.742289066314697\n",
            "Test Loss:  5.5250349044799805\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  70\n",
            "Train Loss:  4.720622539520264\n",
            "Test Loss:  5.523468971252441\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  71\n",
            "Train Loss:  4.699254989624023\n",
            "Test Loss:  5.521980285644531\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  72\n",
            "Train Loss:  4.678182601928711\n",
            "Test Loss:  5.520586013793945\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  73\n",
            "Train Loss:  4.657402038574219\n",
            "Test Loss:  5.519272804260254\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  74\n",
            "Train Loss:  4.636904716491699\n",
            "Test Loss:  5.518044471740723\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  75\n",
            "Train Loss:  4.616689682006836\n",
            "Test Loss:  5.516904830932617\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  76\n",
            "Train Loss:  4.596752166748047\n",
            "Test Loss:  5.51585578918457\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  77\n",
            "Train Loss:  4.577089309692383\n",
            "Test Loss:  5.514902114868164\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  78\n",
            "Train Loss:  4.557694435119629\n",
            "Test Loss:  5.514015197753906\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  79\n",
            "Train Loss:  4.538565635681152\n",
            "Test Loss:  5.513187408447266\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  80\n",
            "Train Loss:  4.519710540771484\n",
            "Test Loss:  5.512434959411621\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  81\n",
            "Train Loss:  4.501115322113037\n",
            "Test Loss:  5.511753559112549\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  82\n",
            "Train Loss:  4.482767105102539\n",
            "Test Loss:  5.511128902435303\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  83\n",
            "Train Loss:  4.464669704437256\n",
            "Test Loss:  5.510575294494629\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  84\n",
            "Train Loss:  4.446815490722656\n",
            "Test Loss:  5.510087013244629\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  85\n",
            "Train Loss:  4.429203033447266\n",
            "Test Loss:  5.50966739654541\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  86\n",
            "Train Loss:  4.411840438842773\n",
            "Test Loss:  5.509311199188232\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  87\n",
            "Train Loss:  4.394724369049072\n",
            "Test Loss:  5.509003639221191\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  88\n",
            "Train Loss:  4.377840995788574\n",
            "Test Loss:  5.508753299713135\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  89\n",
            "Train Loss:  4.361188888549805\n",
            "Test Loss:  5.508545875549316\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  90\n",
            "Train Loss:  4.34477424621582\n",
            "Test Loss:  5.5083770751953125\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  91\n",
            "Train Loss:  4.328587532043457\n",
            "Test Loss:  5.50825309753418\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  92\n",
            "Train Loss:  4.312626361846924\n",
            "Test Loss:  5.508181571960449\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  93\n",
            "Train Loss:  4.296880722045898\n",
            "Test Loss:  5.508152008056641\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  94\n",
            "Train Loss:  4.281341552734375\n",
            "Test Loss:  5.508151531219482\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  95\n",
            "Train Loss:  4.2660112380981445\n",
            "Test Loss:  5.5081787109375\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  96\n",
            "Train Loss:  4.250885009765625\n",
            "Test Loss:  5.508246421813965\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  97\n",
            "Train Loss:  4.235958576202393\n",
            "Test Loss:  5.508354663848877\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  98\n",
            "Train Loss:  4.221236228942871\n",
            "Test Loss:  5.508511543273926\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  99\n",
            "Train Loss:  4.206709861755371\n",
            "Test Loss:  5.508703231811523\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  100\n",
            "Train Loss:  4.192368507385254\n",
            "Test Loss:  5.508930206298828\n",
            "Recall : 0.16952380952380952\n",
            "\n",
            "0.1508476190476191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "553693c3d2784b62940cd2a830e9c778",
            "9eaf98d108df45fdbc67bbb52939f7d7",
            "7b7cbefe266e486482bae6332c97ee25",
            "7efc9c34277448119995fcc87e853224",
            "605b0e4961514d42925fe7ed41b787ae",
            "83a17f5962d34dc8acd55fce8de172d1",
            "d90c5cadcbaf45d0873c0c520a2d63d3",
            "4dd6bfe992dd4ecaac0c292c02091cc2"
          ]
        },
        "id": "vP5ayGqFLXFq",
        "outputId": "bf8d200e-165f-4f20-f074-e81562caba3e"
      },
      "source": [
        "run(path=\"resnet18.npy\",runs=1,epochs=700,k=1,temp=15,type=2,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "553693c3d2784b62940cd2a830e9c778",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.4062628746032715\n",
            "Test Loss:  6.331142425537109\n",
            "Recall : 0.11714285714285715\n",
            "Epoch  2\n",
            "Train Loss:  7.337254524230957\n",
            "Test Loss:  6.299615859985352\n",
            "Recall : 0.11714285714285715\n",
            "Epoch  3\n",
            "Train Loss:  7.271571159362793\n",
            "Test Loss:  6.268995761871338\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  4\n",
            "Train Loss:  7.2073469161987305\n",
            "Test Loss:  6.239062786102295\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  5\n",
            "Train Loss:  7.143993377685547\n",
            "Test Loss:  6.209712028503418\n",
            "Recall : 0.11619047619047619\n",
            "Epoch  6\n",
            "Train Loss:  7.08131217956543\n",
            "Test Loss:  6.180895805358887\n",
            "Recall : 0.11619047619047619\n",
            "Epoch  7\n",
            "Train Loss:  7.019209384918213\n",
            "Test Loss:  6.15268087387085\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  8\n",
            "Train Loss:  6.957712650299072\n",
            "Test Loss:  6.125058174133301\n",
            "Recall : 0.11904761904761904\n",
            "Epoch  9\n",
            "Train Loss:  6.896842002868652\n",
            "Test Loss:  6.098074436187744\n",
            "Recall : 0.11904761904761904\n",
            "Epoch  10\n",
            "Train Loss:  6.836660385131836\n",
            "Test Loss:  6.071798801422119\n",
            "Recall : 0.11904761904761904\n",
            "Epoch  11\n",
            "Train Loss:  6.777230262756348\n",
            "Test Loss:  6.04625129699707\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  12\n",
            "Train Loss:  6.7186102867126465\n",
            "Test Loss:  6.02149772644043\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  13\n",
            "Train Loss:  6.660855293273926\n",
            "Test Loss:  5.997592449188232\n",
            "Recall : 0.12285714285714286\n",
            "Epoch  14\n",
            "Train Loss:  6.604059219360352\n",
            "Test Loss:  5.974581718444824\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  15\n",
            "Train Loss:  6.548285007476807\n",
            "Test Loss:  5.9524688720703125\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  16\n",
            "Train Loss:  6.493581295013428\n",
            "Test Loss:  5.931268692016602\n",
            "Recall : 0.12571428571428572\n",
            "Epoch  17\n",
            "Train Loss:  6.439999580383301\n",
            "Test Loss:  5.910965919494629\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  18\n",
            "Train Loss:  6.387580394744873\n",
            "Test Loss:  5.891590595245361\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  19\n",
            "Train Loss:  6.336358070373535\n",
            "Test Loss:  5.87312126159668\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  20\n",
            "Train Loss:  6.286375522613525\n",
            "Test Loss:  5.855598449707031\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  21\n",
            "Train Loss:  6.237671852111816\n",
            "Test Loss:  5.838996887207031\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  22\n",
            "Train Loss:  6.190220832824707\n",
            "Test Loss:  5.823318004608154\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  23\n",
            "Train Loss:  6.144070625305176\n",
            "Test Loss:  5.808526992797852\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  24\n",
            "Train Loss:  6.099225044250488\n",
            "Test Loss:  5.794591426849365\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  25\n",
            "Train Loss:  6.055665493011475\n",
            "Test Loss:  5.781486511230469\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  26\n",
            "Train Loss:  6.013373851776123\n",
            "Test Loss:  5.769166946411133\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  27\n",
            "Train Loss:  5.972328186035156\n",
            "Test Loss:  5.757628440856934\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  28\n",
            "Train Loss:  5.932539939880371\n",
            "Test Loss:  5.746805191040039\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  29\n",
            "Train Loss:  5.893983364105225\n",
            "Test Loss:  5.7366414070129395\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  30\n",
            "Train Loss:  5.85664701461792\n",
            "Test Loss:  5.727180480957031\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  31\n",
            "Train Loss:  5.820469856262207\n",
            "Test Loss:  5.7183732986450195\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  32\n",
            "Train Loss:  5.785449981689453\n",
            "Test Loss:  5.710134029388428\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  33\n",
            "Train Loss:  5.7515459060668945\n",
            "Test Loss:  5.702445983886719\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  34\n",
            "Train Loss:  5.718745708465576\n",
            "Test Loss:  5.695250511169434\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  35\n",
            "Train Loss:  5.687002182006836\n",
            "Test Loss:  5.688460826873779\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  36\n",
            "Train Loss:  5.656296730041504\n",
            "Test Loss:  5.6821136474609375\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  37\n",
            "Train Loss:  5.626595497131348\n",
            "Test Loss:  5.676196098327637\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  38\n",
            "Train Loss:  5.597820281982422\n",
            "Test Loss:  5.670696258544922\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  39\n",
            "Train Loss:  5.569960594177246\n",
            "Test Loss:  5.665589332580566\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  40\n",
            "Train Loss:  5.542975425720215\n",
            "Test Loss:  5.660841464996338\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  41\n",
            "Train Loss:  5.516831398010254\n",
            "Test Loss:  5.656434059143066\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  42\n",
            "Train Loss:  5.491508483886719\n",
            "Test Loss:  5.652299880981445\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  43\n",
            "Train Loss:  5.466962814331055\n",
            "Test Loss:  5.648425102233887\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  44\n",
            "Train Loss:  5.443171501159668\n",
            "Test Loss:  5.644815444946289\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  45\n",
            "Train Loss:  5.420095443725586\n",
            "Test Loss:  5.641399383544922\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  46\n",
            "Train Loss:  5.397703170776367\n",
            "Test Loss:  5.638218402862549\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  47\n",
            "Train Loss:  5.375972270965576\n",
            "Test Loss:  5.635236740112305\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  48\n",
            "Train Loss:  5.35487174987793\n",
            "Test Loss:  5.632449150085449\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  49\n",
            "Train Loss:  5.334369659423828\n",
            "Test Loss:  5.62986946105957\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  50\n",
            "Train Loss:  5.314452171325684\n",
            "Test Loss:  5.627439498901367\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  51\n",
            "Train Loss:  5.295101642608643\n",
            "Test Loss:  5.625167369842529\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  52\n",
            "Train Loss:  5.276294708251953\n",
            "Test Loss:  5.62302303314209\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  53\n",
            "Train Loss:  5.257996559143066\n",
            "Test Loss:  5.620988845825195\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  54\n",
            "Train Loss:  5.240195274353027\n",
            "Test Loss:  5.619093894958496\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  55\n",
            "Train Loss:  5.222870826721191\n",
            "Test Loss:  5.61733341217041\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  56\n",
            "Train Loss:  5.206007957458496\n",
            "Test Loss:  5.615689277648926\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  57\n",
            "Train Loss:  5.189573287963867\n",
            "Test Loss:  5.614154815673828\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  58\n",
            "Train Loss:  5.173577308654785\n",
            "Test Loss:  5.612692832946777\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  59\n",
            "Train Loss:  5.157998561859131\n",
            "Test Loss:  5.611310958862305\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  60\n",
            "Train Loss:  5.142809867858887\n",
            "Test Loss:  5.61000394821167\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  61\n",
            "Train Loss:  5.128008842468262\n",
            "Test Loss:  5.608767509460449\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  62\n",
            "Train Loss:  5.113584518432617\n",
            "Test Loss:  5.607581615447998\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  63\n",
            "Train Loss:  5.099510669708252\n",
            "Test Loss:  5.606422424316406\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  64\n",
            "Train Loss:  5.085776329040527\n",
            "Test Loss:  5.605306625366211\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  65\n",
            "Train Loss:  5.072360038757324\n",
            "Test Loss:  5.6042351722717285\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  66\n",
            "Train Loss:  5.0592756271362305\n",
            "Test Loss:  5.603247165679932\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  67\n",
            "Train Loss:  5.0464887619018555\n",
            "Test Loss:  5.602309703826904\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  68\n",
            "Train Loss:  5.033995151519775\n",
            "Test Loss:  5.601405620574951\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  69\n",
            "Train Loss:  5.0217790603637695\n",
            "Test Loss:  5.600547790527344\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  70\n",
            "Train Loss:  5.009849548339844\n",
            "Test Loss:  5.599732875823975\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  71\n",
            "Train Loss:  4.998188018798828\n",
            "Test Loss:  5.59893798828125\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  72\n",
            "Train Loss:  4.986776828765869\n",
            "Test Loss:  5.598145484924316\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  73\n",
            "Train Loss:  4.975620269775391\n",
            "Test Loss:  5.597380638122559\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  74\n",
            "Train Loss:  4.964703559875488\n",
            "Test Loss:  5.596639633178711\n",
            "Recall : 0.14\n",
            "Epoch  75\n",
            "Train Loss:  4.954009056091309\n",
            "Test Loss:  5.595912933349609\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  76\n",
            "Train Loss:  4.943548202514648\n",
            "Test Loss:  5.595232963562012\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  77\n",
            "Train Loss:  4.933294296264648\n",
            "Test Loss:  5.5946044921875\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  78\n",
            "Train Loss:  4.923243522644043\n",
            "Test Loss:  5.593999862670898\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  79\n",
            "Train Loss:  4.9133992195129395\n",
            "Test Loss:  5.593412399291992\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  80\n",
            "Train Loss:  4.9037580490112305\n",
            "Test Loss:  5.592846870422363\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  81\n",
            "Train Loss:  4.89431619644165\n",
            "Test Loss:  5.59229850769043\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  82\n",
            "Train Loss:  4.88505220413208\n",
            "Test Loss:  5.591787815093994\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  83\n",
            "Train Loss:  4.875970363616943\n",
            "Test Loss:  5.591296195983887\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  84\n",
            "Train Loss:  4.867055416107178\n",
            "Test Loss:  5.59084415435791\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  85\n",
            "Train Loss:  4.858307838439941\n",
            "Test Loss:  5.590453147888184\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  86\n",
            "Train Loss:  4.849723815917969\n",
            "Test Loss:  5.590083122253418\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  87\n",
            "Train Loss:  4.841306686401367\n",
            "Test Loss:  5.589700698852539\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  88\n",
            "Train Loss:  4.833038330078125\n",
            "Test Loss:  5.589345455169678\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  89\n",
            "Train Loss:  4.824919700622559\n",
            "Test Loss:  5.589022636413574\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  90\n",
            "Train Loss:  4.8169474601745605\n",
            "Test Loss:  5.588752746582031\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  91\n",
            "Train Loss:  4.809112548828125\n",
            "Test Loss:  5.5885114669799805\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  92\n",
            "Train Loss:  4.801412582397461\n",
            "Test Loss:  5.588317394256592\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  93\n",
            "Train Loss:  4.793831825256348\n",
            "Test Loss:  5.588177680969238\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  94\n",
            "Train Loss:  4.786377906799316\n",
            "Test Loss:  5.588075637817383\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  95\n",
            "Train Loss:  4.779051303863525\n",
            "Test Loss:  5.58798885345459\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  96\n",
            "Train Loss:  4.771849632263184\n",
            "Test Loss:  5.587923049926758\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  97\n",
            "Train Loss:  4.764762878417969\n",
            "Test Loss:  5.587872505187988\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  98\n",
            "Train Loss:  4.757781028747559\n",
            "Test Loss:  5.587850093841553\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  99\n",
            "Train Loss:  4.750899314880371\n",
            "Test Loss:  5.587846755981445\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  100\n",
            "Train Loss:  4.744115829467773\n",
            "Test Loss:  5.587841987609863\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  101\n",
            "Train Loss:  4.737438678741455\n",
            "Test Loss:  5.587855815887451\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  102\n",
            "Train Loss:  4.730849266052246\n",
            "Test Loss:  5.587892055511475\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  103\n",
            "Train Loss:  4.72435998916626\n",
            "Test Loss:  5.5879364013671875\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  104\n",
            "Train Loss:  4.717956066131592\n",
            "Test Loss:  5.587984561920166\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  105\n",
            "Train Loss:  4.711627006530762\n",
            "Test Loss:  5.588038444519043\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  106\n",
            "Train Loss:  4.7053680419921875\n",
            "Test Loss:  5.5880937576293945\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  107\n",
            "Train Loss:  4.699189186096191\n",
            "Test Loss:  5.588144302368164\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  108\n",
            "Train Loss:  4.693096160888672\n",
            "Test Loss:  5.588207721710205\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  109\n",
            "Train Loss:  4.687080383300781\n",
            "Test Loss:  5.588263511657715\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  110\n",
            "Train Loss:  4.681135654449463\n",
            "Test Loss:  5.588317394256592\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  111\n",
            "Train Loss:  4.675253868103027\n",
            "Test Loss:  5.588386535644531\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  112\n",
            "Train Loss:  4.669432640075684\n",
            "Test Loss:  5.588460922241211\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  113\n",
            "Train Loss:  4.663663864135742\n",
            "Test Loss:  5.588540077209473\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  114\n",
            "Train Loss:  4.65794563293457\n",
            "Test Loss:  5.5886311531066895\n",
            "Recall : 0.14\n",
            "Epoch  115\n",
            "Train Loss:  4.652273178100586\n",
            "Test Loss:  5.588697910308838\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  116\n",
            "Train Loss:  4.646648406982422\n",
            "Test Loss:  5.5887675285339355\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  117\n",
            "Train Loss:  4.641063690185547\n",
            "Test Loss:  5.5888261795043945\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  118\n",
            "Train Loss:  4.635525703430176\n",
            "Test Loss:  5.58888578414917\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  119\n",
            "Train Loss:  4.630036354064941\n",
            "Test Loss:  5.588947772979736\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  120\n",
            "Train Loss:  4.624589920043945\n",
            "Test Loss:  5.589001655578613\n",
            "Recall : 0.14\n",
            "Epoch  121\n",
            "Train Loss:  4.619170188903809\n",
            "Test Loss:  5.589038372039795\n",
            "Recall : 0.14\n",
            "Epoch  122\n",
            "Train Loss:  4.613781929016113\n",
            "Test Loss:  5.589059829711914\n",
            "Recall : 0.14\n",
            "Epoch  123\n",
            "Train Loss:  4.608425140380859\n",
            "Test Loss:  5.589071273803711\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  124\n",
            "Train Loss:  4.603102684020996\n",
            "Test Loss:  5.589086532592773\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  125\n",
            "Train Loss:  4.597820281982422\n",
            "Test Loss:  5.589118957519531\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  126\n",
            "Train Loss:  4.592569828033447\n",
            "Test Loss:  5.589148998260498\n",
            "Recall : 0.14\n",
            "Epoch  127\n",
            "Train Loss:  4.587352752685547\n",
            "Test Loss:  5.589176177978516\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  128\n",
            "Train Loss:  4.582165718078613\n",
            "Test Loss:  5.589188575744629\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  129\n",
            "Train Loss:  4.577000617980957\n",
            "Test Loss:  5.589195251464844\n",
            "Recall : 0.14\n",
            "Epoch  130\n",
            "Train Loss:  4.571858882904053\n",
            "Test Loss:  5.589206695556641\n",
            "Recall : 0.14\n",
            "Epoch  131\n",
            "Train Loss:  4.566740036010742\n",
            "Test Loss:  5.589231491088867\n",
            "Recall : 0.14\n",
            "Epoch  132\n",
            "Train Loss:  4.561646461486816\n",
            "Test Loss:  5.589262008666992\n",
            "Recall : 0.14\n",
            "Epoch  133\n",
            "Train Loss:  4.556575298309326\n",
            "Test Loss:  5.589297294616699\n",
            "Recall : 0.14\n",
            "Epoch  134\n",
            "Train Loss:  4.55152702331543\n",
            "Test Loss:  5.589325904846191\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  135\n",
            "Train Loss:  4.546499729156494\n",
            "Test Loss:  5.589358329772949\n",
            "Recall : 0.14\n",
            "Epoch  136\n",
            "Train Loss:  4.541494369506836\n",
            "Test Loss:  5.589391708374023\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  137\n",
            "Train Loss:  4.53650426864624\n",
            "Test Loss:  5.589409351348877\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  138\n",
            "Train Loss:  4.53154182434082\n",
            "Test Loss:  5.589409828186035\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  139\n",
            "Train Loss:  4.526603698730469\n",
            "Test Loss:  5.589408874511719\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  140\n",
            "Train Loss:  4.521690368652344\n",
            "Test Loss:  5.589400291442871\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  141\n",
            "Train Loss:  4.516800403594971\n",
            "Test Loss:  5.589381694793701\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  142\n",
            "Train Loss:  4.51193380355835\n",
            "Test Loss:  5.589357376098633\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  143\n",
            "Train Loss:  4.507091522216797\n",
            "Test Loss:  5.589326858520508\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  144\n",
            "Train Loss:  4.502277374267578\n",
            "Test Loss:  5.589288711547852\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  145\n",
            "Train Loss:  4.497494697570801\n",
            "Test Loss:  5.589245796203613\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  146\n",
            "Train Loss:  4.492740631103516\n",
            "Test Loss:  5.589190483093262\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  147\n",
            "Train Loss:  4.488010406494141\n",
            "Test Loss:  5.5891218185424805\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  148\n",
            "Train Loss:  4.483308792114258\n",
            "Test Loss:  5.589046001434326\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  149\n",
            "Train Loss:  4.4786376953125\n",
            "Test Loss:  5.588966369628906\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  150\n",
            "Train Loss:  4.473995208740234\n",
            "Test Loss:  5.588884353637695\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  151\n",
            "Train Loss:  4.469376564025879\n",
            "Test Loss:  5.58878231048584\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  152\n",
            "Train Loss:  4.464788913726807\n",
            "Test Loss:  5.588669776916504\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  153\n",
            "Train Loss:  4.460231304168701\n",
            "Test Loss:  5.588547706604004\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  154\n",
            "Train Loss:  4.455702781677246\n",
            "Test Loss:  5.5884294509887695\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  155\n",
            "Train Loss:  4.451197624206543\n",
            "Test Loss:  5.588313579559326\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  156\n",
            "Train Loss:  4.446721076965332\n",
            "Test Loss:  5.588194847106934\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  157\n",
            "Train Loss:  4.442275524139404\n",
            "Test Loss:  5.588069915771484\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  158\n",
            "Train Loss:  4.437863349914551\n",
            "Test Loss:  5.587944030761719\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  159\n",
            "Train Loss:  4.433485984802246\n",
            "Test Loss:  5.587811470031738\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  160\n",
            "Train Loss:  4.429141044616699\n",
            "Test Loss:  5.587673187255859\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  161\n",
            "Train Loss:  4.424827575683594\n",
            "Test Loss:  5.587535858154297\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  162\n",
            "Train Loss:  4.420551300048828\n",
            "Test Loss:  5.58740234375\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  163\n",
            "Train Loss:  4.4163055419921875\n",
            "Test Loss:  5.587272644042969\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  164\n",
            "Train Loss:  4.4120941162109375\n",
            "Test Loss:  5.587139129638672\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  165\n",
            "Train Loss:  4.407920837402344\n",
            "Test Loss:  5.586997985839844\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  166\n",
            "Train Loss:  4.40378475189209\n",
            "Test Loss:  5.586848735809326\n",
            "Recall : 0.14\n",
            "Epoch  167\n",
            "Train Loss:  4.399681091308594\n",
            "Test Loss:  5.586688995361328\n",
            "Recall : 0.14\n",
            "Epoch  168\n",
            "Train Loss:  4.395603656768799\n",
            "Test Loss:  5.586528778076172\n",
            "Recall : 0.14\n",
            "Epoch  169\n",
            "Train Loss:  4.391558647155762\n",
            "Test Loss:  5.586385250091553\n",
            "Recall : 0.14\n",
            "Epoch  170\n",
            "Train Loss:  4.387551307678223\n",
            "Test Loss:  5.586249351501465\n",
            "Recall : 0.14\n",
            "Epoch  171\n",
            "Train Loss:  4.383578300476074\n",
            "Test Loss:  5.58612060546875\n",
            "Recall : 0.14\n",
            "Epoch  172\n",
            "Train Loss:  4.379634380340576\n",
            "Test Loss:  5.585999011993408\n",
            "Recall : 0.14\n",
            "Epoch  173\n",
            "Train Loss:  4.375725269317627\n",
            "Test Loss:  5.585879325866699\n",
            "Recall : 0.14\n",
            "Epoch  174\n",
            "Train Loss:  4.371849060058594\n",
            "Test Loss:  5.585762977600098\n",
            "Recall : 0.14\n",
            "Epoch  175\n",
            "Train Loss:  4.368008613586426\n",
            "Test Loss:  5.585644245147705\n",
            "Recall : 0.14\n",
            "Epoch  176\n",
            "Train Loss:  4.364199638366699\n",
            "Test Loss:  5.585519790649414\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  177\n",
            "Train Loss:  4.360423564910889\n",
            "Test Loss:  5.58540153503418\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  178\n",
            "Train Loss:  4.356680870056152\n",
            "Test Loss:  5.585293292999268\n",
            "Recall : 0.14\n",
            "Epoch  179\n",
            "Train Loss:  4.352969169616699\n",
            "Test Loss:  5.585186004638672\n",
            "Recall : 0.14\n",
            "Epoch  180\n",
            "Train Loss:  4.349289894104004\n",
            "Test Loss:  5.585081100463867\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  181\n",
            "Train Loss:  4.345641136169434\n",
            "Test Loss:  5.584973335266113\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  182\n",
            "Train Loss:  4.342022895812988\n",
            "Test Loss:  5.584866523742676\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  183\n",
            "Train Loss:  4.338441848754883\n",
            "Test Loss:  5.584769248962402\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  184\n",
            "Train Loss:  4.334893226623535\n",
            "Test Loss:  5.584672927856445\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  185\n",
            "Train Loss:  4.3313751220703125\n",
            "Test Loss:  5.584583282470703\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  186\n",
            "Train Loss:  4.327886581420898\n",
            "Test Loss:  5.584497928619385\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  187\n",
            "Train Loss:  4.324422359466553\n",
            "Test Loss:  5.584417343139648\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  188\n",
            "Train Loss:  4.320989608764648\n",
            "Test Loss:  5.584338188171387\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  189\n",
            "Train Loss:  4.317586421966553\n",
            "Test Loss:  5.58425235748291\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  190\n",
            "Train Loss:  4.314208984375\n",
            "Test Loss:  5.584167957305908\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  191\n",
            "Train Loss:  4.310855865478516\n",
            "Test Loss:  5.584083557128906\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  192\n",
            "Train Loss:  4.307531356811523\n",
            "Test Loss:  5.584001541137695\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  193\n",
            "Train Loss:  4.304230690002441\n",
            "Test Loss:  5.583925247192383\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  194\n",
            "Train Loss:  4.30095100402832\n",
            "Test Loss:  5.583852291107178\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  195\n",
            "Train Loss:  4.297694206237793\n",
            "Test Loss:  5.583774566650391\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  196\n",
            "Train Loss:  4.294460296630859\n",
            "Test Loss:  5.583705902099609\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  197\n",
            "Train Loss:  4.291250228881836\n",
            "Test Loss:  5.5836381912231445\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  198\n",
            "Train Loss:  4.288064002990723\n",
            "Test Loss:  5.5835676193237305\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  199\n",
            "Train Loss:  4.284900188446045\n",
            "Test Loss:  5.583503723144531\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  200\n",
            "Train Loss:  4.281762599945068\n",
            "Test Loss:  5.583452224731445\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  201\n",
            "Train Loss:  4.278650283813477\n",
            "Test Loss:  5.583406448364258\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  202\n",
            "Train Loss:  4.2755608558654785\n",
            "Test Loss:  5.583359718322754\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  203\n",
            "Train Loss:  4.272495269775391\n",
            "Test Loss:  5.583313941955566\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  204\n",
            "Train Loss:  4.269453525543213\n",
            "Test Loss:  5.583274841308594\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  205\n",
            "Train Loss:  4.2664313316345215\n",
            "Test Loss:  5.583244323730469\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  206\n",
            "Train Loss:  4.263430595397949\n",
            "Test Loss:  5.583219528198242\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  207\n",
            "Train Loss:  4.260455131530762\n",
            "Test Loss:  5.583200454711914\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  208\n",
            "Train Loss:  4.25750207901001\n",
            "Test Loss:  5.5831756591796875\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  209\n",
            "Train Loss:  4.254570007324219\n",
            "Test Loss:  5.583148956298828\n",
            "Recall : 0.14\n",
            "Epoch  210\n",
            "Train Loss:  4.2516584396362305\n",
            "Test Loss:  5.583120346069336\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  211\n",
            "Train Loss:  4.248767852783203\n",
            "Test Loss:  5.583093643188477\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  212\n",
            "Train Loss:  4.245896339416504\n",
            "Test Loss:  5.583063125610352\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  213\n",
            "Train Loss:  4.243038177490234\n",
            "Test Loss:  5.583034515380859\n",
            "Recall : 0.14\n",
            "Epoch  214\n",
            "Train Loss:  4.240196228027344\n",
            "Test Loss:  5.5830078125\n",
            "Recall : 0.14\n",
            "Epoch  215\n",
            "Train Loss:  4.237374305725098\n",
            "Test Loss:  5.5829854011535645\n",
            "Recall : 0.14\n",
            "Epoch  216\n",
            "Train Loss:  4.2345685958862305\n",
            "Test Loss:  5.582961559295654\n",
            "Recall : 0.14\n",
            "Epoch  217\n",
            "Train Loss:  4.231781959533691\n",
            "Test Loss:  5.582941055297852\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  218\n",
            "Train Loss:  4.229011535644531\n",
            "Test Loss:  5.582927703857422\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  219\n",
            "Train Loss:  4.226256847381592\n",
            "Test Loss:  5.582915782928467\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  220\n",
            "Train Loss:  4.223518371582031\n",
            "Test Loss:  5.5829057693481445\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  221\n",
            "Train Loss:  4.220795631408691\n",
            "Test Loss:  5.582897186279297\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  222\n",
            "Train Loss:  4.218090534210205\n",
            "Test Loss:  5.582887649536133\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  223\n",
            "Train Loss:  4.2154035568237305\n",
            "Test Loss:  5.582882881164551\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  224\n",
            "Train Loss:  4.212731838226318\n",
            "Test Loss:  5.582880020141602\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  225\n",
            "Train Loss:  4.210074424743652\n",
            "Test Loss:  5.582876205444336\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  226\n",
            "Train Loss:  4.207432746887207\n",
            "Test Loss:  5.5828680992126465\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  227\n",
            "Train Loss:  4.204805374145508\n",
            "Test Loss:  5.582860946655273\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  228\n",
            "Train Loss:  4.202191352844238\n",
            "Test Loss:  5.582852363586426\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  229\n",
            "Train Loss:  4.199588298797607\n",
            "Test Loss:  5.582841873168945\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  230\n",
            "Train Loss:  4.196999549865723\n",
            "Test Loss:  5.582830429077148\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  231\n",
            "Train Loss:  4.194425582885742\n",
            "Test Loss:  5.582815170288086\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  232\n",
            "Train Loss:  4.191863536834717\n",
            "Test Loss:  5.5827956199646\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  233\n",
            "Train Loss:  4.1893157958984375\n",
            "Test Loss:  5.5827741622924805\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  234\n",
            "Train Loss:  4.1867780685424805\n",
            "Test Loss:  5.582753658294678\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  235\n",
            "Train Loss:  4.184255123138428\n",
            "Test Loss:  5.582741737365723\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  236\n",
            "Train Loss:  4.181746482849121\n",
            "Test Loss:  5.582732677459717\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  237\n",
            "Train Loss:  4.1792497634887695\n",
            "Test Loss:  5.58272647857666\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  238\n",
            "Train Loss:  4.176766872406006\n",
            "Test Loss:  5.582719326019287\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  239\n",
            "Train Loss:  4.174294471740723\n",
            "Test Loss:  5.582709312438965\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  240\n",
            "Train Loss:  4.1718339920043945\n",
            "Test Loss:  5.58270263671875\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  241\n",
            "Train Loss:  4.169384956359863\n",
            "Test Loss:  5.582694053649902\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  242\n",
            "Train Loss:  4.166949272155762\n",
            "Test Loss:  5.5826802253723145\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  243\n",
            "Train Loss:  4.164527893066406\n",
            "Test Loss:  5.582663059234619\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  244\n",
            "Train Loss:  4.1621222496032715\n",
            "Test Loss:  5.582651138305664\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  245\n",
            "Train Loss:  4.159729957580566\n",
            "Test Loss:  5.582638263702393\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  246\n",
            "Train Loss:  4.157350540161133\n",
            "Test Loss:  5.582619667053223\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  247\n",
            "Train Loss:  4.154984951019287\n",
            "Test Loss:  5.582604885101318\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  248\n",
            "Train Loss:  4.1526336669921875\n",
            "Test Loss:  5.5825910568237305\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  249\n",
            "Train Loss:  4.150292873382568\n",
            "Test Loss:  5.582575798034668\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  250\n",
            "Train Loss:  4.1479644775390625\n",
            "Test Loss:  5.5825581550598145\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  251\n",
            "Train Loss:  4.145645618438721\n",
            "Test Loss:  5.582540512084961\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  252\n",
            "Train Loss:  4.143336296081543\n",
            "Test Loss:  5.582520961761475\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  253\n",
            "Train Loss:  4.141037940979004\n",
            "Test Loss:  5.582498550415039\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  254\n",
            "Train Loss:  4.138751029968262\n",
            "Test Loss:  5.5824761390686035\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  255\n",
            "Train Loss:  4.136475563049316\n",
            "Test Loss:  5.582449913024902\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  256\n",
            "Train Loss:  4.134210586547852\n",
            "Test Loss:  5.582426071166992\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  257\n",
            "Train Loss:  4.131957054138184\n",
            "Test Loss:  5.582409858703613\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  258\n",
            "Train Loss:  4.129717826843262\n",
            "Test Loss:  5.582391262054443\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  259\n",
            "Train Loss:  4.127488613128662\n",
            "Test Loss:  5.582376480102539\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  260\n",
            "Train Loss:  4.125270843505859\n",
            "Test Loss:  5.582367897033691\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  261\n",
            "Train Loss:  4.1230669021606445\n",
            "Test Loss:  5.5823588371276855\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  262\n",
            "Train Loss:  4.120874404907227\n",
            "Test Loss:  5.582352638244629\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  263\n",
            "Train Loss:  4.118691444396973\n",
            "Test Loss:  5.582347869873047\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  264\n",
            "Train Loss:  4.116520881652832\n",
            "Test Loss:  5.582340240478516\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  265\n",
            "Train Loss:  4.11436128616333\n",
            "Test Loss:  5.582328796386719\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  266\n",
            "Train Loss:  4.112211227416992\n",
            "Test Loss:  5.582315921783447\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  267\n",
            "Train Loss:  4.110074043273926\n",
            "Test Loss:  5.582307815551758\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  268\n",
            "Train Loss:  4.107945442199707\n",
            "Test Loss:  5.582302093505859\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  269\n",
            "Train Loss:  4.105828285217285\n",
            "Test Loss:  5.582303047180176\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  270\n",
            "Train Loss:  4.103725433349609\n",
            "Test Loss:  5.582305431365967\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  271\n",
            "Train Loss:  4.101634979248047\n",
            "Test Loss:  5.582308769226074\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  272\n",
            "Train Loss:  4.099555015563965\n",
            "Test Loss:  5.5823163986206055\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  273\n",
            "Train Loss:  4.097487449645996\n",
            "Test Loss:  5.58232307434082\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  274\n",
            "Train Loss:  4.095430374145508\n",
            "Test Loss:  5.582332611083984\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  275\n",
            "Train Loss:  4.093384265899658\n",
            "Test Loss:  5.582343101501465\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  276\n",
            "Train Loss:  4.0913472175598145\n",
            "Test Loss:  5.582356929779053\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  277\n",
            "Train Loss:  4.089321136474609\n",
            "Test Loss:  5.58237361907959\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  278\n",
            "Train Loss:  4.087306499481201\n",
            "Test Loss:  5.582396507263184\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  279\n",
            "Train Loss:  4.085302829742432\n",
            "Test Loss:  5.582426071166992\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  280\n",
            "Train Loss:  4.083307266235352\n",
            "Test Loss:  5.582457542419434\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  281\n",
            "Train Loss:  4.081321716308594\n",
            "Test Loss:  5.582487106323242\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  282\n",
            "Train Loss:  4.079343318939209\n",
            "Test Loss:  5.582518577575684\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  283\n",
            "Train Loss:  4.077376365661621\n",
            "Test Loss:  5.582558631896973\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  284\n",
            "Train Loss:  4.075421333312988\n",
            "Test Loss:  5.582599639892578\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  285\n",
            "Train Loss:  4.073478698730469\n",
            "Test Loss:  5.582642555236816\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  286\n",
            "Train Loss:  4.071544647216797\n",
            "Test Loss:  5.582685470581055\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  287\n",
            "Train Loss:  4.069622039794922\n",
            "Test Loss:  5.582733631134033\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  288\n",
            "Train Loss:  4.067709922790527\n",
            "Test Loss:  5.582779884338379\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  289\n",
            "Train Loss:  4.0658111572265625\n",
            "Test Loss:  5.582825183868408\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  290\n",
            "Train Loss:  4.063924789428711\n",
            "Test Loss:  5.582873344421387\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  291\n",
            "Train Loss:  4.062050819396973\n",
            "Test Loss:  5.582920074462891\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  292\n",
            "Train Loss:  4.060188293457031\n",
            "Test Loss:  5.582970142364502\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  293\n",
            "Train Loss:  4.058335781097412\n",
            "Test Loss:  5.583024024963379\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  294\n",
            "Train Loss:  4.056494235992432\n",
            "Test Loss:  5.583077907562256\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  295\n",
            "Train Loss:  4.054662704467773\n",
            "Test Loss:  5.5831379890441895\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  296\n",
            "Train Loss:  4.052840232849121\n",
            "Test Loss:  5.583200931549072\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  297\n",
            "Train Loss:  4.051025867462158\n",
            "Test Loss:  5.583264350891113\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  298\n",
            "Train Loss:  4.049224376678467\n",
            "Test Loss:  5.58332633972168\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  299\n",
            "Train Loss:  4.047431945800781\n",
            "Test Loss:  5.5833892822265625\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  300\n",
            "Train Loss:  4.045649528503418\n",
            "Test Loss:  5.583453178405762\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  301\n",
            "Train Loss:  4.043874263763428\n",
            "Test Loss:  5.583518028259277\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  302\n",
            "Train Loss:  4.042107582092285\n",
            "Test Loss:  5.583581924438477\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  303\n",
            "Train Loss:  4.040349960327148\n",
            "Test Loss:  5.583644866943359\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  304\n",
            "Train Loss:  4.038600921630859\n",
            "Test Loss:  5.583709239959717\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  305\n",
            "Train Loss:  4.036862373352051\n",
            "Test Loss:  5.583773612976074\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  306\n",
            "Train Loss:  4.035133361816406\n",
            "Test Loss:  5.58383846282959\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  307\n",
            "Train Loss:  4.033414840698242\n",
            "Test Loss:  5.58390474319458\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  308\n",
            "Train Loss:  4.031705856323242\n",
            "Test Loss:  5.583972454071045\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  309\n",
            "Train Loss:  4.030006408691406\n",
            "Test Loss:  5.584040641784668\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  310\n",
            "Train Loss:  4.028314590454102\n",
            "Test Loss:  5.584109306335449\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  311\n",
            "Train Loss:  4.026633262634277\n",
            "Test Loss:  5.584177017211914\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  312\n",
            "Train Loss:  4.024959564208984\n",
            "Test Loss:  5.584246635437012\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  313\n",
            "Train Loss:  4.023292541503906\n",
            "Test Loss:  5.584320545196533\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  314\n",
            "Train Loss:  4.02163028717041\n",
            "Test Loss:  5.584400177001953\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  315\n",
            "Train Loss:  4.019978046417236\n",
            "Test Loss:  5.5844807624816895\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  316\n",
            "Train Loss:  4.018332481384277\n",
            "Test Loss:  5.584561347961426\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  317\n",
            "Train Loss:  4.016693115234375\n",
            "Test Loss:  5.584641456604004\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  318\n",
            "Train Loss:  4.0150604248046875\n",
            "Test Loss:  5.584719657897949\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  319\n",
            "Train Loss:  4.013436317443848\n",
            "Test Loss:  5.5848002433776855\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  320\n",
            "Train Loss:  4.011819839477539\n",
            "Test Loss:  5.584884166717529\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  321\n",
            "Train Loss:  4.010208606719971\n",
            "Test Loss:  5.584968566894531\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  322\n",
            "Train Loss:  4.008605480194092\n",
            "Test Loss:  5.585054397583008\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  323\n",
            "Train Loss:  4.0070085525512695\n",
            "Test Loss:  5.585143566131592\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  324\n",
            "Train Loss:  4.005419731140137\n",
            "Test Loss:  5.585236549377441\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  325\n",
            "Train Loss:  4.0038347244262695\n",
            "Test Loss:  5.585334300994873\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  326\n",
            "Train Loss:  4.002256870269775\n",
            "Test Loss:  5.585433006286621\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  327\n",
            "Train Loss:  4.000685691833496\n",
            "Test Loss:  5.585533142089844\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  328\n",
            "Train Loss:  3.9991228580474854\n",
            "Test Loss:  5.585629463195801\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  329\n",
            "Train Loss:  3.9975666999816895\n",
            "Test Loss:  5.585725784301758\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  330\n",
            "Train Loss:  3.9960179328918457\n",
            "Test Loss:  5.585820198059082\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  331\n",
            "Train Loss:  3.994476079940796\n",
            "Test Loss:  5.585914611816406\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  332\n",
            "Train Loss:  3.992938995361328\n",
            "Test Loss:  5.5860066413879395\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  333\n",
            "Train Loss:  3.9914088249206543\n",
            "Test Loss:  5.586099624633789\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  334\n",
            "Train Loss:  3.98988676071167\n",
            "Test Loss:  5.5861921310424805\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  335\n",
            "Train Loss:  3.9883694648742676\n",
            "Test Loss:  5.586285591125488\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  336\n",
            "Train Loss:  3.9868578910827637\n",
            "Test Loss:  5.58637809753418\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  337\n",
            "Train Loss:  3.9853522777557373\n",
            "Test Loss:  5.5864691734313965\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  338\n",
            "Train Loss:  3.983853340148926\n",
            "Test Loss:  5.586556434631348\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  339\n",
            "Train Loss:  3.982360363006592\n",
            "Test Loss:  5.586645126342773\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  340\n",
            "Train Loss:  3.9808735847473145\n",
            "Test Loss:  5.586731910705566\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  341\n",
            "Train Loss:  3.9793925285339355\n",
            "Test Loss:  5.586820602416992\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  342\n",
            "Train Loss:  3.977917432785034\n",
            "Test Loss:  5.586909294128418\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  343\n",
            "Train Loss:  3.976447343826294\n",
            "Test Loss:  5.586997032165527\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  344\n",
            "Train Loss:  3.974984645843506\n",
            "Test Loss:  5.587080478668213\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  345\n",
            "Train Loss:  3.973527669906616\n",
            "Test Loss:  5.587166786193848\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  346\n",
            "Train Loss:  3.972078800201416\n",
            "Test Loss:  5.587249279022217\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  347\n",
            "Train Loss:  3.9706344604492188\n",
            "Test Loss:  5.587327003479004\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  348\n",
            "Train Loss:  3.9691948890686035\n",
            "Test Loss:  5.587406158447266\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  349\n",
            "Train Loss:  3.967759132385254\n",
            "Test Loss:  5.587487697601318\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  350\n",
            "Train Loss:  3.9663283824920654\n",
            "Test Loss:  5.587570667266846\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  351\n",
            "Train Loss:  3.9649014472961426\n",
            "Test Loss:  5.587650775909424\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  352\n",
            "Train Loss:  3.963479995727539\n",
            "Test Loss:  5.587728500366211\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  353\n",
            "Train Loss:  3.962062358856201\n",
            "Test Loss:  5.587808132171631\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  354\n",
            "Train Loss:  3.9606494903564453\n",
            "Test Loss:  5.587890148162842\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  355\n",
            "Train Loss:  3.9592437744140625\n",
            "Test Loss:  5.587974548339844\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  356\n",
            "Train Loss:  3.9578423500061035\n",
            "Test Loss:  5.5880584716796875\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  357\n",
            "Train Loss:  3.9564478397369385\n",
            "Test Loss:  5.588140487670898\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  358\n",
            "Train Loss:  3.955059051513672\n",
            "Test Loss:  5.5882248878479\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  359\n",
            "Train Loss:  3.953674793243408\n",
            "Test Loss:  5.588310241699219\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  360\n",
            "Train Loss:  3.952296733856201\n",
            "Test Loss:  5.5883941650390625\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  361\n",
            "Train Loss:  3.9509224891662598\n",
            "Test Loss:  5.588478088378906\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  362\n",
            "Train Loss:  3.949554681777954\n",
            "Test Loss:  5.588564872741699\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  363\n",
            "Train Loss:  3.948192596435547\n",
            "Test Loss:  5.58865213394165\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  364\n",
            "Train Loss:  3.9468374252319336\n",
            "Test Loss:  5.588737964630127\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  365\n",
            "Train Loss:  3.9454879760742188\n",
            "Test Loss:  5.5888261795043945\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  366\n",
            "Train Loss:  3.944143772125244\n",
            "Test Loss:  5.588911056518555\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  367\n",
            "Train Loss:  3.942805290222168\n",
            "Test Loss:  5.588995456695557\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  368\n",
            "Train Loss:  3.941471576690674\n",
            "Test Loss:  5.589076042175293\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  369\n",
            "Train Loss:  3.9401445388793945\n",
            "Test Loss:  5.58915901184082\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  370\n",
            "Train Loss:  3.938821315765381\n",
            "Test Loss:  5.589243412017822\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  371\n",
            "Train Loss:  3.9375014305114746\n",
            "Test Loss:  5.589326858520508\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  372\n",
            "Train Loss:  3.936187505722046\n",
            "Test Loss:  5.589407444000244\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  373\n",
            "Train Loss:  3.9348769187927246\n",
            "Test Loss:  5.589489936828613\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  374\n",
            "Train Loss:  3.933570384979248\n",
            "Test Loss:  5.589576244354248\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  375\n",
            "Train Loss:  3.932267427444458\n",
            "Test Loss:  5.589661598205566\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  376\n",
            "Train Loss:  3.930969715118408\n",
            "Test Loss:  5.589749336242676\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  377\n",
            "Train Loss:  3.929677963256836\n",
            "Test Loss:  5.589836597442627\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  378\n",
            "Train Loss:  3.92838978767395\n",
            "Test Loss:  5.589924335479736\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  379\n",
            "Train Loss:  3.927107334136963\n",
            "Test Loss:  5.590012550354004\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  380\n",
            "Train Loss:  3.925830841064453\n",
            "Test Loss:  5.5901031494140625\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  381\n",
            "Train Loss:  3.9245591163635254\n",
            "Test Loss:  5.5901994705200195\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  382\n",
            "Train Loss:  3.9232935905456543\n",
            "Test Loss:  5.590297222137451\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  383\n",
            "Train Loss:  3.922032356262207\n",
            "Test Loss:  5.590393543243408\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  384\n",
            "Train Loss:  3.920776844024658\n",
            "Test Loss:  5.59049129486084\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  385\n",
            "Train Loss:  3.919524908065796\n",
            "Test Loss:  5.590587615966797\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  386\n",
            "Train Loss:  3.918278455734253\n",
            "Test Loss:  5.590688705444336\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  387\n",
            "Train Loss:  3.9170377254486084\n",
            "Test Loss:  5.590792655944824\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  388\n",
            "Train Loss:  3.915801525115967\n",
            "Test Loss:  5.590897560119629\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  389\n",
            "Train Loss:  3.914569854736328\n",
            "Test Loss:  5.591002464294434\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  390\n",
            "Train Loss:  3.913343906402588\n",
            "Test Loss:  5.591111183166504\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  391\n",
            "Train Loss:  3.912121057510376\n",
            "Test Loss:  5.591221332550049\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  392\n",
            "Train Loss:  3.9109020233154297\n",
            "Test Loss:  5.591331481933594\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  393\n",
            "Train Loss:  3.9096872806549072\n",
            "Test Loss:  5.59144401550293\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  394\n",
            "Train Loss:  3.908477306365967\n",
            "Test Loss:  5.59155797958374\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  395\n",
            "Train Loss:  3.9072718620300293\n",
            "Test Loss:  5.5916748046875\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  396\n",
            "Train Loss:  3.906071662902832\n",
            "Test Loss:  5.591793060302734\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  397\n",
            "Train Loss:  3.904877185821533\n",
            "Test Loss:  5.591910362243652\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  398\n",
            "Train Loss:  3.9036879539489746\n",
            "Test Loss:  5.5920281410217285\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  399\n",
            "Train Loss:  3.902503252029419\n",
            "Test Loss:  5.592145919799805\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  400\n",
            "Train Loss:  3.9013242721557617\n",
            "Test Loss:  5.592264652252197\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  401\n",
            "Train Loss:  3.900150775909424\n",
            "Test Loss:  5.5923848152160645\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  402\n",
            "Train Loss:  3.8989810943603516\n",
            "Test Loss:  5.59250545501709\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  403\n",
            "Train Loss:  3.8978168964385986\n",
            "Test Loss:  5.592624187469482\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  404\n",
            "Train Loss:  3.8966574668884277\n",
            "Test Loss:  5.592741966247559\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  405\n",
            "Train Loss:  3.895500898361206\n",
            "Test Loss:  5.592862129211426\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  406\n",
            "Train Loss:  3.8943493366241455\n",
            "Test Loss:  5.592984199523926\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  407\n",
            "Train Loss:  3.8932018280029297\n",
            "Test Loss:  5.593106269836426\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  408\n",
            "Train Loss:  3.892058849334717\n",
            "Test Loss:  5.593228340148926\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  409\n",
            "Train Loss:  3.8909213542938232\n",
            "Test Loss:  5.593352794647217\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  410\n",
            "Train Loss:  3.889786958694458\n",
            "Test Loss:  5.593480587005615\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  411\n",
            "Train Loss:  3.888657569885254\n",
            "Test Loss:  5.593607425689697\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  412\n",
            "Train Loss:  3.8875322341918945\n",
            "Test Loss:  5.593735218048096\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  413\n",
            "Train Loss:  3.8864102363586426\n",
            "Test Loss:  5.593864440917969\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  414\n",
            "Train Loss:  3.8852932453155518\n",
            "Test Loss:  5.593993186950684\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  415\n",
            "Train Loss:  3.8841805458068848\n",
            "Test Loss:  5.594123840332031\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  416\n",
            "Train Loss:  3.883070945739746\n",
            "Test Loss:  5.594254970550537\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  417\n",
            "Train Loss:  3.8819663524627686\n",
            "Test Loss:  5.594387054443359\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  418\n",
            "Train Loss:  3.8808650970458984\n",
            "Test Loss:  5.594518661499023\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  419\n",
            "Train Loss:  3.879768133163452\n",
            "Test Loss:  5.594653606414795\n",
            "Recall : 0.14\n",
            "Epoch  420\n",
            "Train Loss:  3.8786752223968506\n",
            "Test Loss:  5.594790458679199\n",
            "Recall : 0.14\n",
            "Epoch  421\n",
            "Train Loss:  3.877587080001831\n",
            "Test Loss:  5.594930171966553\n",
            "Recall : 0.14\n",
            "Epoch  422\n",
            "Train Loss:  3.876502513885498\n",
            "Test Loss:  5.595070838928223\n",
            "Recall : 0.14\n",
            "Epoch  423\n",
            "Train Loss:  3.875422239303589\n",
            "Test Loss:  5.59521484375\n",
            "Recall : 0.14\n",
            "Epoch  424\n",
            "Train Loss:  3.8743464946746826\n",
            "Test Loss:  5.595358848571777\n",
            "Recall : 0.14\n",
            "Epoch  425\n",
            "Train Loss:  3.873274326324463\n",
            "Test Loss:  5.595501899719238\n",
            "Recall : 0.14\n",
            "Epoch  426\n",
            "Train Loss:  3.8722071647644043\n",
            "Test Loss:  5.595647811889648\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  427\n",
            "Train Loss:  3.871145725250244\n",
            "Test Loss:  5.595794200897217\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  428\n",
            "Train Loss:  3.870088577270508\n",
            "Test Loss:  5.5959391593933105\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  429\n",
            "Train Loss:  3.869034767150879\n",
            "Test Loss:  5.596083641052246\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  430\n",
            "Train Loss:  3.867985248565674\n",
            "Test Loss:  5.59622859954834\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  431\n",
            "Train Loss:  3.866940498352051\n",
            "Test Loss:  5.59637451171875\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  432\n",
            "Train Loss:  3.8658998012542725\n",
            "Test Loss:  5.596519470214844\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  433\n",
            "Train Loss:  3.864861488342285\n",
            "Test Loss:  5.596663475036621\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  434\n",
            "Train Loss:  3.86382794380188\n",
            "Test Loss:  5.596810340881348\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  435\n",
            "Train Loss:  3.862797975540161\n",
            "Test Loss:  5.596957683563232\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  436\n",
            "Train Loss:  3.861772298812866\n",
            "Test Loss:  5.597108364105225\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  437\n",
            "Train Loss:  3.8607497215270996\n",
            "Test Loss:  5.59726095199585\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  438\n",
            "Train Loss:  3.8597326278686523\n",
            "Test Loss:  5.597415924072266\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  439\n",
            "Train Loss:  3.858719825744629\n",
            "Test Loss:  5.5975751876831055\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  440\n",
            "Train Loss:  3.857710838317871\n",
            "Test Loss:  5.597736358642578\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  441\n",
            "Train Loss:  3.856705665588379\n",
            "Test Loss:  5.597899436950684\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  442\n",
            "Train Loss:  3.8557050228118896\n",
            "Test Loss:  5.598063945770264\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  443\n",
            "Train Loss:  3.8547096252441406\n",
            "Test Loss:  5.598229885101318\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  444\n",
            "Train Loss:  3.8537180423736572\n",
            "Test Loss:  5.598396301269531\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  445\n",
            "Train Loss:  3.8527307510375977\n",
            "Test Loss:  5.598562240600586\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  446\n",
            "Train Loss:  3.851747989654541\n",
            "Test Loss:  5.598730564117432\n",
            "Recall : 0.14\n",
            "Epoch  447\n",
            "Train Loss:  3.8507676124572754\n",
            "Test Loss:  5.5988969802856445\n",
            "Recall : 0.14\n",
            "Epoch  448\n",
            "Train Loss:  3.849792003631592\n",
            "Test Loss:  5.599064826965332\n",
            "Recall : 0.14\n",
            "Epoch  449\n",
            "Train Loss:  3.8488197326660156\n",
            "Test Loss:  5.599234580993652\n",
            "Recall : 0.14\n",
            "Epoch  450\n",
            "Train Loss:  3.8478522300720215\n",
            "Test Loss:  5.5994062423706055\n",
            "Recall : 0.14\n",
            "Epoch  451\n",
            "Train Loss:  3.8468873500823975\n",
            "Test Loss:  5.599578857421875\n",
            "Recall : 0.14\n",
            "Epoch  452\n",
            "Train Loss:  3.8459277153015137\n",
            "Test Loss:  5.599748611450195\n",
            "Recall : 0.14\n",
            "Epoch  453\n",
            "Train Loss:  3.844970226287842\n",
            "Test Loss:  5.599918365478516\n",
            "Recall : 0.14\n",
            "Epoch  454\n",
            "Train Loss:  3.844017505645752\n",
            "Test Loss:  5.600088596343994\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  455\n",
            "Train Loss:  3.8430681228637695\n",
            "Test Loss:  5.600258827209473\n",
            "Recall : 0.14\n",
            "Epoch  456\n",
            "Train Loss:  3.842121124267578\n",
            "Test Loss:  5.600429058074951\n",
            "Recall : 0.14\n",
            "Epoch  457\n",
            "Train Loss:  3.841176986694336\n",
            "Test Loss:  5.6005988121032715\n",
            "Recall : 0.14\n",
            "Epoch  458\n",
            "Train Loss:  3.840238571166992\n",
            "Test Loss:  5.60076904296875\n",
            "Recall : 0.14\n",
            "Epoch  459\n",
            "Train Loss:  3.8393025398254395\n",
            "Test Loss:  5.6009368896484375\n",
            "Recall : 0.14\n",
            "Epoch  460\n",
            "Train Loss:  3.8383688926696777\n",
            "Test Loss:  5.601101875305176\n",
            "Recall : 0.14\n",
            "Epoch  461\n",
            "Train Loss:  3.83743953704834\n",
            "Test Loss:  5.601263999938965\n",
            "Recall : 0.14\n",
            "Epoch  462\n",
            "Train Loss:  3.8365135192871094\n",
            "Test Loss:  5.601424217224121\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  463\n",
            "Train Loss:  3.8355906009674072\n",
            "Test Loss:  5.6015849113464355\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  464\n",
            "Train Loss:  3.834670066833496\n",
            "Test Loss:  5.60174560546875\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  465\n",
            "Train Loss:  3.833754777908325\n",
            "Test Loss:  5.6019086837768555\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  466\n",
            "Train Loss:  3.8328418731689453\n",
            "Test Loss:  5.60207462310791\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  467\n",
            "Train Loss:  3.8319315910339355\n",
            "Test Loss:  5.602243423461914\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  468\n",
            "Train Loss:  3.831023693084717\n",
            "Test Loss:  5.602412223815918\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  469\n",
            "Train Loss:  3.8301193714141846\n",
            "Test Loss:  5.602581977844238\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  470\n",
            "Train Loss:  3.8292183876037598\n",
            "Test Loss:  5.602750778198242\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  471\n",
            "Train Loss:  3.828320026397705\n",
            "Test Loss:  5.602916717529297\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  472\n",
            "Train Loss:  3.8274261951446533\n",
            "Test Loss:  5.603081703186035\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  473\n",
            "Train Loss:  3.8265347480773926\n",
            "Test Loss:  5.60324764251709\n",
            "Recall : 0.14\n",
            "Epoch  474\n",
            "Train Loss:  3.8256471157073975\n",
            "Test Loss:  5.6034088134765625\n",
            "Recall : 0.14\n",
            "Epoch  475\n",
            "Train Loss:  3.8247621059417725\n",
            "Test Loss:  5.603566646575928\n",
            "Recall : 0.14\n",
            "Epoch  476\n",
            "Train Loss:  3.8238797187805176\n",
            "Test Loss:  5.603726387023926\n",
            "Recall : 0.14\n",
            "Epoch  477\n",
            "Train Loss:  3.8230011463165283\n",
            "Test Loss:  5.603883743286133\n",
            "Recall : 0.14\n",
            "Epoch  478\n",
            "Train Loss:  3.8221254348754883\n",
            "Test Loss:  5.604040145874023\n",
            "Recall : 0.14\n",
            "Epoch  479\n",
            "Train Loss:  3.8212532997131348\n",
            "Test Loss:  5.604195594787598\n",
            "Recall : 0.14\n",
            "Epoch  480\n",
            "Train Loss:  3.8203835487365723\n",
            "Test Loss:  5.604348182678223\n",
            "Recall : 0.14\n",
            "Epoch  481\n",
            "Train Loss:  3.819518804550171\n",
            "Test Loss:  5.604499816894531\n",
            "Recall : 0.14\n",
            "Epoch  482\n",
            "Train Loss:  3.818655490875244\n",
            "Test Loss:  5.604647636413574\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  483\n",
            "Train Loss:  3.817796468734741\n",
            "Test Loss:  5.604793548583984\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  484\n",
            "Train Loss:  3.81693959236145\n",
            "Test Loss:  5.6049394607543945\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  485\n",
            "Train Loss:  3.8160860538482666\n",
            "Test Loss:  5.60508394241333\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  486\n",
            "Train Loss:  3.8152341842651367\n",
            "Test Loss:  5.605229377746582\n",
            "Recall : 0.14\n",
            "Epoch  487\n",
            "Train Loss:  3.8143866062164307\n",
            "Test Loss:  5.605373382568359\n",
            "Recall : 0.14\n",
            "Epoch  488\n",
            "Train Loss:  3.8135409355163574\n",
            "Test Loss:  5.60551643371582\n",
            "Recall : 0.14\n",
            "Epoch  489\n",
            "Train Loss:  3.812697649002075\n",
            "Test Loss:  5.605655670166016\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  490\n",
            "Train Loss:  3.811856746673584\n",
            "Test Loss:  5.605792045593262\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  491\n",
            "Train Loss:  3.811018466949463\n",
            "Test Loss:  5.605928897857666\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  492\n",
            "Train Loss:  3.8101837635040283\n",
            "Test Loss:  5.6060638427734375\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  493\n",
            "Train Loss:  3.8093502521514893\n",
            "Test Loss:  5.606199264526367\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  494\n",
            "Train Loss:  3.8085200786590576\n",
            "Test Loss:  5.6063337326049805\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  495\n",
            "Train Loss:  3.8076913356781006\n",
            "Test Loss:  5.6064677238464355\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  496\n",
            "Train Loss:  3.8068652153015137\n",
            "Test Loss:  5.606600761413574\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  497\n",
            "Train Loss:  3.806041717529297\n",
            "Test Loss:  5.606733322143555\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  498\n",
            "Train Loss:  3.805220127105713\n",
            "Test Loss:  5.606866359710693\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  499\n",
            "Train Loss:  3.8043999671936035\n",
            "Test Loss:  5.606996536254883\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  500\n",
            "Train Loss:  3.803582191467285\n",
            "Test Loss:  5.60712194442749\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  501\n",
            "Train Loss:  3.802767276763916\n",
            "Test Loss:  5.607244491577148\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  502\n",
            "Train Loss:  3.8019535541534424\n",
            "Test Loss:  5.607366561889648\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  503\n",
            "Train Loss:  3.8011415004730225\n",
            "Test Loss:  5.607487678527832\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  504\n",
            "Train Loss:  3.8003320693969727\n",
            "Test Loss:  5.607608318328857\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  505\n",
            "Train Loss:  3.799522876739502\n",
            "Test Loss:  5.607725620269775\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  506\n",
            "Train Loss:  3.798715591430664\n",
            "Test Loss:  5.607840061187744\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  507\n",
            "Train Loss:  3.7979092597961426\n",
            "Test Loss:  5.607952117919922\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  508\n",
            "Train Loss:  3.7971043586730957\n",
            "Test Loss:  5.608062744140625\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  509\n",
            "Train Loss:  3.79630184173584\n",
            "Test Loss:  5.608170509338379\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  510\n",
            "Train Loss:  3.7955002784729004\n",
            "Test Loss:  5.608280181884766\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  511\n",
            "Train Loss:  3.7947006225585938\n",
            "Test Loss:  5.6083879470825195\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  512\n",
            "Train Loss:  3.79390287399292\n",
            "Test Loss:  5.608494281768799\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  513\n",
            "Train Loss:  3.7931063175201416\n",
            "Test Loss:  5.608599662780762\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  514\n",
            "Train Loss:  3.792311191558838\n",
            "Test Loss:  5.608702659606934\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  515\n",
            "Train Loss:  3.7915172576904297\n",
            "Test Loss:  5.6088056564331055\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  516\n",
            "Train Loss:  3.7907252311706543\n",
            "Test Loss:  5.608907222747803\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  517\n",
            "Train Loss:  3.7899351119995117\n",
            "Test Loss:  5.609007835388184\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  518\n",
            "Train Loss:  3.7891464233398438\n",
            "Test Loss:  5.609104156494141\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  519\n",
            "Train Loss:  3.788358688354492\n",
            "Test Loss:  5.609200477600098\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  520\n",
            "Train Loss:  3.78757381439209\n",
            "Test Loss:  5.609292984008789\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  521\n",
            "Train Loss:  3.7867908477783203\n",
            "Test Loss:  5.6093854904174805\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  522\n",
            "Train Loss:  3.786008358001709\n",
            "Test Loss:  5.609475135803223\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  523\n",
            "Train Loss:  3.7852284908294678\n",
            "Test Loss:  5.609563827514648\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  524\n",
            "Train Loss:  3.784449338912964\n",
            "Test Loss:  5.609650611877441\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  525\n",
            "Train Loss:  3.7836718559265137\n",
            "Test Loss:  5.609736442565918\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  526\n",
            "Train Loss:  3.782896041870117\n",
            "Test Loss:  5.6098198890686035\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  527\n",
            "Train Loss:  3.7821216583251953\n",
            "Test Loss:  5.60990047454834\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  528\n",
            "Train Loss:  3.781348466873169\n",
            "Test Loss:  5.609981536865234\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  529\n",
            "Train Loss:  3.7805771827697754\n",
            "Test Loss:  5.610062122344971\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  530\n",
            "Train Loss:  3.7798080444335938\n",
            "Test Loss:  5.610141754150391\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  531\n",
            "Train Loss:  3.7790393829345703\n",
            "Test Loss:  5.610221862792969\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  532\n",
            "Train Loss:  3.7782740592956543\n",
            "Test Loss:  5.610301971435547\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  533\n",
            "Train Loss:  3.777510166168213\n",
            "Test Loss:  5.610382080078125\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  534\n",
            "Train Loss:  3.776746988296509\n",
            "Test Loss:  5.610456466674805\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  535\n",
            "Train Loss:  3.7759861946105957\n",
            "Test Loss:  5.610528945922852\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  536\n",
            "Train Loss:  3.7752268314361572\n",
            "Test Loss:  5.610597610473633\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  537\n",
            "Train Loss:  3.774468421936035\n",
            "Test Loss:  5.610664367675781\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  538\n",
            "Train Loss:  3.773712158203125\n",
            "Test Loss:  5.6107306480407715\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  539\n",
            "Train Loss:  3.772956371307373\n",
            "Test Loss:  5.610795021057129\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  540\n",
            "Train Loss:  3.772202491760254\n",
            "Test Loss:  5.610858917236328\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  541\n",
            "Train Loss:  3.7714500427246094\n",
            "Test Loss:  5.610921859741211\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  542\n",
            "Train Loss:  3.770698308944702\n",
            "Test Loss:  5.6109819412231445\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  543\n",
            "Train Loss:  3.769949436187744\n",
            "Test Loss:  5.61104154586792\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  544\n",
            "Train Loss:  3.7692017555236816\n",
            "Test Loss:  5.611098766326904\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  545\n",
            "Train Loss:  3.7684545516967773\n",
            "Test Loss:  5.611152648925781\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  546\n",
            "Train Loss:  3.767709255218506\n",
            "Test Loss:  5.611204147338867\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  547\n",
            "Train Loss:  3.766965866088867\n",
            "Test Loss:  5.611253261566162\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  548\n",
            "Train Loss:  3.7662248611450195\n",
            "Test Loss:  5.611301422119141\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  549\n",
            "Train Loss:  3.7654852867126465\n",
            "Test Loss:  5.6113481521606445\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  550\n",
            "Train Loss:  3.7647461891174316\n",
            "Test Loss:  5.611394882202148\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  551\n",
            "Train Loss:  3.7640089988708496\n",
            "Test Loss:  5.611441135406494\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  552\n",
            "Train Loss:  3.763272762298584\n",
            "Test Loss:  5.611485481262207\n",
            "Recall : 0.14\n",
            "Epoch  553\n",
            "Train Loss:  3.762537956237793\n",
            "Test Loss:  5.611528396606445\n",
            "Recall : 0.14\n",
            "Epoch  554\n",
            "Train Loss:  3.7618041038513184\n",
            "Test Loss:  5.611571311950684\n",
            "Recall : 0.14\n",
            "Epoch  555\n",
            "Train Loss:  3.7610740661621094\n",
            "Test Loss:  5.611611843109131\n",
            "Recall : 0.14\n",
            "Epoch  556\n",
            "Train Loss:  3.7603445053100586\n",
            "Test Loss:  5.611649990081787\n",
            "Recall : 0.14\n",
            "Epoch  557\n",
            "Train Loss:  3.759615898132324\n",
            "Test Loss:  5.611688613891602\n",
            "Recall : 0.14\n",
            "Epoch  558\n",
            "Train Loss:  3.758890151977539\n",
            "Test Loss:  5.611725807189941\n",
            "Recall : 0.14\n",
            "Epoch  559\n",
            "Train Loss:  3.7581655979156494\n",
            "Test Loss:  5.611761093139648\n",
            "Recall : 0.14\n",
            "Epoch  560\n",
            "Train Loss:  3.7574424743652344\n",
            "Test Loss:  5.611798286437988\n",
            "Recall : 0.14\n",
            "Epoch  561\n",
            "Train Loss:  3.756721019744873\n",
            "Test Loss:  5.611832618713379\n",
            "Recall : 0.14\n",
            "Epoch  562\n",
            "Train Loss:  3.7560007572174072\n",
            "Test Loss:  5.611863613128662\n",
            "Recall : 0.14\n",
            "Epoch  563\n",
            "Train Loss:  3.755281925201416\n",
            "Test Loss:  5.611893653869629\n",
            "Recall : 0.14\n",
            "Epoch  564\n",
            "Train Loss:  3.754563570022583\n",
            "Test Loss:  5.611920356750488\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  565\n",
            "Train Loss:  3.7538468837738037\n",
            "Test Loss:  5.611945152282715\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  566\n",
            "Train Loss:  3.7531323432922363\n",
            "Test Loss:  5.611969947814941\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  567\n",
            "Train Loss:  3.7524185180664062\n",
            "Test Loss:  5.611992359161377\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  568\n",
            "Train Loss:  3.7517056465148926\n",
            "Test Loss:  5.612013816833496\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  569\n",
            "Train Loss:  3.75099515914917\n",
            "Test Loss:  5.612035751342773\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  570\n",
            "Train Loss:  3.7502872943878174\n",
            "Test Loss:  5.612057685852051\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  571\n",
            "Train Loss:  3.7495808601379395\n",
            "Test Loss:  5.612078666687012\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  572\n",
            "Train Loss:  3.7488760948181152\n",
            "Test Loss:  5.612098693847656\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  573\n",
            "Train Loss:  3.748173713684082\n",
            "Test Loss:  5.612117767333984\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  574\n",
            "Train Loss:  3.7474722862243652\n",
            "Test Loss:  5.61213493347168\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  575\n",
            "Train Loss:  3.7467727661132812\n",
            "Test Loss:  5.612154006958008\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  576\n",
            "Train Loss:  3.7460761070251465\n",
            "Test Loss:  5.612170219421387\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  577\n",
            "Train Loss:  3.74537992477417\n",
            "Test Loss:  5.612186908721924\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  578\n",
            "Train Loss:  3.744685173034668\n",
            "Test Loss:  5.6122026443481445\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  579\n",
            "Train Loss:  3.7439920902252197\n",
            "Test Loss:  5.612218856811523\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  580\n",
            "Train Loss:  3.743300437927246\n",
            "Test Loss:  5.612235069274902\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  581\n",
            "Train Loss:  3.7426114082336426\n",
            "Test Loss:  5.612253189086914\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  582\n",
            "Train Loss:  3.7419238090515137\n",
            "Test Loss:  5.612271308898926\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  583\n",
            "Train Loss:  3.7412381172180176\n",
            "Test Loss:  5.6122894287109375\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  584\n",
            "Train Loss:  3.740554094314575\n",
            "Test Loss:  5.612308979034424\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  585\n",
            "Train Loss:  3.7398719787597656\n",
            "Test Loss:  5.612329483032227\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  586\n",
            "Train Loss:  3.7391932010650635\n",
            "Test Loss:  5.612348556518555\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  587\n",
            "Train Loss:  3.738516092300415\n",
            "Test Loss:  5.612369537353516\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  588\n",
            "Train Loss:  3.7378413677215576\n",
            "Test Loss:  5.612386703491211\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  589\n",
            "Train Loss:  3.7371678352355957\n",
            "Test Loss:  5.612405776977539\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  590\n",
            "Train Loss:  3.7364959716796875\n",
            "Test Loss:  5.612423896789551\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  591\n",
            "Train Loss:  3.735825538635254\n",
            "Test Loss:  5.6124420166015625\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  592\n",
            "Train Loss:  3.735157012939453\n",
            "Test Loss:  5.612460136413574\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  593\n",
            "Train Loss:  3.734490394592285\n",
            "Test Loss:  5.612475395202637\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  594\n",
            "Train Loss:  3.733825206756592\n",
            "Test Loss:  5.612488746643066\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  595\n",
            "Train Loss:  3.733161449432373\n",
            "Test Loss:  5.6125030517578125\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  596\n",
            "Train Loss:  3.7325000762939453\n",
            "Test Loss:  5.612516403198242\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  597\n",
            "Train Loss:  3.7318413257598877\n",
            "Test Loss:  5.6125288009643555\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  598\n",
            "Train Loss:  3.731184244155884\n",
            "Test Loss:  5.612537384033203\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  599\n",
            "Train Loss:  3.7305283546447754\n",
            "Test Loss:  5.612545490264893\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  600\n",
            "Train Loss:  3.7298741340637207\n",
            "Test Loss:  5.612553596496582\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  601\n",
            "Train Loss:  3.7292213439941406\n",
            "Test Loss:  5.612559795379639\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  602\n",
            "Train Loss:  3.7285714149475098\n",
            "Test Loss:  5.6125664710998535\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  603\n",
            "Train Loss:  3.7279229164123535\n",
            "Test Loss:  5.61257266998291\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  604\n",
            "Train Loss:  3.7272768020629883\n",
            "Test Loss:  5.612578392028809\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  605\n",
            "Train Loss:  3.7266321182250977\n",
            "Test Loss:  5.612585067749023\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  606\n",
            "Train Loss:  3.7259888648986816\n",
            "Test Loss:  5.612590789794922\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  607\n",
            "Train Loss:  3.725348711013794\n",
            "Test Loss:  5.612598419189453\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  608\n",
            "Train Loss:  3.724709987640381\n",
            "Test Loss:  5.612605094909668\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  609\n",
            "Train Loss:  3.7240734100341797\n",
            "Test Loss:  5.612610816955566\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  610\n",
            "Train Loss:  3.7234392166137695\n",
            "Test Loss:  5.612617492675781\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  611\n",
            "Train Loss:  3.722806930541992\n",
            "Test Loss:  5.612626075744629\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  612\n",
            "Train Loss:  3.7221758365631104\n",
            "Test Loss:  5.612633228302002\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  613\n",
            "Train Loss:  3.7215466499328613\n",
            "Test Loss:  5.61264181137085\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  614\n",
            "Train Loss:  3.7209203243255615\n",
            "Test Loss:  5.612648010253906\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  615\n",
            "Train Loss:  3.72029447555542\n",
            "Test Loss:  5.6126556396484375\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  616\n",
            "Train Loss:  3.719670295715332\n",
            "Test Loss:  5.612661361694336\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  617\n",
            "Train Loss:  3.7190494537353516\n",
            "Test Loss:  5.612668037414551\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  618\n",
            "Train Loss:  3.7184295654296875\n",
            "Test Loss:  5.612671852111816\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  619\n",
            "Train Loss:  3.7178115844726562\n",
            "Test Loss:  5.612680435180664\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  620\n",
            "Train Loss:  3.717195749282837\n",
            "Test Loss:  5.612688064575195\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  621\n",
            "Train Loss:  3.716581106185913\n",
            "Test Loss:  5.612697601318359\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  622\n",
            "Train Loss:  3.7159676551818848\n",
            "Test Loss:  5.612706184387207\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  623\n",
            "Train Loss:  3.7153568267822266\n",
            "Test Loss:  5.6127166748046875\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  624\n",
            "Train Loss:  3.7147462368011475\n",
            "Test Loss:  5.612724304199219\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  625\n",
            "Train Loss:  3.714137554168701\n",
            "Test Loss:  5.612730503082275\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  626\n",
            "Train Loss:  3.7135305404663086\n",
            "Test Loss:  5.612739086151123\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  627\n",
            "Train Loss:  3.7129249572753906\n",
            "Test Loss:  5.612750053405762\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  628\n",
            "Train Loss:  3.7123208045959473\n",
            "Test Loss:  5.612760543823242\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  629\n",
            "Train Loss:  3.7117180824279785\n",
            "Test Loss:  5.612771987915039\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  630\n",
            "Train Loss:  3.711116075515747\n",
            "Test Loss:  5.612784385681152\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  631\n",
            "Train Loss:  3.7105159759521484\n",
            "Test Loss:  5.612797737121582\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  632\n",
            "Train Loss:  3.7099175453186035\n",
            "Test Loss:  5.612811088562012\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  633\n",
            "Train Loss:  3.7093210220336914\n",
            "Test Loss:  5.612823486328125\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  634\n",
            "Train Loss:  3.708726167678833\n",
            "Test Loss:  5.612838268280029\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  635\n",
            "Train Loss:  3.708132743835449\n",
            "Test Loss:  5.612853050231934\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  636\n",
            "Train Loss:  3.707540988922119\n",
            "Test Loss:  5.612868309020996\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  637\n",
            "Train Loss:  3.7069501876831055\n",
            "Test Loss:  5.612881660461426\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  638\n",
            "Train Loss:  3.7063612937927246\n",
            "Test Loss:  5.612897872924805\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  639\n",
            "Train Loss:  3.7057740688323975\n",
            "Test Loss:  5.612911224365234\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  640\n",
            "Train Loss:  3.705188512802124\n",
            "Test Loss:  5.6129255294799805\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  641\n",
            "Train Loss:  3.704603672027588\n",
            "Test Loss:  5.612940788269043\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  642\n",
            "Train Loss:  3.704021453857422\n",
            "Test Loss:  5.6129560470581055\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  643\n",
            "Train Loss:  3.703441858291626\n",
            "Test Loss:  5.612973213195801\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  644\n",
            "Train Loss:  3.702863931655884\n",
            "Test Loss:  5.61298942565918\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  645\n",
            "Train Loss:  3.7022876739501953\n",
            "Test Loss:  5.61300802230835\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  646\n",
            "Train Loss:  3.701714277267456\n",
            "Test Loss:  5.613025665283203\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  647\n",
            "Train Loss:  3.701141119003296\n",
            "Test Loss:  5.613044738769531\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  648\n",
            "Train Loss:  3.7005696296691895\n",
            "Test Loss:  5.613064765930176\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  649\n",
            "Train Loss:  3.6999998092651367\n",
            "Test Loss:  5.61308479309082\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  650\n",
            "Train Loss:  3.6994311809539795\n",
            "Test Loss:  5.613104820251465\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  651\n",
            "Train Loss:  3.6988649368286133\n",
            "Test Loss:  5.613123893737793\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  652\n",
            "Train Loss:  3.698300361633301\n",
            "Test Loss:  5.6131439208984375\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  653\n",
            "Train Loss:  3.697737216949463\n",
            "Test Loss:  5.613163948059082\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  654\n",
            "Train Loss:  3.697176218032837\n",
            "Test Loss:  5.613182544708252\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  655\n",
            "Train Loss:  3.696617364883423\n",
            "Test Loss:  5.613203048706055\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  656\n",
            "Train Loss:  3.6960597038269043\n",
            "Test Loss:  5.613222122192383\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  657\n",
            "Train Loss:  3.6955041885375977\n",
            "Test Loss:  5.6132426261901855\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  658\n",
            "Train Loss:  3.694950580596924\n",
            "Test Loss:  5.613263130187988\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  659\n",
            "Train Loss:  3.694398880004883\n",
            "Test Loss:  5.613284111022949\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  660\n",
            "Train Loss:  3.6938486099243164\n",
            "Test Loss:  5.613306045532227\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  661\n",
            "Train Loss:  3.693301200866699\n",
            "Test Loss:  5.613325119018555\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  662\n",
            "Train Loss:  3.692755699157715\n",
            "Test Loss:  5.61334228515625\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  663\n",
            "Train Loss:  3.692211151123047\n",
            "Test Loss:  5.6133623123168945\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  664\n",
            "Train Loss:  3.6916680335998535\n",
            "Test Loss:  5.613381862640381\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  665\n",
            "Train Loss:  3.6911280155181885\n",
            "Test Loss:  5.613400459289551\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  666\n",
            "Train Loss:  3.690589427947998\n",
            "Test Loss:  5.6134209632873535\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  667\n",
            "Train Loss:  3.6900534629821777\n",
            "Test Loss:  5.6134443283081055\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  668\n",
            "Train Loss:  3.689518928527832\n",
            "Test Loss:  5.613467216491699\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  669\n",
            "Train Loss:  3.688985824584961\n",
            "Test Loss:  5.613492488861084\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  670\n",
            "Train Loss:  3.6884541511535645\n",
            "Test Loss:  5.613517761230469\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  671\n",
            "Train Loss:  3.687924385070801\n",
            "Test Loss:  5.613543510437012\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  672\n",
            "Train Loss:  3.687396287918091\n",
            "Test Loss:  5.6135711669921875\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  673\n",
            "Train Loss:  3.6868691444396973\n",
            "Test Loss:  5.613600730895996\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  674\n",
            "Train Loss:  3.686345100402832\n",
            "Test Loss:  5.613628387451172\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  675\n",
            "Train Loss:  3.685821056365967\n",
            "Test Loss:  5.6136555671691895\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  676\n",
            "Train Loss:  3.6852993965148926\n",
            "Test Loss:  5.613683700561523\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  677\n",
            "Train Loss:  3.6847782135009766\n",
            "Test Loss:  5.613710403442383\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  678\n",
            "Train Loss:  3.6842594146728516\n",
            "Test Loss:  5.613738536834717\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  679\n",
            "Train Loss:  3.6837410926818848\n",
            "Test Loss:  5.613767623901367\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  680\n",
            "Train Loss:  3.6832242012023926\n",
            "Test Loss:  5.613799095153809\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  681\n",
            "Train Loss:  3.682708978652954\n",
            "Test Loss:  5.613829135894775\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  682\n",
            "Train Loss:  3.682194709777832\n",
            "Test Loss:  5.613859176635742\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  683\n",
            "Train Loss:  3.6816823482513428\n",
            "Test Loss:  5.613890171051025\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  684\n",
            "Train Loss:  3.68117094039917\n",
            "Test Loss:  5.613918781280518\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  685\n",
            "Train Loss:  3.680661201477051\n",
            "Test Loss:  5.613948822021484\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  686\n",
            "Train Loss:  3.6801517009735107\n",
            "Test Loss:  5.613978385925293\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  687\n",
            "Train Loss:  3.6796436309814453\n",
            "Test Loss:  5.614007472991943\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  688\n",
            "Train Loss:  3.679137706756592\n",
            "Test Loss:  5.614037036895752\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  689\n",
            "Train Loss:  3.6786320209503174\n",
            "Test Loss:  5.614067077636719\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  690\n",
            "Train Loss:  3.6781270503997803\n",
            "Test Loss:  5.614096641540527\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  691\n",
            "Train Loss:  3.677624225616455\n",
            "Test Loss:  5.614126205444336\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  692\n",
            "Train Loss:  3.677122116088867\n",
            "Test Loss:  5.614156723022461\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  693\n",
            "Train Loss:  3.6766204833984375\n",
            "Test Loss:  5.614188194274902\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  694\n",
            "Train Loss:  3.676119804382324\n",
            "Test Loss:  5.614218711853027\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  695\n",
            "Train Loss:  3.6756186485290527\n",
            "Test Loss:  5.614248275756836\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  696\n",
            "Train Loss:  3.675119400024414\n",
            "Test Loss:  5.614278316497803\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  697\n",
            "Train Loss:  3.6746206283569336\n",
            "Test Loss:  5.614306926727295\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  698\n",
            "Train Loss:  3.6741232872009277\n",
            "Test Loss:  5.614337921142578\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  699\n",
            "Train Loss:  3.6736273765563965\n",
            "Test Loss:  5.614367485046387\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  700\n",
            "Train Loss:  3.6731314659118652\n",
            "Test Loss:  5.614398956298828\n",
            "Recall : 0.14476190476190476\n",
            "\n",
            "0.14035102040816358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6d9b7855ed6c4e5680f680ca79c828ec",
            "5ffa89f3b6b841ddad3fbfc276837e5d",
            "e93cac7a83044673a2a8f1675797da60",
            "8732dc5f0f1d4740afdfc6f98479e467",
            "bf4bbf6ce1bb40ce8df2ec9e49d5da8e",
            "3abd886811c641e19395c75c9a6f1065",
            "3babc9816288458eb16c031edb367097",
            "2a599039147f474baf4511fee59b5e91"
          ]
        },
        "id": "dqBnbpb9L0SY",
        "outputId": "c5e84f16-3e00-41ab-f5dc-c261f41193d8"
      },
      "source": [
        "run(path=\"resnet50.npy\",runs=1,epochs=700,k=1,temp=15,type=1,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d9b7855ed6c4e5680f680ca79c828ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.466360092163086\n",
            "Test Loss:  6.267712593078613\n",
            "Recall : 0.11523809523809524\n",
            "Epoch  2\n",
            "Train Loss:  7.392768859863281\n",
            "Test Loss:  6.226260185241699\n",
            "Recall : 0.11714285714285715\n",
            "Epoch  3\n",
            "Train Loss:  7.320338249206543\n",
            "Test Loss:  6.185888290405273\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  4\n",
            "Train Loss:  7.2491068840026855\n",
            "Test Loss:  6.146666526794434\n",
            "Recall : 0.11904761904761904\n",
            "Epoch  5\n",
            "Train Loss:  7.17912483215332\n",
            "Test Loss:  6.108649253845215\n",
            "Recall : 0.11904761904761904\n",
            "Epoch  6\n",
            "Train Loss:  7.110443115234375\n",
            "Test Loss:  6.071834564208984\n",
            "Recall : 0.12\n",
            "Epoch  7\n",
            "Train Loss:  7.043105125427246\n",
            "Test Loss:  6.036253452301025\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  8\n",
            "Train Loss:  6.977138519287109\n",
            "Test Loss:  6.001908302307129\n",
            "Recall : 0.1219047619047619\n",
            "Epoch  9\n",
            "Train Loss:  6.912550926208496\n",
            "Test Loss:  5.968816757202148\n",
            "Recall : 0.12285714285714286\n",
            "Epoch  10\n",
            "Train Loss:  6.849364757537842\n",
            "Test Loss:  5.936989784240723\n",
            "Recall : 0.12571428571428572\n",
            "Epoch  11\n",
            "Train Loss:  6.787575721740723\n",
            "Test Loss:  5.906402587890625\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  12\n",
            "Train Loss:  6.727164268493652\n",
            "Test Loss:  5.8770270347595215\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  13\n",
            "Train Loss:  6.668145656585693\n",
            "Test Loss:  5.848809242248535\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  14\n",
            "Train Loss:  6.610477447509766\n",
            "Test Loss:  5.821715354919434\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  15\n",
            "Train Loss:  6.554139137268066\n",
            "Test Loss:  5.795762538909912\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  16\n",
            "Train Loss:  6.499103546142578\n",
            "Test Loss:  5.770932674407959\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  17\n",
            "Train Loss:  6.445341110229492\n",
            "Test Loss:  5.747182846069336\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  18\n",
            "Train Loss:  6.392800331115723\n",
            "Test Loss:  5.724448204040527\n",
            "Recall : 0.14\n",
            "Epoch  19\n",
            "Train Loss:  6.341456413269043\n",
            "Test Loss:  5.702714920043945\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  20\n",
            "Train Loss:  6.291276931762695\n",
            "Test Loss:  5.681975841522217\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  21\n",
            "Train Loss:  6.242220878601074\n",
            "Test Loss:  5.662170886993408\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  22\n",
            "Train Loss:  6.194258689880371\n",
            "Test Loss:  5.643272399902344\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  23\n",
            "Train Loss:  6.147341251373291\n",
            "Test Loss:  5.625258922576904\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  24\n",
            "Train Loss:  6.101410388946533\n",
            "Test Loss:  5.608060359954834\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  25\n",
            "Train Loss:  6.0564165115356445\n",
            "Test Loss:  5.591622352600098\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  26\n",
            "Train Loss:  6.012321472167969\n",
            "Test Loss:  5.575920104980469\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  27\n",
            "Train Loss:  5.969095706939697\n",
            "Test Loss:  5.560925483703613\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  28\n",
            "Train Loss:  5.926713466644287\n",
            "Test Loss:  5.546618461608887\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  29\n",
            "Train Loss:  5.885131359100342\n",
            "Test Loss:  5.532954216003418\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  30\n",
            "Train Loss:  5.844311714172363\n",
            "Test Loss:  5.5199127197265625\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  31\n",
            "Train Loss:  5.804227828979492\n",
            "Test Loss:  5.507464408874512\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  32\n",
            "Train Loss:  5.764860153198242\n",
            "Test Loss:  5.495562553405762\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  33\n",
            "Train Loss:  5.726192474365234\n",
            "Test Loss:  5.484180450439453\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  34\n",
            "Train Loss:  5.688177108764648\n",
            "Test Loss:  5.473285675048828\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  35\n",
            "Train Loss:  5.650803565979004\n",
            "Test Loss:  5.46284818649292\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  36\n",
            "Train Loss:  5.614029407501221\n",
            "Test Loss:  5.452858924865723\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  37\n",
            "Train Loss:  5.577850341796875\n",
            "Test Loss:  5.443297863006592\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  38\n",
            "Train Loss:  5.542252540588379\n",
            "Test Loss:  5.434154510498047\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  39\n",
            "Train Loss:  5.507213592529297\n",
            "Test Loss:  5.4253950119018555\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  40\n",
            "Train Loss:  5.472721099853516\n",
            "Test Loss:  5.417009353637695\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  41\n",
            "Train Loss:  5.438756465911865\n",
            "Test Loss:  5.408967018127441\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  42\n",
            "Train Loss:  5.405301570892334\n",
            "Test Loss:  5.401250839233398\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  43\n",
            "Train Loss:  5.372345447540283\n",
            "Test Loss:  5.393841743469238\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  44\n",
            "Train Loss:  5.3398637771606445\n",
            "Test Loss:  5.386727333068848\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  45\n",
            "Train Loss:  5.307848930358887\n",
            "Test Loss:  5.379889965057373\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  46\n",
            "Train Loss:  5.276289939880371\n",
            "Test Loss:  5.373318672180176\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  47\n",
            "Train Loss:  5.245182037353516\n",
            "Test Loss:  5.366992473602295\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  48\n",
            "Train Loss:  5.214514255523682\n",
            "Test Loss:  5.360898017883301\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  49\n",
            "Train Loss:  5.184283256530762\n",
            "Test Loss:  5.3550262451171875\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  50\n",
            "Train Loss:  5.154480934143066\n",
            "Test Loss:  5.349398612976074\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  51\n",
            "Train Loss:  5.125107765197754\n",
            "Test Loss:  5.343996047973633\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  52\n",
            "Train Loss:  5.096151351928711\n",
            "Test Loss:  5.338799476623535\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  53\n",
            "Train Loss:  5.067600250244141\n",
            "Test Loss:  5.333799839019775\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  54\n",
            "Train Loss:  5.039442539215088\n",
            "Test Loss:  5.329024791717529\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  55\n",
            "Train Loss:  5.011682987213135\n",
            "Test Loss:  5.3244476318359375\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  56\n",
            "Train Loss:  4.984316825866699\n",
            "Test Loss:  5.320066452026367\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  57\n",
            "Train Loss:  4.957329273223877\n",
            "Test Loss:  5.315853118896484\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  58\n",
            "Train Loss:  4.9307098388671875\n",
            "Test Loss:  5.311803340911865\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  59\n",
            "Train Loss:  4.904463291168213\n",
            "Test Loss:  5.3078932762146\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  60\n",
            "Train Loss:  4.8785810470581055\n",
            "Test Loss:  5.3041181564331055\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  61\n",
            "Train Loss:  4.853059768676758\n",
            "Test Loss:  5.300477981567383\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  62\n",
            "Train Loss:  4.827887535095215\n",
            "Test Loss:  5.2969770431518555\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  63\n",
            "Train Loss:  4.803067684173584\n",
            "Test Loss:  5.293632984161377\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  64\n",
            "Train Loss:  4.778594017028809\n",
            "Test Loss:  5.29042911529541\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  65\n",
            "Train Loss:  4.754457473754883\n",
            "Test Loss:  5.287352561950684\n",
            "Recall : 0.18\n",
            "Epoch  66\n",
            "Train Loss:  4.730652809143066\n",
            "Test Loss:  5.284385681152344\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  67\n",
            "Train Loss:  4.707162857055664\n",
            "Test Loss:  5.281538963317871\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  68\n",
            "Train Loss:  4.683981418609619\n",
            "Test Loss:  5.278830051422119\n",
            "Recall : 0.18\n",
            "Epoch  69\n",
            "Train Loss:  4.661111831665039\n",
            "Test Loss:  5.2762556076049805\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  70\n",
            "Train Loss:  4.638542652130127\n",
            "Test Loss:  5.2737884521484375\n",
            "Recall : 0.18\n",
            "Epoch  71\n",
            "Train Loss:  4.616277694702148\n",
            "Test Loss:  5.271422386169434\n",
            "Recall : 0.18\n",
            "Epoch  72\n",
            "Train Loss:  4.594304084777832\n",
            "Test Loss:  5.269163131713867\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  73\n",
            "Train Loss:  4.572632789611816\n",
            "Test Loss:  5.267027854919434\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  74\n",
            "Train Loss:  4.551261901855469\n",
            "Test Loss:  5.2650146484375\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  75\n",
            "Train Loss:  4.53018856048584\n",
            "Test Loss:  5.263106346130371\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  76\n",
            "Train Loss:  4.509407997131348\n",
            "Test Loss:  5.261290073394775\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  77\n",
            "Train Loss:  4.4889068603515625\n",
            "Test Loss:  5.259565353393555\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  78\n",
            "Train Loss:  4.4686808586120605\n",
            "Test Loss:  5.257936000823975\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  79\n",
            "Train Loss:  4.4487152099609375\n",
            "Test Loss:  5.256404399871826\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  80\n",
            "Train Loss:  4.42901086807251\n",
            "Test Loss:  5.2549662590026855\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  81\n",
            "Train Loss:  4.409574508666992\n",
            "Test Loss:  5.253637313842773\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  82\n",
            "Train Loss:  4.39039421081543\n",
            "Test Loss:  5.25238037109375\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  83\n",
            "Train Loss:  4.371466636657715\n",
            "Test Loss:  5.251219749450684\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  84\n",
            "Train Loss:  4.352792263031006\n",
            "Test Loss:  5.250134468078613\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  85\n",
            "Train Loss:  4.334362030029297\n",
            "Test Loss:  5.249119758605957\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  86\n",
            "Train Loss:  4.316167831420898\n",
            "Test Loss:  5.248183250427246\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  87\n",
            "Train Loss:  4.298211097717285\n",
            "Test Loss:  5.247324466705322\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  88\n",
            "Train Loss:  4.280499458312988\n",
            "Test Loss:  5.246530532836914\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  89\n",
            "Train Loss:  4.263026714324951\n",
            "Test Loss:  5.245805740356445\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  90\n",
            "Train Loss:  4.24578857421875\n",
            "Test Loss:  5.245146751403809\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  91\n",
            "Train Loss:  4.228775978088379\n",
            "Test Loss:  5.244551181793213\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  92\n",
            "Train Loss:  4.2119855880737305\n",
            "Test Loss:  5.244019985198975\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  93\n",
            "Train Loss:  4.195405006408691\n",
            "Test Loss:  5.243541717529297\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  94\n",
            "Train Loss:  4.179043769836426\n",
            "Test Loss:  5.243109703063965\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  95\n",
            "Train Loss:  4.162899017333984\n",
            "Test Loss:  5.242715835571289\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  96\n",
            "Train Loss:  4.1469621658325195\n",
            "Test Loss:  5.242379188537598\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  97\n",
            "Train Loss:  4.131229877471924\n",
            "Test Loss:  5.242091178894043\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  98\n",
            "Train Loss:  4.115704536437988\n",
            "Test Loss:  5.241848468780518\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  99\n",
            "Train Loss:  4.1003851890563965\n",
            "Test Loss:  5.241655349731445\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  100\n",
            "Train Loss:  4.085261344909668\n",
            "Test Loss:  5.241512298583984\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  101\n",
            "Train Loss:  4.070335388183594\n",
            "Test Loss:  5.241418838500977\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  102\n",
            "Train Loss:  4.055598735809326\n",
            "Test Loss:  5.241371154785156\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  103\n",
            "Train Loss:  4.041045665740967\n",
            "Test Loss:  5.24136209487915\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  104\n",
            "Train Loss:  4.02668571472168\n",
            "Test Loss:  5.241384506225586\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  105\n",
            "Train Loss:  4.01251745223999\n",
            "Test Loss:  5.241440296173096\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  106\n",
            "Train Loss:  3.9985430240631104\n",
            "Test Loss:  5.24152135848999\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  107\n",
            "Train Loss:  3.9847524166107178\n",
            "Test Loss:  5.241636276245117\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  108\n",
            "Train Loss:  3.9711427688598633\n",
            "Test Loss:  5.241793632507324\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  109\n",
            "Train Loss:  3.9577155113220215\n",
            "Test Loss:  5.241974830627441\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  110\n",
            "Train Loss:  3.944460868835449\n",
            "Test Loss:  5.242198944091797\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  111\n",
            "Train Loss:  3.931382656097412\n",
            "Test Loss:  5.242452144622803\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  112\n",
            "Train Loss:  3.9184818267822266\n",
            "Test Loss:  5.242725372314453\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  113\n",
            "Train Loss:  3.9057488441467285\n",
            "Test Loss:  5.243022918701172\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  114\n",
            "Train Loss:  3.893186092376709\n",
            "Test Loss:  5.243350505828857\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  115\n",
            "Train Loss:  3.880784749984741\n",
            "Test Loss:  5.243709564208984\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  116\n",
            "Train Loss:  3.8685455322265625\n",
            "Test Loss:  5.244107246398926\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  117\n",
            "Train Loss:  3.856461524963379\n",
            "Test Loss:  5.244512557983398\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  118\n",
            "Train Loss:  3.8445322513580322\n",
            "Test Loss:  5.244959831237793\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  119\n",
            "Train Loss:  3.832753896713257\n",
            "Test Loss:  5.2454376220703125\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  120\n",
            "Train Loss:  3.8211159706115723\n",
            "Test Loss:  5.245946884155273\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  121\n",
            "Train Loss:  3.8096203804016113\n",
            "Test Loss:  5.24647331237793\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  122\n",
            "Train Loss:  3.7982687950134277\n",
            "Test Loss:  5.247023582458496\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  123\n",
            "Train Loss:  3.787061929702759\n",
            "Test Loss:  5.2476115226745605\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  124\n",
            "Train Loss:  3.7759993076324463\n",
            "Test Loss:  5.248232364654541\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  125\n",
            "Train Loss:  3.765082359313965\n",
            "Test Loss:  5.248877048492432\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  126\n",
            "Train Loss:  3.7543115615844727\n",
            "Test Loss:  5.249534606933594\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  127\n",
            "Train Loss:  3.74367094039917\n",
            "Test Loss:  5.250231742858887\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  128\n",
            "Train Loss:  3.733154535293579\n",
            "Test Loss:  5.250943183898926\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  129\n",
            "Train Loss:  3.7227654457092285\n",
            "Test Loss:  5.251673698425293\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  130\n",
            "Train Loss:  3.712508201599121\n",
            "Test Loss:  5.252442836761475\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  131\n",
            "Train Loss:  3.70237398147583\n",
            "Test Loss:  5.25323486328125\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  132\n",
            "Train Loss:  3.692359447479248\n",
            "Test Loss:  5.25405740737915\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  133\n",
            "Train Loss:  3.682469129562378\n",
            "Test Loss:  5.254907608032227\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  134\n",
            "Train Loss:  3.6726999282836914\n",
            "Test Loss:  5.255784034729004\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  135\n",
            "Train Loss:  3.6630473136901855\n",
            "Test Loss:  5.256678581237793\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  136\n",
            "Train Loss:  3.653517007827759\n",
            "Test Loss:  5.257591724395752\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  137\n",
            "Train Loss:  3.644103527069092\n",
            "Test Loss:  5.258511543273926\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  138\n",
            "Train Loss:  3.6348037719726562\n",
            "Test Loss:  5.2594499588012695\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  139\n",
            "Train Loss:  3.6256167888641357\n",
            "Test Loss:  5.260401725769043\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  140\n",
            "Train Loss:  3.6165401935577393\n",
            "Test Loss:  5.261368751525879\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  141\n",
            "Train Loss:  3.607571601867676\n",
            "Test Loss:  5.262350082397461\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  142\n",
            "Train Loss:  3.5987067222595215\n",
            "Test Loss:  5.263340950012207\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  143\n",
            "Train Loss:  3.5899477005004883\n",
            "Test Loss:  5.264340400695801\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  144\n",
            "Train Loss:  3.581282615661621\n",
            "Test Loss:  5.265345573425293\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  145\n",
            "Train Loss:  3.5727148056030273\n",
            "Test Loss:  5.266355037689209\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  146\n",
            "Train Loss:  3.564243793487549\n",
            "Test Loss:  5.26737117767334\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  147\n",
            "Train Loss:  3.555868148803711\n",
            "Test Loss:  5.268390655517578\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  148\n",
            "Train Loss:  3.5475850105285645\n",
            "Test Loss:  5.2694091796875\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  149\n",
            "Train Loss:  3.5393900871276855\n",
            "Test Loss:  5.270442008972168\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  150\n",
            "Train Loss:  3.5312857627868652\n",
            "Test Loss:  5.271487236022949\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  151\n",
            "Train Loss:  3.523277521133423\n",
            "Test Loss:  5.272538185119629\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  152\n",
            "Train Loss:  3.5153589248657227\n",
            "Test Loss:  5.273592948913574\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  153\n",
            "Train Loss:  3.5075206756591797\n",
            "Test Loss:  5.274653434753418\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  154\n",
            "Train Loss:  3.499767303466797\n",
            "Test Loss:  5.275713920593262\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  155\n",
            "Train Loss:  3.4920969009399414\n",
            "Test Loss:  5.2767839431762695\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  156\n",
            "Train Loss:  3.4845120906829834\n",
            "Test Loss:  5.2778730392456055\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  157\n",
            "Train Loss:  3.4770162105560303\n",
            "Test Loss:  5.27897834777832\n",
            "Recall : 0.19428571428571428\n",
            "Epoch  158\n",
            "Train Loss:  3.4695987701416016\n",
            "Test Loss:  5.2801032066345215\n",
            "Recall : 0.19428571428571428\n",
            "Epoch  159\n",
            "Train Loss:  3.462266683578491\n",
            "Test Loss:  5.281228065490723\n",
            "Recall : 0.19428571428571428\n",
            "Epoch  160\n",
            "Train Loss:  3.4550161361694336\n",
            "Test Loss:  5.282366752624512\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  161\n",
            "Train Loss:  3.447845458984375\n",
            "Test Loss:  5.2835235595703125\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  162\n",
            "Train Loss:  3.4407525062561035\n",
            "Test Loss:  5.2846856117248535\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  163\n",
            "Train Loss:  3.4337339401245117\n",
            "Test Loss:  5.285829544067383\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  164\n",
            "Train Loss:  3.4267916679382324\n",
            "Test Loss:  5.286961555480957\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  165\n",
            "Train Loss:  3.4199275970458984\n",
            "Test Loss:  5.288084983825684\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  166\n",
            "Train Loss:  3.4131388664245605\n",
            "Test Loss:  5.289198875427246\n",
            "Recall : 0.19428571428571428\n",
            "Epoch  167\n",
            "Train Loss:  3.4064226150512695\n",
            "Test Loss:  5.2902984619140625\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  168\n",
            "Train Loss:  3.399773120880127\n",
            "Test Loss:  5.2914137840271\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  169\n",
            "Train Loss:  3.3931896686553955\n",
            "Test Loss:  5.292542934417725\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  170\n",
            "Train Loss:  3.3866729736328125\n",
            "Test Loss:  5.293669700622559\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  171\n",
            "Train Loss:  3.3802237510681152\n",
            "Test Loss:  5.294792175292969\n",
            "Recall : 0.19333333333333333\n",
            "Epoch  172\n",
            "Train Loss:  3.3738420009613037\n",
            "Test Loss:  5.295926094055176\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  173\n",
            "Train Loss:  3.3675179481506348\n",
            "Test Loss:  5.297060966491699\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  174\n",
            "Train Loss:  3.3612546920776367\n",
            "Test Loss:  5.298206329345703\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  175\n",
            "Train Loss:  3.3550565242767334\n",
            "Test Loss:  5.2993693351745605\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  176\n",
            "Train Loss:  3.34891676902771\n",
            "Test Loss:  5.30055570602417\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  177\n",
            "Train Loss:  3.342839479446411\n",
            "Test Loss:  5.301767349243164\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  178\n",
            "Train Loss:  3.336820363998413\n",
            "Test Loss:  5.303006172180176\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  179\n",
            "Train Loss:  3.330862045288086\n",
            "Test Loss:  5.3042802810668945\n",
            "Recall : 0.19047619047619047\n",
            "Epoch  180\n",
            "Train Loss:  3.324962615966797\n",
            "Test Loss:  5.30557107925415\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  181\n",
            "Train Loss:  3.319121837615967\n",
            "Test Loss:  5.3068742752075195\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  182\n",
            "Train Loss:  3.313340902328491\n",
            "Test Loss:  5.308198928833008\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  183\n",
            "Train Loss:  3.3076157569885254\n",
            "Test Loss:  5.309523582458496\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  184\n",
            "Train Loss:  3.3019485473632812\n",
            "Test Loss:  5.310854911804199\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  185\n",
            "Train Loss:  3.2963335514068604\n",
            "Test Loss:  5.312189102172852\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  186\n",
            "Train Loss:  3.290771007537842\n",
            "Test Loss:  5.313529014587402\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  187\n",
            "Train Loss:  3.285261392593384\n",
            "Test Loss:  5.31486701965332\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  188\n",
            "Train Loss:  3.279801845550537\n",
            "Test Loss:  5.31620979309082\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  189\n",
            "Train Loss:  3.2743923664093018\n",
            "Test Loss:  5.317562103271484\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  190\n",
            "Train Loss:  3.269031286239624\n",
            "Test Loss:  5.318922996520996\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  191\n",
            "Train Loss:  3.2637147903442383\n",
            "Test Loss:  5.320279598236084\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  192\n",
            "Train Loss:  3.2584426403045654\n",
            "Test Loss:  5.321639060974121\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  193\n",
            "Train Loss:  3.253221035003662\n",
            "Test Loss:  5.323003768920898\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  194\n",
            "Train Loss:  3.2480509281158447\n",
            "Test Loss:  5.324366569519043\n",
            "Recall : 0.19238095238095237\n",
            "Epoch  195\n",
            "Train Loss:  3.2429275512695312\n",
            "Test Loss:  5.3257246017456055\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  196\n",
            "Train Loss:  3.237849235534668\n",
            "Test Loss:  5.327065467834473\n",
            "Recall : 0.19142857142857142\n",
            "Epoch  197\n",
            "Train Loss:  3.232818126678467\n",
            "Test Loss:  5.328393459320068\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  198\n",
            "Train Loss:  3.22782564163208\n",
            "Test Loss:  5.329714298248291\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  199\n",
            "Train Loss:  3.2228751182556152\n",
            "Test Loss:  5.331028461456299\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  200\n",
            "Train Loss:  3.2179691791534424\n",
            "Test Loss:  5.33233642578125\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  201\n",
            "Train Loss:  3.2131083011627197\n",
            "Test Loss:  5.333662986755371\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  202\n",
            "Train Loss:  3.2082934379577637\n",
            "Test Loss:  5.334990501403809\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  203\n",
            "Train Loss:  3.2035257816314697\n",
            "Test Loss:  5.336331367492676\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  204\n",
            "Train Loss:  3.1988019943237305\n",
            "Test Loss:  5.337678909301758\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  205\n",
            "Train Loss:  3.1941161155700684\n",
            "Test Loss:  5.339019775390625\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  206\n",
            "Train Loss:  3.1894683837890625\n",
            "Test Loss:  5.340353965759277\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  207\n",
            "Train Loss:  3.18485951423645\n",
            "Test Loss:  5.341705322265625\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  208\n",
            "Train Loss:  3.180286407470703\n",
            "Test Loss:  5.343079566955566\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  209\n",
            "Train Loss:  3.175746202468872\n",
            "Test Loss:  5.3444623947143555\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  210\n",
            "Train Loss:  3.1712424755096436\n",
            "Test Loss:  5.345848083496094\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  211\n",
            "Train Loss:  3.166775941848755\n",
            "Test Loss:  5.347228527069092\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  212\n",
            "Train Loss:  3.1623430252075195\n",
            "Test Loss:  5.348597526550293\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  213\n",
            "Train Loss:  3.1579418182373047\n",
            "Test Loss:  5.349973201751709\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  214\n",
            "Train Loss:  3.1535744667053223\n",
            "Test Loss:  5.351365566253662\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  215\n",
            "Train Loss:  3.1492414474487305\n",
            "Test Loss:  5.352780342102051\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  216\n",
            "Train Loss:  3.144944190979004\n",
            "Test Loss:  5.35422420501709\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  217\n",
            "Train Loss:  3.140685558319092\n",
            "Test Loss:  5.355694770812988\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  218\n",
            "Train Loss:  3.1364622116088867\n",
            "Test Loss:  5.357195854187012\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  219\n",
            "Train Loss:  3.132272243499756\n",
            "Test Loss:  5.358705520629883\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  220\n",
            "Train Loss:  3.128119468688965\n",
            "Test Loss:  5.360227584838867\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  221\n",
            "Train Loss:  3.124002695083618\n",
            "Test Loss:  5.361746311187744\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  222\n",
            "Train Loss:  3.1199193000793457\n",
            "Test Loss:  5.363265037536621\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  223\n",
            "Train Loss:  3.11586856842041\n",
            "Test Loss:  5.364799499511719\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  224\n",
            "Train Loss:  3.111849308013916\n",
            "Test Loss:  5.366368293762207\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  225\n",
            "Train Loss:  3.107858657836914\n",
            "Test Loss:  5.367948532104492\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  226\n",
            "Train Loss:  3.103896141052246\n",
            "Test Loss:  5.369539737701416\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  227\n",
            "Train Loss:  3.0999655723571777\n",
            "Test Loss:  5.371146202087402\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  228\n",
            "Train Loss:  3.0960617065429688\n",
            "Test Loss:  5.3727617263793945\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  229\n",
            "Train Loss:  3.092182159423828\n",
            "Test Loss:  5.3743743896484375\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  230\n",
            "Train Loss:  3.088329792022705\n",
            "Test Loss:  5.37599515914917\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  231\n",
            "Train Loss:  3.084503173828125\n",
            "Test Loss:  5.377634048461914\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  232\n",
            "Train Loss:  3.0807008743286133\n",
            "Test Loss:  5.379299640655518\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  233\n",
            "Train Loss:  3.076922655105591\n",
            "Test Loss:  5.380998611450195\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  234\n",
            "Train Loss:  3.0731661319732666\n",
            "Test Loss:  5.382709503173828\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  235\n",
            "Train Loss:  3.069431781768799\n",
            "Test Loss:  5.384432792663574\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  236\n",
            "Train Loss:  3.0657200813293457\n",
            "Test Loss:  5.386184215545654\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  237\n",
            "Train Loss:  3.0620312690734863\n",
            "Test Loss:  5.387957572937012\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  238\n",
            "Train Loss:  3.0583701133728027\n",
            "Test Loss:  5.3897552490234375\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  239\n",
            "Train Loss:  3.054733991622925\n",
            "Test Loss:  5.3915486335754395\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  240\n",
            "Train Loss:  3.051121711730957\n",
            "Test Loss:  5.39333438873291\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  241\n",
            "Train Loss:  3.04752779006958\n",
            "Test Loss:  5.395115375518799\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  242\n",
            "Train Loss:  3.0439529418945312\n",
            "Test Loss:  5.396894454956055\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  243\n",
            "Train Loss:  3.0403976440429688\n",
            "Test Loss:  5.398677825927734\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  244\n",
            "Train Loss:  3.0368611812591553\n",
            "Test Loss:  5.400462627410889\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  245\n",
            "Train Loss:  3.03334903717041\n",
            "Test Loss:  5.402251243591309\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  246\n",
            "Train Loss:  3.0298585891723633\n",
            "Test Loss:  5.404045581817627\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  247\n",
            "Train Loss:  3.02638578414917\n",
            "Test Loss:  5.405834197998047\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  248\n",
            "Train Loss:  3.022940158843994\n",
            "Test Loss:  5.407618522644043\n",
            "Recall : 0.18\n",
            "Epoch  249\n",
            "Train Loss:  3.0195212364196777\n",
            "Test Loss:  5.409407615661621\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  250\n",
            "Train Loss:  3.016124963760376\n",
            "Test Loss:  5.411190986633301\n",
            "Recall : 0.18\n",
            "Epoch  251\n",
            "Train Loss:  3.0127477645874023\n",
            "Test Loss:  5.412976264953613\n",
            "Recall : 0.18\n",
            "Epoch  252\n",
            "Train Loss:  3.009394645690918\n",
            "Test Loss:  5.414772987365723\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  253\n",
            "Train Loss:  3.0060644149780273\n",
            "Test Loss:  5.416579246520996\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  254\n",
            "Train Loss:  3.0027518272399902\n",
            "Test Loss:  5.4183735847473145\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  255\n",
            "Train Loss:  2.9994571208953857\n",
            "Test Loss:  5.420159339904785\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  256\n",
            "Train Loss:  2.9961798191070557\n",
            "Test Loss:  5.421935081481934\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  257\n",
            "Train Loss:  2.9929206371307373\n",
            "Test Loss:  5.423686981201172\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  258\n",
            "Train Loss:  2.989682197570801\n",
            "Test Loss:  5.425427436828613\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  259\n",
            "Train Loss:  2.9864625930786133\n",
            "Test Loss:  5.427151679992676\n",
            "Recall : 0.18\n",
            "Epoch  260\n",
            "Train Loss:  2.983262062072754\n",
            "Test Loss:  5.4288716316223145\n",
            "Recall : 0.18\n",
            "Epoch  261\n",
            "Train Loss:  2.98007869720459\n",
            "Test Loss:  5.430598735809326\n",
            "Recall : 0.18\n",
            "Epoch  262\n",
            "Train Loss:  2.976912498474121\n",
            "Test Loss:  5.4323272705078125\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  263\n",
            "Train Loss:  2.973766565322876\n",
            "Test Loss:  5.434062957763672\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  264\n",
            "Train Loss:  2.970640182495117\n",
            "Test Loss:  5.435791492462158\n",
            "Recall : 0.18\n",
            "Epoch  265\n",
            "Train Loss:  2.967529296875\n",
            "Test Loss:  5.43752384185791\n",
            "Recall : 0.18\n",
            "Epoch  266\n",
            "Train Loss:  2.964432716369629\n",
            "Test Loss:  5.4392499923706055\n",
            "Recall : 0.18\n",
            "Epoch  267\n",
            "Train Loss:  2.961355686187744\n",
            "Test Loss:  5.440984725952148\n",
            "Recall : 0.18\n",
            "Epoch  268\n",
            "Train Loss:  2.9582996368408203\n",
            "Test Loss:  5.442738056182861\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  269\n",
            "Train Loss:  2.955256223678589\n",
            "Test Loss:  5.44449520111084\n",
            "Recall : 0.18\n",
            "Epoch  270\n",
            "Train Loss:  2.9522314071655273\n",
            "Test Loss:  5.446255207061768\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  271\n",
            "Train Loss:  2.9492247104644775\n",
            "Test Loss:  5.4480204582214355\n",
            "Recall : 0.18\n",
            "Epoch  272\n",
            "Train Loss:  2.9462380409240723\n",
            "Test Loss:  5.449787139892578\n",
            "Recall : 0.18\n",
            "Epoch  273\n",
            "Train Loss:  2.943272113800049\n",
            "Test Loss:  5.451549530029297\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  274\n",
            "Train Loss:  2.9403223991394043\n",
            "Test Loss:  5.45332145690918\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  275\n",
            "Train Loss:  2.937392234802246\n",
            "Test Loss:  5.455111503601074\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  276\n",
            "Train Loss:  2.934481382369995\n",
            "Test Loss:  5.456918716430664\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  277\n",
            "Train Loss:  2.9315872192382812\n",
            "Test Loss:  5.458734035491943\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  278\n",
            "Train Loss:  2.928711175918579\n",
            "Test Loss:  5.460555076599121\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  279\n",
            "Train Loss:  2.925849199295044\n",
            "Test Loss:  5.462392807006836\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  280\n",
            "Train Loss:  2.922999858856201\n",
            "Test Loss:  5.464254379272461\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  281\n",
            "Train Loss:  2.9201626777648926\n",
            "Test Loss:  5.466125011444092\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  282\n",
            "Train Loss:  2.9173412322998047\n",
            "Test Loss:  5.4679856300354\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  283\n",
            "Train Loss:  2.914529323577881\n",
            "Test Loss:  5.4698333740234375\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  284\n",
            "Train Loss:  2.911729335784912\n",
            "Test Loss:  5.471678733825684\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  285\n",
            "Train Loss:  2.908939838409424\n",
            "Test Loss:  5.473519325256348\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  286\n",
            "Train Loss:  2.9061622619628906\n",
            "Test Loss:  5.475356578826904\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  287\n",
            "Train Loss:  2.9033968448638916\n",
            "Test Loss:  5.477191925048828\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  288\n",
            "Train Loss:  2.9006447792053223\n",
            "Test Loss:  5.479022026062012\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  289\n",
            "Train Loss:  2.8979063034057617\n",
            "Test Loss:  5.480851173400879\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  290\n",
            "Train Loss:  2.8951797485351562\n",
            "Test Loss:  5.48267936706543\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  291\n",
            "Train Loss:  2.892465591430664\n",
            "Test Loss:  5.484505653381348\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  292\n",
            "Train Loss:  2.889761447906494\n",
            "Test Loss:  5.486328125\n",
            "Recall : 0.18\n",
            "Epoch  293\n",
            "Train Loss:  2.8870692253112793\n",
            "Test Loss:  5.488129615783691\n",
            "Recall : 0.18\n",
            "Epoch  294\n",
            "Train Loss:  2.8843889236450195\n",
            "Test Loss:  5.489912986755371\n",
            "Recall : 0.18\n",
            "Epoch  295\n",
            "Train Loss:  2.881721019744873\n",
            "Test Loss:  5.4917144775390625\n",
            "Recall : 0.18\n",
            "Epoch  296\n",
            "Train Loss:  2.8790693283081055\n",
            "Test Loss:  5.493523597717285\n",
            "Recall : 0.18\n",
            "Epoch  297\n",
            "Train Loss:  2.8764333724975586\n",
            "Test Loss:  5.495325088500977\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  298\n",
            "Train Loss:  2.873806953430176\n",
            "Test Loss:  5.497126579284668\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  299\n",
            "Train Loss:  2.871189832687378\n",
            "Test Loss:  5.498941421508789\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  300\n",
            "Train Loss:  2.8685898780822754\n",
            "Test Loss:  5.500771522521973\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  301\n",
            "Train Loss:  2.8660030364990234\n",
            "Test Loss:  5.502620697021484\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  302\n",
            "Train Loss:  2.8634285926818848\n",
            "Test Loss:  5.504490852355957\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  303\n",
            "Train Loss:  2.8608641624450684\n",
            "Test Loss:  5.506374359130859\n",
            "Recall : 0.18\n",
            "Epoch  304\n",
            "Train Loss:  2.8583154678344727\n",
            "Test Loss:  5.508248805999756\n",
            "Recall : 0.18\n",
            "Epoch  305\n",
            "Train Loss:  2.8557801246643066\n",
            "Test Loss:  5.51011848449707\n",
            "Recall : 0.18\n",
            "Epoch  306\n",
            "Train Loss:  2.8532586097717285\n",
            "Test Loss:  5.5119781494140625\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  307\n",
            "Train Loss:  2.850747585296631\n",
            "Test Loss:  5.513831615447998\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  308\n",
            "Train Loss:  2.848249912261963\n",
            "Test Loss:  5.515693664550781\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  309\n",
            "Train Loss:  2.845766067504883\n",
            "Test Loss:  5.51755428314209\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  310\n",
            "Train Loss:  2.8432936668395996\n",
            "Test Loss:  5.519438743591309\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  311\n",
            "Train Loss:  2.840832233428955\n",
            "Test Loss:  5.521343231201172\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  312\n",
            "Train Loss:  2.838381767272949\n",
            "Test Loss:  5.523266315460205\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  313\n",
            "Train Loss:  2.835937976837158\n",
            "Test Loss:  5.525198459625244\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  314\n",
            "Train Loss:  2.8335020542144775\n",
            "Test Loss:  5.527105331420898\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  315\n",
            "Train Loss:  2.8310739994049072\n",
            "Test Loss:  5.528997898101807\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  316\n",
            "Train Loss:  2.8286566734313965\n",
            "Test Loss:  5.530890464782715\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  317\n",
            "Train Loss:  2.8262486457824707\n",
            "Test Loss:  5.532784938812256\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  318\n",
            "Train Loss:  2.8238508701324463\n",
            "Test Loss:  5.534704208374023\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  319\n",
            "Train Loss:  2.8214645385742188\n",
            "Test Loss:  5.536656379699707\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  320\n",
            "Train Loss:  2.8190841674804688\n",
            "Test Loss:  5.538620948791504\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  321\n",
            "Train Loss:  2.8167099952697754\n",
            "Test Loss:  5.540589332580566\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  322\n",
            "Train Loss:  2.814344882965088\n",
            "Test Loss:  5.542544364929199\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  323\n",
            "Train Loss:  2.811988115310669\n",
            "Test Loss:  5.5444769859313965\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  324\n",
            "Train Loss:  2.809640884399414\n",
            "Test Loss:  5.5463762283325195\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  325\n",
            "Train Loss:  2.8073031902313232\n",
            "Test Loss:  5.548279762268066\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  326\n",
            "Train Loss:  2.804975748062134\n",
            "Test Loss:  5.550180912017822\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  327\n",
            "Train Loss:  2.80265736579895\n",
            "Test Loss:  5.552084922790527\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  328\n",
            "Train Loss:  2.8003432750701904\n",
            "Test Loss:  5.553974151611328\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  329\n",
            "Train Loss:  2.7980356216430664\n",
            "Test Loss:  5.555846214294434\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  330\n",
            "Train Loss:  2.7957353591918945\n",
            "Test Loss:  5.557705879211426\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  331\n",
            "Train Loss:  2.793440818786621\n",
            "Test Loss:  5.559569358825684\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  332\n",
            "Train Loss:  2.7911529541015625\n",
            "Test Loss:  5.561455726623535\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  333\n",
            "Train Loss:  2.7888734340667725\n",
            "Test Loss:  5.563359260559082\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  334\n",
            "Train Loss:  2.7866034507751465\n",
            "Test Loss:  5.565263271331787\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  335\n",
            "Train Loss:  2.78433895111084\n",
            "Test Loss:  5.567156791687012\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  336\n",
            "Train Loss:  2.7820825576782227\n",
            "Test Loss:  5.569036960601807\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  337\n",
            "Train Loss:  2.779832363128662\n",
            "Test Loss:  5.570935249328613\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  338\n",
            "Train Loss:  2.777588367462158\n",
            "Test Loss:  5.572867393493652\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  339\n",
            "Train Loss:  2.7753498554229736\n",
            "Test Loss:  5.57482385635376\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  340\n",
            "Train Loss:  2.77311635017395\n",
            "Test Loss:  5.576800346374512\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  341\n",
            "Train Loss:  2.7708871364593506\n",
            "Test Loss:  5.57878303527832\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  342\n",
            "Train Loss:  2.768662452697754\n",
            "Test Loss:  5.580763339996338\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  343\n",
            "Train Loss:  2.7664473056793213\n",
            "Test Loss:  5.5827436447143555\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  344\n",
            "Train Loss:  2.7642385959625244\n",
            "Test Loss:  5.584682464599609\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  345\n",
            "Train Loss:  2.762038230895996\n",
            "Test Loss:  5.586586952209473\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  346\n",
            "Train Loss:  2.7598466873168945\n",
            "Test Loss:  5.588494300842285\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  347\n",
            "Train Loss:  2.7576613426208496\n",
            "Test Loss:  5.590394973754883\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  348\n",
            "Train Loss:  2.7554800510406494\n",
            "Test Loss:  5.592288017272949\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  349\n",
            "Train Loss:  2.7533082962036133\n",
            "Test Loss:  5.59417724609375\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  350\n",
            "Train Loss:  2.751140594482422\n",
            "Test Loss:  5.5960845947265625\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  351\n",
            "Train Loss:  2.748974561691284\n",
            "Test Loss:  5.598025321960449\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  352\n",
            "Train Loss:  2.746818780899048\n",
            "Test Loss:  5.599977493286133\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  353\n",
            "Train Loss:  2.74467134475708\n",
            "Test Loss:  5.601940155029297\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  354\n",
            "Train Loss:  2.7425296306610107\n",
            "Test Loss:  5.603903293609619\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  355\n",
            "Train Loss:  2.7403974533081055\n",
            "Test Loss:  5.60584831237793\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  356\n",
            "Train Loss:  2.7382760047912598\n",
            "Test Loss:  5.607810974121094\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  357\n",
            "Train Loss:  2.7361602783203125\n",
            "Test Loss:  5.6097869873046875\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  358\n",
            "Train Loss:  2.7340481281280518\n",
            "Test Loss:  5.611722946166992\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  359\n",
            "Train Loss:  2.7319414615631104\n",
            "Test Loss:  5.613645553588867\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  360\n",
            "Train Loss:  2.7298450469970703\n",
            "Test Loss:  5.6155476570129395\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  361\n",
            "Train Loss:  2.7277584075927734\n",
            "Test Loss:  5.617438793182373\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  362\n",
            "Train Loss:  2.725679397583008\n",
            "Test Loss:  5.619330883026123\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  363\n",
            "Train Loss:  2.723609209060669\n",
            "Test Loss:  5.621273994445801\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  364\n",
            "Train Loss:  2.721543550491333\n",
            "Test Loss:  5.623258590698242\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  365\n",
            "Train Loss:  2.719484329223633\n",
            "Test Loss:  5.6252522468566895\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  366\n",
            "Train Loss:  2.71743106842041\n",
            "Test Loss:  5.627227783203125\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  367\n",
            "Train Loss:  2.7153847217559814\n",
            "Test Loss:  5.6291823387146\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  368\n",
            "Train Loss:  2.7133448123931885\n",
            "Test Loss:  5.631150245666504\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  369\n",
            "Train Loss:  2.7113144397735596\n",
            "Test Loss:  5.6331377029418945\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  370\n",
            "Train Loss:  2.7093005180358887\n",
            "Test Loss:  5.63511848449707\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  371\n",
            "Train Loss:  2.7072930335998535\n",
            "Test Loss:  5.637120246887207\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  372\n",
            "Train Loss:  2.705291986465454\n",
            "Test Loss:  5.639152526855469\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  373\n",
            "Train Loss:  2.7032947540283203\n",
            "Test Loss:  5.641180038452148\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  374\n",
            "Train Loss:  2.7013065814971924\n",
            "Test Loss:  5.643162727355957\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  375\n",
            "Train Loss:  2.6993229389190674\n",
            "Test Loss:  5.6450934410095215\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  376\n",
            "Train Loss:  2.6973466873168945\n",
            "Test Loss:  5.647022247314453\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  377\n",
            "Train Loss:  2.695375442504883\n",
            "Test Loss:  5.648945331573486\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  378\n",
            "Train Loss:  2.693411350250244\n",
            "Test Loss:  5.650864601135254\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  379\n",
            "Train Loss:  2.6914560794830322\n",
            "Test Loss:  5.652812957763672\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  380\n",
            "Train Loss:  2.6895086765289307\n",
            "Test Loss:  5.65478515625\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  381\n",
            "Train Loss:  2.68756365776062\n",
            "Test Loss:  5.656798362731934\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  382\n",
            "Train Loss:  2.685624122619629\n",
            "Test Loss:  5.658825397491455\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  383\n",
            "Train Loss:  2.6836886405944824\n",
            "Test Loss:  5.660852909088135\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  384\n",
            "Train Loss:  2.6817574501037598\n",
            "Test Loss:  5.662851333618164\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  385\n",
            "Train Loss:  2.6798338890075684\n",
            "Test Loss:  5.664838790893555\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  386\n",
            "Train Loss:  2.6779208183288574\n",
            "Test Loss:  5.666816711425781\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  387\n",
            "Train Loss:  2.6760125160217285\n",
            "Test Loss:  5.668809413909912\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  388\n",
            "Train Loss:  2.6741087436676025\n",
            "Test Loss:  5.670793533325195\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  389\n",
            "Train Loss:  2.6722073554992676\n",
            "Test Loss:  5.672757148742676\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  390\n",
            "Train Loss:  2.6703078746795654\n",
            "Test Loss:  5.67473030090332\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  391\n",
            "Train Loss:  2.6684155464172363\n",
            "Test Loss:  5.676715850830078\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  392\n",
            "Train Loss:  2.666529655456543\n",
            "Test Loss:  5.678705215454102\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  393\n",
            "Train Loss:  2.664649486541748\n",
            "Test Loss:  5.680716037750244\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  394\n",
            "Train Loss:  2.662775993347168\n",
            "Test Loss:  5.68276309967041\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  395\n",
            "Train Loss:  2.6609106063842773\n",
            "Test Loss:  5.684828281402588\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  396\n",
            "Train Loss:  2.6590521335601807\n",
            "Test Loss:  5.686878204345703\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  397\n",
            "Train Loss:  2.6571998596191406\n",
            "Test Loss:  5.688907623291016\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  398\n",
            "Train Loss:  2.6553521156311035\n",
            "Test Loss:  5.690917491912842\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  399\n",
            "Train Loss:  2.653510808944702\n",
            "Test Loss:  5.692926406860352\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  400\n",
            "Train Loss:  2.6516785621643066\n",
            "Test Loss:  5.6949143409729\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  401\n",
            "Train Loss:  2.649848699569702\n",
            "Test Loss:  5.6968994140625\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  402\n",
            "Train Loss:  2.648022174835205\n",
            "Test Loss:  5.69888162612915\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  403\n",
            "Train Loss:  2.6461992263793945\n",
            "Test Loss:  5.700857639312744\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  404\n",
            "Train Loss:  2.6443862915039062\n",
            "Test Loss:  5.702828407287598\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  405\n",
            "Train Loss:  2.64258074760437\n",
            "Test Loss:  5.704812049865723\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  406\n",
            "Train Loss:  2.640779495239258\n",
            "Test Loss:  5.706818580627441\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  407\n",
            "Train Loss:  2.6389803886413574\n",
            "Test Loss:  5.708822250366211\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  408\n",
            "Train Loss:  2.6371822357177734\n",
            "Test Loss:  5.71081018447876\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  409\n",
            "Train Loss:  2.6353840827941895\n",
            "Test Loss:  5.712780952453613\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  410\n",
            "Train Loss:  2.6335911750793457\n",
            "Test Loss:  5.714743614196777\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  411\n",
            "Train Loss:  2.6318039894104004\n",
            "Test Loss:  5.716723442077637\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  412\n",
            "Train Loss:  2.630021572113037\n",
            "Test Loss:  5.718723297119141\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  413\n",
            "Train Loss:  2.6282505989074707\n",
            "Test Loss:  5.720759391784668\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  414\n",
            "Train Loss:  2.6264853477478027\n",
            "Test Loss:  5.722815036773682\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  415\n",
            "Train Loss:  2.624724864959717\n",
            "Test Loss:  5.724878787994385\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  416\n",
            "Train Loss:  2.6229660511016846\n",
            "Test Loss:  5.726933479309082\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  417\n",
            "Train Loss:  2.6212105751037598\n",
            "Test Loss:  5.72895622253418\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  418\n",
            "Train Loss:  2.6194591522216797\n",
            "Test Loss:  5.730955123901367\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  419\n",
            "Train Loss:  2.6177120208740234\n",
            "Test Loss:  5.732949733734131\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  420\n",
            "Train Loss:  2.615973949432373\n",
            "Test Loss:  5.73492956161499\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  421\n",
            "Train Loss:  2.6142420768737793\n",
            "Test Loss:  5.7369232177734375\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  422\n",
            "Train Loss:  2.6125149726867676\n",
            "Test Loss:  5.738919258117676\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  423\n",
            "Train Loss:  2.610795497894287\n",
            "Test Loss:  5.74095344543457\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  424\n",
            "Train Loss:  2.6090853214263916\n",
            "Test Loss:  5.742969512939453\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  425\n",
            "Train Loss:  2.6073834896087646\n",
            "Test Loss:  5.744942665100098\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  426\n",
            "Train Loss:  2.605687141418457\n",
            "Test Loss:  5.7469282150268555\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  427\n",
            "Train Loss:  2.603999137878418\n",
            "Test Loss:  5.748962879180908\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  428\n",
            "Train Loss:  2.6023178100585938\n",
            "Test Loss:  5.751011848449707\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  429\n",
            "Train Loss:  2.6006410121917725\n",
            "Test Loss:  5.7530341148376465\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  430\n",
            "Train Loss:  2.598968982696533\n",
            "Test Loss:  5.755023002624512\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  431\n",
            "Train Loss:  2.5972976684570312\n",
            "Test Loss:  5.756976127624512\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  432\n",
            "Train Loss:  2.5956249237060547\n",
            "Test Loss:  5.758951187133789\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  433\n",
            "Train Loss:  2.5939531326293945\n",
            "Test Loss:  5.760951995849609\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  434\n",
            "Train Loss:  2.592289924621582\n",
            "Test Loss:  5.762972831726074\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  435\n",
            "Train Loss:  2.5906472206115723\n",
            "Test Loss:  5.764965057373047\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  436\n",
            "Train Loss:  2.589111804962158\n",
            "Test Loss:  5.766901016235352\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  437\n",
            "Train Loss:  2.5875296592712402\n",
            "Test Loss:  5.768789291381836\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  438\n",
            "Train Loss:  2.585817813873291\n",
            "Test Loss:  5.770771026611328\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  439\n",
            "Train Loss:  2.584157943725586\n",
            "Test Loss:  5.7728400230407715\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  440\n",
            "Train Loss:  2.5825374126434326\n",
            "Test Loss:  5.774913787841797\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  441\n",
            "Train Loss:  2.5809028148651123\n",
            "Test Loss:  5.776899814605713\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  442\n",
            "Train Loss:  2.5792481899261475\n",
            "Test Loss:  5.778850555419922\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  443\n",
            "Train Loss:  2.5776076316833496\n",
            "Test Loss:  5.780803680419922\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  444\n",
            "Train Loss:  2.5759785175323486\n",
            "Test Loss:  5.782787322998047\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  445\n",
            "Train Loss:  2.574362277984619\n",
            "Test Loss:  5.784791469573975\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  446\n",
            "Train Loss:  2.572756290435791\n",
            "Test Loss:  5.7868475914001465\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  447\n",
            "Train Loss:  2.5711395740509033\n",
            "Test Loss:  5.788900375366211\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  448\n",
            "Train Loss:  2.569523811340332\n",
            "Test Loss:  5.790942192077637\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  449\n",
            "Train Loss:  2.56793212890625\n",
            "Test Loss:  5.792978286743164\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  450\n",
            "Train Loss:  2.566335678100586\n",
            "Test Loss:  5.795011043548584\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  451\n",
            "Train Loss:  2.5647377967834473\n",
            "Test Loss:  5.79704475402832\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  452\n",
            "Train Loss:  2.5631680488586426\n",
            "Test Loss:  5.799062728881836\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  453\n",
            "Train Loss:  2.561598300933838\n",
            "Test Loss:  5.801087379455566\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  454\n",
            "Train Loss:  2.5600295066833496\n",
            "Test Loss:  5.803110122680664\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  455\n",
            "Train Loss:  2.558490037918091\n",
            "Test Loss:  5.805130958557129\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  456\n",
            "Train Loss:  2.556945323944092\n",
            "Test Loss:  5.807136058807373\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  457\n",
            "Train Loss:  2.5554189682006836\n",
            "Test Loss:  5.809120178222656\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  458\n",
            "Train Loss:  2.5538833141326904\n",
            "Test Loss:  5.8110857009887695\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  459\n",
            "Train Loss:  2.5523853302001953\n",
            "Test Loss:  5.813007354736328\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  460\n",
            "Train Loss:  2.5508718490600586\n",
            "Test Loss:  5.814920425415039\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  461\n",
            "Train Loss:  2.549375534057617\n",
            "Test Loss:  5.816781997680664\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  462\n",
            "Train Loss:  2.547882080078125\n",
            "Test Loss:  5.818638801574707\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  463\n",
            "Train Loss:  2.5464026927948\n",
            "Test Loss:  5.82053279876709\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  464\n",
            "Train Loss:  2.544928550720215\n",
            "Test Loss:  5.822381019592285\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  465\n",
            "Train Loss:  2.5434489250183105\n",
            "Test Loss:  5.824309349060059\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  466\n",
            "Train Loss:  2.541975498199463\n",
            "Test Loss:  5.8261919021606445\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  467\n",
            "Train Loss:  2.5405163764953613\n",
            "Test Loss:  5.828083038330078\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  468\n",
            "Train Loss:  2.539059638977051\n",
            "Test Loss:  5.83006477355957\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  469\n",
            "Train Loss:  2.5375866889953613\n",
            "Test Loss:  5.8320631980896\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  470\n",
            "Train Loss:  2.536137580871582\n",
            "Test Loss:  5.834144592285156\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  471\n",
            "Train Loss:  2.534724235534668\n",
            "Test Loss:  5.836064338684082\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  472\n",
            "Train Loss:  2.5333492755889893\n",
            "Test Loss:  5.838010787963867\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  473\n",
            "Train Loss:  2.531886577606201\n",
            "Test Loss:  5.839873313903809\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  474\n",
            "Train Loss:  2.530458927154541\n",
            "Test Loss:  5.841716766357422\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  475\n",
            "Train Loss:  2.5290234088897705\n",
            "Test Loss:  5.843608856201172\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  476\n",
            "Train Loss:  2.527620315551758\n",
            "Test Loss:  5.845561981201172\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  477\n",
            "Train Loss:  2.526183605194092\n",
            "Test Loss:  5.847558498382568\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  478\n",
            "Train Loss:  2.524773120880127\n",
            "Test Loss:  5.849575996398926\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  479\n",
            "Train Loss:  2.5233731269836426\n",
            "Test Loss:  5.851625442504883\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  480\n",
            "Train Loss:  2.5219507217407227\n",
            "Test Loss:  5.85364294052124\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  481\n",
            "Train Loss:  2.5205612182617188\n",
            "Test Loss:  5.855649948120117\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  482\n",
            "Train Loss:  2.51916241645813\n",
            "Test Loss:  5.857608795166016\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  483\n",
            "Train Loss:  2.5177810192108154\n",
            "Test Loss:  5.859567642211914\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  484\n",
            "Train Loss:  2.51639723777771\n",
            "Test Loss:  5.861616134643555\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  485\n",
            "Train Loss:  2.5150227546691895\n",
            "Test Loss:  5.863628387451172\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  486\n",
            "Train Loss:  2.5136730670928955\n",
            "Test Loss:  5.865623474121094\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  487\n",
            "Train Loss:  2.512355327606201\n",
            "Test Loss:  5.867588043212891\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  488\n",
            "Train Loss:  2.5110347270965576\n",
            "Test Loss:  5.869594573974609\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  489\n",
            "Train Loss:  2.509659767150879\n",
            "Test Loss:  5.871572971343994\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  490\n",
            "Train Loss:  2.5083069801330566\n",
            "Test Loss:  5.873497009277344\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  491\n",
            "Train Loss:  2.5071725845336914\n",
            "Test Loss:  5.875272750854492\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  492\n",
            "Train Loss:  2.5058717727661133\n",
            "Test Loss:  5.877080917358398\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  493\n",
            "Train Loss:  2.504744052886963\n",
            "Test Loss:  5.878950595855713\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  494\n",
            "Train Loss:  2.503589630126953\n",
            "Test Loss:  5.880765438079834\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  495\n",
            "Train Loss:  2.5023694038391113\n",
            "Test Loss:  5.882606506347656\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  496\n",
            "Train Loss:  2.5011191368103027\n",
            "Test Loss:  5.884609222412109\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  497\n",
            "Train Loss:  2.4998202323913574\n",
            "Test Loss:  5.886631965637207\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  498\n",
            "Train Loss:  2.4985384941101074\n",
            "Test Loss:  5.888611793518066\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  499\n",
            "Train Loss:  2.49723482131958\n",
            "Test Loss:  5.890436172485352\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  500\n",
            "Train Loss:  2.495875597000122\n",
            "Test Loss:  5.892221927642822\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  501\n",
            "Train Loss:  2.49454402923584\n",
            "Test Loss:  5.8941545486450195\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  502\n",
            "Train Loss:  2.493224859237671\n",
            "Test Loss:  5.8959784507751465\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  503\n",
            "Train Loss:  2.491919994354248\n",
            "Test Loss:  5.897761344909668\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  504\n",
            "Train Loss:  2.4905848503112793\n",
            "Test Loss:  5.8995208740234375\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  505\n",
            "Train Loss:  2.4893150329589844\n",
            "Test Loss:  5.900892734527588\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  506\n",
            "Train Loss:  2.488034248352051\n",
            "Test Loss:  5.902442455291748\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  507\n",
            "Train Loss:  2.4867305755615234\n",
            "Test Loss:  5.904183387756348\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  508\n",
            "Train Loss:  2.485440731048584\n",
            "Test Loss:  5.905800819396973\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  509\n",
            "Train Loss:  2.4842031002044678\n",
            "Test Loss:  5.907504081726074\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  510\n",
            "Train Loss:  2.483071804046631\n",
            "Test Loss:  5.909252643585205\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  511\n",
            "Train Loss:  2.481696128845215\n",
            "Test Loss:  5.911136150360107\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  512\n",
            "Train Loss:  2.4805104732513428\n",
            "Test Loss:  5.913006782531738\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  513\n",
            "Train Loss:  2.4792375564575195\n",
            "Test Loss:  5.914903163909912\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  514\n",
            "Train Loss:  2.4780144691467285\n",
            "Test Loss:  5.916729927062988\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  515\n",
            "Train Loss:  2.4767584800720215\n",
            "Test Loss:  5.918638229370117\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  516\n",
            "Train Loss:  2.4755349159240723\n",
            "Test Loss:  5.920477867126465\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  517\n",
            "Train Loss:  2.4742863178253174\n",
            "Test Loss:  5.922298908233643\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  518\n",
            "Train Loss:  2.4731054306030273\n",
            "Test Loss:  5.924042224884033\n",
            "Recall : 0.16\n",
            "Epoch  519\n",
            "Train Loss:  2.4718892574310303\n",
            "Test Loss:  5.925535202026367\n",
            "Recall : 0.16\n",
            "Epoch  520\n",
            "Train Loss:  2.4706850051879883\n",
            "Test Loss:  5.927382469177246\n",
            "Recall : 0.16\n",
            "Epoch  521\n",
            "Train Loss:  2.469433307647705\n",
            "Test Loss:  5.9291887283325195\n",
            "Recall : 0.16\n",
            "Epoch  522\n",
            "Train Loss:  2.4682364463806152\n",
            "Test Loss:  5.930787086486816\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  523\n",
            "Train Loss:  2.467033624649048\n",
            "Test Loss:  5.9326395988464355\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  524\n",
            "Train Loss:  2.465886354446411\n",
            "Test Loss:  5.934430122375488\n",
            "Recall : 0.16\n",
            "Epoch  525\n",
            "Train Loss:  2.4647159576416016\n",
            "Test Loss:  5.936158180236816\n",
            "Recall : 0.16\n",
            "Epoch  526\n",
            "Train Loss:  2.46356463432312\n",
            "Test Loss:  5.9379072189331055\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  527\n",
            "Train Loss:  2.462369918823242\n",
            "Test Loss:  5.93961763381958\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  528\n",
            "Train Loss:  2.461221933364868\n",
            "Test Loss:  5.941363334655762\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  529\n",
            "Train Loss:  2.4600729942321777\n",
            "Test Loss:  5.943190574645996\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  530\n",
            "Train Loss:  2.4589176177978516\n",
            "Test Loss:  5.944795608520508\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  531\n",
            "Train Loss:  2.457775115966797\n",
            "Test Loss:  5.946478843688965\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  532\n",
            "Train Loss:  2.4566216468811035\n",
            "Test Loss:  5.9483842849731445\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  533\n",
            "Train Loss:  2.4554665088653564\n",
            "Test Loss:  5.949945449829102\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  534\n",
            "Train Loss:  2.4543442726135254\n",
            "Test Loss:  5.951420783996582\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  535\n",
            "Train Loss:  2.453289031982422\n",
            "Test Loss:  5.953092098236084\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  536\n",
            "Train Loss:  2.4522337913513184\n",
            "Test Loss:  5.954815864562988\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  537\n",
            "Train Loss:  2.45111083984375\n",
            "Test Loss:  5.956332206726074\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  538\n",
            "Train Loss:  2.4499645233154297\n",
            "Test Loss:  5.958065986633301\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  539\n",
            "Train Loss:  2.4488539695739746\n",
            "Test Loss:  5.959892272949219\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  540\n",
            "Train Loss:  2.4477343559265137\n",
            "Test Loss:  5.961461067199707\n",
            "Recall : 0.16\n",
            "Epoch  541\n",
            "Train Loss:  2.4466257095336914\n",
            "Test Loss:  5.963132858276367\n",
            "Recall : 0.16\n",
            "Epoch  542\n",
            "Train Loss:  2.4455456733703613\n",
            "Test Loss:  5.964518070220947\n",
            "Recall : 0.16\n",
            "Epoch  543\n",
            "Train Loss:  2.4445743560791016\n",
            "Test Loss:  5.96628999710083\n",
            "Recall : 0.16\n",
            "Epoch  544\n",
            "Train Loss:  2.443591594696045\n",
            "Test Loss:  5.967458248138428\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  545\n",
            "Train Loss:  2.442509651184082\n",
            "Test Loss:  5.969099998474121\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  546\n",
            "Train Loss:  2.4414753913879395\n",
            "Test Loss:  5.970466613769531\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  547\n",
            "Train Loss:  2.4404168128967285\n",
            "Test Loss:  5.972125053405762\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  548\n",
            "Train Loss:  2.4393677711486816\n",
            "Test Loss:  5.973753929138184\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  549\n",
            "Train Loss:  2.4383440017700195\n",
            "Test Loss:  5.975198268890381\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  550\n",
            "Train Loss:  2.4372496604919434\n",
            "Test Loss:  5.976955413818359\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  551\n",
            "Train Loss:  2.436187267303467\n",
            "Test Loss:  5.97878360748291\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  552\n",
            "Train Loss:  2.4352469444274902\n",
            "Test Loss:  5.980475425720215\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  553\n",
            "Train Loss:  2.434215784072876\n",
            "Test Loss:  5.982307434082031\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  554\n",
            "Train Loss:  2.4331250190734863\n",
            "Test Loss:  5.983610153198242\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  555\n",
            "Train Loss:  2.4321441650390625\n",
            "Test Loss:  5.985260009765625\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  556\n",
            "Train Loss:  2.431060314178467\n",
            "Test Loss:  5.986861228942871\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  557\n",
            "Train Loss:  2.4299418926239014\n",
            "Test Loss:  5.988689422607422\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  558\n",
            "Train Loss:  2.4288907051086426\n",
            "Test Loss:  5.990544319152832\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  559\n",
            "Train Loss:  2.427807569503784\n",
            "Test Loss:  5.992266654968262\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  560\n",
            "Train Loss:  2.4268457889556885\n",
            "Test Loss:  5.99400520324707\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  561\n",
            "Train Loss:  2.4258666038513184\n",
            "Test Loss:  5.995840072631836\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  562\n",
            "Train Loss:  2.4248151779174805\n",
            "Test Loss:  5.9971842765808105\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  563\n",
            "Train Loss:  2.423818349838257\n",
            "Test Loss:  5.998994827270508\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  564\n",
            "Train Loss:  2.4227585792541504\n",
            "Test Loss:  6.00074577331543\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  565\n",
            "Train Loss:  2.421722888946533\n",
            "Test Loss:  6.002184867858887\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  566\n",
            "Train Loss:  2.4207916259765625\n",
            "Test Loss:  6.0040178298950195\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  567\n",
            "Train Loss:  2.4198288917541504\n",
            "Test Loss:  6.005314826965332\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  568\n",
            "Train Loss:  2.4188618659973145\n",
            "Test Loss:  6.007108688354492\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  569\n",
            "Train Loss:  2.4179697036743164\n",
            "Test Loss:  6.008913040161133\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  570\n",
            "Train Loss:  2.4168953895568848\n",
            "Test Loss:  6.010477066040039\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  571\n",
            "Train Loss:  2.415949821472168\n",
            "Test Loss:  6.0120849609375\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  572\n",
            "Train Loss:  2.4150731563568115\n",
            "Test Loss:  6.013338088989258\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  573\n",
            "Train Loss:  2.4141077995300293\n",
            "Test Loss:  6.014833450317383\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  574\n",
            "Train Loss:  2.4132838249206543\n",
            "Test Loss:  6.016088485717773\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  575\n",
            "Train Loss:  2.4122965335845947\n",
            "Test Loss:  6.017436981201172\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  576\n",
            "Train Loss:  2.411245822906494\n",
            "Test Loss:  6.0190510749816895\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  577\n",
            "Train Loss:  2.410282611846924\n",
            "Test Loss:  6.02056884765625\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  578\n",
            "Train Loss:  2.409322738647461\n",
            "Test Loss:  6.022214889526367\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  579\n",
            "Train Loss:  2.4085440635681152\n",
            "Test Loss:  6.023715496063232\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  580\n",
            "Train Loss:  2.4076695442199707\n",
            "Test Loss:  6.025145530700684\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  581\n",
            "Train Loss:  2.406848430633545\n",
            "Test Loss:  6.026172161102295\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  582\n",
            "Train Loss:  2.405777931213379\n",
            "Test Loss:  6.027474403381348\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  583\n",
            "Train Loss:  2.404815196990967\n",
            "Test Loss:  6.028980255126953\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  584\n",
            "Train Loss:  2.4038448333740234\n",
            "Test Loss:  6.0304059982299805\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  585\n",
            "Train Loss:  2.4029061794281006\n",
            "Test Loss:  6.032084941864014\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  586\n",
            "Train Loss:  2.4020237922668457\n",
            "Test Loss:  6.033758163452148\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  587\n",
            "Train Loss:  2.401183843612671\n",
            "Test Loss:  6.035227298736572\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  588\n",
            "Train Loss:  2.400407314300537\n",
            "Test Loss:  6.036460876464844\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  589\n",
            "Train Loss:  2.399606227874756\n",
            "Test Loss:  6.037578582763672\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  590\n",
            "Train Loss:  2.3990840911865234\n",
            "Test Loss:  6.038524627685547\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  591\n",
            "Train Loss:  2.398036479949951\n",
            "Test Loss:  6.039768218994141\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  592\n",
            "Train Loss:  2.3968751430511475\n",
            "Test Loss:  6.0411858558654785\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  593\n",
            "Train Loss:  2.3960509300231934\n",
            "Test Loss:  6.042697906494141\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  594\n",
            "Train Loss:  2.395002841949463\n",
            "Test Loss:  6.044193267822266\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  595\n",
            "Train Loss:  2.3940815925598145\n",
            "Test Loss:  6.0458269119262695\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  596\n",
            "Train Loss:  2.3931312561035156\n",
            "Test Loss:  6.047248840332031\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  597\n",
            "Train Loss:  2.39216947555542\n",
            "Test Loss:  6.048667907714844\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  598\n",
            "Train Loss:  2.391206741333008\n",
            "Test Loss:  6.050417900085449\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  599\n",
            "Train Loss:  2.3904929161071777\n",
            "Test Loss:  6.050999641418457\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  600\n",
            "Train Loss:  2.389829158782959\n",
            "Test Loss:  6.052046775817871\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  601\n",
            "Train Loss:  2.3890304565429688\n",
            "Test Loss:  6.053107261657715\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  602\n",
            "Train Loss:  2.3882596492767334\n",
            "Test Loss:  6.0540313720703125\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  603\n",
            "Train Loss:  2.3875362873077393\n",
            "Test Loss:  6.0549468994140625\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  604\n",
            "Train Loss:  2.386922836303711\n",
            "Test Loss:  6.056086540222168\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  605\n",
            "Train Loss:  2.385718584060669\n",
            "Test Loss:  6.057484149932861\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  606\n",
            "Train Loss:  2.385012626647949\n",
            "Test Loss:  6.058809757232666\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  607\n",
            "Train Loss:  2.384089231491089\n",
            "Test Loss:  6.060299873352051\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  608\n",
            "Train Loss:  2.3832736015319824\n",
            "Test Loss:  6.061926364898682\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  609\n",
            "Train Loss:  2.382349967956543\n",
            "Test Loss:  6.063659191131592\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  610\n",
            "Train Loss:  2.3815159797668457\n",
            "Test Loss:  6.064623832702637\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  611\n",
            "Train Loss:  2.380779981613159\n",
            "Test Loss:  6.065749168395996\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  612\n",
            "Train Loss:  2.380046844482422\n",
            "Test Loss:  6.06663703918457\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  613\n",
            "Train Loss:  2.379157543182373\n",
            "Test Loss:  6.067659854888916\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  614\n",
            "Train Loss:  2.378239393234253\n",
            "Test Loss:  6.068665981292725\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  615\n",
            "Train Loss:  2.3775293827056885\n",
            "Test Loss:  6.0698652267456055\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  616\n",
            "Train Loss:  2.3768668174743652\n",
            "Test Loss:  6.071114540100098\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  617\n",
            "Train Loss:  2.37631893157959\n",
            "Test Loss:  6.072333812713623\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  618\n",
            "Train Loss:  2.3751728534698486\n",
            "Test Loss:  6.073782920837402\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  619\n",
            "Train Loss:  2.3745431900024414\n",
            "Test Loss:  6.07537841796875\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  620\n",
            "Train Loss:  2.373711347579956\n",
            "Test Loss:  6.076565742492676\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  621\n",
            "Train Loss:  2.373029947280884\n",
            "Test Loss:  6.078124046325684\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  622\n",
            "Train Loss:  2.3726325035095215\n",
            "Test Loss:  6.078193664550781\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  623\n",
            "Train Loss:  2.3718652725219727\n",
            "Test Loss:  6.079139709472656\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  624\n",
            "Train Loss:  2.3708343505859375\n",
            "Test Loss:  6.080258369445801\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  625\n",
            "Train Loss:  2.369995594024658\n",
            "Test Loss:  6.0815606117248535\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  626\n",
            "Train Loss:  2.3690929412841797\n",
            "Test Loss:  6.082969665527344\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  627\n",
            "Train Loss:  2.3682119846343994\n",
            "Test Loss:  6.084677696228027\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  628\n",
            "Train Loss:  2.3673694133758545\n",
            "Test Loss:  6.086241722106934\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  629\n",
            "Train Loss:  2.3665647506713867\n",
            "Test Loss:  6.087698936462402\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  630\n",
            "Train Loss:  2.3658957481384277\n",
            "Test Loss:  6.089227676391602\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  631\n",
            "Train Loss:  2.3655099868774414\n",
            "Test Loss:  6.090653419494629\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  632\n",
            "Train Loss:  2.3646469116210938\n",
            "Test Loss:  6.0922441482543945\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  633\n",
            "Train Loss:  2.3638925552368164\n",
            "Test Loss:  6.092494010925293\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  634\n",
            "Train Loss:  2.3634233474731445\n",
            "Test Loss:  6.093452453613281\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  635\n",
            "Train Loss:  2.362475633621216\n",
            "Test Loss:  6.094414710998535\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  636\n",
            "Train Loss:  2.3617424964904785\n",
            "Test Loss:  6.095427513122559\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  637\n",
            "Train Loss:  2.3610901832580566\n",
            "Test Loss:  6.0966644287109375\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  638\n",
            "Train Loss:  2.360252618789673\n",
            "Test Loss:  6.098113536834717\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  639\n",
            "Train Loss:  2.359426975250244\n",
            "Test Loss:  6.099644660949707\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  640\n",
            "Train Loss:  2.358631134033203\n",
            "Test Loss:  6.101113796234131\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  641\n",
            "Train Loss:  2.3578567504882812\n",
            "Test Loss:  6.102560043334961\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  642\n",
            "Train Loss:  2.357121706008911\n",
            "Test Loss:  6.104137897491455\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  643\n",
            "Train Loss:  2.3563554286956787\n",
            "Test Loss:  6.105393409729004\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  644\n",
            "Train Loss:  2.3555822372436523\n",
            "Test Loss:  6.106987476348877\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  645\n",
            "Train Loss:  2.354922294616699\n",
            "Test Loss:  6.107586860656738\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  646\n",
            "Train Loss:  2.354367256164551\n",
            "Test Loss:  6.108895301818848\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  647\n",
            "Train Loss:  2.3539414405822754\n",
            "Test Loss:  6.1093902587890625\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  648\n",
            "Train Loss:  2.3531341552734375\n",
            "Test Loss:  6.110213279724121\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  649\n",
            "Train Loss:  2.3524513244628906\n",
            "Test Loss:  6.111485481262207\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  650\n",
            "Train Loss:  2.3518877029418945\n",
            "Test Loss:  6.112656593322754\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  651\n",
            "Train Loss:  2.3515772819519043\n",
            "Test Loss:  6.11332893371582\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  652\n",
            "Train Loss:  2.350656509399414\n",
            "Test Loss:  6.114291191101074\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  653\n",
            "Train Loss:  2.3501315116882324\n",
            "Test Loss:  6.115497589111328\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  654\n",
            "Train Loss:  2.349557399749756\n",
            "Test Loss:  6.116863250732422\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  655\n",
            "Train Loss:  2.3488478660583496\n",
            "Test Loss:  6.118229866027832\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  656\n",
            "Train Loss:  2.348085403442383\n",
            "Test Loss:  6.120176315307617\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  657\n",
            "Train Loss:  2.347447395324707\n",
            "Test Loss:  6.121264457702637\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  658\n",
            "Train Loss:  2.3468379974365234\n",
            "Test Loss:  6.122364521026611\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  659\n",
            "Train Loss:  2.3462071418762207\n",
            "Test Loss:  6.123446464538574\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  660\n",
            "Train Loss:  2.3457398414611816\n",
            "Test Loss:  6.124187469482422\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  661\n",
            "Train Loss:  2.345250129699707\n",
            "Test Loss:  6.1254167556762695\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  662\n",
            "Train Loss:  2.344344139099121\n",
            "Test Loss:  6.126543998718262\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  663\n",
            "Train Loss:  2.3436765670776367\n",
            "Test Loss:  6.12755012512207\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  664\n",
            "Train Loss:  2.343019485473633\n",
            "Test Loss:  6.128665924072266\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  665\n",
            "Train Loss:  2.342254161834717\n",
            "Test Loss:  6.129972457885742\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  666\n",
            "Train Loss:  2.3417632579803467\n",
            "Test Loss:  6.131173610687256\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  667\n",
            "Train Loss:  2.34067440032959\n",
            "Test Loss:  6.132715225219727\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  668\n",
            "Train Loss:  2.339967727661133\n",
            "Test Loss:  6.134239196777344\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  669\n",
            "Train Loss:  2.339311122894287\n",
            "Test Loss:  6.135272026062012\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  670\n",
            "Train Loss:  2.3387765884399414\n",
            "Test Loss:  6.136054992675781\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  671\n",
            "Train Loss:  2.338545322418213\n",
            "Test Loss:  6.136576175689697\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  672\n",
            "Train Loss:  2.337831497192383\n",
            "Test Loss:  6.137503623962402\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  673\n",
            "Train Loss:  2.337406635284424\n",
            "Test Loss:  6.1384429931640625\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  674\n",
            "Train Loss:  2.3368425369262695\n",
            "Test Loss:  6.139439105987549\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  675\n",
            "Train Loss:  2.3363327980041504\n",
            "Test Loss:  6.1402740478515625\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  676\n",
            "Train Loss:  2.335679054260254\n",
            "Test Loss:  6.141413688659668\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  677\n",
            "Train Loss:  2.3352413177490234\n",
            "Test Loss:  6.142609596252441\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  678\n",
            "Train Loss:  2.3346195220947266\n",
            "Test Loss:  6.143821716308594\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  679\n",
            "Train Loss:  2.3337981700897217\n",
            "Test Loss:  6.145180702209473\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  680\n",
            "Train Loss:  2.3332319259643555\n",
            "Test Loss:  6.146782875061035\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  681\n",
            "Train Loss:  2.332664966583252\n",
            "Test Loss:  6.147924423217773\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  682\n",
            "Train Loss:  2.332068920135498\n",
            "Test Loss:  6.1485795974731445\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  683\n",
            "Train Loss:  2.331382989883423\n",
            "Test Loss:  6.149275779724121\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  684\n",
            "Train Loss:  2.330658197402954\n",
            "Test Loss:  6.149801254272461\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  685\n",
            "Train Loss:  2.329843044281006\n",
            "Test Loss:  6.150836944580078\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  686\n",
            "Train Loss:  2.3293583393096924\n",
            "Test Loss:  6.151803016662598\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  687\n",
            "Train Loss:  2.3287229537963867\n",
            "Test Loss:  6.152737140655518\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  688\n",
            "Train Loss:  2.328117847442627\n",
            "Test Loss:  6.153441429138184\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  689\n",
            "Train Loss:  2.3275434970855713\n",
            "Test Loss:  6.154484748840332\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  690\n",
            "Train Loss:  2.32696533203125\n",
            "Test Loss:  6.155643463134766\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  691\n",
            "Train Loss:  2.326444625854492\n",
            "Test Loss:  6.156686782836914\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  692\n",
            "Train Loss:  2.325862407684326\n",
            "Test Loss:  6.157747268676758\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  693\n",
            "Train Loss:  2.325347423553467\n",
            "Test Loss:  6.158884048461914\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  694\n",
            "Train Loss:  2.3246030807495117\n",
            "Test Loss:  6.159931182861328\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  695\n",
            "Train Loss:  2.3238677978515625\n",
            "Test Loss:  6.160885810852051\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  696\n",
            "Train Loss:  2.3232309818267822\n",
            "Test Loss:  6.161918640136719\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  697\n",
            "Train Loss:  2.322640895843506\n",
            "Test Loss:  6.1627655029296875\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  698\n",
            "Train Loss:  2.322139024734497\n",
            "Test Loss:  6.163736820220947\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  699\n",
            "Train Loss:  2.321779251098633\n",
            "Test Loss:  6.16457462310791\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  700\n",
            "Train Loss:  2.321082592010498\n",
            "Test Loss:  6.16568660736084\n",
            "Recall : 0.1523809523809524\n",
            "\n",
            "0.16858775510204083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4beff6f038d4441dbe98b244b46648c0",
            "c7644deabebd4fc2a8de3b197454530f",
            "8f623de6e514414eae7907fe799e56a5",
            "23a53e44747e40db9cbbcd999ff2a8c4",
            "f2a38a801aab4a4397f0b7d6e02e9501",
            "20cc24100080430683940fe8c95b2db0",
            "6620f36b2ee549bbbe87bf85816a506a",
            "4bbd2910ebce47959a0960882981b462"
          ]
        },
        "id": "DRiUvlVVNFhF",
        "outputId": "f541af1d-3209-45b7-ff6f-9ad0aa3cc101"
      },
      "source": [
        "run(path=\"resnet50.npy\",runs=1,epochs=700,k=1,temp=15,type=2,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4beff6f038d4441dbe98b244b46648c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.422816276550293\n",
            "Test Loss:  6.260641098022461\n",
            "Recall : 0.12285714285714286\n",
            "Epoch  2\n",
            "Train Loss:  7.349076271057129\n",
            "Test Loss:  6.221037864685059\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  3\n",
            "Train Loss:  7.278962135314941\n",
            "Test Loss:  6.182674407958984\n",
            "Recall : 0.12\n",
            "Epoch  4\n",
            "Train Loss:  7.210482120513916\n",
            "Test Loss:  6.145260810852051\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  5\n",
            "Train Loss:  7.143012523651123\n",
            "Test Loss:  6.108663558959961\n",
            "Recall : 0.1219047619047619\n",
            "Epoch  6\n",
            "Train Loss:  7.076333045959473\n",
            "Test Loss:  6.072834014892578\n",
            "Recall : 0.12285714285714286\n",
            "Epoch  7\n",
            "Train Loss:  7.010381698608398\n",
            "Test Loss:  6.037796974182129\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  8\n",
            "Train Loss:  6.94518518447876\n",
            "Test Loss:  6.003628253936768\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  9\n",
            "Train Loss:  6.880763053894043\n",
            "Test Loss:  5.970354080200195\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  10\n",
            "Train Loss:  6.817169666290283\n",
            "Test Loss:  5.938026428222656\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  11\n",
            "Train Loss:  6.754481315612793\n",
            "Test Loss:  5.9066619873046875\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  12\n",
            "Train Loss:  6.692752838134766\n",
            "Test Loss:  5.876337051391602\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  13\n",
            "Train Loss:  6.632071495056152\n",
            "Test Loss:  5.847092628479004\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  14\n",
            "Train Loss:  6.572530746459961\n",
            "Test Loss:  5.818932056427002\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  15\n",
            "Train Loss:  6.514194488525391\n",
            "Test Loss:  5.791871070861816\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  16\n",
            "Train Loss:  6.457108020782471\n",
            "Test Loss:  5.765957832336426\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  17\n",
            "Train Loss:  6.401329040527344\n",
            "Test Loss:  5.741230487823486\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  18\n",
            "Train Loss:  6.3469133377075195\n",
            "Test Loss:  5.717632293701172\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  19\n",
            "Train Loss:  6.293891906738281\n",
            "Test Loss:  5.6952009201049805\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  20\n",
            "Train Loss:  6.24228572845459\n",
            "Test Loss:  5.673914909362793\n",
            "Recall : 0.14\n",
            "Epoch  21\n",
            "Train Loss:  6.192098140716553\n",
            "Test Loss:  5.653753280639648\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  22\n",
            "Train Loss:  6.143375396728516\n",
            "Test Loss:  5.6346845626831055\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  23\n",
            "Train Loss:  6.096127986907959\n",
            "Test Loss:  5.616638660430908\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  24\n",
            "Train Loss:  6.050356864929199\n",
            "Test Loss:  5.599596977233887\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  25\n",
            "Train Loss:  6.006035804748535\n",
            "Test Loss:  5.583503723144531\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  26\n",
            "Train Loss:  5.9631500244140625\n",
            "Test Loss:  5.568377494812012\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  27\n",
            "Train Loss:  5.921667098999023\n",
            "Test Loss:  5.554197788238525\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  28\n",
            "Train Loss:  5.881551742553711\n",
            "Test Loss:  5.540897369384766\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  29\n",
            "Train Loss:  5.842771530151367\n",
            "Test Loss:  5.528395652770996\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  30\n",
            "Train Loss:  5.805325508117676\n",
            "Test Loss:  5.516727924346924\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  31\n",
            "Train Loss:  5.769159317016602\n",
            "Test Loss:  5.505831718444824\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  32\n",
            "Train Loss:  5.73421573638916\n",
            "Test Loss:  5.495656967163086\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  33\n",
            "Train Loss:  5.700448513031006\n",
            "Test Loss:  5.4861650466918945\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  34\n",
            "Train Loss:  5.667816162109375\n",
            "Test Loss:  5.477332592010498\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  35\n",
            "Train Loss:  5.636282920837402\n",
            "Test Loss:  5.4691057205200195\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  36\n",
            "Train Loss:  5.605823516845703\n",
            "Test Loss:  5.4614481925964355\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  37\n",
            "Train Loss:  5.576394081115723\n",
            "Test Loss:  5.454350471496582\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  38\n",
            "Train Loss:  5.547952651977539\n",
            "Test Loss:  5.447710990905762\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  39\n",
            "Train Loss:  5.520444869995117\n",
            "Test Loss:  5.441511154174805\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  40\n",
            "Train Loss:  5.493855953216553\n",
            "Test Loss:  5.435731887817383\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  41\n",
            "Train Loss:  5.468158721923828\n",
            "Test Loss:  5.4303364753723145\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  42\n",
            "Train Loss:  5.443302154541016\n",
            "Test Loss:  5.425281524658203\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  43\n",
            "Train Loss:  5.419247627258301\n",
            "Test Loss:  5.420530319213867\n",
            "Recall : 0.16\n",
            "Epoch  44\n",
            "Train Loss:  5.395946502685547\n",
            "Test Loss:  5.416091442108154\n",
            "Recall : 0.16\n",
            "Epoch  45\n",
            "Train Loss:  5.373348236083984\n",
            "Test Loss:  5.411916732788086\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  46\n",
            "Train Loss:  5.351418495178223\n",
            "Test Loss:  5.408001899719238\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  47\n",
            "Train Loss:  5.330104827880859\n",
            "Test Loss:  5.404285430908203\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  48\n",
            "Train Loss:  5.309402942657471\n",
            "Test Loss:  5.400790691375732\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  49\n",
            "Train Loss:  5.289294242858887\n",
            "Test Loss:  5.397480487823486\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  50\n",
            "Train Loss:  5.269743919372559\n",
            "Test Loss:  5.394289970397949\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  51\n",
            "Train Loss:  5.250718116760254\n",
            "Test Loss:  5.391261100769043\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  52\n",
            "Train Loss:  5.232177734375\n",
            "Test Loss:  5.388343334197998\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  53\n",
            "Train Loss:  5.214129447937012\n",
            "Test Loss:  5.385549068450928\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  54\n",
            "Train Loss:  5.196540355682373\n",
            "Test Loss:  5.382892608642578\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  55\n",
            "Train Loss:  5.179401397705078\n",
            "Test Loss:  5.380370140075684\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  56\n",
            "Train Loss:  5.1626739501953125\n",
            "Test Loss:  5.377964973449707\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  57\n",
            "Train Loss:  5.146341323852539\n",
            "Test Loss:  5.375612258911133\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  58\n",
            "Train Loss:  5.130401611328125\n",
            "Test Loss:  5.373323440551758\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  59\n",
            "Train Loss:  5.114825248718262\n",
            "Test Loss:  5.371111869812012\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  60\n",
            "Train Loss:  5.0995988845825195\n",
            "Test Loss:  5.368950843811035\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  61\n",
            "Train Loss:  5.084694862365723\n",
            "Test Loss:  5.366812705993652\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  62\n",
            "Train Loss:  5.070122718811035\n",
            "Test Loss:  5.364706993103027\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  63\n",
            "Train Loss:  5.055850982666016\n",
            "Test Loss:  5.362646102905273\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  64\n",
            "Train Loss:  5.04189920425415\n",
            "Test Loss:  5.360645294189453\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  65\n",
            "Train Loss:  5.028260231018066\n",
            "Test Loss:  5.3587236404418945\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  66\n",
            "Train Loss:  5.014899730682373\n",
            "Test Loss:  5.356863021850586\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  67\n",
            "Train Loss:  5.001805305480957\n",
            "Test Loss:  5.355035781860352\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  68\n",
            "Train Loss:  4.988994121551514\n",
            "Test Loss:  5.353267669677734\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  69\n",
            "Train Loss:  4.97645378112793\n",
            "Test Loss:  5.351548194885254\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  70\n",
            "Train Loss:  4.96417236328125\n",
            "Test Loss:  5.349891662597656\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  71\n",
            "Train Loss:  4.952117919921875\n",
            "Test Loss:  5.348304748535156\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  72\n",
            "Train Loss:  4.940298080444336\n",
            "Test Loss:  5.346780776977539\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  73\n",
            "Train Loss:  4.928701400756836\n",
            "Test Loss:  5.345324516296387\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  74\n",
            "Train Loss:  4.9173197746276855\n",
            "Test Loss:  5.343906402587891\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  75\n",
            "Train Loss:  4.90614652633667\n",
            "Test Loss:  5.342507839202881\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  76\n",
            "Train Loss:  4.895157814025879\n",
            "Test Loss:  5.341132164001465\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  77\n",
            "Train Loss:  4.884347915649414\n",
            "Test Loss:  5.339818000793457\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  78\n",
            "Train Loss:  4.873710632324219\n",
            "Test Loss:  5.338583946228027\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  79\n",
            "Train Loss:  4.863267421722412\n",
            "Test Loss:  5.33737850189209\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  80\n",
            "Train Loss:  4.852998733520508\n",
            "Test Loss:  5.336209297180176\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  81\n",
            "Train Loss:  4.842920780181885\n",
            "Test Loss:  5.335102558135986\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  82\n",
            "Train Loss:  4.833032608032227\n",
            "Test Loss:  5.334057807922363\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  83\n",
            "Train Loss:  4.823313236236572\n",
            "Test Loss:  5.333061218261719\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  84\n",
            "Train Loss:  4.813745498657227\n",
            "Test Loss:  5.3321146965026855\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  85\n",
            "Train Loss:  4.804340839385986\n",
            "Test Loss:  5.331210136413574\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  86\n",
            "Train Loss:  4.7950944900512695\n",
            "Test Loss:  5.330327033996582\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  87\n",
            "Train Loss:  4.786006927490234\n",
            "Test Loss:  5.3294782638549805\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  88\n",
            "Train Loss:  4.77707576751709\n",
            "Test Loss:  5.328667640686035\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  89\n",
            "Train Loss:  4.768296718597412\n",
            "Test Loss:  5.327885627746582\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  90\n",
            "Train Loss:  4.759666442871094\n",
            "Test Loss:  5.327153205871582\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  91\n",
            "Train Loss:  4.751177787780762\n",
            "Test Loss:  5.326456069946289\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  92\n",
            "Train Loss:  4.742828845977783\n",
            "Test Loss:  5.325782775878906\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  93\n",
            "Train Loss:  4.734621524810791\n",
            "Test Loss:  5.32514762878418\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  94\n",
            "Train Loss:  4.726557731628418\n",
            "Test Loss:  5.324541091918945\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  95\n",
            "Train Loss:  4.718634605407715\n",
            "Test Loss:  5.323968887329102\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  96\n",
            "Train Loss:  4.7108473777771\n",
            "Test Loss:  5.323431015014648\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  97\n",
            "Train Loss:  4.703195571899414\n",
            "Test Loss:  5.32292366027832\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  98\n",
            "Train Loss:  4.695676803588867\n",
            "Test Loss:  5.322437763214111\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  99\n",
            "Train Loss:  4.688273906707764\n",
            "Test Loss:  5.3219733238220215\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  100\n",
            "Train Loss:  4.680988788604736\n",
            "Test Loss:  5.321544647216797\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  101\n",
            "Train Loss:  4.673816680908203\n",
            "Test Loss:  5.321133613586426\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  102\n",
            "Train Loss:  4.666745185852051\n",
            "Test Loss:  5.320738315582275\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  103\n",
            "Train Loss:  4.659787654876709\n",
            "Test Loss:  5.320347309112549\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  104\n",
            "Train Loss:  4.652937889099121\n",
            "Test Loss:  5.319958209991455\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  105\n",
            "Train Loss:  4.646200180053711\n",
            "Test Loss:  5.319585800170898\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  106\n",
            "Train Loss:  4.639566421508789\n",
            "Test Loss:  5.319206237792969\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  107\n",
            "Train Loss:  4.633024215698242\n",
            "Test Loss:  5.318841457366943\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  108\n",
            "Train Loss:  4.626574516296387\n",
            "Test Loss:  5.318485260009766\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  109\n",
            "Train Loss:  4.620206832885742\n",
            "Test Loss:  5.318132400512695\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  110\n",
            "Train Loss:  4.613922119140625\n",
            "Test Loss:  5.317797660827637\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  111\n",
            "Train Loss:  4.607722282409668\n",
            "Test Loss:  5.317507743835449\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  112\n",
            "Train Loss:  4.601592063903809\n",
            "Test Loss:  5.317244052886963\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  113\n",
            "Train Loss:  4.595529556274414\n",
            "Test Loss:  5.316979885101318\n",
            "Recall : 0.18\n",
            "Epoch  114\n",
            "Train Loss:  4.589529037475586\n",
            "Test Loss:  5.316722869873047\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  115\n",
            "Train Loss:  4.583578109741211\n",
            "Test Loss:  5.316473007202148\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  116\n",
            "Train Loss:  4.577692031860352\n",
            "Test Loss:  5.316231727600098\n",
            "Recall : 0.18\n",
            "Epoch  117\n",
            "Train Loss:  4.571871757507324\n",
            "Test Loss:  5.316009998321533\n",
            "Recall : 0.18\n",
            "Epoch  118\n",
            "Train Loss:  4.566107749938965\n",
            "Test Loss:  5.315789222717285\n",
            "Recall : 0.18\n",
            "Epoch  119\n",
            "Train Loss:  4.560392379760742\n",
            "Test Loss:  5.31558895111084\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  120\n",
            "Train Loss:  4.554729461669922\n",
            "Test Loss:  5.315385341644287\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  121\n",
            "Train Loss:  4.549103260040283\n",
            "Test Loss:  5.315176010131836\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  122\n",
            "Train Loss:  4.543520450592041\n",
            "Test Loss:  5.314974784851074\n",
            "Recall : 0.18\n",
            "Epoch  123\n",
            "Train Loss:  4.53798770904541\n",
            "Test Loss:  5.314764976501465\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  124\n",
            "Train Loss:  4.53249454498291\n",
            "Test Loss:  5.3145527839660645\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  125\n",
            "Train Loss:  4.527035713195801\n",
            "Test Loss:  5.314337253570557\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  126\n",
            "Train Loss:  4.521605014801025\n",
            "Test Loss:  5.314126968383789\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  127\n",
            "Train Loss:  4.516207218170166\n",
            "Test Loss:  5.313905715942383\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  128\n",
            "Train Loss:  4.51084041595459\n",
            "Test Loss:  5.313686370849609\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  129\n",
            "Train Loss:  4.505505084991455\n",
            "Test Loss:  5.313460350036621\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  130\n",
            "Train Loss:  4.500201225280762\n",
            "Test Loss:  5.313231468200684\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  131\n",
            "Train Loss:  4.494928359985352\n",
            "Test Loss:  5.313020706176758\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  132\n",
            "Train Loss:  4.489683151245117\n",
            "Test Loss:  5.312804222106934\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  133\n",
            "Train Loss:  4.484465599060059\n",
            "Test Loss:  5.312585353851318\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  134\n",
            "Train Loss:  4.4792680740356445\n",
            "Test Loss:  5.31238317489624\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  135\n",
            "Train Loss:  4.474093914031982\n",
            "Test Loss:  5.312178611755371\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  136\n",
            "Train Loss:  4.46895694732666\n",
            "Test Loss:  5.311959266662598\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  137\n",
            "Train Loss:  4.463847637176514\n",
            "Test Loss:  5.311750411987305\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  138\n",
            "Train Loss:  4.458770751953125\n",
            "Test Loss:  5.311531066894531\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  139\n",
            "Train Loss:  4.453719139099121\n",
            "Test Loss:  5.3113250732421875\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  140\n",
            "Train Loss:  4.4486846923828125\n",
            "Test Loss:  5.311117649078369\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  141\n",
            "Train Loss:  4.443668842315674\n",
            "Test Loss:  5.310914039611816\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  142\n",
            "Train Loss:  4.4386701583862305\n",
            "Test Loss:  5.310716152191162\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  143\n",
            "Train Loss:  4.433704853057861\n",
            "Test Loss:  5.310522079467773\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  144\n",
            "Train Loss:  4.428767204284668\n",
            "Test Loss:  5.31033182144165\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  145\n",
            "Train Loss:  4.423859596252441\n",
            "Test Loss:  5.310145854949951\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  146\n",
            "Train Loss:  4.418983459472656\n",
            "Test Loss:  5.309964179992676\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  147\n",
            "Train Loss:  4.414139747619629\n",
            "Test Loss:  5.309784889221191\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  148\n",
            "Train Loss:  4.409323692321777\n",
            "Test Loss:  5.309607982635498\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  149\n",
            "Train Loss:  4.4045305252075195\n",
            "Test Loss:  5.309450149536133\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  150\n",
            "Train Loss:  4.399770736694336\n",
            "Test Loss:  5.309304237365723\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  151\n",
            "Train Loss:  4.395045280456543\n",
            "Test Loss:  5.309173583984375\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  152\n",
            "Train Loss:  4.390347957611084\n",
            "Test Loss:  5.309050559997559\n",
            "Recall : 0.18\n",
            "Epoch  153\n",
            "Train Loss:  4.385673522949219\n",
            "Test Loss:  5.30892276763916\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  154\n",
            "Train Loss:  4.3810319900512695\n",
            "Test Loss:  5.308793544769287\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  155\n",
            "Train Loss:  4.376425266265869\n",
            "Test Loss:  5.308657646179199\n",
            "Recall : 0.18\n",
            "Epoch  156\n",
            "Train Loss:  4.3718461990356445\n",
            "Test Loss:  5.308530807495117\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  157\n",
            "Train Loss:  4.3672943115234375\n",
            "Test Loss:  5.308413028717041\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  158\n",
            "Train Loss:  4.362770080566406\n",
            "Test Loss:  5.308313369750977\n",
            "Recall : 0.18\n",
            "Epoch  159\n",
            "Train Loss:  4.358279705047607\n",
            "Test Loss:  5.308221817016602\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  160\n",
            "Train Loss:  4.353821754455566\n",
            "Test Loss:  5.3081464767456055\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  161\n",
            "Train Loss:  4.349401473999023\n",
            "Test Loss:  5.30807638168335\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  162\n",
            "Train Loss:  4.345020294189453\n",
            "Test Loss:  5.308011531829834\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  163\n",
            "Train Loss:  4.340673923492432\n",
            "Test Loss:  5.307950973510742\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  164\n",
            "Train Loss:  4.336359024047852\n",
            "Test Loss:  5.30789852142334\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  165\n",
            "Train Loss:  4.33207893371582\n",
            "Test Loss:  5.307855606079102\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  166\n",
            "Train Loss:  4.327836990356445\n",
            "Test Loss:  5.307818412780762\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  167\n",
            "Train Loss:  4.323633193969727\n",
            "Test Loss:  5.307781219482422\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  168\n",
            "Train Loss:  4.319465637207031\n",
            "Test Loss:  5.307755470275879\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  169\n",
            "Train Loss:  4.315332412719727\n",
            "Test Loss:  5.307748794555664\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  170\n",
            "Train Loss:  4.3112359046936035\n",
            "Test Loss:  5.307764053344727\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  171\n",
            "Train Loss:  4.307170867919922\n",
            "Test Loss:  5.307783603668213\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  172\n",
            "Train Loss:  4.303143501281738\n",
            "Test Loss:  5.307806015014648\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  173\n",
            "Train Loss:  4.299153804779053\n",
            "Test Loss:  5.307826042175293\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  174\n",
            "Train Loss:  4.295203685760498\n",
            "Test Loss:  5.307854175567627\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  175\n",
            "Train Loss:  4.291282653808594\n",
            "Test Loss:  5.307884216308594\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  176\n",
            "Train Loss:  4.287393569946289\n",
            "Test Loss:  5.3079142570495605\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  177\n",
            "Train Loss:  4.283540725708008\n",
            "Test Loss:  5.30792236328125\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  178\n",
            "Train Loss:  4.279728889465332\n",
            "Test Loss:  5.307923793792725\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  179\n",
            "Train Loss:  4.275951385498047\n",
            "Test Loss:  5.307933330535889\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  180\n",
            "Train Loss:  4.272200584411621\n",
            "Test Loss:  5.30794620513916\n",
            "Recall : 0.18\n",
            "Epoch  181\n",
            "Train Loss:  4.2684831619262695\n",
            "Test Loss:  5.307952880859375\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  182\n",
            "Train Loss:  4.264800071716309\n",
            "Test Loss:  5.307962894439697\n",
            "Recall : 0.18\n",
            "Epoch  183\n",
            "Train Loss:  4.261146545410156\n",
            "Test Loss:  5.3079729080200195\n",
            "Recall : 0.18\n",
            "Epoch  184\n",
            "Train Loss:  4.2575273513793945\n",
            "Test Loss:  5.307985305786133\n",
            "Recall : 0.18\n",
            "Epoch  185\n",
            "Train Loss:  4.253939628601074\n",
            "Test Loss:  5.307999610900879\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  186\n",
            "Train Loss:  4.250377655029297\n",
            "Test Loss:  5.308009147644043\n",
            "Recall : 0.18\n",
            "Epoch  187\n",
            "Train Loss:  4.2468461990356445\n",
            "Test Loss:  5.3080244064331055\n",
            "Recall : 0.18\n",
            "Epoch  188\n",
            "Train Loss:  4.243349075317383\n",
            "Test Loss:  5.308046340942383\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  189\n",
            "Train Loss:  4.23988151550293\n",
            "Test Loss:  5.3080596923828125\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  190\n",
            "Train Loss:  4.236441612243652\n",
            "Test Loss:  5.308067798614502\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  191\n",
            "Train Loss:  4.233029842376709\n",
            "Test Loss:  5.308082580566406\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  192\n",
            "Train Loss:  4.229640960693359\n",
            "Test Loss:  5.308096408843994\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  193\n",
            "Train Loss:  4.2262797355651855\n",
            "Test Loss:  5.308119773864746\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  194\n",
            "Train Loss:  4.22294807434082\n",
            "Test Loss:  5.308154106140137\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  195\n",
            "Train Loss:  4.219639778137207\n",
            "Test Loss:  5.308193206787109\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  196\n",
            "Train Loss:  4.216355323791504\n",
            "Test Loss:  5.308234214782715\n",
            "Recall : 0.18\n",
            "Epoch  197\n",
            "Train Loss:  4.21309757232666\n",
            "Test Loss:  5.308272361755371\n",
            "Recall : 0.18\n",
            "Epoch  198\n",
            "Train Loss:  4.209867477416992\n",
            "Test Loss:  5.308315277099609\n",
            "Recall : 0.18\n",
            "Epoch  199\n",
            "Train Loss:  4.206664085388184\n",
            "Test Loss:  5.3083600997924805\n",
            "Recall : 0.18\n",
            "Epoch  200\n",
            "Train Loss:  4.203482627868652\n",
            "Test Loss:  5.308411121368408\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  201\n",
            "Train Loss:  4.200325012207031\n",
            "Test Loss:  5.308462142944336\n",
            "Recall : 0.18\n",
            "Epoch  202\n",
            "Train Loss:  4.197186470031738\n",
            "Test Loss:  5.308504581451416\n",
            "Recall : 0.18\n",
            "Epoch  203\n",
            "Train Loss:  4.194065570831299\n",
            "Test Loss:  5.308534622192383\n",
            "Recall : 0.18\n",
            "Epoch  204\n",
            "Train Loss:  4.190964698791504\n",
            "Test Loss:  5.308548927307129\n",
            "Recall : 0.18\n",
            "Epoch  205\n",
            "Train Loss:  4.187883377075195\n",
            "Test Loss:  5.308557510375977\n",
            "Recall : 0.18\n",
            "Epoch  206\n",
            "Train Loss:  4.184820175170898\n",
            "Test Loss:  5.308553695678711\n",
            "Recall : 0.18\n",
            "Epoch  207\n",
            "Train Loss:  4.181773662567139\n",
            "Test Loss:  5.308537483215332\n",
            "Recall : 0.18\n",
            "Epoch  208\n",
            "Train Loss:  4.178746223449707\n",
            "Test Loss:  5.308514595031738\n",
            "Recall : 0.18\n",
            "Epoch  209\n",
            "Train Loss:  4.175734519958496\n",
            "Test Loss:  5.308492183685303\n",
            "Recall : 0.18\n",
            "Epoch  210\n",
            "Train Loss:  4.172740936279297\n",
            "Test Loss:  5.3084611892700195\n",
            "Recall : 0.18\n",
            "Epoch  211\n",
            "Train Loss:  4.169763088226318\n",
            "Test Loss:  5.3084306716918945\n",
            "Recall : 0.18\n",
            "Epoch  212\n",
            "Train Loss:  4.166806697845459\n",
            "Test Loss:  5.30839729309082\n",
            "Recall : 0.18\n",
            "Epoch  213\n",
            "Train Loss:  4.163865566253662\n",
            "Test Loss:  5.30836296081543\n",
            "Recall : 0.18\n",
            "Epoch  214\n",
            "Train Loss:  4.160945415496826\n",
            "Test Loss:  5.3083176612854\n",
            "Recall : 0.18\n",
            "Epoch  215\n",
            "Train Loss:  4.158041954040527\n",
            "Test Loss:  5.308270454406738\n",
            "Recall : 0.18\n",
            "Epoch  216\n",
            "Train Loss:  4.155154228210449\n",
            "Test Loss:  5.3082170486450195\n",
            "Recall : 0.18\n",
            "Epoch  217\n",
            "Train Loss:  4.152281761169434\n",
            "Test Loss:  5.308163166046143\n",
            "Recall : 0.18\n",
            "Epoch  218\n",
            "Train Loss:  4.149422645568848\n",
            "Test Loss:  5.308103561401367\n",
            "Recall : 0.18\n",
            "Epoch  219\n",
            "Train Loss:  4.146574020385742\n",
            "Test Loss:  5.308038711547852\n",
            "Recall : 0.18\n",
            "Epoch  220\n",
            "Train Loss:  4.143740653991699\n",
            "Test Loss:  5.307977676391602\n",
            "Recall : 0.18\n",
            "Epoch  221\n",
            "Train Loss:  4.140925407409668\n",
            "Test Loss:  5.30790901184082\n",
            "Recall : 0.18\n",
            "Epoch  222\n",
            "Train Loss:  4.138131141662598\n",
            "Test Loss:  5.307830810546875\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  223\n",
            "Train Loss:  4.135357856750488\n",
            "Test Loss:  5.307751655578613\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  224\n",
            "Train Loss:  4.132603645324707\n",
            "Test Loss:  5.30766487121582\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  225\n",
            "Train Loss:  4.1298627853393555\n",
            "Test Loss:  5.30756950378418\n",
            "Recall : 0.18\n",
            "Epoch  226\n",
            "Train Loss:  4.127135753631592\n",
            "Test Loss:  5.307464122772217\n",
            "Recall : 0.18\n",
            "Epoch  227\n",
            "Train Loss:  4.124423027038574\n",
            "Test Loss:  5.307352066040039\n",
            "Recall : 0.18\n",
            "Epoch  228\n",
            "Train Loss:  4.121725082397461\n",
            "Test Loss:  5.307233810424805\n",
            "Recall : 0.18\n",
            "Epoch  229\n",
            "Train Loss:  4.119039535522461\n",
            "Test Loss:  5.307115077972412\n",
            "Recall : 0.18\n",
            "Epoch  230\n",
            "Train Loss:  4.116368293762207\n",
            "Test Loss:  5.306987762451172\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  231\n",
            "Train Loss:  4.113710403442383\n",
            "Test Loss:  5.306860446929932\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  232\n",
            "Train Loss:  4.111065864562988\n",
            "Test Loss:  5.306723594665527\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  233\n",
            "Train Loss:  4.108435153961182\n",
            "Test Loss:  5.30657958984375\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  234\n",
            "Train Loss:  4.105818748474121\n",
            "Test Loss:  5.306437015533447\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  235\n",
            "Train Loss:  4.103216171264648\n",
            "Test Loss:  5.3062896728515625\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  236\n",
            "Train Loss:  4.100627899169922\n",
            "Test Loss:  5.3061418533325195\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  237\n",
            "Train Loss:  4.098052024841309\n",
            "Test Loss:  5.306002140045166\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  238\n",
            "Train Loss:  4.095490455627441\n",
            "Test Loss:  5.305859565734863\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  239\n",
            "Train Loss:  4.092947006225586\n",
            "Test Loss:  5.305706024169922\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  240\n",
            "Train Loss:  4.090413570404053\n",
            "Test Loss:  5.305539131164551\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  241\n",
            "Train Loss:  4.087894439697266\n",
            "Test Loss:  5.305374622344971\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  242\n",
            "Train Loss:  4.085390090942383\n",
            "Test Loss:  5.30521297454834\n",
            "Recall : 0.18\n",
            "Epoch  243\n",
            "Train Loss:  4.082900047302246\n",
            "Test Loss:  5.3050537109375\n",
            "Recall : 0.18\n",
            "Epoch  244\n",
            "Train Loss:  4.080423355102539\n",
            "Test Loss:  5.304896354675293\n",
            "Recall : 0.18\n",
            "Epoch  245\n",
            "Train Loss:  4.077956199645996\n",
            "Test Loss:  5.304736614227295\n",
            "Recall : 0.18\n",
            "Epoch  246\n",
            "Train Loss:  4.075504779815674\n",
            "Test Loss:  5.304572105407715\n",
            "Recall : 0.18\n",
            "Epoch  247\n",
            "Train Loss:  4.073065280914307\n",
            "Test Loss:  5.304405212402344\n",
            "Recall : 0.18\n",
            "Epoch  248\n",
            "Train Loss:  4.070638179779053\n",
            "Test Loss:  5.304234504699707\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  249\n",
            "Train Loss:  4.0682220458984375\n",
            "Test Loss:  5.3040690422058105\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  250\n",
            "Train Loss:  4.065818786621094\n",
            "Test Loss:  5.303905487060547\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  251\n",
            "Train Loss:  4.063426971435547\n",
            "Test Loss:  5.303743839263916\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  252\n",
            "Train Loss:  4.061046600341797\n",
            "Test Loss:  5.303584575653076\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  253\n",
            "Train Loss:  4.058680534362793\n",
            "Test Loss:  5.303424835205078\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  254\n",
            "Train Loss:  4.056325912475586\n",
            "Test Loss:  5.303262710571289\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  255\n",
            "Train Loss:  4.053988456726074\n",
            "Test Loss:  5.30309534072876\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  256\n",
            "Train Loss:  4.051666259765625\n",
            "Test Loss:  5.3029279708862305\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  257\n",
            "Train Loss:  4.049356460571289\n",
            "Test Loss:  5.302761077880859\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  258\n",
            "Train Loss:  4.04705810546875\n",
            "Test Loss:  5.302590847015381\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  259\n",
            "Train Loss:  4.044775009155273\n",
            "Test Loss:  5.302414894104004\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  260\n",
            "Train Loss:  4.042502403259277\n",
            "Test Loss:  5.302240371704102\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  261\n",
            "Train Loss:  4.040241241455078\n",
            "Test Loss:  5.302066326141357\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  262\n",
            "Train Loss:  4.037989616394043\n",
            "Test Loss:  5.301896572113037\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  263\n",
            "Train Loss:  4.035752773284912\n",
            "Test Loss:  5.301731109619141\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  264\n",
            "Train Loss:  4.033527374267578\n",
            "Test Loss:  5.301571369171143\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  265\n",
            "Train Loss:  4.031315803527832\n",
            "Test Loss:  5.301411151885986\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  266\n",
            "Train Loss:  4.029121398925781\n",
            "Test Loss:  5.301252365112305\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  267\n",
            "Train Loss:  4.026937484741211\n",
            "Test Loss:  5.3011016845703125\n",
            "Recall : 0.18\n",
            "Epoch  268\n",
            "Train Loss:  4.024764537811279\n",
            "Test Loss:  5.3009490966796875\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  269\n",
            "Train Loss:  4.022604942321777\n",
            "Test Loss:  5.300796985626221\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  270\n",
            "Train Loss:  4.02046012878418\n",
            "Test Loss:  5.300648212432861\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  271\n",
            "Train Loss:  4.0183258056640625\n",
            "Test Loss:  5.300507545471191\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  272\n",
            "Train Loss:  4.016205787658691\n",
            "Test Loss:  5.30036735534668\n",
            "Recall : 0.18\n",
            "Epoch  273\n",
            "Train Loss:  4.014096736907959\n",
            "Test Loss:  5.300231456756592\n",
            "Recall : 0.18\n",
            "Epoch  274\n",
            "Train Loss:  4.012002944946289\n",
            "Test Loss:  5.3000946044921875\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  275\n",
            "Train Loss:  4.009920597076416\n",
            "Test Loss:  5.299962520599365\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  276\n",
            "Train Loss:  4.007851600646973\n",
            "Test Loss:  5.299833297729492\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  277\n",
            "Train Loss:  4.005795478820801\n",
            "Test Loss:  5.29970645904541\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  278\n",
            "Train Loss:  4.003749847412109\n",
            "Test Loss:  5.29958438873291\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  279\n",
            "Train Loss:  4.001715660095215\n",
            "Test Loss:  5.2994704246521\n",
            "Recall : 0.18\n",
            "Epoch  280\n",
            "Train Loss:  3.99969482421875\n",
            "Test Loss:  5.299356937408447\n",
            "Recall : 0.18\n",
            "Epoch  281\n",
            "Train Loss:  3.9976890087127686\n",
            "Test Loss:  5.299249649047852\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  282\n",
            "Train Loss:  3.995697021484375\n",
            "Test Loss:  5.299145698547363\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  283\n",
            "Train Loss:  3.993717908859253\n",
            "Test Loss:  5.2990498542785645\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  284\n",
            "Train Loss:  3.9917502403259277\n",
            "Test Loss:  5.298959732055664\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  285\n",
            "Train Loss:  3.9897923469543457\n",
            "Test Loss:  5.298865795135498\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  286\n",
            "Train Loss:  3.987847328186035\n",
            "Test Loss:  5.29877233505249\n",
            "Recall : 0.18\n",
            "Epoch  287\n",
            "Train Loss:  3.9859156608581543\n",
            "Test Loss:  5.298675537109375\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  288\n",
            "Train Loss:  3.983997344970703\n",
            "Test Loss:  5.298583984375\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  289\n",
            "Train Loss:  3.982091188430786\n",
            "Test Loss:  5.298492431640625\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  290\n",
            "Train Loss:  3.980194091796875\n",
            "Test Loss:  5.298409461975098\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  291\n",
            "Train Loss:  3.978311061859131\n",
            "Test Loss:  5.2983293533325195\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  292\n",
            "Train Loss:  3.9764389991760254\n",
            "Test Loss:  5.2982497215271\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  293\n",
            "Train Loss:  3.974576711654663\n",
            "Test Loss:  5.298170566558838\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  294\n",
            "Train Loss:  3.972724437713623\n",
            "Test Loss:  5.298097133636475\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  295\n",
            "Train Loss:  3.97088360786438\n",
            "Test Loss:  5.298029899597168\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  296\n",
            "Train Loss:  3.9690544605255127\n",
            "Test Loss:  5.297969818115234\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  297\n",
            "Train Loss:  3.967233896255493\n",
            "Test Loss:  5.297913551330566\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  298\n",
            "Train Loss:  3.9654202461242676\n",
            "Test Loss:  5.297859191894531\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  299\n",
            "Train Loss:  3.963615894317627\n",
            "Test Loss:  5.297808647155762\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  300\n",
            "Train Loss:  3.961819648742676\n",
            "Test Loss:  5.297760486602783\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  301\n",
            "Train Loss:  3.960033893585205\n",
            "Test Loss:  5.297717094421387\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  302\n",
            "Train Loss:  3.958256483078003\n",
            "Test Loss:  5.2976789474487305\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  303\n",
            "Train Loss:  3.9564871788024902\n",
            "Test Loss:  5.297645568847656\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  304\n",
            "Train Loss:  3.9547231197357178\n",
            "Test Loss:  5.297615051269531\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  305\n",
            "Train Loss:  3.9529666900634766\n",
            "Test Loss:  5.2975850105285645\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  306\n",
            "Train Loss:  3.951216459274292\n",
            "Test Loss:  5.2975568771362305\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  307\n",
            "Train Loss:  3.949474334716797\n",
            "Test Loss:  5.297529697418213\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  308\n",
            "Train Loss:  3.9477391242980957\n",
            "Test Loss:  5.297507286071777\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  309\n",
            "Train Loss:  3.946012496948242\n",
            "Test Loss:  5.297488212585449\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  310\n",
            "Train Loss:  3.944291114807129\n",
            "Test Loss:  5.297466278076172\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  311\n",
            "Train Loss:  3.9425747394561768\n",
            "Test Loss:  5.297444820404053\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  312\n",
            "Train Loss:  3.9408626556396484\n",
            "Test Loss:  5.297428607940674\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  313\n",
            "Train Loss:  3.9391565322875977\n",
            "Test Loss:  5.297416687011719\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  314\n",
            "Train Loss:  3.9374537467956543\n",
            "Test Loss:  5.297404766082764\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  315\n",
            "Train Loss:  3.9357547760009766\n",
            "Test Loss:  5.29738712310791\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  316\n",
            "Train Loss:  3.9340572357177734\n",
            "Test Loss:  5.297367095947266\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  317\n",
            "Train Loss:  3.932361364364624\n",
            "Test Loss:  5.297350883483887\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  318\n",
            "Train Loss:  3.930670738220215\n",
            "Test Loss:  5.297333717346191\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  319\n",
            "Train Loss:  3.928985118865967\n",
            "Test Loss:  5.297317981719971\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  320\n",
            "Train Loss:  3.9273030757904053\n",
            "Test Loss:  5.297308921813965\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  321\n",
            "Train Loss:  3.925626277923584\n",
            "Test Loss:  5.297301769256592\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  322\n",
            "Train Loss:  3.923952102661133\n",
            "Test Loss:  5.297295570373535\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  323\n",
            "Train Loss:  3.922281265258789\n",
            "Test Loss:  5.297290802001953\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  324\n",
            "Train Loss:  3.920614242553711\n",
            "Test Loss:  5.297288417816162\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  325\n",
            "Train Loss:  3.9189515113830566\n",
            "Test Loss:  5.297285079956055\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  326\n",
            "Train Loss:  3.917292594909668\n",
            "Test Loss:  5.297282695770264\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  327\n",
            "Train Loss:  3.9156370162963867\n",
            "Test Loss:  5.297280311584473\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  328\n",
            "Train Loss:  3.91398286819458\n",
            "Test Loss:  5.297279357910156\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  329\n",
            "Train Loss:  3.9123294353485107\n",
            "Test Loss:  5.297276496887207\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  330\n",
            "Train Loss:  3.9106767177581787\n",
            "Test Loss:  5.297279357910156\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  331\n",
            "Train Loss:  3.9090259075164795\n",
            "Test Loss:  5.297284126281738\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  332\n",
            "Train Loss:  3.907376289367676\n",
            "Test Loss:  5.29728889465332\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  333\n",
            "Train Loss:  3.9057273864746094\n",
            "Test Loss:  5.297292709350586\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  334\n",
            "Train Loss:  3.904080867767334\n",
            "Test Loss:  5.297292709350586\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  335\n",
            "Train Loss:  3.902434825897217\n",
            "Test Loss:  5.297297477722168\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  336\n",
            "Train Loss:  3.900792121887207\n",
            "Test Loss:  5.297309875488281\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  337\n",
            "Train Loss:  3.899153470993042\n",
            "Test Loss:  5.297325134277344\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  338\n",
            "Train Loss:  3.8975167274475098\n",
            "Test Loss:  5.297342300415039\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  339\n",
            "Train Loss:  3.8958821296691895\n",
            "Test Loss:  5.297358512878418\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  340\n",
            "Train Loss:  3.894249200820923\n",
            "Test Loss:  5.297368049621582\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  341\n",
            "Train Loss:  3.8926172256469727\n",
            "Test Loss:  5.297374725341797\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  342\n",
            "Train Loss:  3.890988826751709\n",
            "Test Loss:  5.297380447387695\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  343\n",
            "Train Loss:  3.889362335205078\n",
            "Test Loss:  5.297389984130859\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  344\n",
            "Train Loss:  3.887737274169922\n",
            "Test Loss:  5.297394275665283\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  345\n",
            "Train Loss:  3.8861160278320312\n",
            "Test Loss:  5.297398090362549\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  346\n",
            "Train Loss:  3.8844971656799316\n",
            "Test Loss:  5.297404766082764\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  347\n",
            "Train Loss:  3.882883071899414\n",
            "Test Loss:  5.2974114418029785\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  348\n",
            "Train Loss:  3.8812739849090576\n",
            "Test Loss:  5.297419548034668\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  349\n",
            "Train Loss:  3.879667282104492\n",
            "Test Loss:  5.297429084777832\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  350\n",
            "Train Loss:  3.8780651092529297\n",
            "Test Loss:  5.297435283660889\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  351\n",
            "Train Loss:  3.876466751098633\n",
            "Test Loss:  5.297438621520996\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  352\n",
            "Train Loss:  3.8748738765716553\n",
            "Test Loss:  5.297445297241211\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  353\n",
            "Train Loss:  3.873284101486206\n",
            "Test Loss:  5.2974534034729\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  354\n",
            "Train Loss:  3.8716988563537598\n",
            "Test Loss:  5.297456741333008\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  355\n",
            "Train Loss:  3.8701205253601074\n",
            "Test Loss:  5.297460556030273\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  356\n",
            "Train Loss:  3.8685462474823\n",
            "Test Loss:  5.2974677085876465\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  357\n",
            "Train Loss:  3.8669776916503906\n",
            "Test Loss:  5.297472953796387\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  358\n",
            "Train Loss:  3.8654139041900635\n",
            "Test Loss:  5.297485828399658\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  359\n",
            "Train Loss:  3.8638553619384766\n",
            "Test Loss:  5.297502517700195\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  360\n",
            "Train Loss:  3.862304210662842\n",
            "Test Loss:  5.297524452209473\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  361\n",
            "Train Loss:  3.8607587814331055\n",
            "Test Loss:  5.297545433044434\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  362\n",
            "Train Loss:  3.859218120574951\n",
            "Test Loss:  5.297567367553711\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  363\n",
            "Train Loss:  3.857682704925537\n",
            "Test Loss:  5.297593116760254\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  364\n",
            "Train Loss:  3.8561530113220215\n",
            "Test Loss:  5.2976202964782715\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  365\n",
            "Train Loss:  3.8546295166015625\n",
            "Test Loss:  5.297649383544922\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  366\n",
            "Train Loss:  3.8531155586242676\n",
            "Test Loss:  5.2976789474487305\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  367\n",
            "Train Loss:  3.8516058921813965\n",
            "Test Loss:  5.2977142333984375\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  368\n",
            "Train Loss:  3.850105047225952\n",
            "Test Loss:  5.297754287719727\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  369\n",
            "Train Loss:  3.8486099243164062\n",
            "Test Loss:  5.297797203063965\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  370\n",
            "Train Loss:  3.847121238708496\n",
            "Test Loss:  5.297845363616943\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  371\n",
            "Train Loss:  3.84564208984375\n",
            "Test Loss:  5.297896385192871\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  372\n",
            "Train Loss:  3.8441689014434814\n",
            "Test Loss:  5.29794979095459\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  373\n",
            "Train Loss:  3.8427014350891113\n",
            "Test Loss:  5.298004150390625\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  374\n",
            "Train Loss:  3.841240406036377\n",
            "Test Loss:  5.298061370849609\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  375\n",
            "Train Loss:  3.8397865295410156\n",
            "Test Loss:  5.298122406005859\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  376\n",
            "Train Loss:  3.8383398056030273\n",
            "Test Loss:  5.298185348510742\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  377\n",
            "Train Loss:  3.8369016647338867\n",
            "Test Loss:  5.298249244689941\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  378\n",
            "Train Loss:  3.835470199584961\n",
            "Test Loss:  5.298315525054932\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  379\n",
            "Train Loss:  3.8340468406677246\n",
            "Test Loss:  5.298379898071289\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  380\n",
            "Train Loss:  3.832632064819336\n",
            "Test Loss:  5.298443794250488\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  381\n",
            "Train Loss:  3.8312253952026367\n",
            "Test Loss:  5.298506736755371\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  382\n",
            "Train Loss:  3.8298263549804688\n",
            "Test Loss:  5.298574447631836\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  383\n",
            "Train Loss:  3.828434467315674\n",
            "Test Loss:  5.298648834228516\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  384\n",
            "Train Loss:  3.8270490169525146\n",
            "Test Loss:  5.298727989196777\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  385\n",
            "Train Loss:  3.8256707191467285\n",
            "Test Loss:  5.298810958862305\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  386\n",
            "Train Loss:  3.8243017196655273\n",
            "Test Loss:  5.298897743225098\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  387\n",
            "Train Loss:  3.8229408264160156\n",
            "Test Loss:  5.298986434936523\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  388\n",
            "Train Loss:  3.8215889930725098\n",
            "Test Loss:  5.299074649810791\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  389\n",
            "Train Loss:  3.8202438354492188\n",
            "Test Loss:  5.299164772033691\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  390\n",
            "Train Loss:  3.8189072608947754\n",
            "Test Loss:  5.299259662628174\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  391\n",
            "Train Loss:  3.8175792694091797\n",
            "Test Loss:  5.299356937408447\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  392\n",
            "Train Loss:  3.816258668899536\n",
            "Test Loss:  5.299461364746094\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  393\n",
            "Train Loss:  3.814945936203003\n",
            "Test Loss:  5.299565315246582\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  394\n",
            "Train Loss:  3.813640594482422\n",
            "Test Loss:  5.299667835235596\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  395\n",
            "Train Loss:  3.812343120574951\n",
            "Test Loss:  5.299772262573242\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  396\n",
            "Train Loss:  3.8110527992248535\n",
            "Test Loss:  5.2998762130737305\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  397\n",
            "Train Loss:  3.809769868850708\n",
            "Test Loss:  5.299981117248535\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  398\n",
            "Train Loss:  3.808494806289673\n",
            "Test Loss:  5.300088882446289\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  399\n",
            "Train Loss:  3.807227373123169\n",
            "Test Loss:  5.300199508666992\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  400\n",
            "Train Loss:  3.8059659004211426\n",
            "Test Loss:  5.300311088562012\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  401\n",
            "Train Loss:  3.8047118186950684\n",
            "Test Loss:  5.300426483154297\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  402\n",
            "Train Loss:  3.8034658432006836\n",
            "Test Loss:  5.300545692443848\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  403\n",
            "Train Loss:  3.8022267818450928\n",
            "Test Loss:  5.300668716430664\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  404\n",
            "Train Loss:  3.800994873046875\n",
            "Test Loss:  5.300788402557373\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  405\n",
            "Train Loss:  3.7997708320617676\n",
            "Test Loss:  5.300906181335449\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  406\n",
            "Train Loss:  3.798552989959717\n",
            "Test Loss:  5.301022529602051\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  407\n",
            "Train Loss:  3.7973411083221436\n",
            "Test Loss:  5.301140785217285\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  408\n",
            "Train Loss:  3.796138286590576\n",
            "Test Loss:  5.301257610321045\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  409\n",
            "Train Loss:  3.794940948486328\n",
            "Test Loss:  5.301375389099121\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  410\n",
            "Train Loss:  3.7937517166137695\n",
            "Test Loss:  5.3014912605285645\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  411\n",
            "Train Loss:  3.7925686836242676\n",
            "Test Loss:  5.301608085632324\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  412\n",
            "Train Loss:  3.791391611099243\n",
            "Test Loss:  5.301727294921875\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  413\n",
            "Train Loss:  3.790221929550171\n",
            "Test Loss:  5.301848888397217\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  414\n",
            "Train Loss:  3.7890572547912598\n",
            "Test Loss:  5.301971435546875\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  415\n",
            "Train Loss:  3.7878992557525635\n",
            "Test Loss:  5.302095413208008\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  416\n",
            "Train Loss:  3.7867465019226074\n",
            "Test Loss:  5.302221298217773\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  417\n",
            "Train Loss:  3.785597801208496\n",
            "Test Loss:  5.302344799041748\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  418\n",
            "Train Loss:  3.784456729888916\n",
            "Test Loss:  5.302467346191406\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  419\n",
            "Train Loss:  3.783320426940918\n",
            "Test Loss:  5.3025922775268555\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  420\n",
            "Train Loss:  3.7821903228759766\n",
            "Test Loss:  5.302717208862305\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  421\n",
            "Train Loss:  3.78106689453125\n",
            "Test Loss:  5.3028459548950195\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  422\n",
            "Train Loss:  3.7799487113952637\n",
            "Test Loss:  5.302979469299316\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  423\n",
            "Train Loss:  3.7788357734680176\n",
            "Test Loss:  5.3031158447265625\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  424\n",
            "Train Loss:  3.777728796005249\n",
            "Test Loss:  5.303257942199707\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  425\n",
            "Train Loss:  3.776625156402588\n",
            "Test Loss:  5.303404808044434\n",
            "Recall : 0.1895238095238095\n",
            "Epoch  426\n",
            "Train Loss:  3.775526523590088\n",
            "Test Loss:  5.303552627563477\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  427\n",
            "Train Loss:  3.7744336128234863\n",
            "Test Loss:  5.303701400756836\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  428\n",
            "Train Loss:  3.773345708847046\n",
            "Test Loss:  5.3038506507873535\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  429\n",
            "Train Loss:  3.7722630500793457\n",
            "Test Loss:  5.30400276184082\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  430\n",
            "Train Loss:  3.7711853981018066\n",
            "Test Loss:  5.304157733917236\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  431\n",
            "Train Loss:  3.7701125144958496\n",
            "Test Loss:  5.304314613342285\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  432\n",
            "Train Loss:  3.7690443992614746\n",
            "Test Loss:  5.304466247558594\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  433\n",
            "Train Loss:  3.767979621887207\n",
            "Test Loss:  5.304621696472168\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  434\n",
            "Train Loss:  3.7669196128845215\n",
            "Test Loss:  5.304777145385742\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  435\n",
            "Train Loss:  3.7658627033233643\n",
            "Test Loss:  5.304932594299316\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  436\n",
            "Train Loss:  3.76481032371521\n",
            "Test Loss:  5.305086135864258\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  437\n",
            "Train Loss:  3.763763427734375\n",
            "Test Loss:  5.305240154266357\n",
            "Recall : 0.18857142857142858\n",
            "Epoch  438\n",
            "Train Loss:  3.7627205848693848\n",
            "Test Loss:  5.305394172668457\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  439\n",
            "Train Loss:  3.761681079864502\n",
            "Test Loss:  5.305546283721924\n",
            "Recall : 0.18761904761904763\n",
            "Epoch  440\n",
            "Train Loss:  3.760648250579834\n",
            "Test Loss:  5.305696964263916\n",
            "Recall : 0.18666666666666668\n",
            "Epoch  441\n",
            "Train Loss:  3.7596189975738525\n",
            "Test Loss:  5.305846214294434\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  442\n",
            "Train Loss:  3.7585959434509277\n",
            "Test Loss:  5.30599308013916\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  443\n",
            "Train Loss:  3.7575759887695312\n",
            "Test Loss:  5.30613899230957\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  444\n",
            "Train Loss:  3.756560802459717\n",
            "Test Loss:  5.3062849044799805\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  445\n",
            "Train Loss:  3.7555489540100098\n",
            "Test Loss:  5.306431770324707\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  446\n",
            "Train Loss:  3.75454044342041\n",
            "Test Loss:  5.306577682495117\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  447\n",
            "Train Loss:  3.7535367012023926\n",
            "Test Loss:  5.306725978851318\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  448\n",
            "Train Loss:  3.752534866333008\n",
            "Test Loss:  5.306874752044678\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  449\n",
            "Train Loss:  3.7515358924865723\n",
            "Test Loss:  5.3070220947265625\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  450\n",
            "Train Loss:  3.7505393028259277\n",
            "Test Loss:  5.3071675300598145\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  451\n",
            "Train Loss:  3.7495455741882324\n",
            "Test Loss:  5.307314395904541\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  452\n",
            "Train Loss:  3.7485547065734863\n",
            "Test Loss:  5.307462692260742\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  453\n",
            "Train Loss:  3.747567892074585\n",
            "Test Loss:  5.307612419128418\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  454\n",
            "Train Loss:  3.746584415435791\n",
            "Test Loss:  5.307762145996094\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  455\n",
            "Train Loss:  3.7456037998199463\n",
            "Test Loss:  5.307915687561035\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  456\n",
            "Train Loss:  3.744626998901367\n",
            "Test Loss:  5.308070182800293\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  457\n",
            "Train Loss:  3.7436554431915283\n",
            "Test Loss:  5.308226585388184\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  458\n",
            "Train Loss:  3.742687463760376\n",
            "Test Loss:  5.308386325836182\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  459\n",
            "Train Loss:  3.7417237758636475\n",
            "Test Loss:  5.308545112609863\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  460\n",
            "Train Loss:  3.7407636642456055\n",
            "Test Loss:  5.308704376220703\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  461\n",
            "Train Loss:  3.7398061752319336\n",
            "Test Loss:  5.308865070343018\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  462\n",
            "Train Loss:  3.738852024078369\n",
            "Test Loss:  5.309022903442383\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  463\n",
            "Train Loss:  3.7378997802734375\n",
            "Test Loss:  5.309178352355957\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  464\n",
            "Train Loss:  3.736952543258667\n",
            "Test Loss:  5.309332847595215\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  465\n",
            "Train Loss:  3.7360076904296875\n",
            "Test Loss:  5.309483528137207\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  466\n",
            "Train Loss:  3.7350664138793945\n",
            "Test Loss:  5.309634208679199\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  467\n",
            "Train Loss:  3.734127998352051\n",
            "Test Loss:  5.3097825050354\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  468\n",
            "Train Loss:  3.7331924438476562\n",
            "Test Loss:  5.309928894042969\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  469\n",
            "Train Loss:  3.732260227203369\n",
            "Test Loss:  5.3100762367248535\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  470\n",
            "Train Loss:  3.7313294410705566\n",
            "Test Loss:  5.310224533081055\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  471\n",
            "Train Loss:  3.7304019927978516\n",
            "Test Loss:  5.310373306274414\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  472\n",
            "Train Loss:  3.729475975036621\n",
            "Test Loss:  5.310522079467773\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  473\n",
            "Train Loss:  3.72855281829834\n",
            "Test Loss:  5.310669898986816\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  474\n",
            "Train Loss:  3.7276320457458496\n",
            "Test Loss:  5.310820579528809\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  475\n",
            "Train Loss:  3.726715087890625\n",
            "Test Loss:  5.310968399047852\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  476\n",
            "Train Loss:  3.725799798965454\n",
            "Test Loss:  5.311117172241211\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  477\n",
            "Train Loss:  3.724886894226074\n",
            "Test Loss:  5.3112664222717285\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  478\n",
            "Train Loss:  3.72397518157959\n",
            "Test Loss:  5.311415672302246\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  479\n",
            "Train Loss:  3.7230660915374756\n",
            "Test Loss:  5.311563491821289\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  480\n",
            "Train Loss:  3.722158908843994\n",
            "Test Loss:  5.311708450317383\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  481\n",
            "Train Loss:  3.7212533950805664\n",
            "Test Loss:  5.311850547790527\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  482\n",
            "Train Loss:  3.720348596572876\n",
            "Test Loss:  5.311992645263672\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  483\n",
            "Train Loss:  3.7194461822509766\n",
            "Test Loss:  5.312132358551025\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  484\n",
            "Train Loss:  3.718545913696289\n",
            "Test Loss:  5.31227445602417\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  485\n",
            "Train Loss:  3.7176458835601807\n",
            "Test Loss:  5.312413215637207\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  486\n",
            "Train Loss:  3.7167491912841797\n",
            "Test Loss:  5.312548637390137\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  487\n",
            "Train Loss:  3.7158544063568115\n",
            "Test Loss:  5.312682628631592\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  488\n",
            "Train Loss:  3.714961528778076\n",
            "Test Loss:  5.312816143035889\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  489\n",
            "Train Loss:  3.7140707969665527\n",
            "Test Loss:  5.312952995300293\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  490\n",
            "Train Loss:  3.7131829261779785\n",
            "Test Loss:  5.313091278076172\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  491\n",
            "Train Loss:  3.712296962738037\n",
            "Test Loss:  5.313232421875\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  492\n",
            "Train Loss:  3.7114131450653076\n",
            "Test Loss:  5.313370704650879\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  493\n",
            "Train Loss:  3.710531711578369\n",
            "Test Loss:  5.313509464263916\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  494\n",
            "Train Loss:  3.7096545696258545\n",
            "Test Loss:  5.313649654388428\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  495\n",
            "Train Loss:  3.7087795734405518\n",
            "Test Loss:  5.313789367675781\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  496\n",
            "Train Loss:  3.7079062461853027\n",
            "Test Loss:  5.31392765045166\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  497\n",
            "Train Loss:  3.7070350646972656\n",
            "Test Loss:  5.3140668869018555\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  498\n",
            "Train Loss:  3.7061643600463867\n",
            "Test Loss:  5.314205646514893\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  499\n",
            "Train Loss:  3.7052950859069824\n",
            "Test Loss:  5.314343452453613\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  500\n",
            "Train Loss:  3.7044270038604736\n",
            "Test Loss:  5.314477920532227\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  501\n",
            "Train Loss:  3.703561305999756\n",
            "Test Loss:  5.314609050750732\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  502\n",
            "Train Loss:  3.702697277069092\n",
            "Test Loss:  5.31473970413208\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  503\n",
            "Train Loss:  3.701836585998535\n",
            "Test Loss:  5.314870357513428\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  504\n",
            "Train Loss:  3.7009785175323486\n",
            "Test Loss:  5.31500244140625\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  505\n",
            "Train Loss:  3.700122356414795\n",
            "Test Loss:  5.315134525299072\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  506\n",
            "Train Loss:  3.699268341064453\n",
            "Test Loss:  5.315265655517578\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  507\n",
            "Train Loss:  3.6984171867370605\n",
            "Test Loss:  5.315398216247559\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  508\n",
            "Train Loss:  3.6975677013397217\n",
            "Test Loss:  5.31552791595459\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  509\n",
            "Train Loss:  3.696720600128174\n",
            "Test Loss:  5.315657615661621\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  510\n",
            "Train Loss:  3.6958751678466797\n",
            "Test Loss:  5.315786361694336\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  511\n",
            "Train Loss:  3.695033550262451\n",
            "Test Loss:  5.315914154052734\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  512\n",
            "Train Loss:  3.6941933631896973\n",
            "Test Loss:  5.316040992736816\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  513\n",
            "Train Loss:  3.6933557987213135\n",
            "Test Loss:  5.316167831420898\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  514\n",
            "Train Loss:  3.6925201416015625\n",
            "Test Loss:  5.3162946701049805\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  515\n",
            "Train Loss:  3.691685199737549\n",
            "Test Loss:  5.3164215087890625\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  516\n",
            "Train Loss:  3.690852165222168\n",
            "Test Loss:  5.316549301147461\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  517\n",
            "Train Loss:  3.690021276473999\n",
            "Test Loss:  5.316678047180176\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  518\n",
            "Train Loss:  3.6891918182373047\n",
            "Test Loss:  5.316804885864258\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  519\n",
            "Train Loss:  3.6883649826049805\n",
            "Test Loss:  5.316932201385498\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  520\n",
            "Train Loss:  3.687540054321289\n",
            "Test Loss:  5.317054748535156\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  521\n",
            "Train Loss:  3.686718463897705\n",
            "Test Loss:  5.317177772521973\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  522\n",
            "Train Loss:  3.685896396636963\n",
            "Test Loss:  5.317299842834473\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  523\n",
            "Train Loss:  3.6850762367248535\n",
            "Test Loss:  5.317420482635498\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  524\n",
            "Train Loss:  3.684258460998535\n",
            "Test Loss:  5.317538261413574\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  525\n",
            "Train Loss:  3.683443069458008\n",
            "Test Loss:  5.317655563354492\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  526\n",
            "Train Loss:  3.6826303005218506\n",
            "Test Loss:  5.317773342132568\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  527\n",
            "Train Loss:  3.681819438934326\n",
            "Test Loss:  5.3178911209106445\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  528\n",
            "Train Loss:  3.6810100078582764\n",
            "Test Loss:  5.3180084228515625\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  529\n",
            "Train Loss:  3.680201768875122\n",
            "Test Loss:  5.318122863769531\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  530\n",
            "Train Loss:  3.6793932914733887\n",
            "Test Loss:  5.318236351013184\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  531\n",
            "Train Loss:  3.678586006164551\n",
            "Test Loss:  5.318349361419678\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  532\n",
            "Train Loss:  3.677781820297241\n",
            "Test Loss:  5.3184614181518555\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  533\n",
            "Train Loss:  3.676978588104248\n",
            "Test Loss:  5.318573951721191\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  534\n",
            "Train Loss:  3.676177740097046\n",
            "Test Loss:  5.318685531616211\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  535\n",
            "Train Loss:  3.675379753112793\n",
            "Test Loss:  5.3187947273254395\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  536\n",
            "Train Loss:  3.674583911895752\n",
            "Test Loss:  5.318901062011719\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  537\n",
            "Train Loss:  3.673790454864502\n",
            "Test Loss:  5.3190083503723145\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  538\n",
            "Train Loss:  3.672999382019043\n",
            "Test Loss:  5.319113254547119\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  539\n",
            "Train Loss:  3.6722092628479004\n",
            "Test Loss:  5.319220542907715\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  540\n",
            "Train Loss:  3.671422004699707\n",
            "Test Loss:  5.319326400756836\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  541\n",
            "Train Loss:  3.6706361770629883\n",
            "Test Loss:  5.319433212280273\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  542\n",
            "Train Loss:  3.6698527336120605\n",
            "Test Loss:  5.3195390701293945\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  543\n",
            "Train Loss:  3.6690707206726074\n",
            "Test Loss:  5.319643020629883\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  544\n",
            "Train Loss:  3.668290376663208\n",
            "Test Loss:  5.3197455406188965\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  545\n",
            "Train Loss:  3.667511463165283\n",
            "Test Loss:  5.319844722747803\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  546\n",
            "Train Loss:  3.666733980178833\n",
            "Test Loss:  5.319944381713867\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  547\n",
            "Train Loss:  3.665958881378174\n",
            "Test Loss:  5.320042610168457\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  548\n",
            "Train Loss:  3.665184736251831\n",
            "Test Loss:  5.320140838623047\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  549\n",
            "Train Loss:  3.6644134521484375\n",
            "Test Loss:  5.320241928100586\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  550\n",
            "Train Loss:  3.6636438369750977\n",
            "Test Loss:  5.320342063903809\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  551\n",
            "Train Loss:  3.6628758907318115\n",
            "Test Loss:  5.320438385009766\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  552\n",
            "Train Loss:  3.662109851837158\n",
            "Test Loss:  5.320533752441406\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  553\n",
            "Train Loss:  3.661344528198242\n",
            "Test Loss:  5.320626735687256\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  554\n",
            "Train Loss:  3.660581588745117\n",
            "Test Loss:  5.320719242095947\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  555\n",
            "Train Loss:  3.6598196029663086\n",
            "Test Loss:  5.320807456970215\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  556\n",
            "Train Loss:  3.6590609550476074\n",
            "Test Loss:  5.320892810821533\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  557\n",
            "Train Loss:  3.6583032608032227\n",
            "Test Loss:  5.320978164672852\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  558\n",
            "Train Loss:  3.6575469970703125\n",
            "Test Loss:  5.321061134338379\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  559\n",
            "Train Loss:  3.656792402267456\n",
            "Test Loss:  5.321143627166748\n",
            "Recall : 0.18571428571428572\n",
            "Epoch  560\n",
            "Train Loss:  3.656038761138916\n",
            "Test Loss:  5.32122802734375\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  561\n",
            "Train Loss:  3.655287742614746\n",
            "Test Loss:  5.321308135986328\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  562\n",
            "Train Loss:  3.654539108276367\n",
            "Test Loss:  5.321389198303223\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  563\n",
            "Train Loss:  3.653791904449463\n",
            "Test Loss:  5.321470260620117\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  564\n",
            "Train Loss:  3.6530466079711914\n",
            "Test Loss:  5.321548938751221\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  565\n",
            "Train Loss:  3.652304172515869\n",
            "Test Loss:  5.321627616882324\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  566\n",
            "Train Loss:  3.6515636444091797\n",
            "Test Loss:  5.321706295013428\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  567\n",
            "Train Loss:  3.650824546813965\n",
            "Test Loss:  5.321786403656006\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  568\n",
            "Train Loss:  3.6500868797302246\n",
            "Test Loss:  5.321867942810059\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  569\n",
            "Train Loss:  3.6493520736694336\n",
            "Test Loss:  5.321949005126953\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  570\n",
            "Train Loss:  3.6486172676086426\n",
            "Test Loss:  5.322031021118164\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  571\n",
            "Train Loss:  3.647885322570801\n",
            "Test Loss:  5.322113037109375\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  572\n",
            "Train Loss:  3.647156238555908\n",
            "Test Loss:  5.3221964836120605\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  573\n",
            "Train Loss:  3.646428108215332\n",
            "Test Loss:  5.322278022766113\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  574\n",
            "Train Loss:  3.6457014083862305\n",
            "Test Loss:  5.322359085083008\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  575\n",
            "Train Loss:  3.6449766159057617\n",
            "Test Loss:  5.3224382400512695\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  576\n",
            "Train Loss:  3.644254207611084\n",
            "Test Loss:  5.322517395019531\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  577\n",
            "Train Loss:  3.643533229827881\n",
            "Test Loss:  5.322596549987793\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  578\n",
            "Train Loss:  3.642815351486206\n",
            "Test Loss:  5.322676181793213\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  579\n",
            "Train Loss:  3.6420998573303223\n",
            "Test Loss:  5.322752475738525\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  580\n",
            "Train Loss:  3.641385078430176\n",
            "Test Loss:  5.322828769683838\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  581\n",
            "Train Loss:  3.640674591064453\n",
            "Test Loss:  5.32290506362915\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  582\n",
            "Train Loss:  3.639965057373047\n",
            "Test Loss:  5.32297945022583\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  583\n",
            "Train Loss:  3.639256477355957\n",
            "Test Loss:  5.323052406311035\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  584\n",
            "Train Loss:  3.638550043106079\n",
            "Test Loss:  5.323127746582031\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  585\n",
            "Train Loss:  3.6378448009490967\n",
            "Test Loss:  5.323202610015869\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  586\n",
            "Train Loss:  3.637141704559326\n",
            "Test Loss:  5.323278427124023\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  587\n",
            "Train Loss:  3.636439085006714\n",
            "Test Loss:  5.323354244232178\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  588\n",
            "Train Loss:  3.6357390880584717\n",
            "Test Loss:  5.323431968688965\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  589\n",
            "Train Loss:  3.635040044784546\n",
            "Test Loss:  5.323509216308594\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  590\n",
            "Train Loss:  3.634341239929199\n",
            "Test Loss:  5.323586463928223\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  591\n",
            "Train Loss:  3.6336441040039062\n",
            "Test Loss:  5.323663711547852\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  592\n",
            "Train Loss:  3.6329493522644043\n",
            "Test Loss:  5.323740005493164\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  593\n",
            "Train Loss:  3.632256031036377\n",
            "Test Loss:  5.32381534576416\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  594\n",
            "Train Loss:  3.6315646171569824\n",
            "Test Loss:  5.323891639709473\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  595\n",
            "Train Loss:  3.6308748722076416\n",
            "Test Loss:  5.323966026306152\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  596\n",
            "Train Loss:  3.6301872730255127\n",
            "Test Loss:  5.324042320251465\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  597\n",
            "Train Loss:  3.6295013427734375\n",
            "Test Loss:  5.324119567871094\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  598\n",
            "Train Loss:  3.628817081451416\n",
            "Test Loss:  5.324199199676514\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  599\n",
            "Train Loss:  3.628134250640869\n",
            "Test Loss:  5.324280738830566\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  600\n",
            "Train Loss:  3.627453327178955\n",
            "Test Loss:  5.324361801147461\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  601\n",
            "Train Loss:  3.626774311065674\n",
            "Test Loss:  5.324443817138672\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  602\n",
            "Train Loss:  3.626098155975342\n",
            "Test Loss:  5.324527740478516\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  603\n",
            "Train Loss:  3.6254234313964844\n",
            "Test Loss:  5.324609756469727\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  604\n",
            "Train Loss:  3.624751091003418\n",
            "Test Loss:  5.3246917724609375\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  605\n",
            "Train Loss:  3.6240808963775635\n",
            "Test Loss:  5.324772834777832\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  606\n",
            "Train Loss:  3.6234121322631836\n",
            "Test Loss:  5.32485294342041\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  607\n",
            "Train Loss:  3.6227455139160156\n",
            "Test Loss:  5.324934482574463\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  608\n",
            "Train Loss:  3.622080087661743\n",
            "Test Loss:  5.325015544891357\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  609\n",
            "Train Loss:  3.6214170455932617\n",
            "Test Loss:  5.325096130371094\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  610\n",
            "Train Loss:  3.6207566261291504\n",
            "Test Loss:  5.32517671585083\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  611\n",
            "Train Loss:  3.620096445083618\n",
            "Test Loss:  5.325256824493408\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  612\n",
            "Train Loss:  3.619438648223877\n",
            "Test Loss:  5.3253374099731445\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  613\n",
            "Train Loss:  3.6187822818756104\n",
            "Test Loss:  5.3254194259643555\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  614\n",
            "Train Loss:  3.6181278228759766\n",
            "Test Loss:  5.325501918792725\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  615\n",
            "Train Loss:  3.6174745559692383\n",
            "Test Loss:  5.325583457946777\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  616\n",
            "Train Loss:  3.616824150085449\n",
            "Test Loss:  5.32566499710083\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  617\n",
            "Train Loss:  3.616175651550293\n",
            "Test Loss:  5.325746536254883\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  618\n",
            "Train Loss:  3.6155271530151367\n",
            "Test Loss:  5.325827121734619\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  619\n",
            "Train Loss:  3.6148812770843506\n",
            "Test Loss:  5.3259077072143555\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  620\n",
            "Train Loss:  3.614236831665039\n",
            "Test Loss:  5.325987815856934\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  621\n",
            "Train Loss:  3.6135942935943604\n",
            "Test Loss:  5.32606840133667\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  622\n",
            "Train Loss:  3.6129536628723145\n",
            "Test Loss:  5.326148986816406\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  623\n",
            "Train Loss:  3.6123147010803223\n",
            "Test Loss:  5.326229095458984\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  624\n",
            "Train Loss:  3.6116766929626465\n",
            "Test Loss:  5.326309680938721\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  625\n",
            "Train Loss:  3.611041307449341\n",
            "Test Loss:  5.326389789581299\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  626\n",
            "Train Loss:  3.6104068756103516\n",
            "Test Loss:  5.326468467712402\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  627\n",
            "Train Loss:  3.609773635864258\n",
            "Test Loss:  5.326546669006348\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  628\n",
            "Train Loss:  3.6091418266296387\n",
            "Test Loss:  5.326625347137451\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  629\n",
            "Train Loss:  3.6085119247436523\n",
            "Test Loss:  5.3267035484313965\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  630\n",
            "Train Loss:  3.6078827381134033\n",
            "Test Loss:  5.326781272888184\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  631\n",
            "Train Loss:  3.607254981994629\n",
            "Test Loss:  5.326859474182129\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  632\n",
            "Train Loss:  3.606628894805908\n",
            "Test Loss:  5.326940059661865\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  633\n",
            "Train Loss:  3.606004238128662\n",
            "Test Loss:  5.327019691467285\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  634\n",
            "Train Loss:  3.605380058288574\n",
            "Test Loss:  5.327098846435547\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  635\n",
            "Train Loss:  3.604757785797119\n",
            "Test Loss:  5.327179908752441\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  636\n",
            "Train Loss:  3.6041383743286133\n",
            "Test Loss:  5.327260971069336\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  637\n",
            "Train Loss:  3.603520393371582\n",
            "Test Loss:  5.327342987060547\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  638\n",
            "Train Loss:  3.6029040813446045\n",
            "Test Loss:  5.327426433563232\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  639\n",
            "Train Loss:  3.6022896766662598\n",
            "Test Loss:  5.327507972717285\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  640\n",
            "Train Loss:  3.601677417755127\n",
            "Test Loss:  5.327587604522705\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  641\n",
            "Train Loss:  3.6010661125183105\n",
            "Test Loss:  5.327666759490967\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  642\n",
            "Train Loss:  3.600456476211548\n",
            "Test Loss:  5.327746391296387\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  643\n",
            "Train Loss:  3.5998480319976807\n",
            "Test Loss:  5.327825546264648\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  644\n",
            "Train Loss:  3.5992424488067627\n",
            "Test Loss:  5.32790470123291\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  645\n",
            "Train Loss:  3.598637819290161\n",
            "Test Loss:  5.327981948852539\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  646\n",
            "Train Loss:  3.5980358123779297\n",
            "Test Loss:  5.328060150146484\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  647\n",
            "Train Loss:  3.597433090209961\n",
            "Test Loss:  5.328138828277588\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  648\n",
            "Train Loss:  3.596832752227783\n",
            "Test Loss:  5.328217029571533\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  649\n",
            "Train Loss:  3.596233606338501\n",
            "Test Loss:  5.328297138214111\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  650\n",
            "Train Loss:  3.595634937286377\n",
            "Test Loss:  5.328377723693848\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  651\n",
            "Train Loss:  3.595038890838623\n",
            "Test Loss:  5.328458786010742\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  652\n",
            "Train Loss:  3.5944418907165527\n",
            "Test Loss:  5.3285393714904785\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  653\n",
            "Train Loss:  3.5938475131988525\n",
            "Test Loss:  5.328620433807373\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  654\n",
            "Train Loss:  3.593254566192627\n",
            "Test Loss:  5.328702449798584\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  655\n",
            "Train Loss:  3.592663288116455\n",
            "Test Loss:  5.328783988952637\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  656\n",
            "Train Loss:  3.592074394226074\n",
            "Test Loss:  5.3288655281066895\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  657\n",
            "Train Loss:  3.591487169265747\n",
            "Test Loss:  5.328948497772217\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  658\n",
            "Train Loss:  3.5909013748168945\n",
            "Test Loss:  5.3290300369262695\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  659\n",
            "Train Loss:  3.590317964553833\n",
            "Test Loss:  5.329110145568848\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  660\n",
            "Train Loss:  3.589735746383667\n",
            "Test Loss:  5.329190254211426\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  661\n",
            "Train Loss:  3.589155912399292\n",
            "Test Loss:  5.3292694091796875\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  662\n",
            "Train Loss:  3.5885775089263916\n",
            "Test Loss:  5.329350471496582\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  663\n",
            "Train Loss:  3.5879998207092285\n",
            "Test Loss:  5.329429626464844\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  664\n",
            "Train Loss:  3.587423801422119\n",
            "Test Loss:  5.329509735107422\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  665\n",
            "Train Loss:  3.58685040473938\n",
            "Test Loss:  5.32958984375\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  666\n",
            "Train Loss:  3.586277961730957\n",
            "Test Loss:  5.329670429229736\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  667\n",
            "Train Loss:  3.585707187652588\n",
            "Test Loss:  5.329751014709473\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  668\n",
            "Train Loss:  3.5851387977600098\n",
            "Test Loss:  5.329831123352051\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  669\n",
            "Train Loss:  3.584571361541748\n",
            "Test Loss:  5.329912185668945\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  670\n",
            "Train Loss:  3.5840039253234863\n",
            "Test Loss:  5.32999324798584\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  671\n",
            "Train Loss:  3.583439350128174\n",
            "Test Loss:  5.330074310302734\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  672\n",
            "Train Loss:  3.582876205444336\n",
            "Test Loss:  5.3301544189453125\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  673\n",
            "Train Loss:  3.5823140144348145\n",
            "Test Loss:  5.330233573913574\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  674\n",
            "Train Loss:  3.5817534923553467\n",
            "Test Loss:  5.330312728881836\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  675\n",
            "Train Loss:  3.5811944007873535\n",
            "Test Loss:  5.330390930175781\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  676\n",
            "Train Loss:  3.580636501312256\n",
            "Test Loss:  5.330471038818359\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  677\n",
            "Train Loss:  3.580080270767212\n",
            "Test Loss:  5.330550193786621\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  678\n",
            "Train Loss:  3.579526424407959\n",
            "Test Loss:  5.330629348754883\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  679\n",
            "Train Loss:  3.578972816467285\n",
            "Test Loss:  5.330709934234619\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  680\n",
            "Train Loss:  3.5784196853637695\n",
            "Test Loss:  5.33078670501709\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  681\n",
            "Train Loss:  3.577868938446045\n",
            "Test Loss:  5.330863952636719\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  682\n",
            "Train Loss:  3.5773191452026367\n",
            "Test Loss:  5.330939769744873\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  683\n",
            "Train Loss:  3.5767717361450195\n",
            "Test Loss:  5.331016540527344\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  684\n",
            "Train Loss:  3.576226234436035\n",
            "Test Loss:  5.331094741821289\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  685\n",
            "Train Loss:  3.575681209564209\n",
            "Test Loss:  5.331171989440918\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  686\n",
            "Train Loss:  3.575137138366699\n",
            "Test Loss:  5.331249237060547\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  687\n",
            "Train Loss:  3.5745949745178223\n",
            "Test Loss:  5.331327438354492\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  688\n",
            "Train Loss:  3.5740537643432617\n",
            "Test Loss:  5.331406593322754\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  689\n",
            "Train Loss:  3.573514938354492\n",
            "Test Loss:  5.331484794616699\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  690\n",
            "Train Loss:  3.57297682762146\n",
            "Test Loss:  5.331562519073486\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  691\n",
            "Train Loss:  3.5724403858184814\n",
            "Test Loss:  5.331640243530273\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  692\n",
            "Train Loss:  3.5719056129455566\n",
            "Test Loss:  5.331719398498535\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  693\n",
            "Train Loss:  3.5713725090026855\n",
            "Test Loss:  5.331798553466797\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  694\n",
            "Train Loss:  3.5708389282226562\n",
            "Test Loss:  5.331878662109375\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  695\n",
            "Train Loss:  3.5703072547912598\n",
            "Test Loss:  5.331958770751953\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  696\n",
            "Train Loss:  3.5697779655456543\n",
            "Test Loss:  5.3320393562316895\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  697\n",
            "Train Loss:  3.5692501068115234\n",
            "Test Loss:  5.332119941711426\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  698\n",
            "Train Loss:  3.5687220096588135\n",
            "Test Loss:  5.33220100402832\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  699\n",
            "Train Loss:  3.5681958198547363\n",
            "Test Loss:  5.332280158996582\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  700\n",
            "Train Loss:  3.5676698684692383\n",
            "Test Loss:  5.332361221313477\n",
            "Recall : 0.1819047619047619\n",
            "\n",
            "0.1796489795918363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcnk0km+w4JSSCACLKEAAFZlKV116qttMXqVWotUq1UvV6X+rut9md/tbe9t61W5aK11dZardYdxWpFQFRMEJBVtiBZgJCE7Hu+vz/mJEyGCdkmmSWf5+NxHnPm+z1z5pMQ3vOd75w5R4wxKKWUCnwhvi5AKaWUd2igK6VUkNBAV0qpIKGBrpRSQUIDXSmlgkSor544OTnZZGVl+erplVIqIOXn5x83xqR46vNZoGdlZZGXl+erp1dKqYAkIoe66tMpF6WUChLdBrqIjBeRLS5LlYjc5rbNQhGpdNnmJwNXslJKKU+6nXIxxuwBcgBExAYUAS972HS9MeYy75anlFKqp3o7h/5VYL8xpss5HKVU4GtubqawsJCGhgZflzJkORwOMjIysNvtPX5MbwN9CfBcF31zRGQrUAzcaYzZ4b6BiCwDlgGMHDmyl0+tlBoshYWFxMTEkJWVhYj4upwhxxhDWVkZhYWFjB49useP6/GHoiISBlwO/N1D92ZglDFmKvAI8EoXRa4yxuQaY3JTUjwedaOU8gMNDQ0kJSVpmPuIiJCUlNTrd0i9OcrlYmCzMeaoe4cxpsoYU2OtrwbsIpLcq0qUUn5Fw9y3+vL7702gX00X0y0ikirWs4vILGu/Zb2upgd2H6niv97eTWVd80DsXimlAlaPAl1EooDzgX+4tC0XkeXW3cXAdmsO/WFgiRmgE60fKqvjsbX7KSirHYjdK6X8QFlZGTk5OeTk5JCamkp6enrH/aamptM+Ni8vjxUrVnT7HHPnzvVKrWvXruWyy/zjAL8efShqjKkFktzaVrqs/x74vXdL8yw9PgKAohP1TM2MH4ynVEoNsqSkJLZs2QLA/fffT3R0NHfeeWdHf0tLC6GhnuMrNzeX3Nzcbp9j48aN3inWjwTcN0UzEqxAr6j3cSVKqcG0dOlSli9fztlnn81dd93Fpk2bmDNnDtOmTWPu3Lns2bMH6Dxivv/++7nhhhtYuHAhY8aM4eGHH+7YX3R0dMf2CxcuZPHixUyYMIFrrrmG9gmG1atXM2HCBGbMmMGKFSu6HYmXl5dz5ZVXkp2dzezZs9m2bRsAH3zwQcc7jGnTplFdXU1JSQnz588nJyeHyZMns379+n7/jnx2Lpe+iouwEx0eStEJDXSlBsMDr+9gZ3GVV/c5cUQsP/3apF4/rrCwkI0bN2Kz2aiqqmL9+vWEhoby7rvv8uMf/5iXXnrplMfs3r2b999/n+rqasaPH88PfvCDU47t/uyzz9ixYwcjRoxg3rx5fPjhh+Tm5nLTTTexbt06Ro8ezdVXX91tfT/96U+ZNm0ar7zyCv/617+47rrr2LJlC7/+9a959NFHmTdvHjU1NTgcDlatWsWFF17IfffdR2trK3V1db3+fbgLuEAXEdLjIyjUEbpSQ843v/lNbDYbAJWVlVx//fXs3bsXEaG52fOBEpdeeinh4eGEh4czbNgwjh49SkZGRqdtZs2a1dGWk5NDQUEB0dHRjBkzpuM48KuvvppVq1adtr4NGzZ0vKh85StfoaysjKqqKubNm8cdd9zBNddcwze+8Q0yMjKYOXMmN9xwA83NzVx55ZXk5OT063cDARjoAOkJETpCV2qQ9GUkPVCioqI61v/zP/+TRYsW8fLLL1NQUMDChQs9PiY8PLxj3Waz0dLS0qdt+uOee+7h0ksvZfXq1cybN481a9Ywf/581q1bx5tvvsnSpUu54447uO666/r1PAE3hw7OD0aLKvr/9kQpFbgqKytJT08H4E9/+pPX9z9+/HgOHDhAQUEBAM8//3y3jzn33HN59tlnAefcfHJyMrGxsezfv58pU6Zw9913M3PmTHbv3s2hQ4cYPnw43//+97nxxhvZvHlzv2sOzEBPiKCqoYXqBj0WXamh6q677uLee+9l2rRpXh9RA0RERPDYY49x0UUXMWPGDGJiYoiLizvtY+6//37y8/PJzs7mnnvu4emnnwbgt7/9LZMnTyY7Oxu73c7FF1/M2rVrmTp1KtOmTeP555/nRz/6Ub9rlgE6XLxbubm5pq8XuHh9azG3PvcZb992LhNSY71cmVJq165dnHXWWb4uw+dqamqIjo7GGMMtt9zCuHHjuP322wft+T39O4hIvjHG43GZATtCBz10USk1sJ544glycnKYNGkSlZWV3HTTTb4u6bQC8kPRDJcvFyml1EC5/fbbB3VE3l8BOUJPjg4nzBaiI3SllHIRkIEeEiKMiHdQqCN0pZTqEJCBDtax6DpCV0qpDgEb6BnxkfptUaWUchGwgZ6ZGMHxmkbqm1p9XYpSysv6c/pccH6px/VsiitXruSZZ57xSm0LFy6kr4dcD7SAPMoFIDMxEoDCijrGDY/xcTVKKW/q7vS53Vm7di3R0dEd5zxfvnx5N48IDgE7Qh9pBfqX5XoKAKWGgvz8fBYsWMCMGTO48MILKSkpAeDhhx9m4sSJZGdns2TJEgoKCli5ciW/+c1vyMnJYf369dx///38+te/Bpwj7LvvvptZs2Zx5plndpy2tq6ujm9961tMnDiRr3/965x99tndjsSfe+45pkyZwuTJk7n77rsBaG1tZenSpUyePJkpU6bwm9/8xmOdAyHgR+ga6EoNsLfugSOfe3efqVPg4od6vLkxhltvvZVXX32VlJQUnn/+ee677z6eeuopHnroIQ4ePEh4eDgnTpwgPj6e5cuXdxrVv/fee53219LSwqZNm1i9ejUPPPAA7777Lo899hgJCQns3LmT7du3d3v2w+LiYu6++27y8/NJSEjgggsu4JVXXiEzM5OioiK2b98OwIkTJwBOqXMgdDtCF5HxIrLFZakSkdvcthEReVhE9onINhGZPiDVukiKCiMyzKaBrtQQ0NjYyPbt2zn//PPJycnhwQcfpLCwEIDs7GyuueYa/vKXv3R5FSN33/jGNwCYMWNGx8m3NmzY0DFybj/vyul8+umnLFy4kJSUFEJDQ7nmmmtYt24dY8aM4cCBA9x66628/fbbxMbG9rnO3up2r8aYPUAOgIjYgCLgZbfNLgbGWcvZwOPW7YAREUYmRnJYA12pgdWLkfRAMcYwadIkPvroo1P63nzzTdatW8frr7/Oz3/+cz7/vPt3E+2nyx2IU+UmJCSwdetW1qxZw8qVK3nhhRd46qmnPNbp7WDv7Rz6V4H9xphDbu1XAM8Yp4+BeBFJ80qFp5GZGMnhcj10UalgFx4eTmlpaUegNzc3s2PHDtra2jh8+DCLFi3il7/8JZWVldTU1BATE0N1dXWvnmPevHm88MILAOzcubPbF4ZZs2bxwQcfcPz4cVpbW3nuuedYsGABx48fp62tjauuuooHH3yQzZs3d1mnt/X25WEJ8JyH9nTgsMv9QqutxHUjEVkGLAMYOXJkL5/6VCMTI9mw9zjGGESk3/tTSvmnkJAQXnzxRVasWEFlZSUtLS3cdtttnHnmmVx77bVUVlZijGHFihXEx8fzta99jcWLF/Pqq6/yyCOP9Og5br75Zq6//nomTpzIhAkTmDRp0mlPl5uWlsZDDz3EokWLMMZw6aWXcsUVV7B161a++93v0tbWBsAvfvELWltbPdbpbT0+fa6IhAHFwCRjzFG3vjeAh4wxG6z77wF3G2O6/Ii4P6fPbff0xgJ++toOPr3vPFJiwrt/gFKqR4bi6XNbW1tpbm7G4XCwf/9+zjvvPPbs2UNYWJjPaurt6XN7M0K/GNjsHuaWIiDT5X6G1TagMhOdZ138srxOA10p1S91dXUsWrSI5uZmjDE89thjPg3zvuhNoF+N5+kWgNeAH4rI33B+GFppjCnpYluvaT8W/XB5HTNGJQz00ymlglhMTIzffgO0p3oU6CISBZwP3OTSthzAGLMSWA1cAuwD6oDver1SDzISTga6Usq79LMp3+rL1eR6FOjGmFogya1tpcu6AW7p9bP3k8NuY3hsuB6LrpSXORwOysrKSEpK0lD3AWMMZWVlOByOXj0uYL8p2m5kYqQGulJelpGRQWFhIaWlpb4uZchyOBxkZGT06jEBH+iZCZF8fKDM12UoFVTsdjujR4/2dRmqlwL25FztMhMjKalqoLFFT6OrlBraAj7QRyZGYgwUn2jwdSlKKeVTgR/oSXrWRaWUgmAIdD2NrlJKAUEQ6CnR4YSFhuix6EqpIS/gAz0kRMhMiNBAV0oNeQEf6KDHoiulFARToJfV9emrskopFSyCItBHJUVR3dhCeW2Tr0tRSimfCYpAH50cBcDB47U+rkQppXxHA10ppYJEUAR6RkIEoSFCQZkGulJq6AqKQA+1hZCZGKkjdKXUkBYUgQ7OaZeDx/XQRaXU0NWjQBeReBF5UUR2i8guEZnj1r9QRCpFZIu1/GRgyu1aVlIUh8pq9dBFpdSQ1dPzof8OeNsYs1hEwoBID9usN8Zc5r3Semd0ciR1Ta0cq25keGzvrvKhlFLBoNsRuojEAfOBPwAYY5qMMScGurDeGp0cDcCBUp1HV0oNTT2ZchkNlAJ/FJHPRORJ66LR7uaIyFYReUtEJnm3zO5lJTvfNOiRLkqpoaongR4KTAceN8ZMA2qBe9y22QyMMsZMBR4BXvG0IxFZJiJ5IpLn7WsVjoiLICw0hAI90kUpNUT1JNALgUJjzCfW/RdxBnwHY0yVMabGWl8N2EUk2X1HxphVxphcY0xuSkpKP0vvLCREGJUYyQENdKXUENVtoBtjjgCHRWS81fRVYKfrNiKSKiJirc+y9jvoV24enRylI3Sl1JDV06NcbgWetY5wOQB8V0SWAxhjVgKLgR+ISAtQDywxPjh+cHRyFGu/KKW1zWALkcF+eqWU8qkeBboxZguQ69a80qX/98DvvVhXn4xOjqKppY3iE/VkJno6slIppYJX0HxTFGDsMOehi/tKa3xciVJKDb6gCvQzUqxAP6qBrpQaeoIq0BOiwkiODmPfMQ10pdTQE1SBDnDGsGj2Hqv2dRlKKTXogjLQ9x2r0ZN0KaWGnMAM9LbWLrvGDYuhqqGF0urGQSxIKaV8L/ACfedr8NAoqCz02H2GdaTLXp1HV0oNMYEX6HEZ0FQNhzd57B7XfuiiBrpSaogJvEBPnQKhEV0GekpMODGOUP1gVCk15AReoNvskD4DDn/isVtEGDcsmr16LLpSaogJvEAHyJwFR7ZBc73H7nHDYtirR7oopYaYAA30s6GtBYo/89g9IS2G8tomjumRLkqpISQwAz1jpvO2i2mXs9JiAdhVUjVYFSmllM8FZqBHJUHSGV1+MHpWanug6wejSqmhIzADHZzTLoc/AQ/z5HGRdkbEOXSErpQaUgI40GdBXRmUH/DYfVZaLLuPaKArpYaOAA70s523X37ksfustFj2l9bS0Nz1aQKUUiqY9CjQRSReRF4Ukd0isktE5rj1i4g8LCL7RGSbiEzval9ekzIBIpPh4HqP3WelxdLaZvQbo0qpIaOnI/TfAW8bYyYAU4Fdbv0XA+OsZRnwuNcq7IoIjD4XCtZ7nEefkBYDwE6dR1dKDRHdBrqIxAHzgT8AGGOajDEn3Da7AnjGOH0MxItImterdZd1LlQVeZxHz0qKwmEP0Q9GlVJDRk9G6KOBUuCPIvKZiDwpIlFu26QDh13uF1ptnYjIMhHJE5G80tLSPhd9srIFztuD607psoUIE9Ni2V5U2f/nUUqpANCTQA8FpgOPG2OmAbXAPX15MmPMKmNMrjEmNyUlpS+76CxpLMSkeQx0gOyMeLYXVdHS2tb/51JKKT/Xk0AvBAqNMe1fy3wRZ8C7KgIyXe5nWG0DSwRGz+9yHj0nM5765lY9N7pSakjoNtCNMUeAwyIy3mr6KrDTbbPXgOuso11mA5XGmBLvltqFrHOhthRKd5/SlZ0RB8C2Qvcpf6WUCj49PcrlVuBZEdkG5AD/T0SWi8hyq381cADYBzwB3Oz1Srsy+lznrYdpl6ykKGIcoWwt1Hl0pVTwC+3JRsaYLUCuW/NKl34D3OLFunouIQsSRsO+d+Hsmzp1hYQI2RlxOkJXSg0JgftNUVdnXuQcoTfVndI1NSOe3SXV+o1RpVTQC5JAvxBaGjxOu2RnxNPSZvQLRkqpoBccgT5qHoRFwxdvn9I1bWQ8AJsPVQx2VUopNaiCI9BDw2DsIvhizSmHLw6PdZCZGMGnBeU+Kk4ppQZHcAQ6OOfRq4ud1xp1MzMrkbyCCr3GqFIqqAVXoIsNdrxyStesrETKapvYX1rrg8KUUmpwBE+gRyXDmAWw/aVTpl1mjk4E0GkXpVRQC55AB5h8FZw4BMWbOzWPSY4iOTqMTw9qoCulgldwBfqEy8AWBtv+3qlZRMgdlcgmHaErpYJYcAV6RDxMuBS2/Q2aGzp1zRydSGFFPUUn6n1UnFJKDazgCnSAGUuhvgJ2vdap+ZwzkgHYsNcL52FXSik/FHyBnjXfeW6XvKc6NZ85PJrhseGs23vcR4UppdTACr5ADwmBmTfClx9BYV5Hs4hw7rgUPtx3nNY2PR5dKRV8gi/QAWZcD4542PCbTs3njkvmRF2zXpZOKRWUgjPQw2Ng1jLY/QYc2d7R3D6Pvl7n0ZVSQSg4Ax1g9g+co/R37uv4olFSdDiT02NZ94XOoyulgk/wBnpkIiy4Gw6sdZ60y7Jo/DDyDpVTUdvku9qUUmoA9CjQRaRARD4XkS0ikuehf6GIVFr9W0TkJ94vtQ9m3gjJ4+HNO6DeedWiCyam0mbg3V1HfVycUkp5V29G6IuMMTnGGPdL0bVbb/XnGGN+5o3i+i00DL7+OFQfgdV3gjFMTo9lRJyDd3ZqoCulgkvwTrm0S58BC++Fz/8OGx9BRLhgUirrviilrqnF19UppZTX9DTQDfCOiOSLyLIutpkjIltF5C0RmeRpAxFZJiJ5IpJXWjqIR5qc++8w6evwz59A/tNcMHE4jS1t+uGoUiqo9DTQzzHGTAcuBm4Rkflu/ZuBUcaYqcAjwKknJQeMMauMMbnGmNyUlJQ+F91rISFw5eNwxnnw+grO/vIJEiNCeGt7yeDVoJRSA6xHgW6MKbJujwEvA7Pc+quMMTXW+mrALiLJXq61f+wRsORZyF6Cbd1DPB/1a3bu2EZto067KKWCQ7eBLiJRIhLTvg5cAGx32yZVRMRan2Xtt8z75fZTaDh8fSV87XeMadjBGyF3UPz3O6GyyNeVKaVUv/VkhD4c2CAiW4FNwJvGmLdFZLmILLe2WQxst7Z5GFhi/PUCniIwYynyw3z+ZTuHsfueht9lw9+Xwu7V0NLo6wqVUqpPxFe5m5uba/LyTjmkfVD9as1uXl/7EW/P3U3kjr9BwwkIj4Uzvgqj58PoBZA4xvkioJRSfkBE8rs6fDx0sIvxJ1+fls6j7w/jz7Hzuek/HoQDH8COl2H/e85bgNh0yDwbRuTAiGmQNhUccb4tXCmlPBjSgX7GsBhmZiXw3KYv+f65YwgZdx6MO8957pey/XDwAzi4znka3h3/OPnAmBGQNNa5JI6FhFEQNQyirSUsWkf1SvkbY6ylFUybc2lrX2+1+tzbXLfrzWNdHt/Wdmpb4lgYPtHrP+KQDnSA75w9ktuf38pHB8qYZ52NERFIPsO5zPyes622DEo+g+ItcHwvlB+AXa9DnYfPfu2RzhODhUc7wz08GsJinLf2CAh1OK99GhruXGztt1ZbiB1sodatHUJCnYvN7rmvo90OITZnDe5TaR33TTf3Ofk7kBBATr44ubdJiLXYnM8rIfpCNliMgbaWzktry6ltnZZWt1tr3bjdd+03radu73prWj0/rq3FCjP353fbtzGeQ7BTEHoK0TYPbe23xkObtfiLebfB+Q94fbdDPtAvnpzGA6/v5K+ffHky0D2JSnIex37GeZ3b6yugshBqjjmXWuu24QQ01kBTDTRWO18QmqqhuR5amqC10foA1j8/O+6zU0Le5vwewClttpPbdmo73fbihX24bA/WC5k5GQQd96220663Wf98Lo/var0jfFqgtdktHN3ud+pv7hyI7X2m1Sf/vKdoH2yIzVrv4rZTv2tb+7+Ldb/j3zKk89KprX27EA9t3nisdLG/9r9B13bXv6kQD202z4+NGpjv4Qz5QHfYbSyensGfNhZwpLKB1DhH73YQkeBc+sIY53/Q1sbOId/xn7rZGnU1u/wnd+1r9rBti8so2WVk7fE+nvvbgwvcwqmLkDKt1miq/S1m+6jPfWTV6nLr+tjutrfaWvuzD9fRoNXW/rN3vOtof4fRvk4X7R7eqSDO7T22W4/pFHTWu6zQcAiJcnknZjvZ53q/U7/Lu7YQW+d3ce6LzSVwbXYrUEI7P95j6LrXanPpb1+C/8whgWbIBzrA9XOzeOrDg/xx40HuvfiswXtiEecJxELDIHzwnlYpFZz0JRbITIzk4ilp/PXjL6luaPZ1OUop1Sca6Jab5o+hurGF5zZ96etSlFKqTzTQLdkZ8cwek8hTGwpoavGjT8OVUqqHNNBd3LRgLEeqGngxv9DXpSilVK9poLtYeGYKOZnxPPKvvTQ0+8lhYUop1UMa6C5EhP+4cDwllQ08+4nOpSulAosGupt5ZyQzZ0wSj72/T8+VrpQKKBroHtx54XjKapt4Yv0BX5eilFI9poHuwYxRCVwyJZWVH+yn6ES9r8tRSqke0UDvwo8vOQtj4Berd/m6FKWU6pEeBbqIFIjI5yKyRUROuSqFOD0sIvtEZJuITPd+qYMrIyGSmxaM5Y1tJXxywP+upqeUUu56M0JfZIzJ6eJKGRcD46xlGfC4N4rztR8sGEt6fAT/55XtNLboYYxKKf/mrSmXK4BnjNPHQLyIpHlp3z4TEWbjwSsns/dYDY++v9/X5Sil1Gn1NNAN8I6I5IvIMg/96cBhl/uFVlsnIrJMRPJEJK+0tLT31frAognD+Pq0dB57fx+7Sqp8XY5SSnWpp4F+jjFmOs6plVtEZH5fnswYs8oYk2uMyU1JGZgTvA+En1w2kbgIO//x4lY9z4tSym/1KNCNMUXW7THgZWCW2yZFQKbL/QyrLSgkRIXxi29MYXtRFb9+Z4+vy1FKKY+6DXQRiRKRmPZ14AJgu9tmrwHXWUe7zAYqjTElXq/Why6YlMq/zR7FqnUH+OCLwJguUkoNLT0ZoQ8HNojIVmAT8KYx5m0RWS4iy61tVgMHgH3AE8DNA1Ktj9136VmMHx7Dv7+wldLqRl+Xo5RSnYhxv9r7IMnNzTV5eacc0u739hyp5opHN5CdEc+zN56N3abfzVJKDR4Rye/i8HH9pmhvjU+N4ZdXZbPpYDn/942dvi5HKaU66EWi++CKnHR2FFexat0BJo2I5dszR/q6JKWU0hF6X9190QTOHZfM/3llOx/uO+7rcpRSSgO9r2whwu+/M50xydHc9Od8dhRX+rokpdQQp4HeD3ERdv50w0xiHKEs/eOnHC6v83VJSqkhTAO9n9LiInjmhlk0tbRxzZOf6PnTlVI+o4HuBeOGx/DMDbOoqGvi6lUfa6grpXxCA91LpmbG85fvna2hrpTyGQ10L3IN9W8+vpEvjlb7uiSl1BCige5lUzPj+duy2TS3GRY/vpGP9WpHSqlBooE+ACaNiOPlm+eSEhPOdX/YxGtbi31dklJqCNBAHyAZCZG89IO5TM2MY8Vzn/GLt3bR0qrnUldKDRwN9AEUHxnGszfO5trZI/nfDw6w9I+fUlHb5OuylFJBSgN9gIWFhvDglVP4r6uy2VRQziUPr9d5daXUgNBAHyTfmpnJS8vn4rDbuPqJj/nVmt006xSMUsqLNNAH0ZSMON649Ry+NSOTR9/fz+KVH1FwvNbXZSmlgoQG+iCLCg/ll4uzeeya6RwsreGi363jyfUHaG3zzYVGlFLBo8eBLiI2EflMRN7w0LdUREpFZIu13OjdMoPPJVPSeOf2Bcwbm8yDb+5i8cqN7NUvIiml+qE3I/QfAbtO0/+8MSbHWp7sZ11DQmqcgyevz+V3S3IoOF7LpQ9v4JH39urculKqT3oU6CKSAVwKaFB7mYhwRU46/7xjARdMGs5///MLLn14PZ/okTBKqV7q6Qj9t8BdwOmGjleJyDYReVFEMj1tICLLRCRPRPJKS0t7W2tQS44O5/ffmc6T1+VS29jKt1d9zB3Pb6G0utHXpSmlAkS3gS4ilwHHjDH5p9nsdSDLGJMN/BN42tNGxphVxphcY0xuSkpKnwoOdudNHM67dyzgh4vO4PVtxXzlv9fy9MYC/dBUKdUtMeb0QSEivwD+DWgBHEAs8A9jzLVdbG8Dyo0xcafbb25ursnLy+tT0UPF/tIafvrqDjbsO87k9FgeuHwyM0Yl+LospZQPiUi+MSbXU1+3I3RjzL3GmAxjTBawBPiXe5iLSJrL3cs5/YenqofGpkTz5+/N4vffmUZpdSNXPb6RH/51s17qTinlUWhfHygiPwPyjDGvAStE5HKco/hyYKl3ylMiwmXZI1g0fhj/u+4Aq9bt552dR/neOaO5eeFYYhx2X5eolPIT3U65DBSdcumbksp6fvX2Hv7xWRHJ0WHcfv6ZfDs3k1CbfkdMqaGgX1Muyr+kxUXwP9/O4bUfzmNMcjT3vbyd83+zjle3FNGmH5wqNaRpoAeo7Ix4nr9pNk9cl0t4aAg/+tsWLv7detbsOIKv3nUppXxLAz2AiQjnTxzO6hXn8sjV02hubeOmP+dzxaMf8u7OozpiV2qI0Tn0INLS2sY/Pivi4ff2UlhRz7hh0SxfMJbLc0Zg1zl2pYLC6ebQNdCDUHNrG29uK+HxtfvZc7Sa9PgIbjx3NN+emUlkWJ8PbFJK+QEN9CHKGMP7e47x+Nr9fFpQQawjlG/lZnLt7FFkJUf5ujylVB9ooCvyD5Xzp42HeOvzElqNYeGZKVw3N4sF41IICRFfl6eU6iENdNXhWFUDfwcEVB4AAA7/SURBVN30Jc9+8iWl1Y1kJkaweHomV81IJyMh0tflKaW6oYGuTtHU0saaHUf426df8uG+MkRg3thkvpmbwYWTUnHYbb4uUSnlgQa6Oq3D5XW8tLmQF/MLKayoJ8YRymXZI7giZwSzshJ1SkYpP6KBrnqkrc3w8cEy/p5XyNvbj1Df3Mrw2HAuyx7B16aOYGpGHCIa7kr5kga66rW6phbe23WM17YW88GeUppa2xiZGMnXpqZxWfYIJqTGaLgr5QMa6KpfKuubWbPjCK9vLWbj/jJa2wwjEyO5cNJwLpiUyvSRCdh0WkapQaGBrrzmeE0j7+w4ypodR9i4/zjNrYbk6DDOO2s4F05KZe4ZSYSH6geqSg0UDXQ1IKobmnl/Tynv7DjC2j2l1DS2EBVm45xxySwcP4yF41NIi4vwdZlKBZXTBbp+D1z1WYzDzuVTR3D51BE0trSycX8Z7+w4yto9x1iz4ygAE1JjWDA+hYVnDiM3K0HPKaPUANIRuvI6YwxfHK1h7Z5jrN1TyqcF5bS0GaLDQ5l3RhLzz0xh7thkspIi9YNVpXrJK1Mu1sWf84AiY8xlbn3hwDPADKAM+LYxpuB0+9NAHzqqG5r5cF8ZH3zhDPiSygYA0uIczBmbxNyxycwZm0R6vE7PKNUdb025/AjnxZ9jPfR9D6gwxpwhIkuAXwLf7nWlKijFOOxcNDmViyanYozh4PFaNu4v46P9ZazdU8o/NhcBMCopkrljk5g9JokZoxJIj4/QEbxSvdCjEbqIZABPAz8H7vAwQl8D3G+M+UhEQoEjQIo5zc51hK7A+WWmL45Vs3FfGRv3l/HJgTKqG1sASI11MCMrgRkjE8jNSuCstFidg1dDnjdG6L8F7gJiuuhPBw4DGGNaRKQSSAKOuxWyDFgGMHLkyB4+tQpmISHChNRYJqTGcsM5o2lpbWP3kWryD1V0LG9uKwEgwm5jamYcM0YlMDUjnuyMeFLjHD7+CZTyH90GuohcBhwzxuSLyML+PJkxZhWwCpwj9P7sSwWnUFsIk9PjmJwex/VzswAoqawn/1AFeQUVbP6ygpUfHKDVurzesJhwsjPiyc6Is5Z4EqPCfPgTKOU7PRmhzwMuF5FLAAcQKyJ/McZc67JNEZAJFFpTLnE4PxxVqt/S4iK4LDuCy7JHAFDf1MrOkiq2FZ5gW2El2wpP8N7uo7RP8GUkRDA1I54pVshPSosjLtLuw59AqcHRq8MWrRH6nR7m0G8Bphhjllsfin7DGPOt0+1L59CVN1U3NLO9yAr5ImfIHy6v7+jPSIhg0ohYJqbFMWlELJPSY0mNdeiHrirgDMgXi0TkZ0CeMeY14A/An0VkH1AOLOnrfpXqixiHnTljk5gzNqmjraK2ic+LKtlRXMWO4kp2Flfxzs6TI/nEqDBnyI+IZdIIZ9BnJUXpeWlUwNIvFqkhpbaxhV0lVSdDvqSKL47U0NTaBkBkmI0JqTEdAT9pRBxnpkbr+WmU39BzuSh1Gk0tbew7VsOOYudofmdxFTtLqqixDp8MDRHOGBbNmcNjGJ8a47wdHkNGQoRe/EMNOj2Xi1KnERYawkRr6uWbVltbm+HL8rqOkfyukiryD1Xw2tbijsdF2G2cOdwt6FNjGBYTrnPzyid0hK5UL1Q3NLP3WA1fHKlmz9FqvjhazZ4jNRyvaezYJsYRypjkKMakRDM6OYrRyVGMSXHeRobpGEr1j47QlfKSGIed6SMTmD4yoVN7WU0jXxytYc+RKvaX1nLgeA2fHCjj5c+KOm2XFufoCPispChGJUWRmRhBZkIkUeH631H1j/4FKeUFSdHhzIkO73SUDTiPmT94vNZaajhwvJYDpbW8tqWYqoaWzvuICiMzMdK5JEQw0lofmRhJWpyDUD3tgeqGBrpSAygizNYxP+/KGENFXTOHy+v4sryOwxV1HC6v43B5PVsPn+Ctz0toaTs5HWoLEdLiHKTHR5AeH0FavIMR8RGMiDu5HuvQL08NdRroSvmAiJAYFUZiVBhTM+NP6W9pbaOksoHDFXUUltd3hH7xiXo+OVjOkaqGjtMftIsOD2VEvIO0uAgr7J1BnxbvYERcBKlxDhx2PfwymGmgK+WHQm0hHdMvjD21v7XNcKy6geITDRSfqKeksr5jvbiynu1FlZTVNp3yuLgIO8Njwxke67CWcFJjHQyLdZBqtSVHh+n0ToDSQFcqADmnYCJIi4tgxqgEj9s0NLdSUmmF/Il6jlU3cqSygaNVzmXv0RpKaxpPGemHCCRHdw794VbgD4sNJzXOwbAYB/ERdj0O389ooCsVpBx2W8dhk11pbTOU1TRytKqRI1bQH6tqsNYbKayoI/9QORV1zac8NjRESI4OJzkmjJTocFJiwkm2bt3XY8JD9dj8QaCBrtQQZgsRhllTLlOI63K7huZWSqsbOeoS9sdrGjle3UhpTSPHqhvZWVLF8ZqmU0b8AOGhIV2GfUp0GCkx4SRFhZMYHabh3w8a6EqpbjnstpNz+qfR1maoqGvieE0TpdWNlNY0cLy6idKaRkqrnS8Ch8vr2HyogvK6Jjx9rzHMFkJClJ3EqHCSo8M6PjxOigojMSrcuR59si3WoVM/7TTQlVJeExIiJEWHkxQdzvjUri5w5tTS2kZ5bRPHrFF+WU0T5bWNlNU2UV7TRHltE2W1TRwqq6O8tqnj3DrubCFCQmR74IeRGH1yPSkqjPjIMOIj7SREhhEXYSchKoyoMFtQvgvQQFdK+USoLaRjuqcnGppbqahrsoL/ZOCX1zZSXut8V1Be28TO4irKahpP+eKWK7tNiItwBn18hN0l9E+ux0eEkRBpJ856MYiPtBNh9+8XAg10pVRAcNhtHUf29ERzaxsVdU1U1jVTUdfMibomTtQ1c6K+ybp/sq3oRD07iis5UddMfXNrl/sMCw0hPuLkaD82wk5sRCixDnvH/bgIO7GO0M73I+yD8q5AA10pFZTsthCGxTgPseyNhuZWKuubqWh/AbBuK6wXA+cLRBOV9c4Xgl0lzVTVN1PdxZRQO1uIdAT9tbNHceO5Y/rz43nUk4tEO4B1QLi1/YvGmJ+6bbMU+BXOa4sC/N4Y86R3S1VKqYHnsNtw2G0M7+FUULvWNkN1QzNV9S1U1jdT1dDsvK133p5sayElJnxAau/JCL0R+IoxpkZE7MAGEXnLGPOx23bPG2N+6P0SlVLK/9lCxJp/D/NZDd0GunGeML3Gumu3Ft+cRF0ppVSXenTCBhGxicgW4BjwT2PMJx42u0pEtonIiyKS2cV+lolInojklZaW9qNspZRS7noU6MaYVmNMDpABzBKRyW6bvA5kGWOygX8CT3exn1XGmFxjTG5KSkp/6lZKKeWmV6dUM8acAN4HLnJrLzPGtF+D60lghnfKU0op1VPdBrqIpIhIvLUeAZwP7HbbJs3l7uXALm8WqZRSqns9OcolDXhaRGw4XwBeMMa8ISI/A/KMMa8BK0TkcqAFKAeWDlTBSimlPBPj6ew4gyA3N9fk5eX55LmVUipQiUi+MSbXU59elkQppYKEz0boIlIKHOrjw5OB414sZ6BpvQMnkGqFwKo3kGqFwKq3P7WOMsZ4PEzQZ4HeHyKS19VbDn+k9Q6cQKoVAqveQKoVAqvegapVp1yUUipIaKArpVSQCNRAX+XrAnpJ6x04gVQrBFa9gVQrBFa9A1JrQM6hK6WUOlWgjtCVUkq50UBXSqkgEXCBLiIXicgeEdknIvf4uh4AEXlKRI6JyHaXtkQR+aeI7LVuE6x2EZGHrfq3icj0Qa41U0TeF5GdIrJDRH7kr/WKiENENonIVqvWB6z20SLyiVXT8yISZrWHW/f3Wf1Zg1WrW902EflMRN7w93pFpEBEPheRLSKSZ7X53d+C9fzx1um5d4vILhGZ48e1jrd+p+1LlYjcNuD1GmMCZgFswH5gDBAGbAUm+kFd84HpwHaXtv8C7rHW7wF+aa1fArwFCDAb+GSQa00DplvrMcAXwER/rNd6zmhr3Q58YtXwArDEal8J/MBavxlYaa0vwXkVLV/8PdwB/BV4w7rvt/UCBUCyW5vf/S1Yz/80cKO1HgbE+2utbnXbgCPAqIGu1yc/YD9+MXOANS737wXu9XVdVi1ZboG+B0iz1tOAPdb6/wJXe9rOR3W/ivMMmn5dLxAJbAbOxvkNu1D3vwlgDTDHWg+1tpNBrjMDeA/4CvCG9R/Un+v1FOh+97cAxAEH3X8//lirh9ovAD4cjHoDbcolHTjscr/QavNHw40xJdb6EWC4te43P4P1Fn8azpGvX9YrblfLwvkO7YQxpv0S6671dNRq9VcCSYNVq+W3wF1Am3U/Cf+u1wDviEi+iCyz2vzxb2E0UAr80ZrOelJEovy0VndLgOes9QGtN9ACPSAZ50uuXx0fKiLRwEvAbcaYKtc+f6rXuF0tC5jg45K6JCKXAceMMfm+rqUXzjHGTAcuBm4RkfmunX70txCKc1rzcWPMNKAW55RFBz+qtYP1ecnlwN/d+wai3kAL9CLA9XqlGVabPzoq1oU/rNtjVrvPfwYRseMM82eNMf+wmv22Xuh0taw5QLyItJ/L37Wejlqt/jigbBDLnAdcLiIFwN9wTrv8zo/rxRhTZN0eA17G+aLpj38LhUChOXk94xdxBrw/1urqYmCzMeaodX9A6w20QP8UGGcdNRCG863Maz6uqSuvAddb69fjnKtub7/O+lR7NlDp8hZswImIAH8Adhlj/sef6xXPV8vahTPYF3dRa/vPsBj4lzUKGhTGmHuNMRnGmCycf5v/MsZc46/1ikiUiMS0r+Oc692OH/4tGGOOAIdFZLzV9FVgpz/W6uZqTk63tNc1cPX64kOCfn7AcAnOIzP2A/f5uh6rpueAEqAZ50jiezjnQt8D9gLvAonWtgI8atX/OZA7yLWeg/Nt3jZgi7Vc4o/1AtnAZ1at24GfWO1jgE3APpxvZcOtdod1f5/VP8aHfxMLOXmUi1/Wa9W11Vp2tP9/8se/Bev5c4A86+/hFSDBX2u1aojC+Y4rzqVtQOvVr/4rpVSQCLQpF6WUUl3QQFdKqSChga6UUkFCA10ppYKEBrpSSgUJDXSllAoSGuhKKRUk/j/eGqtmTZ3pyQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c6cd7a171ab248d1afb33773894e045d",
            "b58d2c734d734c53a5e6b16334bd6b21",
            "e6395d244d404122ae329d486f2de8c0",
            "eec873c5b0574da2b6ce617cbaf43478",
            "297efd08d7464baf8f9cb4002c5d66c3",
            "6387627745de47ada80c8320c8c1d14b",
            "6212c0008df74b6aa55a6cb64f2fa006",
            "644b037e60d34861877ccf757ecc1a69"
          ]
        },
        "id": "eFmGGvNTNLih",
        "outputId": "74b7aa07-5c3a-491f-c7ee-c07aed0ac38c"
      },
      "source": [
        "run(path=\"resnet101.npy\",runs=1,epochs=700,k=1,temp=15,type=1,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6cd7a171ab248d1afb33773894e045d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.465764999389648\n",
            "Test Loss:  6.306556224822998\n",
            "Recall : 0.11238095238095239\n",
            "Epoch  2\n",
            "Train Loss:  7.393074035644531\n",
            "Test Loss:  6.2659196853637695\n",
            "Recall : 0.11142857142857143\n",
            "Epoch  3\n",
            "Train Loss:  7.321505546569824\n",
            "Test Loss:  6.226320266723633\n",
            "Recall : 0.11142857142857143\n",
            "Epoch  4\n",
            "Train Loss:  7.251111030578613\n",
            "Test Loss:  6.18784236907959\n",
            "Recall : 0.11333333333333333\n",
            "Epoch  5\n",
            "Train Loss:  7.1819562911987305\n",
            "Test Loss:  6.150552749633789\n",
            "Recall : 0.11428571428571428\n",
            "Epoch  6\n",
            "Train Loss:  7.114090442657471\n",
            "Test Loss:  6.1144561767578125\n",
            "Recall : 0.11714285714285715\n",
            "Epoch  7\n",
            "Train Loss:  7.047557830810547\n",
            "Test Loss:  6.079598426818848\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  8\n",
            "Train Loss:  6.982392311096191\n",
            "Test Loss:  6.045991897583008\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  9\n",
            "Train Loss:  6.918620586395264\n",
            "Test Loss:  6.013633728027344\n",
            "Recall : 0.11904761904761904\n",
            "Epoch  10\n",
            "Train Loss:  6.856264114379883\n",
            "Test Loss:  5.982527732849121\n",
            "Recall : 0.11904761904761904\n",
            "Epoch  11\n",
            "Train Loss:  6.79532527923584\n",
            "Test Loss:  5.952655792236328\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  12\n",
            "Train Loss:  6.735797882080078\n",
            "Test Loss:  5.924029350280762\n",
            "Recall : 0.12285714285714286\n",
            "Epoch  13\n",
            "Train Loss:  6.677665710449219\n",
            "Test Loss:  5.896609783172607\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  14\n",
            "Train Loss:  6.620904922485352\n",
            "Test Loss:  5.870370388031006\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  15\n",
            "Train Loss:  6.565481185913086\n",
            "Test Loss:  5.845295429229736\n",
            "Recall : 0.12571428571428572\n",
            "Epoch  16\n",
            "Train Loss:  6.511349201202393\n",
            "Test Loss:  5.821376800537109\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  17\n",
            "Train Loss:  6.458478927612305\n",
            "Test Loss:  5.798564910888672\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  18\n",
            "Train Loss:  6.406833648681641\n",
            "Test Loss:  5.776803016662598\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  19\n",
            "Train Loss:  6.356389999389648\n",
            "Test Loss:  5.756075382232666\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  20\n",
            "Train Loss:  6.307106018066406\n",
            "Test Loss:  5.736358165740967\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  21\n",
            "Train Loss:  6.2589216232299805\n",
            "Test Loss:  5.717580318450928\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  22\n",
            "Train Loss:  6.21180534362793\n",
            "Test Loss:  5.699704170227051\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  23\n",
            "Train Loss:  6.165719985961914\n",
            "Test Loss:  5.68272066116333\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  24\n",
            "Train Loss:  6.1205902099609375\n",
            "Test Loss:  5.666571617126465\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  25\n",
            "Train Loss:  6.076387405395508\n",
            "Test Loss:  5.651236057281494\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  26\n",
            "Train Loss:  6.033081531524658\n",
            "Test Loss:  5.636673927307129\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  27\n",
            "Train Loss:  5.990639686584473\n",
            "Test Loss:  5.622817039489746\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  28\n",
            "Train Loss:  5.949009895324707\n",
            "Test Loss:  5.609654903411865\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  29\n",
            "Train Loss:  5.908164024353027\n",
            "Test Loss:  5.5971550941467285\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  30\n",
            "Train Loss:  5.868080139160156\n",
            "Test Loss:  5.58527946472168\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  31\n",
            "Train Loss:  5.8287353515625\n",
            "Test Loss:  5.573951721191406\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  32\n",
            "Train Loss:  5.79008150100708\n",
            "Test Loss:  5.563164234161377\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  33\n",
            "Train Loss:  5.752086639404297\n",
            "Test Loss:  5.552878379821777\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  34\n",
            "Train Loss:  5.714734077453613\n",
            "Test Loss:  5.54304838180542\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  35\n",
            "Train Loss:  5.678007125854492\n",
            "Test Loss:  5.533675193786621\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  36\n",
            "Train Loss:  5.641903400421143\n",
            "Test Loss:  5.52472448348999\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  37\n",
            "Train Loss:  5.606385231018066\n",
            "Test Loss:  5.516180992126465\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  38\n",
            "Train Loss:  5.571422576904297\n",
            "Test Loss:  5.508023738861084\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  39\n",
            "Train Loss:  5.536998748779297\n",
            "Test Loss:  5.500221252441406\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  40\n",
            "Train Loss:  5.503104209899902\n",
            "Test Loss:  5.492800712585449\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  41\n",
            "Train Loss:  5.46972131729126\n",
            "Test Loss:  5.485719680786133\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  42\n",
            "Train Loss:  5.436834812164307\n",
            "Test Loss:  5.478945255279541\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  43\n",
            "Train Loss:  5.40444803237915\n",
            "Test Loss:  5.472489833831787\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  44\n",
            "Train Loss:  5.372556686401367\n",
            "Test Loss:  5.466332912445068\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  45\n",
            "Train Loss:  5.3411359786987305\n",
            "Test Loss:  5.460460662841797\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  46\n",
            "Train Loss:  5.310171127319336\n",
            "Test Loss:  5.454842567443848\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  47\n",
            "Train Loss:  5.279654026031494\n",
            "Test Loss:  5.449481964111328\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  48\n",
            "Train Loss:  5.249579429626465\n",
            "Test Loss:  5.444375991821289\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  49\n",
            "Train Loss:  5.219934463500977\n",
            "Test Loss:  5.43950080871582\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  50\n",
            "Train Loss:  5.190713882446289\n",
            "Test Loss:  5.434853553771973\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  51\n",
            "Train Loss:  5.161905288696289\n",
            "Test Loss:  5.43039083480835\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  52\n",
            "Train Loss:  5.133504390716553\n",
            "Test Loss:  5.426087379455566\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  53\n",
            "Train Loss:  5.105493545532227\n",
            "Test Loss:  5.421957015991211\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  54\n",
            "Train Loss:  5.077866554260254\n",
            "Test Loss:  5.417993545532227\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  55\n",
            "Train Loss:  5.050615310668945\n",
            "Test Loss:  5.414214611053467\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  56\n",
            "Train Loss:  5.023728370666504\n",
            "Test Loss:  5.410613536834717\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  57\n",
            "Train Loss:  4.997200012207031\n",
            "Test Loss:  5.407172203063965\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  58\n",
            "Train Loss:  4.971030235290527\n",
            "Test Loss:  5.403871536254883\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  59\n",
            "Train Loss:  4.945217609405518\n",
            "Test Loss:  5.400743007659912\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  60\n",
            "Train Loss:  4.919755935668945\n",
            "Test Loss:  5.39780330657959\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  61\n",
            "Train Loss:  4.894641876220703\n",
            "Test Loss:  5.39501953125\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  62\n",
            "Train Loss:  4.869863033294678\n",
            "Test Loss:  5.39238166809082\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  63\n",
            "Train Loss:  4.845410346984863\n",
            "Test Loss:  5.389887809753418\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  64\n",
            "Train Loss:  4.821292400360107\n",
            "Test Loss:  5.387516975402832\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  65\n",
            "Train Loss:  4.797495365142822\n",
            "Test Loss:  5.385251045227051\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  66\n",
            "Train Loss:  4.774009704589844\n",
            "Test Loss:  5.383078575134277\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  67\n",
            "Train Loss:  4.750845909118652\n",
            "Test Loss:  5.381016731262207\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  68\n",
            "Train Loss:  4.727992534637451\n",
            "Test Loss:  5.3790435791015625\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  69\n",
            "Train Loss:  4.705439567565918\n",
            "Test Loss:  5.3771514892578125\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  70\n",
            "Train Loss:  4.6831817626953125\n",
            "Test Loss:  5.3753557205200195\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  71\n",
            "Train Loss:  4.661214828491211\n",
            "Test Loss:  5.373664855957031\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  72\n",
            "Train Loss:  4.639533519744873\n",
            "Test Loss:  5.372079849243164\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  73\n",
            "Train Loss:  4.61814546585083\n",
            "Test Loss:  5.370582103729248\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  74\n",
            "Train Loss:  4.597037315368652\n",
            "Test Loss:  5.369154930114746\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  75\n",
            "Train Loss:  4.576207160949707\n",
            "Test Loss:  5.367792129516602\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  76\n",
            "Train Loss:  4.5556535720825195\n",
            "Test Loss:  5.366508483886719\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  77\n",
            "Train Loss:  4.535372734069824\n",
            "Test Loss:  5.365293979644775\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  78\n",
            "Train Loss:  4.515355110168457\n",
            "Test Loss:  5.364142417907715\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  79\n",
            "Train Loss:  4.495596885681152\n",
            "Test Loss:  5.363069534301758\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  80\n",
            "Train Loss:  4.476097106933594\n",
            "Test Loss:  5.362044334411621\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  81\n",
            "Train Loss:  4.4568562507629395\n",
            "Test Loss:  5.361085891723633\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  82\n",
            "Train Loss:  4.437858581542969\n",
            "Test Loss:  5.36019229888916\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  83\n",
            "Train Loss:  4.419099807739258\n",
            "Test Loss:  5.3593525886535645\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  84\n",
            "Train Loss:  4.400589942932129\n",
            "Test Loss:  5.358580589294434\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  85\n",
            "Train Loss:  4.382321357727051\n",
            "Test Loss:  5.3578643798828125\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  86\n",
            "Train Loss:  4.364297866821289\n",
            "Test Loss:  5.357203006744385\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  87\n",
            "Train Loss:  4.346512317657471\n",
            "Test Loss:  5.356592655181885\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  88\n",
            "Train Loss:  4.328958988189697\n",
            "Test Loss:  5.3560380935668945\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  89\n",
            "Train Loss:  4.311640739440918\n",
            "Test Loss:  5.355526924133301\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  90\n",
            "Train Loss:  4.294552803039551\n",
            "Test Loss:  5.3550591468811035\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  91\n",
            "Train Loss:  4.277698516845703\n",
            "Test Loss:  5.354635238647461\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  92\n",
            "Train Loss:  4.2610673904418945\n",
            "Test Loss:  5.354260444641113\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  93\n",
            "Train Loss:  4.244656562805176\n",
            "Test Loss:  5.353931427001953\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  94\n",
            "Train Loss:  4.228460788726807\n",
            "Test Loss:  5.353650093078613\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  95\n",
            "Train Loss:  4.212474822998047\n",
            "Test Loss:  5.353402137756348\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  96\n",
            "Train Loss:  4.1967010498046875\n",
            "Test Loss:  5.353188514709473\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  97\n",
            "Train Loss:  4.18112850189209\n",
            "Test Loss:  5.352989196777344\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  98\n",
            "Train Loss:  4.165760040283203\n",
            "Test Loss:  5.352814674377441\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  99\n",
            "Train Loss:  4.150602340698242\n",
            "Test Loss:  5.352669715881348\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  100\n",
            "Train Loss:  4.135644912719727\n",
            "Test Loss:  5.352572441101074\n",
            "Recall : 0.16\n",
            "Epoch  101\n",
            "Train Loss:  4.12088680267334\n",
            "Test Loss:  5.352515697479248\n",
            "Recall : 0.16\n",
            "Epoch  102\n",
            "Train Loss:  4.106313705444336\n",
            "Test Loss:  5.3524980545043945\n",
            "Recall : 0.16\n",
            "Epoch  103\n",
            "Train Loss:  4.091917514801025\n",
            "Test Loss:  5.352533340454102\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  104\n",
            "Train Loss:  4.0777082443237305\n",
            "Test Loss:  5.352594375610352\n",
            "Recall : 0.16\n",
            "Epoch  105\n",
            "Train Loss:  4.063676834106445\n",
            "Test Loss:  5.352680683135986\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  106\n",
            "Train Loss:  4.049821853637695\n",
            "Test Loss:  5.352808952331543\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  107\n",
            "Train Loss:  4.036144733428955\n",
            "Test Loss:  5.352963447570801\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  108\n",
            "Train Loss:  4.022638320922852\n",
            "Test Loss:  5.353142738342285\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  109\n",
            "Train Loss:  4.009307861328125\n",
            "Test Loss:  5.353360652923584\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  110\n",
            "Train Loss:  3.99615478515625\n",
            "Test Loss:  5.353597640991211\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  111\n",
            "Train Loss:  3.9831721782684326\n",
            "Test Loss:  5.353857040405273\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  112\n",
            "Train Loss:  3.970350980758667\n",
            "Test Loss:  5.354152202606201\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  113\n",
            "Train Loss:  3.9576926231384277\n",
            "Test Loss:  5.3544769287109375\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  114\n",
            "Train Loss:  3.945197343826294\n",
            "Test Loss:  5.354822158813477\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  115\n",
            "Train Loss:  3.932857036590576\n",
            "Test Loss:  5.355181694030762\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  116\n",
            "Train Loss:  3.9206695556640625\n",
            "Test Loss:  5.3555498123168945\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  117\n",
            "Train Loss:  3.9086241722106934\n",
            "Test Loss:  5.355948448181152\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  118\n",
            "Train Loss:  3.896728038787842\n",
            "Test Loss:  5.356380462646484\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  119\n",
            "Train Loss:  3.884989023208618\n",
            "Test Loss:  5.356832981109619\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  120\n",
            "Train Loss:  3.8733983039855957\n",
            "Test Loss:  5.357300758361816\n",
            "Recall : 0.16\n",
            "Epoch  121\n",
            "Train Loss:  3.861948013305664\n",
            "Test Loss:  5.3577961921691895\n",
            "Recall : 0.16\n",
            "Epoch  122\n",
            "Train Loss:  3.8506364822387695\n",
            "Test Loss:  5.358318328857422\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  123\n",
            "Train Loss:  3.8394618034362793\n",
            "Test Loss:  5.358875274658203\n",
            "Recall : 0.16\n",
            "Epoch  124\n",
            "Train Loss:  3.828420639038086\n",
            "Test Loss:  5.359468460083008\n",
            "Recall : 0.16\n",
            "Epoch  125\n",
            "Train Loss:  3.8175110816955566\n",
            "Test Loss:  5.360090732574463\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  126\n",
            "Train Loss:  3.806725025177002\n",
            "Test Loss:  5.360740661621094\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  127\n",
            "Train Loss:  3.7960705757141113\n",
            "Test Loss:  5.361408233642578\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  128\n",
            "Train Loss:  3.785547971725464\n",
            "Test Loss:  5.36207389831543\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  129\n",
            "Train Loss:  3.775150775909424\n",
            "Test Loss:  5.3627519607543945\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  130\n",
            "Train Loss:  3.7648746967315674\n",
            "Test Loss:  5.363434791564941\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  131\n",
            "Train Loss:  3.7547214031219482\n",
            "Test Loss:  5.364132881164551\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  132\n",
            "Train Loss:  3.7446835041046143\n",
            "Test Loss:  5.364844799041748\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  133\n",
            "Train Loss:  3.734760284423828\n",
            "Test Loss:  5.365579605102539\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  134\n",
            "Train Loss:  3.7249529361724854\n",
            "Test Loss:  5.366328239440918\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  135\n",
            "Train Loss:  3.7152605056762695\n",
            "Test Loss:  5.367095947265625\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  136\n",
            "Train Loss:  3.705679178237915\n",
            "Test Loss:  5.367882251739502\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  137\n",
            "Train Loss:  3.6962127685546875\n",
            "Test Loss:  5.368680953979492\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  138\n",
            "Train Loss:  3.686859607696533\n",
            "Test Loss:  5.369487285614014\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  139\n",
            "Train Loss:  3.677616596221924\n",
            "Test Loss:  5.37030029296875\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  140\n",
            "Train Loss:  3.6684837341308594\n",
            "Test Loss:  5.371119499206543\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  141\n",
            "Train Loss:  3.6594574451446533\n",
            "Test Loss:  5.371951103210449\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  142\n",
            "Train Loss:  3.6505346298217773\n",
            "Test Loss:  5.37279748916626\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  143\n",
            "Train Loss:  3.641704559326172\n",
            "Test Loss:  5.3736572265625\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  144\n",
            "Train Loss:  3.6329662799835205\n",
            "Test Loss:  5.374542236328125\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  145\n",
            "Train Loss:  3.624326467514038\n",
            "Test Loss:  5.375445365905762\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  146\n",
            "Train Loss:  3.6157901287078857\n",
            "Test Loss:  5.376359939575195\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  147\n",
            "Train Loss:  3.6073508262634277\n",
            "Test Loss:  5.37730598449707\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  148\n",
            "Train Loss:  3.5990066528320312\n",
            "Test Loss:  5.378274917602539\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  149\n",
            "Train Loss:  3.590759754180908\n",
            "Test Loss:  5.379260540008545\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  150\n",
            "Train Loss:  3.582608699798584\n",
            "Test Loss:  5.3802595138549805\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  151\n",
            "Train Loss:  3.5745527744293213\n",
            "Test Loss:  5.38125467300415\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  152\n",
            "Train Loss:  3.566588878631592\n",
            "Test Loss:  5.382235527038574\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  153\n",
            "Train Loss:  3.5587093830108643\n",
            "Test Loss:  5.383214950561523\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  154\n",
            "Train Loss:  3.550919532775879\n",
            "Test Loss:  5.384186744689941\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  155\n",
            "Train Loss:  3.5432167053222656\n",
            "Test Loss:  5.38514518737793\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  156\n",
            "Train Loss:  3.535600185394287\n",
            "Test Loss:  5.386102676391602\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  157\n",
            "Train Loss:  3.528069019317627\n",
            "Test Loss:  5.387059211730957\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  158\n",
            "Train Loss:  3.5206236839294434\n",
            "Test Loss:  5.3880228996276855\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  159\n",
            "Train Loss:  3.513256549835205\n",
            "Test Loss:  5.388994216918945\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  160\n",
            "Train Loss:  3.5059714317321777\n",
            "Test Loss:  5.389976501464844\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  161\n",
            "Train Loss:  3.498764753341675\n",
            "Test Loss:  5.390981674194336\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  162\n",
            "Train Loss:  3.491638660430908\n",
            "Test Loss:  5.392004013061523\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  163\n",
            "Train Loss:  3.484588384628296\n",
            "Test Loss:  5.393045425415039\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  164\n",
            "Train Loss:  3.477614402770996\n",
            "Test Loss:  5.394096374511719\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  165\n",
            "Train Loss:  3.4707164764404297\n",
            "Test Loss:  5.3951497077941895\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  166\n",
            "Train Loss:  3.4638891220092773\n",
            "Test Loss:  5.396197319030762\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  167\n",
            "Train Loss:  3.4571361541748047\n",
            "Test Loss:  5.397253036499023\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  168\n",
            "Train Loss:  3.4504566192626953\n",
            "Test Loss:  5.398320198059082\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  169\n",
            "Train Loss:  3.4438421726226807\n",
            "Test Loss:  5.3993940353393555\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  170\n",
            "Train Loss:  3.437291145324707\n",
            "Test Loss:  5.40047550201416\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  171\n",
            "Train Loss:  3.430807113647461\n",
            "Test Loss:  5.401560306549072\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  172\n",
            "Train Loss:  3.4243881702423096\n",
            "Test Loss:  5.402643203735352\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  173\n",
            "Train Loss:  3.418034076690674\n",
            "Test Loss:  5.40373420715332\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  174\n",
            "Train Loss:  3.4117441177368164\n",
            "Test Loss:  5.404835224151611\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  175\n",
            "Train Loss:  3.405517578125\n",
            "Test Loss:  5.405942440032959\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  176\n",
            "Train Loss:  3.399350643157959\n",
            "Test Loss:  5.40705680847168\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  177\n",
            "Train Loss:  3.3932456970214844\n",
            "Test Loss:  5.408180236816406\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  178\n",
            "Train Loss:  3.3872013092041016\n",
            "Test Loss:  5.4093170166015625\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  179\n",
            "Train Loss:  3.3812146186828613\n",
            "Test Loss:  5.410466194152832\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  180\n",
            "Train Loss:  3.375286102294922\n",
            "Test Loss:  5.411622047424316\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  181\n",
            "Train Loss:  3.3694167137145996\n",
            "Test Loss:  5.412786960601807\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  182\n",
            "Train Loss:  3.3636035919189453\n",
            "Test Loss:  5.413958549499512\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  183\n",
            "Train Loss:  3.357849597930908\n",
            "Test Loss:  5.415133476257324\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  184\n",
            "Train Loss:  3.352151870727539\n",
            "Test Loss:  5.41633415222168\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  185\n",
            "Train Loss:  3.3465042114257812\n",
            "Test Loss:  5.417535781860352\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  186\n",
            "Train Loss:  3.340902805328369\n",
            "Test Loss:  5.418740272521973\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  187\n",
            "Train Loss:  3.3353512287139893\n",
            "Test Loss:  5.419934272766113\n",
            "Recall : 0.16\n",
            "Epoch  188\n",
            "Train Loss:  3.3298468589782715\n",
            "Test Loss:  5.421132564544678\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  189\n",
            "Train Loss:  3.3243894577026367\n",
            "Test Loss:  5.422329902648926\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  190\n",
            "Train Loss:  3.3189802169799805\n",
            "Test Loss:  5.423524856567383\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  191\n",
            "Train Loss:  3.313614845275879\n",
            "Test Loss:  5.424711227416992\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  192\n",
            "Train Loss:  3.3082962036132812\n",
            "Test Loss:  5.425909519195557\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  193\n",
            "Train Loss:  3.303025484085083\n",
            "Test Loss:  5.42711067199707\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  194\n",
            "Train Loss:  3.297800064086914\n",
            "Test Loss:  5.42832088470459\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  195\n",
            "Train Loss:  3.292619228363037\n",
            "Test Loss:  5.429546356201172\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  196\n",
            "Train Loss:  3.287480592727661\n",
            "Test Loss:  5.430774688720703\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  197\n",
            "Train Loss:  3.2823879718780518\n",
            "Test Loss:  5.432004928588867\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  198\n",
            "Train Loss:  3.277339458465576\n",
            "Test Loss:  5.433233261108398\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  199\n",
            "Train Loss:  3.2723350524902344\n",
            "Test Loss:  5.434473037719727\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  200\n",
            "Train Loss:  3.2673733234405518\n",
            "Test Loss:  5.435717582702637\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  201\n",
            "Train Loss:  3.2624545097351074\n",
            "Test Loss:  5.436956882476807\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  202\n",
            "Train Loss:  3.257575750350952\n",
            "Test Loss:  5.438185691833496\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  203\n",
            "Train Loss:  3.252744674682617\n",
            "Test Loss:  5.439408302307129\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  204\n",
            "Train Loss:  3.247959613800049\n",
            "Test Loss:  5.440631866455078\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  205\n",
            "Train Loss:  3.243218183517456\n",
            "Test Loss:  5.441867828369141\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  206\n",
            "Train Loss:  3.2385168075561523\n",
            "Test Loss:  5.443112373352051\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  207\n",
            "Train Loss:  3.233853816986084\n",
            "Test Loss:  5.444361209869385\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  208\n",
            "Train Loss:  3.2292251586914062\n",
            "Test Loss:  5.445616245269775\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  209\n",
            "Train Loss:  3.22462797164917\n",
            "Test Loss:  5.446873664855957\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  210\n",
            "Train Loss:  3.220065116882324\n",
            "Test Loss:  5.4481353759765625\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  211\n",
            "Train Loss:  3.2155351638793945\n",
            "Test Loss:  5.4494171142578125\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  212\n",
            "Train Loss:  3.21103835105896\n",
            "Test Loss:  5.450710296630859\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  213\n",
            "Train Loss:  3.2065725326538086\n",
            "Test Loss:  5.452010631561279\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  214\n",
            "Train Loss:  3.2021336555480957\n",
            "Test Loss:  5.45332145690918\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  215\n",
            "Train Loss:  3.1977286338806152\n",
            "Test Loss:  5.454641819000244\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  216\n",
            "Train Loss:  3.1933541297912598\n",
            "Test Loss:  5.455975532531738\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  217\n",
            "Train Loss:  3.1890130043029785\n",
            "Test Loss:  5.457314491271973\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  218\n",
            "Train Loss:  3.1847057342529297\n",
            "Test Loss:  5.45865535736084\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  219\n",
            "Train Loss:  3.1804275512695312\n",
            "Test Loss:  5.459991455078125\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  220\n",
            "Train Loss:  3.176177501678467\n",
            "Test Loss:  5.46132755279541\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  221\n",
            "Train Loss:  3.1719536781311035\n",
            "Test Loss:  5.462668418884277\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  222\n",
            "Train Loss:  3.167759418487549\n",
            "Test Loss:  5.464014053344727\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  223\n",
            "Train Loss:  3.1636016368865967\n",
            "Test Loss:  5.465372085571289\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  224\n",
            "Train Loss:  3.1594772338867188\n",
            "Test Loss:  5.466731071472168\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  225\n",
            "Train Loss:  3.1553773880004883\n",
            "Test Loss:  5.468086242675781\n",
            "Recall : 0.16\n",
            "Epoch  226\n",
            "Train Loss:  3.1513071060180664\n",
            "Test Loss:  5.46944522857666\n",
            "Recall : 0.16\n",
            "Epoch  227\n",
            "Train Loss:  3.147268295288086\n",
            "Test Loss:  5.470803260803223\n",
            "Recall : 0.16\n",
            "Epoch  228\n",
            "Train Loss:  3.1432557106018066\n",
            "Test Loss:  5.472161293029785\n",
            "Recall : 0.16\n",
            "Epoch  229\n",
            "Train Loss:  3.1392664909362793\n",
            "Test Loss:  5.473535537719727\n",
            "Recall : 0.16\n",
            "Epoch  230\n",
            "Train Loss:  3.1353001594543457\n",
            "Test Loss:  5.474928855895996\n",
            "Recall : 0.16\n",
            "Epoch  231\n",
            "Train Loss:  3.131357192993164\n",
            "Test Loss:  5.476346969604492\n",
            "Recall : 0.16\n",
            "Epoch  232\n",
            "Train Loss:  3.1274356842041016\n",
            "Test Loss:  5.477787017822266\n",
            "Recall : 0.16\n",
            "Epoch  233\n",
            "Train Loss:  3.1235342025756836\n",
            "Test Loss:  5.4792327880859375\n",
            "Recall : 0.16\n",
            "Epoch  234\n",
            "Train Loss:  3.119657039642334\n",
            "Test Loss:  5.480674743652344\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  235\n",
            "Train Loss:  3.1158082485198975\n",
            "Test Loss:  5.482091903686523\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  236\n",
            "Train Loss:  3.11198353767395\n",
            "Test Loss:  5.4834885597229\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  237\n",
            "Train Loss:  3.1081814765930176\n",
            "Test Loss:  5.484877586364746\n",
            "Recall : 0.16\n",
            "Epoch  238\n",
            "Train Loss:  3.10440731048584\n",
            "Test Loss:  5.486264228820801\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  239\n",
            "Train Loss:  3.1006572246551514\n",
            "Test Loss:  5.487657070159912\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  240\n",
            "Train Loss:  3.0969302654266357\n",
            "Test Loss:  5.48906135559082\n",
            "Recall : 0.16\n",
            "Epoch  241\n",
            "Train Loss:  3.093226194381714\n",
            "Test Loss:  5.490479469299316\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  242\n",
            "Train Loss:  3.0895490646362305\n",
            "Test Loss:  5.4919047355651855\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  243\n",
            "Train Loss:  3.085890769958496\n",
            "Test Loss:  5.493325233459473\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  244\n",
            "Train Loss:  3.08225417137146\n",
            "Test Loss:  5.494755744934082\n",
            "Recall : 0.16\n",
            "Epoch  245\n",
            "Train Loss:  3.078641414642334\n",
            "Test Loss:  5.4962005615234375\n",
            "Recall : 0.16\n",
            "Epoch  246\n",
            "Train Loss:  3.07505464553833\n",
            "Test Loss:  5.49766206741333\n",
            "Recall : 0.16\n",
            "Epoch  247\n",
            "Train Loss:  3.0714921951293945\n",
            "Test Loss:  5.499144554138184\n",
            "Recall : 0.16\n",
            "Epoch  248\n",
            "Train Loss:  3.0679502487182617\n",
            "Test Loss:  5.50063419342041\n",
            "Recall : 0.16\n",
            "Epoch  249\n",
            "Train Loss:  3.0644283294677734\n",
            "Test Loss:  5.502132415771484\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  250\n",
            "Train Loss:  3.0609257221221924\n",
            "Test Loss:  5.503647804260254\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  251\n",
            "Train Loss:  3.0574398040771484\n",
            "Test Loss:  5.505152702331543\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  252\n",
            "Train Loss:  3.053968667984009\n",
            "Test Loss:  5.506643772125244\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  253\n",
            "Train Loss:  3.050515651702881\n",
            "Test Loss:  5.508130073547363\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  254\n",
            "Train Loss:  3.047078847885132\n",
            "Test Loss:  5.509593963623047\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  255\n",
            "Train Loss:  3.043661117553711\n",
            "Test Loss:  5.511052131652832\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  256\n",
            "Train Loss:  3.040262222290039\n",
            "Test Loss:  5.512528896331787\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  257\n",
            "Train Loss:  3.0368781089782715\n",
            "Test Loss:  5.514033794403076\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  258\n",
            "Train Loss:  3.033506393432617\n",
            "Test Loss:  5.51557731628418\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  259\n",
            "Train Loss:  3.030151605606079\n",
            "Test Loss:  5.517145156860352\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  260\n",
            "Train Loss:  3.0268168449401855\n",
            "Test Loss:  5.51873779296875\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  261\n",
            "Train Loss:  3.02349853515625\n",
            "Test Loss:  5.520347595214844\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  262\n",
            "Train Loss:  3.02020001411438\n",
            "Test Loss:  5.521975994110107\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  263\n",
            "Train Loss:  3.016920804977417\n",
            "Test Loss:  5.523625373840332\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  264\n",
            "Train Loss:  3.0136539936065674\n",
            "Test Loss:  5.525282859802246\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  265\n",
            "Train Loss:  3.010403633117676\n",
            "Test Loss:  5.5269455909729\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  266\n",
            "Train Loss:  3.007168769836426\n",
            "Test Loss:  5.528617858886719\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  267\n",
            "Train Loss:  3.003955364227295\n",
            "Test Loss:  5.530304908752441\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  268\n",
            "Train Loss:  3.000760555267334\n",
            "Test Loss:  5.531983375549316\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  269\n",
            "Train Loss:  2.99758243560791\n",
            "Test Loss:  5.533658981323242\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  270\n",
            "Train Loss:  2.9944186210632324\n",
            "Test Loss:  5.535326957702637\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  271\n",
            "Train Loss:  2.991269588470459\n",
            "Test Loss:  5.536985397338867\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  272\n",
            "Train Loss:  2.9881339073181152\n",
            "Test Loss:  5.538640022277832\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  273\n",
            "Train Loss:  2.9850151538848877\n",
            "Test Loss:  5.5402936935424805\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  274\n",
            "Train Loss:  2.9819154739379883\n",
            "Test Loss:  5.541942596435547\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  275\n",
            "Train Loss:  2.9788317680358887\n",
            "Test Loss:  5.543583869934082\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  276\n",
            "Train Loss:  2.9757580757141113\n",
            "Test Loss:  5.54522180557251\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  277\n",
            "Train Loss:  2.9726948738098145\n",
            "Test Loss:  5.546871185302734\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  278\n",
            "Train Loss:  2.969640016555786\n",
            "Test Loss:  5.548551082611084\n",
            "Recall : 0.16\n",
            "Epoch  279\n",
            "Train Loss:  2.966595411300659\n",
            "Test Loss:  5.550249099731445\n",
            "Recall : 0.16\n",
            "Epoch  280\n",
            "Train Loss:  2.963564395904541\n",
            "Test Loss:  5.551965236663818\n",
            "Recall : 0.16\n",
            "Epoch  281\n",
            "Train Loss:  2.9605441093444824\n",
            "Test Loss:  5.553690433502197\n",
            "Recall : 0.16\n",
            "Epoch  282\n",
            "Train Loss:  2.957534074783325\n",
            "Test Loss:  5.555415630340576\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  283\n",
            "Train Loss:  2.9545340538024902\n",
            "Test Loss:  5.557151794433594\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  284\n",
            "Train Loss:  2.9515511989593506\n",
            "Test Loss:  5.558902740478516\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  285\n",
            "Train Loss:  2.9485864639282227\n",
            "Test Loss:  5.560676574707031\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  286\n",
            "Train Loss:  2.9456372261047363\n",
            "Test Loss:  5.562471389770508\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  287\n",
            "Train Loss:  2.9427008628845215\n",
            "Test Loss:  5.564272880554199\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  288\n",
            "Train Loss:  2.9397788047790527\n",
            "Test Loss:  5.566081523895264\n",
            "Recall : 0.16\n",
            "Epoch  289\n",
            "Train Loss:  2.9368677139282227\n",
            "Test Loss:  5.5678863525390625\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  290\n",
            "Train Loss:  2.933966636657715\n",
            "Test Loss:  5.569666862487793\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  291\n",
            "Train Loss:  2.931076765060425\n",
            "Test Loss:  5.571457862854004\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  292\n",
            "Train Loss:  2.9281980991363525\n",
            "Test Loss:  5.5732879638671875\n",
            "Recall : 0.16\n",
            "Epoch  293\n",
            "Train Loss:  2.9253311157226562\n",
            "Test Loss:  5.575129985809326\n",
            "Recall : 0.16\n",
            "Epoch  294\n",
            "Train Loss:  2.9224796295166016\n",
            "Test Loss:  5.576968193054199\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  295\n",
            "Train Loss:  2.9196391105651855\n",
            "Test Loss:  5.578794956207275\n",
            "Recall : 0.16\n",
            "Epoch  296\n",
            "Train Loss:  2.916813850402832\n",
            "Test Loss:  5.58057975769043\n",
            "Recall : 0.16\n",
            "Epoch  297\n",
            "Train Loss:  2.9140007495880127\n",
            "Test Loss:  5.582331657409668\n",
            "Recall : 0.16\n",
            "Epoch  298\n",
            "Train Loss:  2.9111974239349365\n",
            "Test Loss:  5.584057331085205\n",
            "Recall : 0.16\n",
            "Epoch  299\n",
            "Train Loss:  2.908405065536499\n",
            "Test Loss:  5.585756301879883\n",
            "Recall : 0.16\n",
            "Epoch  300\n",
            "Train Loss:  2.9056243896484375\n",
            "Test Loss:  5.587440490722656\n",
            "Recall : 0.16\n",
            "Epoch  301\n",
            "Train Loss:  2.902853488922119\n",
            "Test Loss:  5.58913516998291\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  302\n",
            "Train Loss:  2.9000933170318604\n",
            "Test Loss:  5.590826034545898\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  303\n",
            "Train Loss:  2.8973493576049805\n",
            "Test Loss:  5.592517852783203\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  304\n",
            "Train Loss:  2.894620418548584\n",
            "Test Loss:  5.594217300415039\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  305\n",
            "Train Loss:  2.8919029235839844\n",
            "Test Loss:  5.595914840698242\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  306\n",
            "Train Loss:  2.8892011642456055\n",
            "Test Loss:  5.597606658935547\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  307\n",
            "Train Loss:  2.8865137100219727\n",
            "Test Loss:  5.599313735961914\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  308\n",
            "Train Loss:  2.883835792541504\n",
            "Test Loss:  5.601064682006836\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  309\n",
            "Train Loss:  2.8811662197113037\n",
            "Test Loss:  5.602853775024414\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  310\n",
            "Train Loss:  2.8785107135772705\n",
            "Test Loss:  5.6046552658081055\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  311\n",
            "Train Loss:  2.8758621215820312\n",
            "Test Loss:  5.606476783752441\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  312\n",
            "Train Loss:  2.8732216358184814\n",
            "Test Loss:  5.608295440673828\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  313\n",
            "Train Loss:  2.87058687210083\n",
            "Test Loss:  5.61008358001709\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  314\n",
            "Train Loss:  2.8679592609405518\n",
            "Test Loss:  5.611849784851074\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  315\n",
            "Train Loss:  2.8653404712677\n",
            "Test Loss:  5.61358642578125\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  316\n",
            "Train Loss:  2.8627302646636963\n",
            "Test Loss:  5.615307807922363\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  317\n",
            "Train Loss:  2.860124111175537\n",
            "Test Loss:  5.617038726806641\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  318\n",
            "Train Loss:  2.8575260639190674\n",
            "Test Loss:  5.618776321411133\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  319\n",
            "Train Loss:  2.854933738708496\n",
            "Test Loss:  5.620522499084473\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  320\n",
            "Train Loss:  2.8523433208465576\n",
            "Test Loss:  5.622276306152344\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  321\n",
            "Train Loss:  2.8497581481933594\n",
            "Test Loss:  5.624027252197266\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  322\n",
            "Train Loss:  2.8471741676330566\n",
            "Test Loss:  5.625765800476074\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  323\n",
            "Train Loss:  2.8445920944213867\n",
            "Test Loss:  5.627506256103516\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  324\n",
            "Train Loss:  2.8420181274414062\n",
            "Test Loss:  5.629258155822754\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  325\n",
            "Train Loss:  2.8394525051116943\n",
            "Test Loss:  5.631039619445801\n",
            "Recall : 0.16\n",
            "Epoch  326\n",
            "Train Loss:  2.836890697479248\n",
            "Test Loss:  5.6328606605529785\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  327\n",
            "Train Loss:  2.8343381881713867\n",
            "Test Loss:  5.634676456451416\n",
            "Recall : 0.16\n",
            "Epoch  328\n",
            "Train Loss:  2.831796169281006\n",
            "Test Loss:  5.6364898681640625\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  329\n",
            "Train Loss:  2.8292629718780518\n",
            "Test Loss:  5.6383137702941895\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  330\n",
            "Train Loss:  2.8267364501953125\n",
            "Test Loss:  5.640140533447266\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  331\n",
            "Train Loss:  2.8242149353027344\n",
            "Test Loss:  5.641976356506348\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  332\n",
            "Train Loss:  2.8217029571533203\n",
            "Test Loss:  5.643786430358887\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  333\n",
            "Train Loss:  2.8191988468170166\n",
            "Test Loss:  5.645613193511963\n",
            "Recall : 0.16\n",
            "Epoch  334\n",
            "Train Loss:  2.8167033195495605\n",
            "Test Loss:  5.647469997406006\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  335\n",
            "Train Loss:  2.814208984375\n",
            "Test Loss:  5.649350643157959\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  336\n",
            "Train Loss:  2.8117170333862305\n",
            "Test Loss:  5.651237487792969\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  337\n",
            "Train Loss:  2.8092331886291504\n",
            "Test Loss:  5.653131484985352\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  338\n",
            "Train Loss:  2.8067617416381836\n",
            "Test Loss:  5.655041694641113\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  339\n",
            "Train Loss:  2.8042991161346436\n",
            "Test Loss:  5.656962871551514\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  340\n",
            "Train Loss:  2.8018436431884766\n",
            "Test Loss:  5.658878803253174\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  341\n",
            "Train Loss:  2.79939603805542\n",
            "Test Loss:  5.660768508911133\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  342\n",
            "Train Loss:  2.7969579696655273\n",
            "Test Loss:  5.662628173828125\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  343\n",
            "Train Loss:  2.7945332527160645\n",
            "Test Loss:  5.664493560791016\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  344\n",
            "Train Loss:  2.7921226024627686\n",
            "Test Loss:  5.666385173797607\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  345\n",
            "Train Loss:  2.789717674255371\n",
            "Test Loss:  5.668322563171387\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  346\n",
            "Train Loss:  2.7873196601867676\n",
            "Test Loss:  5.67030143737793\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  347\n",
            "Train Loss:  2.784931182861328\n",
            "Test Loss:  5.672294616699219\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  348\n",
            "Train Loss:  2.7825489044189453\n",
            "Test Loss:  5.674267768859863\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  349\n",
            "Train Loss:  2.7801733016967773\n",
            "Test Loss:  5.67622184753418\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  350\n",
            "Train Loss:  2.777806282043457\n",
            "Test Loss:  5.678160190582275\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  351\n",
            "Train Loss:  2.7754454612731934\n",
            "Test Loss:  5.680083274841309\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  352\n",
            "Train Loss:  2.7730917930603027\n",
            "Test Loss:  5.682019233703613\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  353\n",
            "Train Loss:  2.770745038986206\n",
            "Test Loss:  5.683978080749512\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  354\n",
            "Train Loss:  2.7684085369110107\n",
            "Test Loss:  5.685967922210693\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  355\n",
            "Train Loss:  2.7660861015319824\n",
            "Test Loss:  5.687978744506836\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  356\n",
            "Train Loss:  2.7637741565704346\n",
            "Test Loss:  5.6899800300598145\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  357\n",
            "Train Loss:  2.7614665031433105\n",
            "Test Loss:  5.6919660568237305\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  358\n",
            "Train Loss:  2.759164810180664\n",
            "Test Loss:  5.693936824798584\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  359\n",
            "Train Loss:  2.756870746612549\n",
            "Test Loss:  5.695920944213867\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  360\n",
            "Train Loss:  2.7545828819274902\n",
            "Test Loss:  5.697911262512207\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  361\n",
            "Train Loss:  2.7523036003112793\n",
            "Test Loss:  5.699909687042236\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  362\n",
            "Train Loss:  2.750032901763916\n",
            "Test Loss:  5.701912879943848\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  363\n",
            "Train Loss:  2.7477681636810303\n",
            "Test Loss:  5.703900337219238\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  364\n",
            "Train Loss:  2.7455086708068848\n",
            "Test Loss:  5.70587158203125\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  365\n",
            "Train Loss:  2.743255615234375\n",
            "Test Loss:  5.707839012145996\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  366\n",
            "Train Loss:  2.741014003753662\n",
            "Test Loss:  5.709836959838867\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  367\n",
            "Train Loss:  2.738776683807373\n",
            "Test Loss:  5.711863994598389\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  368\n",
            "Train Loss:  2.7365474700927734\n",
            "Test Loss:  5.713888168334961\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  369\n",
            "Train Loss:  2.734321355819702\n",
            "Test Loss:  5.715878009796143\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  370\n",
            "Train Loss:  2.7320945262908936\n",
            "Test Loss:  5.7178544998168945\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  371\n",
            "Train Loss:  2.7298736572265625\n",
            "Test Loss:  5.719842433929443\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  372\n",
            "Train Loss:  2.727659225463867\n",
            "Test Loss:  5.721846103668213\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  373\n",
            "Train Loss:  2.7254557609558105\n",
            "Test Loss:  5.723834037780762\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  374\n",
            "Train Loss:  2.7232611179351807\n",
            "Test Loss:  5.725818634033203\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  375\n",
            "Train Loss:  2.7210769653320312\n",
            "Test Loss:  5.727832794189453\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  376\n",
            "Train Loss:  2.7189016342163086\n",
            "Test Loss:  5.729864120483398\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  377\n",
            "Train Loss:  2.716729164123535\n",
            "Test Loss:  5.731910228729248\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  378\n",
            "Train Loss:  2.7145605087280273\n",
            "Test Loss:  5.7339982986450195\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  379\n",
            "Train Loss:  2.712397336959839\n",
            "Test Loss:  5.73610258102417\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  380\n",
            "Train Loss:  2.7102391719818115\n",
            "Test Loss:  5.738194465637207\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  381\n",
            "Train Loss:  2.7080907821655273\n",
            "Test Loss:  5.740257263183594\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  382\n",
            "Train Loss:  2.705953598022461\n",
            "Test Loss:  5.742273330688477\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  383\n",
            "Train Loss:  2.703824043273926\n",
            "Test Loss:  5.744289875030518\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  384\n",
            "Train Loss:  2.701702117919922\n",
            "Test Loss:  5.74630880355835\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  385\n",
            "Train Loss:  2.699587106704712\n",
            "Test Loss:  5.7483134269714355\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  386\n",
            "Train Loss:  2.6974823474884033\n",
            "Test Loss:  5.750295162200928\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  387\n",
            "Train Loss:  2.6953859329223633\n",
            "Test Loss:  5.752269268035889\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  388\n",
            "Train Loss:  2.693295955657959\n",
            "Test Loss:  5.754262924194336\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  389\n",
            "Train Loss:  2.6912169456481934\n",
            "Test Loss:  5.756290435791016\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  390\n",
            "Train Loss:  2.6891415119171143\n",
            "Test Loss:  5.758340835571289\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  391\n",
            "Train Loss:  2.687070846557617\n",
            "Test Loss:  5.760350227355957\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  392\n",
            "Train Loss:  2.6850075721740723\n",
            "Test Loss:  5.762317180633545\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  393\n",
            "Train Loss:  2.6829514503479004\n",
            "Test Loss:  5.764279365539551\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  394\n",
            "Train Loss:  2.680905342102051\n",
            "Test Loss:  5.766286849975586\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  395\n",
            "Train Loss:  2.6788618564605713\n",
            "Test Loss:  5.76830530166626\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  396\n",
            "Train Loss:  2.676823377609253\n",
            "Test Loss:  5.770357608795166\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  397\n",
            "Train Loss:  2.674790382385254\n",
            "Test Loss:  5.772406578063965\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  398\n",
            "Train Loss:  2.6727607250213623\n",
            "Test Loss:  5.774461269378662\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  399\n",
            "Train Loss:  2.670734405517578\n",
            "Test Loss:  5.776468276977539\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  400\n",
            "Train Loss:  2.6687121391296387\n",
            "Test Loss:  5.778438568115234\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  401\n",
            "Train Loss:  2.666700601577759\n",
            "Test Loss:  5.780360221862793\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  402\n",
            "Train Loss:  2.6646933555603027\n",
            "Test Loss:  5.7822723388671875\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  403\n",
            "Train Loss:  2.6626927852630615\n",
            "Test Loss:  5.7841796875\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  404\n",
            "Train Loss:  2.6606979370117188\n",
            "Test Loss:  5.786065578460693\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  405\n",
            "Train Loss:  2.658705711364746\n",
            "Test Loss:  5.787934303283691\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  406\n",
            "Train Loss:  2.6567115783691406\n",
            "Test Loss:  5.7898406982421875\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  407\n",
            "Train Loss:  2.654719114303589\n",
            "Test Loss:  5.791773796081543\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  408\n",
            "Train Loss:  2.652730703353882\n",
            "Test Loss:  5.79373836517334\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  409\n",
            "Train Loss:  2.6507530212402344\n",
            "Test Loss:  5.79572868347168\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  410\n",
            "Train Loss:  2.6487839221954346\n",
            "Test Loss:  5.79774284362793\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  411\n",
            "Train Loss:  2.6468210220336914\n",
            "Test Loss:  5.799761772155762\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  412\n",
            "Train Loss:  2.6448678970336914\n",
            "Test Loss:  5.801814079284668\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  413\n",
            "Train Loss:  2.642918586730957\n",
            "Test Loss:  5.803871154785156\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  414\n",
            "Train Loss:  2.6409738063812256\n",
            "Test Loss:  5.805906295776367\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  415\n",
            "Train Loss:  2.639033794403076\n",
            "Test Loss:  5.8079376220703125\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  416\n",
            "Train Loss:  2.637096405029297\n",
            "Test Loss:  5.810029983520508\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  417\n",
            "Train Loss:  2.6351585388183594\n",
            "Test Loss:  5.812103271484375\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  418\n",
            "Train Loss:  2.633218765258789\n",
            "Test Loss:  5.814175128936768\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  419\n",
            "Train Loss:  2.6312828063964844\n",
            "Test Loss:  5.816272735595703\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  420\n",
            "Train Loss:  2.6293540000915527\n",
            "Test Loss:  5.8184003829956055\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  421\n",
            "Train Loss:  2.6274337768554688\n",
            "Test Loss:  5.820522308349609\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  422\n",
            "Train Loss:  2.6255249977111816\n",
            "Test Loss:  5.8226318359375\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  423\n",
            "Train Loss:  2.6236228942871094\n",
            "Test Loss:  5.82473087310791\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  424\n",
            "Train Loss:  2.621730089187622\n",
            "Test Loss:  5.82681131362915\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  425\n",
            "Train Loss:  2.6198463439941406\n",
            "Test Loss:  5.828849792480469\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  426\n",
            "Train Loss:  2.6179676055908203\n",
            "Test Loss:  5.830855369567871\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  427\n",
            "Train Loss:  2.6161012649536133\n",
            "Test Loss:  5.832846641540527\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  428\n",
            "Train Loss:  2.6142401695251465\n",
            "Test Loss:  5.834857940673828\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  429\n",
            "Train Loss:  2.61238169670105\n",
            "Test Loss:  5.836874485015869\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  430\n",
            "Train Loss:  2.610527515411377\n",
            "Test Loss:  5.838876724243164\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  431\n",
            "Train Loss:  2.6086792945861816\n",
            "Test Loss:  5.840871810913086\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  432\n",
            "Train Loss:  2.6068334579467773\n",
            "Test Loss:  5.842873573303223\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  433\n",
            "Train Loss:  2.604991912841797\n",
            "Test Loss:  5.844902992248535\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  434\n",
            "Train Loss:  2.6031556129455566\n",
            "Test Loss:  5.8469133377075195\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  435\n",
            "Train Loss:  2.6013236045837402\n",
            "Test Loss:  5.848893165588379\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  436\n",
            "Train Loss:  2.5995030403137207\n",
            "Test Loss:  5.850861549377441\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  437\n",
            "Train Loss:  2.597895622253418\n",
            "Test Loss:  5.852553367614746\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  438\n",
            "Train Loss:  2.5962705612182617\n",
            "Test Loss:  5.854245185852051\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  439\n",
            "Train Loss:  2.5948715209960938\n",
            "Test Loss:  5.856027126312256\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  440\n",
            "Train Loss:  2.5934598445892334\n",
            "Test Loss:  5.857962608337402\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  441\n",
            "Train Loss:  2.5919413566589355\n",
            "Test Loss:  5.859984397888184\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  442\n",
            "Train Loss:  2.590318202972412\n",
            "Test Loss:  5.862064361572266\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  443\n",
            "Train Loss:  2.5886106491088867\n",
            "Test Loss:  5.8641791343688965\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  444\n",
            "Train Loss:  2.5868375301361084\n",
            "Test Loss:  5.8662543296813965\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  445\n",
            "Train Loss:  2.58502197265625\n",
            "Test Loss:  5.868277549743652\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  446\n",
            "Train Loss:  2.5831894874572754\n",
            "Test Loss:  5.870274543762207\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  447\n",
            "Train Loss:  2.581359624862671\n",
            "Test Loss:  5.87227201461792\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  448\n",
            "Train Loss:  2.5795438289642334\n",
            "Test Loss:  5.874279975891113\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  449\n",
            "Train Loss:  2.5777456760406494\n",
            "Test Loss:  5.876282215118408\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  450\n",
            "Train Loss:  2.575957775115967\n",
            "Test Loss:  5.878239631652832\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  451\n",
            "Train Loss:  2.5741872787475586\n",
            "Test Loss:  5.880127906799316\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  452\n",
            "Train Loss:  2.5724353790283203\n",
            "Test Loss:  5.882024765014648\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  453\n",
            "Train Loss:  2.5706984996795654\n",
            "Test Loss:  5.883973121643066\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  454\n",
            "Train Loss:  2.5689735412597656\n",
            "Test Loss:  5.885951995849609\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  455\n",
            "Train Loss:  2.567255973815918\n",
            "Test Loss:  5.887937545776367\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  456\n",
            "Train Loss:  2.5655436515808105\n",
            "Test Loss:  5.889886856079102\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  457\n",
            "Train Loss:  2.563847541809082\n",
            "Test Loss:  5.8918023109436035\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  458\n",
            "Train Loss:  2.5621590614318848\n",
            "Test Loss:  5.893731117248535\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  459\n",
            "Train Loss:  2.5604751110076904\n",
            "Test Loss:  5.895700454711914\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  460\n",
            "Train Loss:  2.5588011741638184\n",
            "Test Loss:  5.897722244262695\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  461\n",
            "Train Loss:  2.5571630001068115\n",
            "Test Loss:  5.899816513061523\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  462\n",
            "Train Loss:  2.555570602416992\n",
            "Test Loss:  5.901698112487793\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  463\n",
            "Train Loss:  2.553956985473633\n",
            "Test Loss:  5.903611660003662\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  464\n",
            "Train Loss:  2.5522913932800293\n",
            "Test Loss:  5.90559196472168\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  465\n",
            "Train Loss:  2.550863265991211\n",
            "Test Loss:  5.907074928283691\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  466\n",
            "Train Loss:  2.549405097961426\n",
            "Test Loss:  5.908627510070801\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  467\n",
            "Train Loss:  2.548227071762085\n",
            "Test Loss:  5.910338401794434\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  468\n",
            "Train Loss:  2.546999216079712\n",
            "Test Loss:  5.912270545959473\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  469\n",
            "Train Loss:  2.5456039905548096\n",
            "Test Loss:  5.914313793182373\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  470\n",
            "Train Loss:  2.5440526008605957\n",
            "Test Loss:  5.916440486907959\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  471\n",
            "Train Loss:  2.5424065589904785\n",
            "Test Loss:  5.918633937835693\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  472\n",
            "Train Loss:  2.540719985961914\n",
            "Test Loss:  5.920784950256348\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  473\n",
            "Train Loss:  2.5390396118164062\n",
            "Test Loss:  5.922854423522949\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  474\n",
            "Train Loss:  2.5373663902282715\n",
            "Test Loss:  5.9248809814453125\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  475\n",
            "Train Loss:  2.5357108116149902\n",
            "Test Loss:  5.926878929138184\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  476\n",
            "Train Loss:  2.5340566635131836\n",
            "Test Loss:  5.928773403167725\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  477\n",
            "Train Loss:  2.532421112060547\n",
            "Test Loss:  5.930713176727295\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  478\n",
            "Train Loss:  2.530777931213379\n",
            "Test Loss:  5.932547092437744\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  479\n",
            "Train Loss:  2.529197931289673\n",
            "Test Loss:  5.934309005737305\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  480\n",
            "Train Loss:  2.5276641845703125\n",
            "Test Loss:  5.93613338470459\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  481\n",
            "Train Loss:  2.5261051654815674\n",
            "Test Loss:  5.937921524047852\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  482\n",
            "Train Loss:  2.5244698524475098\n",
            "Test Loss:  5.939783096313477\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  483\n",
            "Train Loss:  2.5229127407073975\n",
            "Test Loss:  5.941728591918945\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  484\n",
            "Train Loss:  2.521329879760742\n",
            "Test Loss:  5.94373893737793\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  485\n",
            "Train Loss:  2.5197534561157227\n",
            "Test Loss:  5.945720672607422\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  486\n",
            "Train Loss:  2.518214702606201\n",
            "Test Loss:  5.9477715492248535\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  487\n",
            "Train Loss:  2.5166993141174316\n",
            "Test Loss:  5.949726104736328\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  488\n",
            "Train Loss:  2.5152530670166016\n",
            "Test Loss:  5.951760292053223\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  489\n",
            "Train Loss:  2.5144033432006836\n",
            "Test Loss:  5.953080177307129\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  490\n",
            "Train Loss:  2.5127010345458984\n",
            "Test Loss:  5.954451560974121\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  491\n",
            "Train Loss:  2.511599063873291\n",
            "Test Loss:  5.956045150756836\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  492\n",
            "Train Loss:  2.5104050636291504\n",
            "Test Loss:  5.957767486572266\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  493\n",
            "Train Loss:  2.509188652038574\n",
            "Test Loss:  5.959627151489258\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  494\n",
            "Train Loss:  2.5078868865966797\n",
            "Test Loss:  5.961669445037842\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  495\n",
            "Train Loss:  2.50650691986084\n",
            "Test Loss:  5.963749885559082\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  496\n",
            "Train Loss:  2.5050530433654785\n",
            "Test Loss:  5.965702056884766\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  497\n",
            "Train Loss:  2.5035457611083984\n",
            "Test Loss:  5.967569828033447\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  498\n",
            "Train Loss:  2.5020432472229004\n",
            "Test Loss:  5.969448089599609\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  499\n",
            "Train Loss:  2.500467300415039\n",
            "Test Loss:  5.971304893493652\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  500\n",
            "Train Loss:  2.4988999366760254\n",
            "Test Loss:  5.973241806030273\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  501\n",
            "Train Loss:  2.4973483085632324\n",
            "Test Loss:  5.975247383117676\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  502\n",
            "Train Loss:  2.495830774307251\n",
            "Test Loss:  5.9770941734313965\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  503\n",
            "Train Loss:  2.4943389892578125\n",
            "Test Loss:  5.978979110717773\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  504\n",
            "Train Loss:  2.492898464202881\n",
            "Test Loss:  5.9808349609375\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  505\n",
            "Train Loss:  2.491429090499878\n",
            "Test Loss:  5.982612609863281\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  506\n",
            "Train Loss:  2.4900338649749756\n",
            "Test Loss:  5.98445987701416\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  507\n",
            "Train Loss:  2.488705635070801\n",
            "Test Loss:  5.98622989654541\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  508\n",
            "Train Loss:  2.487169027328491\n",
            "Test Loss:  5.987967491149902\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  509\n",
            "Train Loss:  2.485836982727051\n",
            "Test Loss:  5.989911079406738\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  510\n",
            "Train Loss:  2.484424114227295\n",
            "Test Loss:  5.991702079772949\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  511\n",
            "Train Loss:  2.4829654693603516\n",
            "Test Loss:  5.993397235870361\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  512\n",
            "Train Loss:  2.481597661972046\n",
            "Test Loss:  5.995207786560059\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  513\n",
            "Train Loss:  2.4802184104919434\n",
            "Test Loss:  5.997124671936035\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  514\n",
            "Train Loss:  2.478825092315674\n",
            "Test Loss:  5.998964309692383\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  515\n",
            "Train Loss:  2.4773597717285156\n",
            "Test Loss:  6.000825881958008\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  516\n",
            "Train Loss:  2.4759764671325684\n",
            "Test Loss:  6.002617835998535\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  517\n",
            "Train Loss:  2.4745612144470215\n",
            "Test Loss:  6.004504203796387\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  518\n",
            "Train Loss:  2.4731850624084473\n",
            "Test Loss:  6.00631046295166\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  519\n",
            "Train Loss:  2.471895217895508\n",
            "Test Loss:  6.007990837097168\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  520\n",
            "Train Loss:  2.4706332683563232\n",
            "Test Loss:  6.00962495803833\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  521\n",
            "Train Loss:  2.4692864418029785\n",
            "Test Loss:  6.01125431060791\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  522\n",
            "Train Loss:  2.468055009841919\n",
            "Test Loss:  6.012984275817871\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  523\n",
            "Train Loss:  2.466792106628418\n",
            "Test Loss:  6.014784812927246\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  524\n",
            "Train Loss:  2.4653890132904053\n",
            "Test Loss:  6.016560077667236\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  525\n",
            "Train Loss:  2.4641129970550537\n",
            "Test Loss:  6.018291473388672\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  526\n",
            "Train Loss:  2.462782859802246\n",
            "Test Loss:  6.020086288452148\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  527\n",
            "Train Loss:  2.4614510536193848\n",
            "Test Loss:  6.0218706130981445\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  528\n",
            "Train Loss:  2.460129976272583\n",
            "Test Loss:  6.023536682128906\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  529\n",
            "Train Loss:  2.4589338302612305\n",
            "Test Loss:  6.025302886962891\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  530\n",
            "Train Loss:  2.457761764526367\n",
            "Test Loss:  6.0268402099609375\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  531\n",
            "Train Loss:  2.4566214084625244\n",
            "Test Loss:  6.028598785400391\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  532\n",
            "Train Loss:  2.4554169178009033\n",
            "Test Loss:  6.030088424682617\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  533\n",
            "Train Loss:  2.45412015914917\n",
            "Test Loss:  6.031540393829346\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  534\n",
            "Train Loss:  2.452941417694092\n",
            "Test Loss:  6.03324031829834\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  535\n",
            "Train Loss:  2.4516377449035645\n",
            "Test Loss:  6.03497838973999\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  536\n",
            "Train Loss:  2.4503908157348633\n",
            "Test Loss:  6.03657341003418\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  537\n",
            "Train Loss:  2.449152946472168\n",
            "Test Loss:  6.038235187530518\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  538\n",
            "Train Loss:  2.4479801654815674\n",
            "Test Loss:  6.039577484130859\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  539\n",
            "Train Loss:  2.4467618465423584\n",
            "Test Loss:  6.041003704071045\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  540\n",
            "Train Loss:  2.4457874298095703\n",
            "Test Loss:  6.042515754699707\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  541\n",
            "Train Loss:  2.4446539878845215\n",
            "Test Loss:  6.043774604797363\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  542\n",
            "Train Loss:  2.4434847831726074\n",
            "Test Loss:  6.045239448547363\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  543\n",
            "Train Loss:  2.4424214363098145\n",
            "Test Loss:  6.0467095375061035\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  544\n",
            "Train Loss:  2.4411380290985107\n",
            "Test Loss:  6.048373222351074\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  545\n",
            "Train Loss:  2.4399545192718506\n",
            "Test Loss:  6.050050258636475\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  546\n",
            "Train Loss:  2.4387259483337402\n",
            "Test Loss:  6.051857948303223\n",
            "Recall : 0.14\n",
            "Epoch  547\n",
            "Train Loss:  2.437481164932251\n",
            "Test Loss:  6.0537261962890625\n",
            "Recall : 0.14\n",
            "Epoch  548\n",
            "Train Loss:  2.4363105297088623\n",
            "Test Loss:  6.055490016937256\n",
            "Recall : 0.14\n",
            "Epoch  549\n",
            "Train Loss:  2.4351067543029785\n",
            "Test Loss:  6.0573577880859375\n",
            "Recall : 0.14\n",
            "Epoch  550\n",
            "Train Loss:  2.4339663982391357\n",
            "Test Loss:  6.058830261230469\n",
            "Recall : 0.14\n",
            "Epoch  551\n",
            "Train Loss:  2.4328794479370117\n",
            "Test Loss:  6.060337066650391\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  552\n",
            "Train Loss:  2.4316864013671875\n",
            "Test Loss:  6.0619659423828125\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  553\n",
            "Train Loss:  2.430671215057373\n",
            "Test Loss:  6.063488006591797\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  554\n",
            "Train Loss:  2.429597854614258\n",
            "Test Loss:  6.065053939819336\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  555\n",
            "Train Loss:  2.4286956787109375\n",
            "Test Loss:  6.066439628601074\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  556\n",
            "Train Loss:  2.427694320678711\n",
            "Test Loss:  6.067700386047363\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  557\n",
            "Train Loss:  2.426699638366699\n",
            "Test Loss:  6.069019317626953\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  558\n",
            "Train Loss:  2.425482749938965\n",
            "Test Loss:  6.070379257202148\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  559\n",
            "Train Loss:  2.4243743419647217\n",
            "Test Loss:  6.071887016296387\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  560\n",
            "Train Loss:  2.4232654571533203\n",
            "Test Loss:  6.073520660400391\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  561\n",
            "Train Loss:  2.422175407409668\n",
            "Test Loss:  6.075453281402588\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  562\n",
            "Train Loss:  2.4210147857666016\n",
            "Test Loss:  6.0770673751831055\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  563\n",
            "Train Loss:  2.4199819564819336\n",
            "Test Loss:  6.07857608795166\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  564\n",
            "Train Loss:  2.418954849243164\n",
            "Test Loss:  6.080094814300537\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  565\n",
            "Train Loss:  2.4180126190185547\n",
            "Test Loss:  6.081327438354492\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  566\n",
            "Train Loss:  2.4168615341186523\n",
            "Test Loss:  6.082784175872803\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  567\n",
            "Train Loss:  2.415761709213257\n",
            "Test Loss:  6.0842695236206055\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  568\n",
            "Train Loss:  2.414677858352661\n",
            "Test Loss:  6.085692882537842\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  569\n",
            "Train Loss:  2.4136972427368164\n",
            "Test Loss:  6.087385177612305\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  570\n",
            "Train Loss:  2.412543296813965\n",
            "Test Loss:  6.088892936706543\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  571\n",
            "Train Loss:  2.4115118980407715\n",
            "Test Loss:  6.090404510498047\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  572\n",
            "Train Loss:  2.410508632659912\n",
            "Test Loss:  6.091708183288574\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  573\n",
            "Train Loss:  2.409512758255005\n",
            "Test Loss:  6.093177795410156\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  574\n",
            "Train Loss:  2.408336639404297\n",
            "Test Loss:  6.094862937927246\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  575\n",
            "Train Loss:  2.407240867614746\n",
            "Test Loss:  6.096580505371094\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  576\n",
            "Train Loss:  2.406158924102783\n",
            "Test Loss:  6.098214626312256\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  577\n",
            "Train Loss:  2.4051315784454346\n",
            "Test Loss:  6.099783897399902\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  578\n",
            "Train Loss:  2.4041643142700195\n",
            "Test Loss:  6.101353645324707\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  579\n",
            "Train Loss:  2.4031078815460205\n",
            "Test Loss:  6.1028242111206055\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  580\n",
            "Train Loss:  2.4022107124328613\n",
            "Test Loss:  6.104227066040039\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  581\n",
            "Train Loss:  2.401249408721924\n",
            "Test Loss:  6.105687141418457\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  582\n",
            "Train Loss:  2.4002537727355957\n",
            "Test Loss:  6.107093811035156\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  583\n",
            "Train Loss:  2.3993287086486816\n",
            "Test Loss:  6.1084065437316895\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  584\n",
            "Train Loss:  2.398392915725708\n",
            "Test Loss:  6.109617710113525\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  585\n",
            "Train Loss:  2.397427558898926\n",
            "Test Loss:  6.111057281494141\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  586\n",
            "Train Loss:  2.3964905738830566\n",
            "Test Loss:  6.112707614898682\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  587\n",
            "Train Loss:  2.395620822906494\n",
            "Test Loss:  6.114255905151367\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  588\n",
            "Train Loss:  2.3948373794555664\n",
            "Test Loss:  6.115994453430176\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  589\n",
            "Train Loss:  2.3940463066101074\n",
            "Test Loss:  6.117447376251221\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  590\n",
            "Train Loss:  2.3933818340301514\n",
            "Test Loss:  6.11862325668335\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  591\n",
            "Train Loss:  2.392427921295166\n",
            "Test Loss:  6.119977951049805\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  592\n",
            "Train Loss:  2.391278028488159\n",
            "Test Loss:  6.121466636657715\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  593\n",
            "Train Loss:  2.390354871749878\n",
            "Test Loss:  6.123235702514648\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  594\n",
            "Train Loss:  2.3892736434936523\n",
            "Test Loss:  6.124750137329102\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  595\n",
            "Train Loss:  2.3882532119750977\n",
            "Test Loss:  6.12631893157959\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  596\n",
            "Train Loss:  2.3872272968292236\n",
            "Test Loss:  6.127860069274902\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  597\n",
            "Train Loss:  2.3861231803894043\n",
            "Test Loss:  6.129492282867432\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  598\n",
            "Train Loss:  2.3851521015167236\n",
            "Test Loss:  6.130878448486328\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  599\n",
            "Train Loss:  2.384303569793701\n",
            "Test Loss:  6.131877899169922\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  600\n",
            "Train Loss:  2.3835253715515137\n",
            "Test Loss:  6.132744789123535\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  601\n",
            "Train Loss:  2.3824357986450195\n",
            "Test Loss:  6.1337690353393555\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  602\n",
            "Train Loss:  2.3815736770629883\n",
            "Test Loss:  6.135001182556152\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  603\n",
            "Train Loss:  2.380688190460205\n",
            "Test Loss:  6.136205673217773\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  604\n",
            "Train Loss:  2.3798060417175293\n",
            "Test Loss:  6.137800216674805\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  605\n",
            "Train Loss:  2.3788020610809326\n",
            "Test Loss:  6.139294624328613\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  606\n",
            "Train Loss:  2.3779239654541016\n",
            "Test Loss:  6.140642166137695\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  607\n",
            "Train Loss:  2.376925468444824\n",
            "Test Loss:  6.142195701599121\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  608\n",
            "Train Loss:  2.37595796585083\n",
            "Test Loss:  6.143736839294434\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  609\n",
            "Train Loss:  2.3750619888305664\n",
            "Test Loss:  6.145383834838867\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  610\n",
            "Train Loss:  2.374312400817871\n",
            "Test Loss:  6.1467084884643555\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  611\n",
            "Train Loss:  2.3733015060424805\n",
            "Test Loss:  6.148155212402344\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  612\n",
            "Train Loss:  2.3722143173217773\n",
            "Test Loss:  6.149453163146973\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  613\n",
            "Train Loss:  2.3715219497680664\n",
            "Test Loss:  6.15045166015625\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  614\n",
            "Train Loss:  2.3708419799804688\n",
            "Test Loss:  6.151475429534912\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  615\n",
            "Train Loss:  2.369943141937256\n",
            "Test Loss:  6.152620792388916\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  616\n",
            "Train Loss:  2.369086742401123\n",
            "Test Loss:  6.154073238372803\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  617\n",
            "Train Loss:  2.368180751800537\n",
            "Test Loss:  6.155420303344727\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  618\n",
            "Train Loss:  2.3673906326293945\n",
            "Test Loss:  6.156992435455322\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  619\n",
            "Train Loss:  2.3665056228637695\n",
            "Test Loss:  6.158663749694824\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  620\n",
            "Train Loss:  2.3654966354370117\n",
            "Test Loss:  6.1601481437683105\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  621\n",
            "Train Loss:  2.364635467529297\n",
            "Test Loss:  6.161657333374023\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  622\n",
            "Train Loss:  2.3636703491210938\n",
            "Test Loss:  6.163066864013672\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  623\n",
            "Train Loss:  2.362712860107422\n",
            "Test Loss:  6.164422035217285\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  624\n",
            "Train Loss:  2.3617734909057617\n",
            "Test Loss:  6.16586971282959\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  625\n",
            "Train Loss:  2.3610825538635254\n",
            "Test Loss:  6.16734504699707\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  626\n",
            "Train Loss:  2.3611481189727783\n",
            "Test Loss:  6.168583393096924\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  627\n",
            "Train Loss:  2.3601205348968506\n",
            "Test Loss:  6.1697564125061035\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  628\n",
            "Train Loss:  2.3595173358917236\n",
            "Test Loss:  6.170718669891357\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  629\n",
            "Train Loss:  2.3585658073425293\n",
            "Test Loss:  6.171706199645996\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  630\n",
            "Train Loss:  2.3579163551330566\n",
            "Test Loss:  6.172844409942627\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  631\n",
            "Train Loss:  2.3573014736175537\n",
            "Test Loss:  6.1740875244140625\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  632\n",
            "Train Loss:  2.3565924167633057\n",
            "Test Loss:  6.175299644470215\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  633\n",
            "Train Loss:  2.3558602333068848\n",
            "Test Loss:  6.176403522491455\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  634\n",
            "Train Loss:  2.3551831245422363\n",
            "Test Loss:  6.177605152130127\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  635\n",
            "Train Loss:  2.354405641555786\n",
            "Test Loss:  6.178790092468262\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  636\n",
            "Train Loss:  2.3535945415496826\n",
            "Test Loss:  6.180214881896973\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  637\n",
            "Train Loss:  2.352787971496582\n",
            "Test Loss:  6.181501865386963\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  638\n",
            "Train Loss:  2.3519539833068848\n",
            "Test Loss:  6.183048248291016\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  639\n",
            "Train Loss:  2.351210594177246\n",
            "Test Loss:  6.184345245361328\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  640\n",
            "Train Loss:  2.350770950317383\n",
            "Test Loss:  6.185577869415283\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  641\n",
            "Train Loss:  2.3501944541931152\n",
            "Test Loss:  6.18647575378418\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  642\n",
            "Train Loss:  2.349432945251465\n",
            "Test Loss:  6.187427520751953\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  643\n",
            "Train Loss:  2.3487462997436523\n",
            "Test Loss:  6.188551902770996\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  644\n",
            "Train Loss:  2.3478329181671143\n",
            "Test Loss:  6.189718246459961\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  645\n",
            "Train Loss:  2.347095251083374\n",
            "Test Loss:  6.190981864929199\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  646\n",
            "Train Loss:  2.3462109565734863\n",
            "Test Loss:  6.192215919494629\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  647\n",
            "Train Loss:  2.345376968383789\n",
            "Test Loss:  6.193588733673096\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  648\n",
            "Train Loss:  2.344731330871582\n",
            "Test Loss:  6.195132255554199\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  649\n",
            "Train Loss:  2.3446645736694336\n",
            "Test Loss:  6.196132659912109\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  650\n",
            "Train Loss:  2.3432960510253906\n",
            "Test Loss:  6.1974687576293945\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  651\n",
            "Train Loss:  2.3425683975219727\n",
            "Test Loss:  6.198548316955566\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  652\n",
            "Train Loss:  2.3415772914886475\n",
            "Test Loss:  6.199728488922119\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  653\n",
            "Train Loss:  2.3407785892486572\n",
            "Test Loss:  6.200785160064697\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  654\n",
            "Train Loss:  2.3402047157287598\n",
            "Test Loss:  6.202048301696777\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  655\n",
            "Train Loss:  2.339505195617676\n",
            "Test Loss:  6.203061580657959\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  656\n",
            "Train Loss:  2.338625431060791\n",
            "Test Loss:  6.2041754722595215\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  657\n",
            "Train Loss:  2.337759017944336\n",
            "Test Loss:  6.205278396606445\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  658\n",
            "Train Loss:  2.3370919227600098\n",
            "Test Loss:  6.206349849700928\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  659\n",
            "Train Loss:  2.3362789154052734\n",
            "Test Loss:  6.207457542419434\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  660\n",
            "Train Loss:  2.3357295989990234\n",
            "Test Loss:  6.208285808563232\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  661\n",
            "Train Loss:  2.335089921951294\n",
            "Test Loss:  6.20944881439209\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  662\n",
            "Train Loss:  2.334427833557129\n",
            "Test Loss:  6.21068000793457\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  663\n",
            "Train Loss:  2.3336637020111084\n",
            "Test Loss:  6.211638927459717\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  664\n",
            "Train Loss:  2.332908868789673\n",
            "Test Loss:  6.212824821472168\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  665\n",
            "Train Loss:  2.3322582244873047\n",
            "Test Loss:  6.214282512664795\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  666\n",
            "Train Loss:  2.3315606117248535\n",
            "Test Loss:  6.215273857116699\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  667\n",
            "Train Loss:  2.330907106399536\n",
            "Test Loss:  6.216475486755371\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  668\n",
            "Train Loss:  2.3304226398468018\n",
            "Test Loss:  6.217604637145996\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  669\n",
            "Train Loss:  2.3300681114196777\n",
            "Test Loss:  6.218879699707031\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  670\n",
            "Train Loss:  2.3293440341949463\n",
            "Test Loss:  6.2199296951293945\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  671\n",
            "Train Loss:  2.328221559524536\n",
            "Test Loss:  6.220948219299316\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  672\n",
            "Train Loss:  2.3276023864746094\n",
            "Test Loss:  6.222030162811279\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  673\n",
            "Train Loss:  2.3268442153930664\n",
            "Test Loss:  6.2229108810424805\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  674\n",
            "Train Loss:  2.3260440826416016\n",
            "Test Loss:  6.2238264083862305\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  675\n",
            "Train Loss:  2.325639247894287\n",
            "Test Loss:  6.224681854248047\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  676\n",
            "Train Loss:  2.3248534202575684\n",
            "Test Loss:  6.225718021392822\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  677\n",
            "Train Loss:  2.3241817951202393\n",
            "Test Loss:  6.226535797119141\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  678\n",
            "Train Loss:  2.323491096496582\n",
            "Test Loss:  6.22776985168457\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  679\n",
            "Train Loss:  2.3229269981384277\n",
            "Test Loss:  6.228475570678711\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  680\n",
            "Train Loss:  2.3223958015441895\n",
            "Test Loss:  6.229409217834473\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  681\n",
            "Train Loss:  2.3216328620910645\n",
            "Test Loss:  6.2306928634643555\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  682\n",
            "Train Loss:  2.3209519386291504\n",
            "Test Loss:  6.231402397155762\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  683\n",
            "Train Loss:  2.320234775543213\n",
            "Test Loss:  6.232217788696289\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  684\n",
            "Train Loss:  2.3196089267730713\n",
            "Test Loss:  6.2335405349731445\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  685\n",
            "Train Loss:  2.318902015686035\n",
            "Test Loss:  6.234775543212891\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  686\n",
            "Train Loss:  2.3181586265563965\n",
            "Test Loss:  6.2356767654418945\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  687\n",
            "Train Loss:  2.3176774978637695\n",
            "Test Loss:  6.236706733703613\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  688\n",
            "Train Loss:  2.3170180320739746\n",
            "Test Loss:  6.237788677215576\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  689\n",
            "Train Loss:  2.316436290740967\n",
            "Test Loss:  6.238517761230469\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  690\n",
            "Train Loss:  2.3157694339752197\n",
            "Test Loss:  6.239581108093262\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  691\n",
            "Train Loss:  2.315608501434326\n",
            "Test Loss:  6.240407466888428\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  692\n",
            "Train Loss:  2.315865993499756\n",
            "Test Loss:  6.241115093231201\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  693\n",
            "Train Loss:  2.3145265579223633\n",
            "Test Loss:  6.2420759201049805\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  694\n",
            "Train Loss:  2.313749074935913\n",
            "Test Loss:  6.243188858032227\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  695\n",
            "Train Loss:  2.313412666320801\n",
            "Test Loss:  6.24429988861084\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  696\n",
            "Train Loss:  2.3125901222229004\n",
            "Test Loss:  6.24537467956543\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  697\n",
            "Train Loss:  2.3120317459106445\n",
            "Test Loss:  6.246284484863281\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  698\n",
            "Train Loss:  2.3114161491394043\n",
            "Test Loss:  6.247460842132568\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  699\n",
            "Train Loss:  2.310929298400879\n",
            "Test Loss:  6.248711585998535\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  700\n",
            "Train Loss:  2.31016206741333\n",
            "Test Loss:  6.24984073638916\n",
            "Recall : 0.13428571428571429\n",
            "\n",
            "0.14905714285714217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8deZTGYmyySZTBYSkhACCRAgBIgIoiwqbqi1bpXSr1td61dsbX9q668t3W2/tnb51lJtrfZna6Wudd9ZVTBBQHYIJBAg+75PkvP74042CBBIJnMn+Twfj3ncO/femfkkjm9Ozj33XKW1RgghhHlZ/F2AEEKIk5OgFkIIk5OgFkIIk5OgFkIIk5OgFkIIk7P64k1jYmJ0amqqL95aCCGGpby8vHKtdWxf+3wS1KmpqeTm5vrirYUQYlhSShWeaJ90fQghhMlJUAshhMlJUAshhMn5pI9aCGFOHo+HoqIimpub/V3KiOVwOEhKSiI4OLjfr5GgFmIEKSoqwul0kpqailLK3+WMOFprKioqKCoqYuzYsf1+nXR9CDGCNDc343a7JaT9RCmF2+0+7b9oJKiFGGEkpP3rTH7/pgnqtvYOHl+1jzV7yvxdihBCmIppgjrIonhizX7e3l7s71KEED5SUVFBdnY22dnZjBo1itGjR3c9b21tPelrc3NzWbZs2Sk/45xzzhmUWletWsXll18+KO81UKY5maiUIj0unH0l9f4uRQjhI263m82bNwOwfPlywsPD+c53vtO1v62tDau171jKyckhJyfnlJ/x8ccfD06xJmKaFjXA+Lhw9pbW+bsMIcQQuvnmm7nrrrs4++yzeeCBB9i4cSNz5sxh+vTpnHPOOezevRvo3cJdvnw5t956KwsWLCAtLY3f//73Xe8XHh7edfyCBQu49tprmThxIkuXLqXzjlZvvvkmEydOZObMmSxbtuyULefKykquuuoqsrKymD17Nlu3bgVg9erVXX8RTJ8+nbq6Oo4ePcq8efPIzs5mypQprF27dsC/I9O0qAHGxzmpajxERX0L7nC7v8sRYlj70Wvb2XGkdlDfMzMxgh9eMfm0X1dUVMTHH39MUFAQtbW1rF27FqvVyvvvv8/3vvc9XnzxxeNes2vXLj766CPq6uqYMGECd99993Fjkz///HO2b99OYmIic+fOZf369eTk5HDnnXeyZs0axo4dy5IlS05Z3w9/+EOmT5/OK6+8wocffsiNN97I5s2befTRR/njH//I3Llzqa+vx+Fw8MQTT3DxxRfz8MMP097eTmNj42n/Po5lqqBOjzP+JdxbWi9BLcQIct111xEUFARATU0NN910E3v37kUphcfj6fM1ixcvxm63Y7fbiYuLo6SkhKSkpF7HzJo1q2tbdnY2BQUFhIeHk5aW1jWOecmSJTzxxBMnrW/dunVd/1icf/75VFRUUFtby9y5c7n//vtZunQpV199NUlJSZx11lnceuuteDwerrrqKrKzswf0uwGTBfX4HkE9O83t52qEGN7OpOXrK2FhYV3r3//+91m4cCEvv/wyBQUFLFiwoM/X2O3djbmgoCDa2trO6JiBeOihh1i8eDFvvvkmc+fO5Z133mHevHmsWbOGN954g5tvvpn777+fG2+8cUCfY6o+6oRIB2G2IPJL5YSiECNVTU0No0ePBuDpp58e9PefMGEC+/fvp6CgAIDnn3/+lK8577zz+Mc//gEYfd8xMTFERESQn5/P1KlTefDBBznrrLPYtWsXhYWFxMfHc/vtt3PbbbexadOmAddsqqBWSjE+3iknFIUYwR544AG++93vMn369EFvAQOEhITw+OOPc8kllzBz5kycTieRkZEnfc3y5cvJy8sjKyuLhx56iGeeeQaA3/72t0yZMoWsrCyCg4O59NJLWbVqFdOmTWP69Ok8//zz3HfffQOuWXWeBR1MOTk5+kxvHPCdf29hzZ4yNj584SBXJYTYuXMnkyZN8ncZfldfX094eDhaa+655x7S09P51re+NWSf39d/B6VUnta6z/GHpmpRg9FPXVrXQk1T3ycQhBBioJ588kmys7OZPHkyNTU13Hnnnf4u6aRMdTIRukd+7CutZ+YYl5+rEUIMR9/61reGtAU9UKZrUafHOQHYJ/3UQggBmDCoR7tCsFst7JORH0IIAZgwqIMsinGx4eyVoBZCCMCEQQ2QHh/OXpmcSQghgH4EtVJqglJqc49HrVLqm74sKj0unMPVTTS2Dv4YSiGE/wxkmlMwLjbpOTveihUr+Pvf/z4otS1YsIAzHVbsa6cc9aG13g1kAyilgoDDwMu+LGq894Ti3pJ6piVH+fKjhBBD6FTTnJ7KqlWrCA8P75pz+q677vJJnWZzul0fFwD5WutCXxTTaVKCEdQ7jw7uzF5CCPPJy8tj/vz5zJw5k4svvpijR48C8Pvf/57MzEyysrK44YYbKCgoYMWKFTz22GNkZ2ezdu1ali9fzqOPPgoYLeIHH3yQWbNmkZGR0TW9aGNjI9dffz2ZmZl8+ctf5uyzzz5ly/m5555j6tSpTJkyhQcffBCA9vZ2br75ZqZMmcLUqVN57LHH+qzTF053HPUNwHN97VBK3QHcAZCSkjKgopJdoYTZgthVLEP0hPCZtx6C4i8G9z1HTYVLH+n34Vpr7r33Xl599VViY2N5/vnnefjhh3nqqad45JFHOHDgAHa7nerqaqKiorjrrrt6tcI/+OCDXu/X1tbGxo0befPNN/nRj37E+++/z+OPP47L5WLHjh1s27btlLPZHTlyhAcffJC8vDxcLhcXXXQRr7zyCsnJyRw+fJht27YBUF1dDXBcnb7Q7xa1UsoGXAn8u6/9WusntNY5Wuuc2NjYgRVlUUwY5WSHtKiFGNZaWlrYtm0bixYtIjs7m5/+9KcUFRUBkJWVxdKlS3n22WdPeNeXY1199dUAzJw5s2vSpXXr1nW1dDvn5TiZzz77jAULFhAbG4vVamXp0qWsWbOGtLQ09u/fz7333svbb79NRETEGdd5uk7nXS8FNmmtS3xSyTEmJUTwny1H0FrLXZOF8IXTaPn6itaayZMn88knnxy374033mDNmjW89tpr/OxnP+OLL07d+u+c1tQXU5q6XC62bNnCO++8w4oVK1i5ciVPPfVUn3UOdmCfTh/1Ek7Q7eELkxIiqGtu40hN81B9pBBiiNntdsrKyrqC2uPxsH37djo6Ojh06BALFy7kl7/8JTU1NdTX1+N0OqmrO70u0blz57Jy5UoAduzYccrAnzVrFqtXr6a8vJz29naee+455s+fT3l5OR0dHVxzzTX89Kc/ZdOmTSesc7D1K/aVUmHAImDIZi7pOqF4pJbRUSFD9bFCiCFksVh44YUXWLZsGTU1NbS1tfHNb36TjIwMvva1r1FTU4PWmmXLlhEVFcUVV1zBtddey6uvvsof/vCHfn3GN77xDW666SYyMzOZOHEikydPPum0pgkJCTzyyCMsXLgQrTWLFy/mS1/6Elu2bOGWW26ho6MDgF/84he0t7f3WedgM900p53qW9qY8sN3+PaiDO69IH2QKhNiZBuJ05y2t7fj8XhwOBzk5+dz4YUXsnv3bmw2m99qOt1pTk03e16ncLuVMe5QGfkhhBiQxsZGFi5ciMfjQWvN448/7teQPhOmDWqAiaOcMpZaCDEgTqfTtFcc9pcp5/roNCkhggMVDXIpuRCDyBfdnaL/zuT3b+qgnjgqAq1hj0zQJMSgcDgcVFRUSFj7idaaiooKHA7Hab3O1F0fkxONAeXbDteQLXN+CDFgSUlJFBUVUVZW5u9SRiyHw0FSUtJpvcbUQZ3kCsEVGswXRTX+LkWIYSE4OJixY8f6uwxxmkzd9aGUYmpSFFsPS1ALIUYuUwc1QNboSPaU1NHsafd3KUII4RemD+qpSZG0d2i2H5FhekKIkcn0QT0tyTiJ+EWRb6YPFEIIszN9UMdH2Il12tkqJxSFECOU6YNaKcW0pEg5oSiEGLFMH9QAU0dHkV9WT32LXKEohBh5AiKos5Ii0dq48EUIIUaagAjqqUnG3LFb5YSiEGIECoigjgm3kxwdwqZCCWohxMgTEEENkDMmmtzCKplMRggx4gRMUM8c46K8voWDlY3+LkUIIYZUwAR1TqoLgNyCKj9XIoQQQ8tcQd3aAI2Vfe7KiHPidFjJOyhBLYQYWcwT1J4m+J90+OR/+9xtsShmpLjIkxa1EGKEMU9QB4dAYjbsffeEh8wc42JPaR01TZ4hLEwIIfzLXDcOSF8E7y+H2iMQkXjc7pwxLrSGTQerWDghbujrE0KMTG0tUF8CDWXQUO59lEFjOdSXQX0x1BVDUDDctW7QP95kQX2xEdR734OZNx23OzsliiCLIq9AgloIMQg8zUYA1xV3h23no74Y6kqg7ig09X3uDKsDwmIhPB7c4yEqxSdlmiuo4yZBZLLR/dFHUIfarExOjGDjgRP80oQQAowArjvqDeGj3YHbGcqdQdzUxzkvi9UIXucocKVCymxjPTzeeITFQKjbCGhbGCjl8x/HXEGtlNH9sXWl8aeG1X7cIXPS3Dy1/gBNre2E2IL8UKQQwq86OqChFKoPQlUhVBca67VHjDCuPdJ3C9gS3B247nGQOtf7fBQ4E8AZb6yHusFintN3YLagBqP7I/cpKFgH4y84bveccW7+vGY/uYWVnJce64cChRA+1d5mBG71Qag5BNWHjDDuXK85BO2tvV8TGgORo42/yJNngTMRIhJ6B3GIy3QB3F/mC+q0+WALh53/6TOoz0qNxmpRfJJfIUEtRCBqb4PaIm9ruDOMD3pD+CDUHAZ9zD1Sw+IgKhkSsmDiYqMvOGqMd5kCtlD//CxDxHxBHRwCGRfDztfgsl9DUO8Sw+xWspOj+Di/wk8FCiFOqa3FCOKqA1C5Hyo7l/uNUO7oOcRWGaO8IpMheTZMTTbCN7JzmWTkwgjWr6BWSkUBfwGmABq4VWv9ic+qyrwKtr0IBWth3MLjds8Z5+aPH+2jttlDhCPYZ2UIIU6itaE7gKt6BHFlgdFKpscEajYnRI+FUVMh80qITutuEUeMBqvNXz9FQOhvi/p3wNta62uVUjbAt39npC+C4DDY8coJg/oPH+7jswOVXDAp3qelCDGiNVX1aA0f6B3I9SW9jw11g2usMUoi+qtGMEenGY9Q95CMjhiuThnUSqlIYB5wM4DWuhVoPdlrBqxX98ejxiDyHmakuLBZLXycXyFBLcRAtXuM4C3bDeW7oWwPVOYb244dvuZMMIJ3/KIeQTzWCOiQKP/UPwL0p0U9FigD/qaUmgbkAfdprRt6HqSUugO4AyAlZRAGfU+9Dra/ZFz8MvGyXrscwUHkjHGxfl/5wD9HiJHC0wTle3sEsvdRmQ8dPe5HGplsDF+b/GUjgDtbxa7UYX/Szqz6E9RWYAZwr9Z6g1Lqd8BDwPd7HqS1fgJ4AiAnJ2fgs/unLzLGO276+3FBDXBuegy/ens3pbXNxEU4BvxxQgwbTVVQuhNKdxjBXL4XKvYZJ/E6+41VkNESjplgjKKInQAxGcbDHu7X8sXx+hPURUCR1nqD9/kLGEHtW0HBMG0JfPwH4yoi56heu+dnxPKrt3ezek8Z1+Uk+7wcIUzH02y0jEt3Qsl2I5hLdkDdke5jbOFG6zjpLMj+qjeQJxjb+rigTJjTKYNaa12slDqklJqgtd4NXADs8H1pwIwbYf1vYfM/4bz7e+3KTIgg1mlnlQS1GO462qGqoDuIS7cb4VyR3z3eOMhmhPDY8yAuE+InG1MyRIyWk3jDQH9HfdwL/MM74mM/cIvvSurBPQ7GnAu5f4NzlvUaU62UYn5GLO/tKKGtvQNrUGBecSREF62hvtQI4pId3u6L7VC6C9qavAcpo684frIxjDVukrEePe64aw7E8NGv/7Ja681Ajo9r6duce+BfS2D7y5B1Xa9dCybE8kJeEVuKapg5xuWX8oQ4Iy113f3IJTuMZekOaOxxIVdYHMRnQs4t3lZyJsRONCYCEiOK+f8JzrjE6FNb/zuYem2vP+POHR+DRcHq3aUS1MKc2j3GybzSHd5+ZG8rufpg9zG2cKNlPHExxE02Ajku05ilTQgCIagtFpi7DF69B/Z9AOkXdu2KCrUxPcXF6j1l3H/RBD8WKUY8rY3w7WwZd7aSy/d2Xy5tsYI73TixN+Om7lZyZErAThYkhob5gxpg6vXw0S/gwx/DuPN7fannZ8Ty2Pt7KKtrIdYpZ7HFEGio6BHI3tEWpbugta77mMgUI4QzLu5uJbvT5VJpcUYCI6itNrjwh/DS7bD1eche0rVrUWY8v3lvDx/sLOGGWb65u4IYoVoboWzX8f3IPS+dDnEZQZy9pHu0RexEcET4r24x7ARGUANMuRY+/RN88GNjUhfvCZWJo5wkuUJ4d4cEtThD7W3G5dLHtpIrD9B1gYjVYQTw+AuNQO4cbREeL8PfhM8FTlBbLHDJL+Cpi42wvvSXgDFM76LMUTy7oZCGljbC7IHzI4kh1tFhzINctrt3K7lsN7S3GMcoizHUbdRUyPpKdyvZlQoWuaOQ8I/ASrWU2TDrTtiwAiZcZtxkALhocjxPrT/Amj1lXDo1wc9FCr9rbzPuCFK2y/vYYyzL94Cnsfs4Z6LRMk6b392PHJMx4uc+FuYTWEENcOFyyP8AXrkb7lgN4bHkjHHhCg3m3R0lEtQjSVurMaFQ2a7uCYbKdkPF3t63aooYbVy1N/NmI4hjJxrPQ6P9VroQpyPwgtoWCtf8FZ66BJ5fCjf+B2uwg/MnxvPejmI87R0Ey1WKw0tro9EaLt/TO5Qr9/e4ZZMC1xhvP/IF3jCeCDHpcmJPBLzAC2qAxGz48gr4903wyl1w9V+4aHI8L24qYuOBSuaOlwsFAk5HhzGZUNdsbz1mfas51H2cCjKmFoidAJlf6m4du8fLFJxi2ArMoAaYfBVU/wTe+z7oDuZd8QSOYAvvbi+WoDazljojfMv39QjjvcYEQz37j23hRvimzAb3fxlhHDvBONEnY5HFCBO4QQ3GFYuWIHjne4Q0VrJ43P28ua2YH1wxmSCLDJnym5a67hubVhUYXRSdreO6o93HKYtxzzx3OqSeZwRzTLrx3DlKhr0J4RXYQQ3GpE0h0fDaffzE/t/cWP91NhzI5pxx0qr2mY4OI3A7g7jzUel93njMnXccUUYIpy3whnGGEciusRAsN30Q4lQCP6jBuCosJgPHC7ew0vYTPn1rB9z2G3BE+ruywKS1cZeQmkNQU3R8EFcX9h5VoYIgMskYazxxsfceeqndjxCZMEuIgVBaD/yuWcfKycnRubm5g/6+p9RSz6o/LWNe9UuokCjU3PvgrNvl1kLHam2AmsNGENce9q4XGReD1BQZz7vmP/ayRxihe2wIu1KNe+wdcwNiIcTpUUrlaa37nE56eLSoO9nDaV30c654dgZ/T3gX9/vLYc2vIet6Y07f+CnDu99Ta2iuMW5dVl9sLGuPeMO4qDucm6uPeaEy+oQjRhu/o4xLjPXIpO6WcohreP/uhDCx4RXUwPwJsXzbns7PXefx68Ue2PgkfP4s5P7VGDEwcbFx49zRMwNnAnatoaUW6kqMvuG6YmNZ3/O593FsSxiMPuLIZIgcDcmzugM4MskIZGeCjKQQwsSGV9eH17dXbuHd7cXkfv9C7NYgaKyE7S/BrjfgwFpjfmAVZFwynDjdOLnlTjdOcEUk+v4S4rZWI3iba4y+4IZyaCgzTsI1lPf9vHMuip5s4UZL2JlgTA7Uue4c1Xu7dP0IYXojp+vD64ppCby4qYiPdpVyyZQE41Lhs24zHs01cHADFG2EQxuN8G78e+83sEcYARceB3YnBIcarW9buHeUgvJ2AyhjiJlS0NEGbS3Q1ux9eNc9zd2h3PnoOV74WMGhxp09QmMgfJTRFREWA2GxPQI5AZzxRm1CiGFvWAb1ueNjiHXaeSHvsBHUPTkiIeMi49GpsdIY49s5zre+1OhGaCgznrc2dD88TYA2uiN6Li1WYypMq91YBtm6nzsiISbeWDoija4IRySEeJedwRwWEzjdMUKIITMsg9oaZOHq6aP5y7oD/bvzS2g0hM4y+m+FEMJkhu3sRdfMTKK9Q/Pq5sP+LkUIIQZk2AZ1RryTaUmRvJBXhC9OmAohxFAZtkENcO3MJHYV17H9SK2/SxFCiDM2rIP6immJ2IIsvLipyN+lCCHEGRvWQR0VamNRZjyvfH6YZk/7qV8ghBAmNKyDGmDJrBSqGj28te3oqQ8WQggTGvZBfc44N2NjwvjHpwf9XYoQQpyRYR/UFoviq7NSyC2sYlexnFQUQgSeYR/UYIz+sFkt0qoWQgSkfgW1UqpAKfWFUmqzUsp/sy2dIVeYjcunJvDy54dpaGnzdzlCCHFaTqdFvVBrnX2i2Z3MbunsFOpb2nj5c7lSUQgRWEZE1wfAjBQXkxMjePrjArlSUQgRUPob1Bp4VymVp5S6o68DlFJ3KKVylVK5ZWVlg1fhIFFK8fVzx7KvtJ7Ve8xXnxBCnEh/g/pcrfUM4FLgHqXUvGMP0Fo/obXO0VrnxMbGDmqRg+XyrETinHb+uu6Av0sRQoh+61dQa60Pe5elwMtAQM4HarNauOmcVNbuLWd3cZ2/yxFCiH45ZVArpcKUUs7OdeAiYJuvC/OVr85KwRFs4SlpVQshAkR/WtTxwDql1BZgI/CG1vpt35blO64wG1fPSOLlzYcprWv2dzlCCHFKpwxqrfV+rfU072Oy1vpnQ1GYL91+Xhpt7R38da20qoUQ5jdihuf1NDYmjMuzEnn200KqGlr9XY4QQpzUiAxqgHsWjqehtZ2/fVzg71KEEOKkRmxQTxjl5OLJ8Ty9/gB1zR5/lyOEECc0YoMa4L8XplPb3Mb/+7TQ36UIIcQJjeignpoUyYIJsfxl7QEaW2WyJiGEOY3ooAa49/x0Khta+dv6An+XIoQQfRrxQT1zjIsLJ8WxYnU+1Y0yAkQIYT4jPqgBvnPxBOpb2vjT6nx/lyKEEMeRoAYmjorgy9mjeXp9AcU1crWiEMJcJKi9vrUogw6t+d0He/1dihBC9CJB7ZUcHcpXZ6WwMvcQ+0rr/V2OEEJ0kaDu4d4L0gkNDuKnb+zwdylCCNFFgrqHmHA7912YzqrdZXy4q8Tf5QghBCBBfZwb56SSFhvGT17fSWtbh7/LEUIICepj2awWfnB5JgfKG/jbepkGVQjhfxLUfVgwIY4LJsbxhw/3UVorw/WEEP4lQX0C3788k9b2Dpa/tt3fpQghRjgJ6hNIjQnjvgvSefOLYt7dXuzvcoQQI5gE9UncMS+NiaOc/ODV7TJntRDCbySoTyI4yMIj12RRUtfMr97e7e9yhBAjlAT1KWQnR3HLOWP5f58WsmF/hb/LEUKMQBLU/fDtizIY4w7l/pVbqJUuECHEEJOg7ocwu5XHvpJNcW0zy/8jo0CEEENLgrqfZqS4uGfheF7adJg3th71dzlCiBFEgvo03Hv+eKYlRfK9l7/gaE2Tv8sRQowQEtSnITjIwmNfycbT3sG9//wcT7vMBSKE8D0J6tOUFhvOI9dkkVtYxSNv7fJ3OUKIEUCC+gxcOS2Rm+aM4a/rDvDWF9JfLYTwLQnqM/Tw4kyyk6P4Py9sJb9M7ggjhPCdfge1UipIKfW5Uup1XxYUKGxWC48vnYHdauG2Z3Kpbmz1d0lCiGHqdFrU9wE7fVVIIEqMCuHP/zWTw1VN3P3sJjm5KITwiX4FtVIqCVgM/MW35QSenNRoHrlmKp/sr+AHr25Da+3vkoQQw4y1n8f9FngAcJ7oAKXUHcAdACkpKQOvLIBcPSOJfaX1PL4qn5ToMO5eMM7fJQkhhpFTtqiVUpcDpVrrvJMdp7V+Qmudo7XOiY2NHbQCA8V3LprAFdMS+eXbu1j52SF/lyOEGEb606KeC1yplLoMcAARSqlntdZf821pgcViUfz6umnUNHl46KWtRIYGc/HkUf4uSwgxDJyyRa21/q7WOklrnQrcAHwoId03m9XCiq/NYFpyFPc+9zkf7yv3d0lCiGFAxlEPslCblb/dfBZj3WHc+sxnrJewFkIM0GkFtdZ6ldb6cl8VM1xEhdr45+1nk+oO49anP2Pt3jJ/lySECGDSovYRd7idf94+m7ExYXz9mVxW75GwFkKcGQlqH4oOs/Hc7bMZHxvO7c/kyjzWQogzIkHtYy5vWGclRfLfz23i6fUH/F2SECLASFAPgcjQYJ697WwunBTP8td28Ku3d8kVjEKIfpOgHiKO4CD+tHQGS2al8PiqfO7712aaPe3+LksIEQD6ewm5GATWIAs///IUklwh/M87uzlQ3sATN84kITLE36UJIUxMWtRDTCnFPQvH8+SNOewvq+fK/13PpoNV/i5LCGFiEtR+sigznpfvmUtIcBBf+fMnPLXugPRbCyH6JEHtRxnxTv7z33OZnxHHj1/fwe1/z5MbEAghjiNB7WdRoTaevHEmP7g8k9V7Srnsd2vJK6z0d1lCCBORoDYBpRS3njuWF+8+B2uQhetWfMIjb+2SUSFCCECC2lSykqJ4Y9m5XJ+TzIrV+Vzxh3VsOVTt77KEEH4mQW0yTkcwj1yTxdO3nEVdcxtX/+ljHnlrF42tbf4uTQjhJxLUJrVgQhzvfGse18wYzYrV+Sz6zRre3lYsI0OEGIEkqE0sMiSYX107jZV3zsHpsHLXs3nc8vRnFFY0+Ls0IcQQkqAOALPGRvPavefyfxdPIregikW/WcPP39xJTaPH36UJIYaABHWACA6ycNt5aXzw7flcmZ3Ik2v3M+9/PuLJNftldIgQw5wEdYCJj3Dw6HXTeHPZeUxPieJnb+7kgl+vZuVnh/C0d/i7PCGED0hQB6hJCRE8fcss/nnb2bjDbTzw4lYWPrqK5zYepLVNAluI4UT5YhRBTk6Ozs3NHfT3FX3TWrNqdxm//WAvWw5VMzoqhLsXjOPamUk4goP8XZ4Qoh+UUnla65w+90lQDx9aa9bsLed37+9h08Fq3GE2/mvOGL42ewwx4XZ/lyeEOAkJ6hFGa82n+yv5y9r9fLCrFF7ttxkAAA35SURBVJvVwtXTR/P1c8eSHu/0d3lCiD6cLKjlxgHDkFKKOePczBnnJr+snr+uO8CLeUX867NDzB3v5quzxrAoMx6bVU5RCBEIpEU9QlQ2tPLPDYU8t/EQh6ubiAm3cV1OMkvOSiHFHerv8oQY8aTrQ3Rp79Cs2VPGPzYc5MNdJXRoOC89hmtnJnFR5ihCbHLyUQh/kKAWfTpa08Tznx3i37lFHK5uIswWxKVTE7h6xmhmj3VjsSh/lyjEiCFBLU6qo0Oz4UAlL20q4q1txdS3tJEY6eBL00dzRVYikxKcKCWhLYQvSVCLfmtqbee9nSW8tKmItXvLae/QjI0J47Kpo7hsagKZCRES2kL4gAS1OCPl9S28u72EN784yif7K2jv0KS6Q7l0agKLpyYwOVFCW4jBMqCgVko5gDWAHWM43wta6x+e7DUS1MNPRX0L7+4wQvvjfCO0EyIdnD8xjgsnxTNnnFuughRiAAYa1AoI01rXK6WCgXXAfVrrT0/0Ggnq4a2yoZX3d5bwwc4S1u4tp7G1nZDgIOaOj+HCSXGcPzGOuAiHv8sUIqAM6IIXbSR5vfdpsPchtxkZwaLDbFyfk8z1Ock0e9r5dH8FH+4q5YOdpby/swSAaUmRzM+I5byMWLKTowgOkotrhDhT/eqjVkoFAXnAeOCPWusH+zjmDuAOgJSUlJmFhYWDXKowO601u4rr+HCXEdhbDlXToSHcbmV2mpt5GTGclx5LqjtU+raFOMagnUxUSkUBLwP3aq23neg46foQADWNHj7ZX86aveWs3VvGocomAEZHhTAvI4Zzx8cyOy0at0wYJcTgjvpQSv0AaNRaP3qiYySoRV8KKxqM0N5Txif5FdS1GHdWz4gP5+yxbmanuTk7LVpm+hMj0kBPJsYCHq11tVIqBHgX+KXW+vUTvUaCWpxKW3sHW4pq2HCggk/3V5JbUEljq3FLsfFx4cxOizaCe6ybWKcEtxj+BhrUWcAzQBDGHWFWaq1/fLLXSFCL0+Vp72Db4Ro+3V/JhgMVfHagkgZvcKfFhDFzjKvrMS42XC5vF8OOXPAiAk5bewfbj9Ty6f4KPiuoYtPBKiobWgGIcFiZMcbFzBQjuKclRxFmlxl7RWCT+ahFwLEGWZiWHMW05CjunG+MKCmoaCSvsIq8wkryCqtYtbsMgCCLYlKCk5kpLiPAx7gYHRUiI0vEsCEtahGwaho9fH6oik2FVeQdrOLzg9Vd/dwx4XamJUUyLTmKrKRIpiVF4Qqz+bliIU5MWtRiWIoMDWbBhDgWTIgDjO6S3SV1bCqsYvOhGrYUVfPh7lI62yIp0aFGK90b4JMTIwi1yf8CwvykRS2GtbpmD18crmFrUQ1bDlWztaiGw9XGeG6Lgox4J1NHRzI5MYLJoyOZlBBBuPR3Cz+QFrUYsZyOYM4ZF8M542K6tpXVtbC1qJot3vD+cFcp/84rAkApSHWHkZkQQWZihBHgiZEyRFD4lQS1GHFinXYumBTPBZPiAeNEZWldC9uP1LD9cC3bj9Sy9XA1b3xxtOs1cU57r+CelBBBSnQoQTJMUAwBCWox4imliI9wEB/h4PyJ8V3ba5o87DhSy/YjNew4WsuOI7VdN1MAcARbyIh3khHvZOIoYzlhlJM4p11GnIhBJUEtxAlEhgQzZ5ybOePcXduaPe3sKalj19E6dpfUsbu4jtV7ynjB23UCEBUa3Cu8J45ykh7vJDIk2B8/hhgGJKiFOA2O4CCykqLISorqtb2ivoU9JfXsLq5lt3f50qbD1HvnMwFIjHSQMcpJelw442LDSYsNZ1xsGNFhNmmBi5OSoBZiELjD7cwJt/dqfWutOVzdZLTAi+vYU2wsP86voLWto+u4yJBg0mLDvOFtLMfFhpESHYbNKvN4CwlqIXxGKUWSK5QkV2ivvu/2Ds2R6ibyy+rJL2tgf1k9+WX1rDmmCyXIokhyhTDGHUaqO5Qx7jDGxhjLJFcIdqvc+mykkKAWYogFWRTJ0aEkR4eyYELvfXXNHvaXNbC/vJ780gYKKhoorGjk88KqrmlhwRgDnhgVQqo7jDHuUFLdYaTGGIGeHB0q968cZiSohTARpyO4a46TnrTWVDV6vMHdQEF5IwUVDRRUNPLGF0epbvT0Oj4m3MZoVyhJrhDvw1hP9i4lyAOLBLUQAUApRXSYjegwGzNSXMftr25spbDCCO+iqiaKqhopqmpix5Fa3tteQmt7R6/jY512kl0hJEeHdgV5QqSDxKgQEiIdOB0yQsVMJKiFGAaiQm1EhdqOa4kDdHQYF/QUVTVyqKqRQ5VNHKo0gjyvsIrXtx7tGhveyWm3khDlYFRkCImRDhIiQ0iIcpAYGcKoSAeJUQ6ZJ2UIyW9aiGHOYlGMinQwKtJBTmr0cfvb2jsorm3maE0zR6qbOFrTTHGP9R1Haiivbz3udeF2K7FOO7HhdmIjvEtn9yPOu3SH2eUKzgGSoBZihLMGWbpGp5xIS1s7JTUtHKlp4miNEeBldS1dj51HallT19LrhGcni4LosOMD/Nhgd4XaiAwJllDvgwS1EOKU7NYgUtyhpLhPHOYATa3tlNe3UFrXQlldjzCv7w71vSV1lNW10NZx/MydSkGEIxhXaDBRobauZVRoMK4ez13ebZ3bQ21Bw/qiIQlqIcSgCbEFdQ09PJmODk1Nk6dXgFc2tFLd5KG6sZWqRmNZVt/C3tJ6qhs9va7yPJYtyNIV3J0B7/L227t6bTeeR4YGExkSHDBj0SWohRBDzmJRuMJsuMJsZMQ7+/Wa1rYOqptaqW70UN3ooaqxtSvUqxpbqW7wUN1kPD9Q3sCmxmqqG1vxtJ94zn271UJESDBOh5UIR/Ax696lw4rTEUy43Uq4w2ose6zbrRaft+YlqIUQAcFmtRDndBDndPT7NVprGlvbvaFuBHpVo4eaJg81ja3UNbdR2+yhtrmN2iYPtU0eiqoaqW1qo67ZQ0tbxyk/w2pRXaGdGBnCyrvmDOTH7PszBv0dhRDCJJRShNmthNmtJB0//PyUmj3t1DUboV3f0kZ9c5ux9D7qmtto6Hze3OazuVkkqIUQ4gQcwUE4goP8focfmZpLCCFMToJaCCFMToJaCCFMToJaCCFMToJaCCFMToJaCCFMToJaCCFMToJaCCFMTml94uvgz/hNlSoDCs/w5TFA+SCW40uBVCsEVr2BVCtIvb4USLXCmdc7Rmsd29cOnwT1QCilcrXWOf6uoz8CqVYIrHoDqVaQen0pkGoF39QrXR9CCGFyEtRCCGFyZgzqJ/xdwGkIpFohsOoNpFpB6vWlQKoVfFCv6fqohRBC9GbGFrUQQogeJKiFEMLkTBPUSqlLlFK7lVL7lFIP+bseAKXUU0qpUqXUth7bopVS7yml9nqXLu92pZT6vbf+rUqpGUNca7JS6iOl1A6l1Hal1H0mr9ehlNqolNrirfdH3u1jlVIbvHU9r5Syebfbvc/3efenDmW93hqClFKfK6VeD4BaC5RSXyilNiulcr3bzPpdiFJKvaCU2qWU2qmUmmPiWid4f6edj1ql1Dd9Xq/W2u8PIAjIB9IAG7AFyDRBXfOAGcC2Htt+BTzkXX8I+KV3/TLgLUABs4ENQ1xrAjDDu+4E9gCZJq5XAeHe9WBgg7eOlcAN3u0rgLu9698AVnjXbwCe98P34X7gn8Dr3udmrrUAiDlmm1m/C88At3nXbUCUWWs9pu4goBgY4+t6/fID9vEDzwHe6fH8u8B3/V2Xt5bUY4J6N5DgXU8AdnvX/wws6es4P9X9KrAoEOoFQoFNwNkYV3RZj/1eAO8Ac7zrVu9xaghrTAI+AM4HXvf+j2fKWr2f21dQm+67AEQCB479/Zix1j5qvwhYPxT1mqXrYzRwqMfzIu82M4rXWh/1rhcD8d510/wM3j+1p2O0Uk1br7crYTNQCryH8VdVtda6rY+auur17q8B3ENY7m+BB4DO21K7MW+tABp4VymVp5S6w7vNjN+FsUAZ8Ddvt9JflFJhJq31WDcAz3nXfVqvWYI6IGnjn0hTjW9USoUDLwLf1FrX9txntnq11u1a62yM1uosYKKfS+qTUupyoFRrnefvWk7DuVrrGcClwD1KqXk9d5rou2DF6F78k9Z6OtCA0XXQxUS1dvGej7gS+Pex+3xRr1mC+jCQ3ON5knebGZUopRIAvMtS73a//wxKqWCMkP6H1vol72bT1ttJa10NfITRfRCllLL2UVNXvd79kUDFEJU4F7hSKVUA/Auj++N3Jq0VAK31Ye+yFHgZ4x9CM34XioAirfUG7/MXMILbjLX2dCmwSWtd4n3u03rNEtSfAenes+g2jD8p/uPnmk7kP8BN3vWbMPqCO7ff6D3LOxuo6fGnkM8ppRTwV2Cn1vo3AVBvrFIqyrsegtGfvhMjsK89Qb2dP8e1wIfelovPaa2/q7VO0lqnYnw3P9RaLzVjrQBKqTCllLNzHaMvdRsm/C5orYuBQ0qpCd5NFwA7zFjrMZbQ3e3RWZfv6vVHJ/wJOuYvwxipkA887O96vDU9BxwFPBj/8n8do6/xA2Av8D4Q7T1WAX/01v8FkDPEtZ6L8efWVmCz93GZievNAj731rsN+IF3exqwEdiH8Wel3bvd4X2+z7s/zU/fiQV0j/owZa3eurZ4H9s7/38y8XchG8j1fhdeAVxmrdVbQxjGX0iRPbb5tF65hFwIIUzOLF0fQgghTkCCWgghTE6CWgghTE6CWgghTE6CWgghTE6CWgghTE6CWgghTO7/Axy1mYJPEie1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f657c56072f43bbb9a1bba86dde9ae7",
            "f8b9bfd6404e4fb7b8da48e1012b00d9",
            "8c660cd311114afe9bd0a8a5fc875c85",
            "6e7cc47893e742f983b7c726f9c47a84",
            "8e955622679942ff975d75b013d39472",
            "d8828340c2fb44249ed8e7f2f44f176e",
            "bfd641d2255f4ae1835c7a31e5c77cd5",
            "5dcea2a747cc47e8acb78e83aa0fbb23"
          ]
        },
        "id": "O9dViGRRUYvU",
        "outputId": "b109c7e1-aa6b-4e7b-c7cd-71e17e3212ef"
      },
      "source": [
        "run(path=\"resnet101.npy\",runs=1,epochs=700,k=1,temp=15,type=2,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f657c56072f43bbb9a1bba86dde9ae7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.515873432159424\n",
            "Test Loss:  6.253229141235352\n",
            "Recall : 0.1180952380952381\n",
            "Epoch  2\n",
            "Train Loss:  7.44246768951416\n",
            "Test Loss:  6.214075088500977\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  3\n",
            "Train Loss:  7.372601509094238\n",
            "Test Loss:  6.176089286804199\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  4\n",
            "Train Loss:  7.3042802810668945\n",
            "Test Loss:  6.139005661010742\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  5\n",
            "Train Loss:  7.236928939819336\n",
            "Test Loss:  6.102731704711914\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  6\n",
            "Train Loss:  7.170311450958252\n",
            "Test Loss:  6.067212104797363\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  7\n",
            "Train Loss:  7.10438346862793\n",
            "Test Loss:  6.032499313354492\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  8\n",
            "Train Loss:  7.039150238037109\n",
            "Test Loss:  5.998648643493652\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  9\n",
            "Train Loss:  6.974661350250244\n",
            "Test Loss:  5.965672969818115\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  10\n",
            "Train Loss:  6.910962104797363\n",
            "Test Loss:  5.933601379394531\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  11\n",
            "Train Loss:  6.848138809204102\n",
            "Test Loss:  5.9025421142578125\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  12\n",
            "Train Loss:  6.786280632019043\n",
            "Test Loss:  5.872518539428711\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  13\n",
            "Train Loss:  6.7254638671875\n",
            "Test Loss:  5.843611717224121\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  14\n",
            "Train Loss:  6.665793418884277\n",
            "Test Loss:  5.8158369064331055\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  15\n",
            "Train Loss:  6.607320785522461\n",
            "Test Loss:  5.789236068725586\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  16\n",
            "Train Loss:  6.550107002258301\n",
            "Test Loss:  5.763823986053467\n",
            "Recall : 0.14\n",
            "Epoch  17\n",
            "Train Loss:  6.494214057922363\n",
            "Test Loss:  5.739629745483398\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  18\n",
            "Train Loss:  6.439711570739746\n",
            "Test Loss:  5.716630935668945\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  19\n",
            "Train Loss:  6.386651992797852\n",
            "Test Loss:  5.694822311401367\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  20\n",
            "Train Loss:  6.335073471069336\n",
            "Test Loss:  5.674155235290527\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  21\n",
            "Train Loss:  6.284966945648193\n",
            "Test Loss:  5.654661178588867\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  22\n",
            "Train Loss:  6.236349105834961\n",
            "Test Loss:  5.63627815246582\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  23\n",
            "Train Loss:  6.189212322235107\n",
            "Test Loss:  5.61900520324707\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  24\n",
            "Train Loss:  6.1435699462890625\n",
            "Test Loss:  5.6028008460998535\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  25\n",
            "Train Loss:  6.099401473999023\n",
            "Test Loss:  5.587587356567383\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  26\n",
            "Train Loss:  6.056683540344238\n",
            "Test Loss:  5.573302268981934\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  27\n",
            "Train Loss:  6.015398979187012\n",
            "Test Loss:  5.559945583343506\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  28\n",
            "Train Loss:  5.9755120277404785\n",
            "Test Loss:  5.547496795654297\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  29\n",
            "Train Loss:  5.936978340148926\n",
            "Test Loss:  5.535884857177734\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  30\n",
            "Train Loss:  5.899775981903076\n",
            "Test Loss:  5.525090217590332\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  31\n",
            "Train Loss:  5.863864898681641\n",
            "Test Loss:  5.515069961547852\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  32\n",
            "Train Loss:  5.829211235046387\n",
            "Test Loss:  5.505756378173828\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  33\n",
            "Train Loss:  5.795788764953613\n",
            "Test Loss:  5.497065544128418\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  34\n",
            "Train Loss:  5.763525009155273\n",
            "Test Loss:  5.488973617553711\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  35\n",
            "Train Loss:  5.732377529144287\n",
            "Test Loss:  5.4814558029174805\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  36\n",
            "Train Loss:  5.702329158782959\n",
            "Test Loss:  5.474520206451416\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  37\n",
            "Train Loss:  5.67332649230957\n",
            "Test Loss:  5.4681315422058105\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  38\n",
            "Train Loss:  5.645304203033447\n",
            "Test Loss:  5.462194442749023\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  39\n",
            "Train Loss:  5.6182403564453125\n",
            "Test Loss:  5.456660270690918\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  40\n",
            "Train Loss:  5.592078685760498\n",
            "Test Loss:  5.451523780822754\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  41\n",
            "Train Loss:  5.566775321960449\n",
            "Test Loss:  5.446796417236328\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  42\n",
            "Train Loss:  5.542266368865967\n",
            "Test Loss:  5.442378997802734\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  43\n",
            "Train Loss:  5.518519401550293\n",
            "Test Loss:  5.438232421875\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  44\n",
            "Train Loss:  5.495498180389404\n",
            "Test Loss:  5.434348106384277\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  45\n",
            "Train Loss:  5.47318172454834\n",
            "Test Loss:  5.430696487426758\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  46\n",
            "Train Loss:  5.4515204429626465\n",
            "Test Loss:  5.427248001098633\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  47\n",
            "Train Loss:  5.4304962158203125\n",
            "Test Loss:  5.424043655395508\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  48\n",
            "Train Loss:  5.410055160522461\n",
            "Test Loss:  5.421009063720703\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  49\n",
            "Train Loss:  5.390182018280029\n",
            "Test Loss:  5.418131351470947\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  50\n",
            "Train Loss:  5.370857238769531\n",
            "Test Loss:  5.4153947830200195\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  51\n",
            "Train Loss:  5.352063179016113\n",
            "Test Loss:  5.412772178649902\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  52\n",
            "Train Loss:  5.33375883102417\n",
            "Test Loss:  5.4102373123168945\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  53\n",
            "Train Loss:  5.3159284591674805\n",
            "Test Loss:  5.407809257507324\n",
            "Recall : 0.16\n",
            "Epoch  54\n",
            "Train Loss:  5.298558235168457\n",
            "Test Loss:  5.405472278594971\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  55\n",
            "Train Loss:  5.281615257263184\n",
            "Test Loss:  5.403216361999512\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  56\n",
            "Train Loss:  5.2650651931762695\n",
            "Test Loss:  5.401078224182129\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  57\n",
            "Train Loss:  5.248902320861816\n",
            "Test Loss:  5.399053573608398\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  58\n",
            "Train Loss:  5.233104705810547\n",
            "Test Loss:  5.397086143493652\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  59\n",
            "Train Loss:  5.217666149139404\n",
            "Test Loss:  5.395209312438965\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  60\n",
            "Train Loss:  5.202556610107422\n",
            "Test Loss:  5.393418312072754\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  61\n",
            "Train Loss:  5.187777042388916\n",
            "Test Loss:  5.391685485839844\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  62\n",
            "Train Loss:  5.173325538635254\n",
            "Test Loss:  5.389959335327148\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  63\n",
            "Train Loss:  5.159190654754639\n",
            "Test Loss:  5.388302803039551\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  64\n",
            "Train Loss:  5.14536714553833\n",
            "Test Loss:  5.3867363929748535\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  65\n",
            "Train Loss:  5.131842613220215\n",
            "Test Loss:  5.385225296020508\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  66\n",
            "Train Loss:  5.118599891662598\n",
            "Test Loss:  5.383787631988525\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  67\n",
            "Train Loss:  5.105632781982422\n",
            "Test Loss:  5.382406234741211\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  68\n",
            "Train Loss:  5.092925548553467\n",
            "Test Loss:  5.381058692932129\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  69\n",
            "Train Loss:  5.080477237701416\n",
            "Test Loss:  5.379751205444336\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  70\n",
            "Train Loss:  5.0682783126831055\n",
            "Test Loss:  5.378510475158691\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  71\n",
            "Train Loss:  5.056331634521484\n",
            "Test Loss:  5.377277374267578\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  72\n",
            "Train Loss:  5.044633865356445\n",
            "Test Loss:  5.3760881423950195\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  73\n",
            "Train Loss:  5.033188819885254\n",
            "Test Loss:  5.374958038330078\n",
            "Recall : 0.16\n",
            "Epoch  74\n",
            "Train Loss:  5.0219879150390625\n",
            "Test Loss:  5.37387228012085\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  75\n",
            "Train Loss:  5.011019229888916\n",
            "Test Loss:  5.372851371765137\n",
            "Recall : 0.16\n",
            "Epoch  76\n",
            "Train Loss:  5.000293254852295\n",
            "Test Loss:  5.371875762939453\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  77\n",
            "Train Loss:  4.989778518676758\n",
            "Test Loss:  5.370946884155273\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  78\n",
            "Train Loss:  4.979459285736084\n",
            "Test Loss:  5.370038032531738\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  79\n",
            "Train Loss:  4.969325542449951\n",
            "Test Loss:  5.369177341461182\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  80\n",
            "Train Loss:  4.9593610763549805\n",
            "Test Loss:  5.368403434753418\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  81\n",
            "Train Loss:  4.94957160949707\n",
            "Test Loss:  5.367701530456543\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  82\n",
            "Train Loss:  4.939969062805176\n",
            "Test Loss:  5.367025375366211\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  83\n",
            "Train Loss:  4.930564880371094\n",
            "Test Loss:  5.366371154785156\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  84\n",
            "Train Loss:  4.92133903503418\n",
            "Test Loss:  5.365738868713379\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  85\n",
            "Train Loss:  4.9122772216796875\n",
            "Test Loss:  5.3651041984558105\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  86\n",
            "Train Loss:  4.903365135192871\n",
            "Test Loss:  5.3644914627075195\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  87\n",
            "Train Loss:  4.894601821899414\n",
            "Test Loss:  5.363905906677246\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  88\n",
            "Train Loss:  4.885984420776367\n",
            "Test Loss:  5.363384246826172\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  89\n",
            "Train Loss:  4.8775224685668945\n",
            "Test Loss:  5.362910270690918\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  90\n",
            "Train Loss:  4.869194030761719\n",
            "Test Loss:  5.362483978271484\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  91\n",
            "Train Loss:  4.861000061035156\n",
            "Test Loss:  5.362074851989746\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  92\n",
            "Train Loss:  4.852923393249512\n",
            "Test Loss:  5.361705780029297\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  93\n",
            "Train Loss:  4.844965934753418\n",
            "Test Loss:  5.361371040344238\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  94\n",
            "Train Loss:  4.83713436126709\n",
            "Test Loss:  5.361071586608887\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  95\n",
            "Train Loss:  4.829425811767578\n",
            "Test Loss:  5.360780715942383\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  96\n",
            "Train Loss:  4.821830749511719\n",
            "Test Loss:  5.360498905181885\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  97\n",
            "Train Loss:  4.814361572265625\n",
            "Test Loss:  5.360228538513184\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  98\n",
            "Train Loss:  4.807003498077393\n",
            "Test Loss:  5.359977722167969\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  99\n",
            "Train Loss:  4.799741744995117\n",
            "Test Loss:  5.359731197357178\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  100\n",
            "Train Loss:  4.792567253112793\n",
            "Test Loss:  5.359477996826172\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  101\n",
            "Train Loss:  4.7854814529418945\n",
            "Test Loss:  5.359236240386963\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  102\n",
            "Train Loss:  4.7784881591796875\n",
            "Test Loss:  5.358992099761963\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  103\n",
            "Train Loss:  4.771578311920166\n",
            "Test Loss:  5.358758926391602\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  104\n",
            "Train Loss:  4.764740943908691\n",
            "Test Loss:  5.358536720275879\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  105\n",
            "Train Loss:  4.757974624633789\n",
            "Test Loss:  5.358316421508789\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  106\n",
            "Train Loss:  4.751278877258301\n",
            "Test Loss:  5.358081817626953\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  107\n",
            "Train Loss:  4.744659423828125\n",
            "Test Loss:  5.3578386306762695\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  108\n",
            "Train Loss:  4.738125324249268\n",
            "Test Loss:  5.357607841491699\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  109\n",
            "Train Loss:  4.73167085647583\n",
            "Test Loss:  5.357389450073242\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  110\n",
            "Train Loss:  4.725287437438965\n",
            "Test Loss:  5.357172012329102\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  111\n",
            "Train Loss:  4.718970775604248\n",
            "Test Loss:  5.356937408447266\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  112\n",
            "Train Loss:  4.7127275466918945\n",
            "Test Loss:  5.356695652008057\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  113\n",
            "Train Loss:  4.706564903259277\n",
            "Test Loss:  5.3564534187316895\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  114\n",
            "Train Loss:  4.700469970703125\n",
            "Test Loss:  5.356208801269531\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  115\n",
            "Train Loss:  4.694436073303223\n",
            "Test Loss:  5.355973243713379\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  116\n",
            "Train Loss:  4.688465595245361\n",
            "Test Loss:  5.355750560760498\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  117\n",
            "Train Loss:  4.682551860809326\n",
            "Test Loss:  5.355560302734375\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  118\n",
            "Train Loss:  4.676694869995117\n",
            "Test Loss:  5.355378150939941\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  119\n",
            "Train Loss:  4.670901298522949\n",
            "Test Loss:  5.355198383331299\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  120\n",
            "Train Loss:  4.665171146392822\n",
            "Test Loss:  5.355025768280029\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  121\n",
            "Train Loss:  4.659502983093262\n",
            "Test Loss:  5.35483455657959\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  122\n",
            "Train Loss:  4.653897285461426\n",
            "Test Loss:  5.354632377624512\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  123\n",
            "Train Loss:  4.648348808288574\n",
            "Test Loss:  5.354442119598389\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  124\n",
            "Train Loss:  4.642843246459961\n",
            "Test Loss:  5.354250431060791\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  125\n",
            "Train Loss:  4.637385368347168\n",
            "Test Loss:  5.354068756103516\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  126\n",
            "Train Loss:  4.631969451904297\n",
            "Test Loss:  5.353908061981201\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  127\n",
            "Train Loss:  4.6265950202941895\n",
            "Test Loss:  5.353748321533203\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  128\n",
            "Train Loss:  4.621262550354004\n",
            "Test Loss:  5.353588104248047\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  129\n",
            "Train Loss:  4.615975379943848\n",
            "Test Loss:  5.353427886962891\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  130\n",
            "Train Loss:  4.61073112487793\n",
            "Test Loss:  5.35328483581543\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  131\n",
            "Train Loss:  4.6055169105529785\n",
            "Test Loss:  5.353145599365234\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  132\n",
            "Train Loss:  4.6003313064575195\n",
            "Test Loss:  5.352998733520508\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  133\n",
            "Train Loss:  4.595185279846191\n",
            "Test Loss:  5.3528594970703125\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  134\n",
            "Train Loss:  4.590062618255615\n",
            "Test Loss:  5.352718353271484\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  135\n",
            "Train Loss:  4.584965705871582\n",
            "Test Loss:  5.352573394775391\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  136\n",
            "Train Loss:  4.579907417297363\n",
            "Test Loss:  5.352418899536133\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  137\n",
            "Train Loss:  4.574881076812744\n",
            "Test Loss:  5.3522467613220215\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  138\n",
            "Train Loss:  4.569880962371826\n",
            "Test Loss:  5.352046012878418\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  139\n",
            "Train Loss:  4.564908027648926\n",
            "Test Loss:  5.351835250854492\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  140\n",
            "Train Loss:  4.55996036529541\n",
            "Test Loss:  5.351614475250244\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  141\n",
            "Train Loss:  4.5550432205200195\n",
            "Test Loss:  5.351397514343262\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  142\n",
            "Train Loss:  4.55014705657959\n",
            "Test Loss:  5.351172924041748\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  143\n",
            "Train Loss:  4.545275688171387\n",
            "Test Loss:  5.350930213928223\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  144\n",
            "Train Loss:  4.540430068969727\n",
            "Test Loss:  5.350683689117432\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  145\n",
            "Train Loss:  4.535608291625977\n",
            "Test Loss:  5.350419998168945\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  146\n",
            "Train Loss:  4.530811786651611\n",
            "Test Loss:  5.350115776062012\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  147\n",
            "Train Loss:  4.526038646697998\n",
            "Test Loss:  5.349804878234863\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  148\n",
            "Train Loss:  4.521296977996826\n",
            "Test Loss:  5.349491119384766\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  149\n",
            "Train Loss:  4.51658296585083\n",
            "Test Loss:  5.349172592163086\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  150\n",
            "Train Loss:  4.511896133422852\n",
            "Test Loss:  5.348852634429932\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  151\n",
            "Train Loss:  4.507235527038574\n",
            "Test Loss:  5.348531723022461\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  152\n",
            "Train Loss:  4.502606391906738\n",
            "Test Loss:  5.348199844360352\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  153\n",
            "Train Loss:  4.4980058670043945\n",
            "Test Loss:  5.347867012023926\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  154\n",
            "Train Loss:  4.49343204498291\n",
            "Test Loss:  5.347529888153076\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  155\n",
            "Train Loss:  4.488888740539551\n",
            "Test Loss:  5.34718656539917\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  156\n",
            "Train Loss:  4.484377384185791\n",
            "Test Loss:  5.346845626831055\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  157\n",
            "Train Loss:  4.479894638061523\n",
            "Test Loss:  5.346499443054199\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  158\n",
            "Train Loss:  4.475443363189697\n",
            "Test Loss:  5.346138000488281\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  159\n",
            "Train Loss:  4.47102165222168\n",
            "Test Loss:  5.345752716064453\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  160\n",
            "Train Loss:  4.466623306274414\n",
            "Test Loss:  5.34535551071167\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  161\n",
            "Train Loss:  4.4622602462768555\n",
            "Test Loss:  5.344956874847412\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  162\n",
            "Train Loss:  4.457930088043213\n",
            "Test Loss:  5.344560623168945\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  163\n",
            "Train Loss:  4.45363187789917\n",
            "Test Loss:  5.344145774841309\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  164\n",
            "Train Loss:  4.449368476867676\n",
            "Test Loss:  5.3437347412109375\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  165\n",
            "Train Loss:  4.445135593414307\n",
            "Test Loss:  5.343325614929199\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  166\n",
            "Train Loss:  4.44093132019043\n",
            "Test Loss:  5.34291934967041\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  167\n",
            "Train Loss:  4.436757564544678\n",
            "Test Loss:  5.342508316040039\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  168\n",
            "Train Loss:  4.432621002197266\n",
            "Test Loss:  5.342097282409668\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  169\n",
            "Train Loss:  4.428519248962402\n",
            "Test Loss:  5.341681003570557\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  170\n",
            "Train Loss:  4.424449443817139\n",
            "Test Loss:  5.3412628173828125\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  171\n",
            "Train Loss:  4.420406818389893\n",
            "Test Loss:  5.340843200683594\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  172\n",
            "Train Loss:  4.416390419006348\n",
            "Test Loss:  5.34042501449585\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  173\n",
            "Train Loss:  4.412402153015137\n",
            "Test Loss:  5.340000152587891\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  174\n",
            "Train Loss:  4.408441066741943\n",
            "Test Loss:  5.339582443237305\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  175\n",
            "Train Loss:  4.404512405395508\n",
            "Test Loss:  5.339171886444092\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  176\n",
            "Train Loss:  4.400603294372559\n",
            "Test Loss:  5.338764190673828\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  177\n",
            "Train Loss:  4.3967180252075195\n",
            "Test Loss:  5.338345527648926\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  178\n",
            "Train Loss:  4.392861366271973\n",
            "Test Loss:  5.337923049926758\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  179\n",
            "Train Loss:  4.389033794403076\n",
            "Test Loss:  5.337502479553223\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  180\n",
            "Train Loss:  4.385235786437988\n",
            "Test Loss:  5.337098121643066\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  181\n",
            "Train Loss:  4.381464004516602\n",
            "Test Loss:  5.336694717407227\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  182\n",
            "Train Loss:  4.377712726593018\n",
            "Test Loss:  5.3362932205200195\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  183\n",
            "Train Loss:  4.373980522155762\n",
            "Test Loss:  5.335898399353027\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  184\n",
            "Train Loss:  4.370269775390625\n",
            "Test Loss:  5.335495948791504\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  185\n",
            "Train Loss:  4.366580963134766\n",
            "Test Loss:  5.33509635925293\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  186\n",
            "Train Loss:  4.362914562225342\n",
            "Test Loss:  5.33471155166626\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  187\n",
            "Train Loss:  4.359271049499512\n",
            "Test Loss:  5.334336280822754\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  188\n",
            "Train Loss:  4.35565185546875\n",
            "Test Loss:  5.3339691162109375\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  189\n",
            "Train Loss:  4.352054119110107\n",
            "Test Loss:  5.3336076736450195\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  190\n",
            "Train Loss:  4.348476886749268\n",
            "Test Loss:  5.333242416381836\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  191\n",
            "Train Loss:  4.344921112060547\n",
            "Test Loss:  5.332880020141602\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  192\n",
            "Train Loss:  4.341388702392578\n",
            "Test Loss:  5.33251428604126\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  193\n",
            "Train Loss:  4.3378801345825195\n",
            "Test Loss:  5.332155704498291\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  194\n",
            "Train Loss:  4.3343963623046875\n",
            "Test Loss:  5.331804275512695\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  195\n",
            "Train Loss:  4.330933570861816\n",
            "Test Loss:  5.331457614898682\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  196\n",
            "Train Loss:  4.3274946212768555\n",
            "Test Loss:  5.331125259399414\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  197\n",
            "Train Loss:  4.3240766525268555\n",
            "Test Loss:  5.330799102783203\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  198\n",
            "Train Loss:  4.320674896240234\n",
            "Test Loss:  5.330485820770264\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  199\n",
            "Train Loss:  4.317291259765625\n",
            "Test Loss:  5.330181121826172\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  200\n",
            "Train Loss:  4.313922882080078\n",
            "Test Loss:  5.3298797607421875\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  201\n",
            "Train Loss:  4.310573101043701\n",
            "Test Loss:  5.3295698165893555\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  202\n",
            "Train Loss:  4.307246208190918\n",
            "Test Loss:  5.3292646408081055\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  203\n",
            "Train Loss:  4.303943157196045\n",
            "Test Loss:  5.328967094421387\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  204\n",
            "Train Loss:  4.300663948059082\n",
            "Test Loss:  5.3286848068237305\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  205\n",
            "Train Loss:  4.297408103942871\n",
            "Test Loss:  5.328410625457764\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  206\n",
            "Train Loss:  4.294170379638672\n",
            "Test Loss:  5.328149795532227\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  207\n",
            "Train Loss:  4.290951728820801\n",
            "Test Loss:  5.327900409698486\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  208\n",
            "Train Loss:  4.287750720977783\n",
            "Test Loss:  5.327661514282227\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  209\n",
            "Train Loss:  4.284564971923828\n",
            "Test Loss:  5.327422142028809\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  210\n",
            "Train Loss:  4.2813944816589355\n",
            "Test Loss:  5.327185153961182\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  211\n",
            "Train Loss:  4.278243541717529\n",
            "Test Loss:  5.3269548416137695\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  212\n",
            "Train Loss:  4.275113105773926\n",
            "Test Loss:  5.326743125915527\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  213\n",
            "Train Loss:  4.272005081176758\n",
            "Test Loss:  5.326544761657715\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  214\n",
            "Train Loss:  4.268917083740234\n",
            "Test Loss:  5.326360702514648\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  215\n",
            "Train Loss:  4.265851020812988\n",
            "Test Loss:  5.326188564300537\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  216\n",
            "Train Loss:  4.262804985046387\n",
            "Test Loss:  5.326030731201172\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  217\n",
            "Train Loss:  4.259780406951904\n",
            "Test Loss:  5.32589054107666\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  218\n",
            "Train Loss:  4.256773948669434\n",
            "Test Loss:  5.325760841369629\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  219\n",
            "Train Loss:  4.253786087036133\n",
            "Test Loss:  5.325638771057129\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  220\n",
            "Train Loss:  4.250819206237793\n",
            "Test Loss:  5.325536727905273\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  221\n",
            "Train Loss:  4.247876167297363\n",
            "Test Loss:  5.325445175170898\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  222\n",
            "Train Loss:  4.244955062866211\n",
            "Test Loss:  5.32536506652832\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  223\n",
            "Train Loss:  4.242055892944336\n",
            "Test Loss:  5.325298309326172\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  224\n",
            "Train Loss:  4.239174842834473\n",
            "Test Loss:  5.325239181518555\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  225\n",
            "Train Loss:  4.23631477355957\n",
            "Test Loss:  5.325197219848633\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  226\n",
            "Train Loss:  4.233473777770996\n",
            "Test Loss:  5.325159072875977\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  227\n",
            "Train Loss:  4.23065185546875\n",
            "Test Loss:  5.325129508972168\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  228\n",
            "Train Loss:  4.227849960327148\n",
            "Test Loss:  5.325108528137207\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  229\n",
            "Train Loss:  4.225067138671875\n",
            "Test Loss:  5.325100898742676\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  230\n",
            "Train Loss:  4.222295761108398\n",
            "Test Loss:  5.325102806091309\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  231\n",
            "Train Loss:  4.219540596008301\n",
            "Test Loss:  5.325117588043213\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  232\n",
            "Train Loss:  4.216799736022949\n",
            "Test Loss:  5.325143337249756\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  233\n",
            "Train Loss:  4.214077949523926\n",
            "Test Loss:  5.325178623199463\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  234\n",
            "Train Loss:  4.211373329162598\n",
            "Test Loss:  5.325221538543701\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  235\n",
            "Train Loss:  4.20868444442749\n",
            "Test Loss:  5.325270175933838\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  236\n",
            "Train Loss:  4.2060136795043945\n",
            "Test Loss:  5.325331211090088\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  237\n",
            "Train Loss:  4.203363418579102\n",
            "Test Loss:  5.325401306152344\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  238\n",
            "Train Loss:  4.200732231140137\n",
            "Test Loss:  5.325475215911865\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  239\n",
            "Train Loss:  4.198118209838867\n",
            "Test Loss:  5.325552940368652\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  240\n",
            "Train Loss:  4.195519924163818\n",
            "Test Loss:  5.325634002685547\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  241\n",
            "Train Loss:  4.192934036254883\n",
            "Test Loss:  5.32572078704834\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  242\n",
            "Train Loss:  4.190361022949219\n",
            "Test Loss:  5.325816631317139\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  243\n",
            "Train Loss:  4.187806129455566\n",
            "Test Loss:  5.325913429260254\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  244\n",
            "Train Loss:  4.185266494750977\n",
            "Test Loss:  5.326013565063477\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  245\n",
            "Train Loss:  4.182743072509766\n",
            "Test Loss:  5.326120376586914\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  246\n",
            "Train Loss:  4.180232524871826\n",
            "Test Loss:  5.326230049133301\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  247\n",
            "Train Loss:  4.177739143371582\n",
            "Test Loss:  5.326340198516846\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  248\n",
            "Train Loss:  4.175260543823242\n",
            "Test Loss:  5.326456546783447\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  249\n",
            "Train Loss:  4.172797203063965\n",
            "Test Loss:  5.326578140258789\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  250\n",
            "Train Loss:  4.170348167419434\n",
            "Test Loss:  5.326708793640137\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  251\n",
            "Train Loss:  4.167913436889648\n",
            "Test Loss:  5.326848983764648\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  252\n",
            "Train Loss:  4.165492057800293\n",
            "Test Loss:  5.3269944190979\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  253\n",
            "Train Loss:  4.163084030151367\n",
            "Test Loss:  5.327144145965576\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  254\n",
            "Train Loss:  4.160689353942871\n",
            "Test Loss:  5.327299118041992\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  255\n",
            "Train Loss:  4.15830659866333\n",
            "Test Loss:  5.327457427978516\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  256\n",
            "Train Loss:  4.155939102172852\n",
            "Test Loss:  5.327619552612305\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  257\n",
            "Train Loss:  4.153584957122803\n",
            "Test Loss:  5.327785015106201\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  258\n",
            "Train Loss:  4.151242256164551\n",
            "Test Loss:  5.32795524597168\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  259\n",
            "Train Loss:  4.148910999298096\n",
            "Test Loss:  5.328134536743164\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  260\n",
            "Train Loss:  4.146588325500488\n",
            "Test Loss:  5.328313827514648\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  261\n",
            "Train Loss:  4.144278049468994\n",
            "Test Loss:  5.3285017013549805\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  262\n",
            "Train Loss:  4.141979694366455\n",
            "Test Loss:  5.328692436218262\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  263\n",
            "Train Loss:  4.139693260192871\n",
            "Test Loss:  5.328892230987549\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  264\n",
            "Train Loss:  4.137413501739502\n",
            "Test Loss:  5.3290839195251465\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  265\n",
            "Train Loss:  4.1351423263549805\n",
            "Test Loss:  5.329277992248535\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  266\n",
            "Train Loss:  4.132879734039307\n",
            "Test Loss:  5.329465866088867\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  267\n",
            "Train Loss:  4.1306257247924805\n",
            "Test Loss:  5.329653739929199\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  268\n",
            "Train Loss:  4.128382682800293\n",
            "Test Loss:  5.329840660095215\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  269\n",
            "Train Loss:  4.126148223876953\n",
            "Test Loss:  5.3300299644470215\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  270\n",
            "Train Loss:  4.123920440673828\n",
            "Test Loss:  5.33021354675293\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  271\n",
            "Train Loss:  4.121704578399658\n",
            "Test Loss:  5.33039665222168\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  272\n",
            "Train Loss:  4.1194963455200195\n",
            "Test Loss:  5.330574989318848\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  273\n",
            "Train Loss:  4.11729621887207\n",
            "Test Loss:  5.330757141113281\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  274\n",
            "Train Loss:  4.115103721618652\n",
            "Test Loss:  5.330936431884766\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  275\n",
            "Train Loss:  4.112920761108398\n",
            "Test Loss:  5.331114768981934\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  276\n",
            "Train Loss:  4.110743522644043\n",
            "Test Loss:  5.331298828125\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  277\n",
            "Train Loss:  4.108571529388428\n",
            "Test Loss:  5.33148193359375\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  278\n",
            "Train Loss:  4.106407165527344\n",
            "Test Loss:  5.331666469573975\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  279\n",
            "Train Loss:  4.104254722595215\n",
            "Test Loss:  5.331850528717041\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  280\n",
            "Train Loss:  4.102109909057617\n",
            "Test Loss:  5.332032203674316\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  281\n",
            "Train Loss:  4.099973678588867\n",
            "Test Loss:  5.332217216491699\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  282\n",
            "Train Loss:  4.097846984863281\n",
            "Test Loss:  5.332399845123291\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  283\n",
            "Train Loss:  4.095727920532227\n",
            "Test Loss:  5.332588195800781\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  284\n",
            "Train Loss:  4.093615531921387\n",
            "Test Loss:  5.332776069641113\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  285\n",
            "Train Loss:  4.091512203216553\n",
            "Test Loss:  5.3329572677612305\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  286\n",
            "Train Loss:  4.089417457580566\n",
            "Test Loss:  5.33313512802124\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  287\n",
            "Train Loss:  4.08732795715332\n",
            "Test Loss:  5.333303928375244\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  288\n",
            "Train Loss:  4.085244178771973\n",
            "Test Loss:  5.333467960357666\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  289\n",
            "Train Loss:  4.0831685066223145\n",
            "Test Loss:  5.333625793457031\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  290\n",
            "Train Loss:  4.081103324890137\n",
            "Test Loss:  5.333784103393555\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  291\n",
            "Train Loss:  4.079048156738281\n",
            "Test Loss:  5.333944320678711\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  292\n",
            "Train Loss:  4.077003479003906\n",
            "Test Loss:  5.334096908569336\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  293\n",
            "Train Loss:  4.074968338012695\n",
            "Test Loss:  5.334242820739746\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  294\n",
            "Train Loss:  4.072942733764648\n",
            "Test Loss:  5.334386825561523\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  295\n",
            "Train Loss:  4.070930004119873\n",
            "Test Loss:  5.334525108337402\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  296\n",
            "Train Loss:  4.068926811218262\n",
            "Test Loss:  5.334664344787598\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  297\n",
            "Train Loss:  4.066932678222656\n",
            "Test Loss:  5.334804058074951\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  298\n",
            "Train Loss:  4.064948558807373\n",
            "Test Loss:  5.334941864013672\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  299\n",
            "Train Loss:  4.0629730224609375\n",
            "Test Loss:  5.335081100463867\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  300\n",
            "Train Loss:  4.061006546020508\n",
            "Test Loss:  5.335219383239746\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  301\n",
            "Train Loss:  4.059052467346191\n",
            "Test Loss:  5.335357189178467\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  302\n",
            "Train Loss:  4.057107925415039\n",
            "Test Loss:  5.335496425628662\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  303\n",
            "Train Loss:  4.055171966552734\n",
            "Test Loss:  5.33563756942749\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  304\n",
            "Train Loss:  4.053244113922119\n",
            "Test Loss:  5.335778713226318\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  305\n",
            "Train Loss:  4.051324844360352\n",
            "Test Loss:  5.335915565490723\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  306\n",
            "Train Loss:  4.049415111541748\n",
            "Test Loss:  5.3360443115234375\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  307\n",
            "Train Loss:  4.047515392303467\n",
            "Test Loss:  5.3361711502075195\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  308\n",
            "Train Loss:  4.045624732971191\n",
            "Test Loss:  5.336292266845703\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  309\n",
            "Train Loss:  4.043745994567871\n",
            "Test Loss:  5.336408615112305\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  310\n",
            "Train Loss:  4.041879653930664\n",
            "Test Loss:  5.336521148681641\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  311\n",
            "Train Loss:  4.04002571105957\n",
            "Test Loss:  5.336633682250977\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  312\n",
            "Train Loss:  4.038183212280273\n",
            "Test Loss:  5.336748123168945\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  313\n",
            "Train Loss:  4.03635311126709\n",
            "Test Loss:  5.336867332458496\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  314\n",
            "Train Loss:  4.034534454345703\n",
            "Test Loss:  5.336984634399414\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  315\n",
            "Train Loss:  4.032731056213379\n",
            "Test Loss:  5.337099075317383\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  316\n",
            "Train Loss:  4.030941009521484\n",
            "Test Loss:  5.337213516235352\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  317\n",
            "Train Loss:  4.0291643142700195\n",
            "Test Loss:  5.337325096130371\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  318\n",
            "Train Loss:  4.027397155761719\n",
            "Test Loss:  5.337438583374023\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  319\n",
            "Train Loss:  4.025641441345215\n",
            "Test Loss:  5.337552547454834\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  320\n",
            "Train Loss:  4.023896217346191\n",
            "Test Loss:  5.3376641273498535\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  321\n",
            "Train Loss:  4.022162437438965\n",
            "Test Loss:  5.337770938873291\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  322\n",
            "Train Loss:  4.020441055297852\n",
            "Test Loss:  5.337880611419678\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  323\n",
            "Train Loss:  4.01873254776001\n",
            "Test Loss:  5.3379926681518555\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  324\n",
            "Train Loss:  4.017033576965332\n",
            "Test Loss:  5.338105201721191\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  325\n",
            "Train Loss:  4.015348434448242\n",
            "Test Loss:  5.3382134437561035\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  326\n",
            "Train Loss:  4.013674736022949\n",
            "Test Loss:  5.338319301605225\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  327\n",
            "Train Loss:  4.012012958526611\n",
            "Test Loss:  5.3384222984313965\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  328\n",
            "Train Loss:  4.0103631019592285\n",
            "Test Loss:  5.338521957397461\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  329\n",
            "Train Loss:  4.008725166320801\n",
            "Test Loss:  5.338619709014893\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  330\n",
            "Train Loss:  4.00709867477417\n",
            "Test Loss:  5.338718414306641\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  331\n",
            "Train Loss:  4.005483150482178\n",
            "Test Loss:  5.338817119598389\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  332\n",
            "Train Loss:  4.003878593444824\n",
            "Test Loss:  5.338917255401611\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  333\n",
            "Train Loss:  4.002285957336426\n",
            "Test Loss:  5.339015960693359\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  334\n",
            "Train Loss:  4.0007004737854\n",
            "Test Loss:  5.339113235473633\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  335\n",
            "Train Loss:  3.9991257190704346\n",
            "Test Loss:  5.339205265045166\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  336\n",
            "Train Loss:  3.997560501098633\n",
            "Test Loss:  5.339295864105225\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  337\n",
            "Train Loss:  3.9960060119628906\n",
            "Test Loss:  5.33939266204834\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  338\n",
            "Train Loss:  3.994462013244629\n",
            "Test Loss:  5.3394927978515625\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  339\n",
            "Train Loss:  3.9929275512695312\n",
            "Test Loss:  5.339593410491943\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  340\n",
            "Train Loss:  3.9914023876190186\n",
            "Test Loss:  5.339692115783691\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  341\n",
            "Train Loss:  3.989889144897461\n",
            "Test Loss:  5.339786529541016\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  342\n",
            "Train Loss:  3.9883859157562256\n",
            "Test Loss:  5.339879035949707\n",
            "Recall : 0.16\n",
            "Epoch  343\n",
            "Train Loss:  3.986891269683838\n",
            "Test Loss:  5.339972496032715\n",
            "Recall : 0.16\n",
            "Epoch  344\n",
            "Train Loss:  3.9854066371917725\n",
            "Test Loss:  5.34006929397583\n",
            "Recall : 0.16\n",
            "Epoch  345\n",
            "Train Loss:  3.9839296340942383\n",
            "Test Loss:  5.340165138244629\n",
            "Recall : 0.16\n",
            "Epoch  346\n",
            "Train Loss:  3.9824585914611816\n",
            "Test Loss:  5.3402557373046875\n",
            "Recall : 0.16\n",
            "Epoch  347\n",
            "Train Loss:  3.9809927940368652\n",
            "Test Loss:  5.3403425216674805\n",
            "Recall : 0.16\n",
            "Epoch  348\n",
            "Train Loss:  3.9795379638671875\n",
            "Test Loss:  5.340427398681641\n",
            "Recall : 0.16\n",
            "Epoch  349\n",
            "Train Loss:  3.9780900478363037\n",
            "Test Loss:  5.340511322021484\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  350\n",
            "Train Loss:  3.976649045944214\n",
            "Test Loss:  5.340595722198486\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  351\n",
            "Train Loss:  3.975213050842285\n",
            "Test Loss:  5.340677261352539\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  352\n",
            "Train Loss:  3.973782539367676\n",
            "Test Loss:  5.340758323669434\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  353\n",
            "Train Loss:  3.9723567962646484\n",
            "Test Loss:  5.340838432312012\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  354\n",
            "Train Loss:  3.9709396362304688\n",
            "Test Loss:  5.34091854095459\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  355\n",
            "Train Loss:  3.96952486038208\n",
            "Test Loss:  5.340998649597168\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  356\n",
            "Train Loss:  3.9681167602539062\n",
            "Test Loss:  5.34107780456543\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  357\n",
            "Train Loss:  3.966714382171631\n",
            "Test Loss:  5.341146469116211\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  358\n",
            "Train Loss:  3.9653186798095703\n",
            "Test Loss:  5.341211318969727\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  359\n",
            "Train Loss:  3.963925361633301\n",
            "Test Loss:  5.341272354125977\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  360\n",
            "Train Loss:  3.9625353813171387\n",
            "Test Loss:  5.341333866119385\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  361\n",
            "Train Loss:  3.9611501693725586\n",
            "Test Loss:  5.341394424438477\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  362\n",
            "Train Loss:  3.959768772125244\n",
            "Test Loss:  5.341452121734619\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  363\n",
            "Train Loss:  3.958392858505249\n",
            "Test Loss:  5.3415045738220215\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  364\n",
            "Train Loss:  3.9570212364196777\n",
            "Test Loss:  5.341558456420898\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  365\n",
            "Train Loss:  3.9556527137756348\n",
            "Test Loss:  5.341609477996826\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  366\n",
            "Train Loss:  3.9542887210845947\n",
            "Test Loss:  5.341656684875488\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  367\n",
            "Train Loss:  3.952929973602295\n",
            "Test Loss:  5.341701984405518\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  368\n",
            "Train Loss:  3.9515748023986816\n",
            "Test Loss:  5.341749668121338\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  369\n",
            "Train Loss:  3.9502224922180176\n",
            "Test Loss:  5.341793060302734\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  370\n",
            "Train Loss:  3.94887375831604\n",
            "Test Loss:  5.341831684112549\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  371\n",
            "Train Loss:  3.9475276470184326\n",
            "Test Loss:  5.341864585876465\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  372\n",
            "Train Loss:  3.9461870193481445\n",
            "Test Loss:  5.341891288757324\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  373\n",
            "Train Loss:  3.9448487758636475\n",
            "Test Loss:  5.341913223266602\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  374\n",
            "Train Loss:  3.943511962890625\n",
            "Test Loss:  5.341935634613037\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  375\n",
            "Train Loss:  3.9421796798706055\n",
            "Test Loss:  5.341958045959473\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  376\n",
            "Train Loss:  3.9408507347106934\n",
            "Test Loss:  5.34197998046875\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  377\n",
            "Train Loss:  3.9395227432250977\n",
            "Test Loss:  5.341999053955078\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  378\n",
            "Train Loss:  3.938197612762451\n",
            "Test Loss:  5.342018127441406\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  379\n",
            "Train Loss:  3.936875820159912\n",
            "Test Loss:  5.342035293579102\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  380\n",
            "Train Loss:  3.9355568885803223\n",
            "Test Loss:  5.342046737670898\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  381\n",
            "Train Loss:  3.9342398643493652\n",
            "Test Loss:  5.342055797576904\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  382\n",
            "Train Loss:  3.932925224304199\n",
            "Test Loss:  5.342061519622803\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  383\n",
            "Train Loss:  3.931612968444824\n",
            "Test Loss:  5.342062950134277\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  384\n",
            "Train Loss:  3.9303030967712402\n",
            "Test Loss:  5.342066287994385\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  385\n",
            "Train Loss:  3.9289956092834473\n",
            "Test Loss:  5.3420634269714355\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  386\n",
            "Train Loss:  3.92769193649292\n",
            "Test Loss:  5.3420586585998535\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  387\n",
            "Train Loss:  3.926389217376709\n",
            "Test Loss:  5.342053413391113\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  388\n",
            "Train Loss:  3.925088882446289\n",
            "Test Loss:  5.342044830322266\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  389\n",
            "Train Loss:  3.9237911701202393\n",
            "Test Loss:  5.342034816741943\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  390\n",
            "Train Loss:  3.922494411468506\n",
            "Test Loss:  5.342024326324463\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  391\n",
            "Train Loss:  3.921200752258301\n",
            "Test Loss:  5.342013359069824\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  392\n",
            "Train Loss:  3.9199092388153076\n",
            "Test Loss:  5.341998100280762\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  393\n",
            "Train Loss:  3.9186203479766846\n",
            "Test Loss:  5.34197998046875\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  394\n",
            "Train Loss:  3.9173340797424316\n",
            "Test Loss:  5.341960906982422\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  395\n",
            "Train Loss:  3.9160499572753906\n",
            "Test Loss:  5.341939449310303\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  396\n",
            "Train Loss:  3.9147706031799316\n",
            "Test Loss:  5.341917037963867\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  397\n",
            "Train Loss:  3.913494110107422\n",
            "Test Loss:  5.341894626617432\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  398\n",
            "Train Loss:  3.912224292755127\n",
            "Test Loss:  5.341867446899414\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  399\n",
            "Train Loss:  3.9109582901000977\n",
            "Test Loss:  5.341835021972656\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  400\n",
            "Train Loss:  3.9096953868865967\n",
            "Test Loss:  5.341798782348633\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  401\n",
            "Train Loss:  3.908435583114624\n",
            "Test Loss:  5.341760635375977\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  402\n",
            "Train Loss:  3.907176971435547\n",
            "Test Loss:  5.34172248840332\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  403\n",
            "Train Loss:  3.9059224128723145\n",
            "Test Loss:  5.341686248779297\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  404\n",
            "Train Loss:  3.9046716690063477\n",
            "Test Loss:  5.341652870178223\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  405\n",
            "Train Loss:  3.9034249782562256\n",
            "Test Loss:  5.341617584228516\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  406\n",
            "Train Loss:  3.9021835327148438\n",
            "Test Loss:  5.341581344604492\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  407\n",
            "Train Loss:  3.900944471359253\n",
            "Test Loss:  5.341548919677734\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  408\n",
            "Train Loss:  3.8997106552124023\n",
            "Test Loss:  5.341517925262451\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  409\n",
            "Train Loss:  3.8984804153442383\n",
            "Test Loss:  5.341485023498535\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  410\n",
            "Train Loss:  3.8972554206848145\n",
            "Test Loss:  5.34145450592041\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  411\n",
            "Train Loss:  3.89603328704834\n",
            "Test Loss:  5.341425895690918\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  412\n",
            "Train Loss:  3.8948161602020264\n",
            "Test Loss:  5.341401100158691\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  413\n",
            "Train Loss:  3.8936004638671875\n",
            "Test Loss:  5.341372489929199\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  414\n",
            "Train Loss:  3.8923892974853516\n",
            "Test Loss:  5.341346740722656\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  415\n",
            "Train Loss:  3.891183376312256\n",
            "Test Loss:  5.341324806213379\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  416\n",
            "Train Loss:  3.8899827003479004\n",
            "Test Loss:  5.341301918029785\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  417\n",
            "Train Loss:  3.888787031173706\n",
            "Test Loss:  5.341280937194824\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  418\n",
            "Train Loss:  3.8875951766967773\n",
            "Test Loss:  5.341261863708496\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  419\n",
            "Train Loss:  3.8864059448242188\n",
            "Test Loss:  5.341246128082275\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  420\n",
            "Train Loss:  3.885220766067505\n",
            "Test Loss:  5.341231346130371\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  421\n",
            "Train Loss:  3.8840420246124268\n",
            "Test Loss:  5.34121561050415\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  422\n",
            "Train Loss:  3.8828675746917725\n",
            "Test Loss:  5.341198444366455\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  423\n",
            "Train Loss:  3.881697177886963\n",
            "Test Loss:  5.341184139251709\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  424\n",
            "Train Loss:  3.880530595779419\n",
            "Test Loss:  5.341172695159912\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  425\n",
            "Train Loss:  3.8793671131134033\n",
            "Test Loss:  5.341160774230957\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  426\n",
            "Train Loss:  3.8782076835632324\n",
            "Test Loss:  5.341147422790527\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  427\n",
            "Train Loss:  3.877051830291748\n",
            "Test Loss:  5.341135501861572\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  428\n",
            "Train Loss:  3.875899314880371\n",
            "Test Loss:  5.341121673583984\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  429\n",
            "Train Loss:  3.8747501373291016\n",
            "Test Loss:  5.341109275817871\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  430\n",
            "Train Loss:  3.8736066818237305\n",
            "Test Loss:  5.341097831726074\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  431\n",
            "Train Loss:  3.872467041015625\n",
            "Test Loss:  5.341087341308594\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  432\n",
            "Train Loss:  3.8713324069976807\n",
            "Test Loss:  5.341075897216797\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  433\n",
            "Train Loss:  3.8702011108398438\n",
            "Test Loss:  5.341064453125\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  434\n",
            "Train Loss:  3.869074821472168\n",
            "Test Loss:  5.341053485870361\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  435\n",
            "Train Loss:  3.867953062057495\n",
            "Test Loss:  5.34104061126709\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  436\n",
            "Train Loss:  3.866835832595825\n",
            "Test Loss:  5.341029167175293\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  437\n",
            "Train Loss:  3.8657214641571045\n",
            "Test Loss:  5.341021537780762\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  438\n",
            "Train Loss:  3.8646116256713867\n",
            "Test Loss:  5.3410139083862305\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  439\n",
            "Train Loss:  3.8635051250457764\n",
            "Test Loss:  5.34100866317749\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  440\n",
            "Train Loss:  3.8624043464660645\n",
            "Test Loss:  5.341004371643066\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  441\n",
            "Train Loss:  3.86130952835083\n",
            "Test Loss:  5.341001987457275\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  442\n",
            "Train Loss:  3.8602190017700195\n",
            "Test Loss:  5.34099817276001\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  443\n",
            "Train Loss:  3.85913348197937\n",
            "Test Loss:  5.340996742248535\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  444\n",
            "Train Loss:  3.8580527305603027\n",
            "Test Loss:  5.340993881225586\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  445\n",
            "Train Loss:  3.856975793838501\n",
            "Test Loss:  5.3409905433654785\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  446\n",
            "Train Loss:  3.8559036254882812\n",
            "Test Loss:  5.340989112854004\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  447\n",
            "Train Loss:  3.85483455657959\n",
            "Test Loss:  5.340989589691162\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  448\n",
            "Train Loss:  3.8537697792053223\n",
            "Test Loss:  5.340991497039795\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  449\n",
            "Train Loss:  3.8527092933654785\n",
            "Test Loss:  5.340994834899902\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  450\n",
            "Train Loss:  3.851653575897217\n",
            "Test Loss:  5.341001510620117\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  451\n",
            "Train Loss:  3.8506031036376953\n",
            "Test Loss:  5.341007232666016\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  452\n",
            "Train Loss:  3.8495583534240723\n",
            "Test Loss:  5.341014862060547\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  453\n",
            "Train Loss:  3.848517417907715\n",
            "Test Loss:  5.3410186767578125\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  454\n",
            "Train Loss:  3.847480058670044\n",
            "Test Loss:  5.34102725982666\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  455\n",
            "Train Loss:  3.8464465141296387\n",
            "Test Loss:  5.341035842895508\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  456\n",
            "Train Loss:  3.845414876937866\n",
            "Test Loss:  5.341044902801514\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  457\n",
            "Train Loss:  3.8443875312805176\n",
            "Test Loss:  5.341059684753418\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  458\n",
            "Train Loss:  3.8433663845062256\n",
            "Test Loss:  5.341075897216797\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  459\n",
            "Train Loss:  3.842348098754883\n",
            "Test Loss:  5.341094493865967\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  460\n",
            "Train Loss:  3.8413333892822266\n",
            "Test Loss:  5.341114521026611\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  461\n",
            "Train Loss:  3.840322732925415\n",
            "Test Loss:  5.341136932373047\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  462\n",
            "Train Loss:  3.83931565284729\n",
            "Test Loss:  5.341156959533691\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  463\n",
            "Train Loss:  3.8383119106292725\n",
            "Test Loss:  5.341178894042969\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  464\n",
            "Train Loss:  3.837312698364258\n",
            "Test Loss:  5.341202735900879\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  465\n",
            "Train Loss:  3.836315631866455\n",
            "Test Loss:  5.34122371673584\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  466\n",
            "Train Loss:  3.8353238105773926\n",
            "Test Loss:  5.341246128082275\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  467\n",
            "Train Loss:  3.834334373474121\n",
            "Test Loss:  5.3412675857543945\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  468\n",
            "Train Loss:  3.833347797393799\n",
            "Test Loss:  5.341290473937988\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  469\n",
            "Train Loss:  3.8323652744293213\n",
            "Test Loss:  5.341315269470215\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  470\n",
            "Train Loss:  3.8313870429992676\n",
            "Test Loss:  5.341341018676758\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  471\n",
            "Train Loss:  3.830411434173584\n",
            "Test Loss:  5.341368675231934\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  472\n",
            "Train Loss:  3.8294386863708496\n",
            "Test Loss:  5.341397285461426\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  473\n",
            "Train Loss:  3.828469753265381\n",
            "Test Loss:  5.341429233551025\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  474\n",
            "Train Loss:  3.8275036811828613\n",
            "Test Loss:  5.341462135314941\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  475\n",
            "Train Loss:  3.826539993286133\n",
            "Test Loss:  5.341494560241699\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  476\n",
            "Train Loss:  3.825580596923828\n",
            "Test Loss:  5.34152889251709\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  477\n",
            "Train Loss:  3.8246238231658936\n",
            "Test Loss:  5.341561317443848\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  478\n",
            "Train Loss:  3.823668956756592\n",
            "Test Loss:  5.3415937423706055\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  479\n",
            "Train Loss:  3.8227171897888184\n",
            "Test Loss:  5.341628074645996\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  480\n",
            "Train Loss:  3.8217687606811523\n",
            "Test Loss:  5.341663360595703\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  481\n",
            "Train Loss:  3.8208224773406982\n",
            "Test Loss:  5.341701507568359\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  482\n",
            "Train Loss:  3.819877862930298\n",
            "Test Loss:  5.341741561889648\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  483\n",
            "Train Loss:  3.818937301635742\n",
            "Test Loss:  5.34178352355957\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  484\n",
            "Train Loss:  3.8179991245269775\n",
            "Test Loss:  5.341825008392334\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  485\n",
            "Train Loss:  3.817063331604004\n",
            "Test Loss:  5.341867923736572\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  486\n",
            "Train Loss:  3.8161282539367676\n",
            "Test Loss:  5.341911792755127\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  487\n",
            "Train Loss:  3.815195083618164\n",
            "Test Loss:  5.341958045959473\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  488\n",
            "Train Loss:  3.814265251159668\n",
            "Test Loss:  5.342006683349609\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  489\n",
            "Train Loss:  3.813338041305542\n",
            "Test Loss:  5.342058181762695\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  490\n",
            "Train Loss:  3.8124120235443115\n",
            "Test Loss:  5.342110633850098\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  491\n",
            "Train Loss:  3.8114891052246094\n",
            "Test Loss:  5.342162609100342\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  492\n",
            "Train Loss:  3.810567855834961\n",
            "Test Loss:  5.342215061187744\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  493\n",
            "Train Loss:  3.8096494674682617\n",
            "Test Loss:  5.342267036437988\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  494\n",
            "Train Loss:  3.8087339401245117\n",
            "Test Loss:  5.342318534851074\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  495\n",
            "Train Loss:  3.8078227043151855\n",
            "Test Loss:  5.342370986938477\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  496\n",
            "Train Loss:  3.8069121837615967\n",
            "Test Loss:  5.3424248695373535\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  497\n",
            "Train Loss:  3.8060054779052734\n",
            "Test Loss:  5.34248161315918\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  498\n",
            "Train Loss:  3.8051013946533203\n",
            "Test Loss:  5.3425397872924805\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  499\n",
            "Train Loss:  3.8041980266571045\n",
            "Test Loss:  5.342599391937256\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  500\n",
            "Train Loss:  3.803297281265259\n",
            "Test Loss:  5.342658996582031\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  501\n",
            "Train Loss:  3.802398204803467\n",
            "Test Loss:  5.342719078063965\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  502\n",
            "Train Loss:  3.801499366760254\n",
            "Test Loss:  5.342781066894531\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  503\n",
            "Train Loss:  3.8006019592285156\n",
            "Test Loss:  5.342842102050781\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  504\n",
            "Train Loss:  3.79970645904541\n",
            "Test Loss:  5.342906475067139\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  505\n",
            "Train Loss:  3.798814058303833\n",
            "Test Loss:  5.342973709106445\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  506\n",
            "Train Loss:  3.7979209423065186\n",
            "Test Loss:  5.343045234680176\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  507\n",
            "Train Loss:  3.797030210494995\n",
            "Test Loss:  5.343114376068115\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  508\n",
            "Train Loss:  3.796140670776367\n",
            "Test Loss:  5.343183994293213\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  509\n",
            "Train Loss:  3.795252799987793\n",
            "Test Loss:  5.343251705169678\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  510\n",
            "Train Loss:  3.7943663597106934\n",
            "Test Loss:  5.343320369720459\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  511\n",
            "Train Loss:  3.79348087310791\n",
            "Test Loss:  5.343391418457031\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  512\n",
            "Train Loss:  3.7925961017608643\n",
            "Test Loss:  5.343466281890869\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  513\n",
            "Train Loss:  3.791712760925293\n",
            "Test Loss:  5.34354305267334\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  514\n",
            "Train Loss:  3.790830373764038\n",
            "Test Loss:  5.343621253967285\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  515\n",
            "Train Loss:  3.789950370788574\n",
            "Test Loss:  5.343703746795654\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  516\n",
            "Train Loss:  3.7890725135803223\n",
            "Test Loss:  5.343788146972656\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  517\n",
            "Train Loss:  3.788196086883545\n",
            "Test Loss:  5.3438720703125\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  518\n",
            "Train Loss:  3.7873215675354004\n",
            "Test Loss:  5.343957901000977\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  519\n",
            "Train Loss:  3.7864489555358887\n",
            "Test Loss:  5.344046592712402\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  520\n",
            "Train Loss:  3.7855770587921143\n",
            "Test Loss:  5.3441362380981445\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  521\n",
            "Train Loss:  3.7847070693969727\n",
            "Test Loss:  5.344227313995361\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  522\n",
            "Train Loss:  3.783839225769043\n",
            "Test Loss:  5.3443193435668945\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  523\n",
            "Train Loss:  3.782973289489746\n",
            "Test Loss:  5.344411849975586\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  524\n",
            "Train Loss:  3.782109022140503\n",
            "Test Loss:  5.344504356384277\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  525\n",
            "Train Loss:  3.781247615814209\n",
            "Test Loss:  5.344598770141602\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  526\n",
            "Train Loss:  3.780388116836548\n",
            "Test Loss:  5.344692707061768\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  527\n",
            "Train Loss:  3.779531240463257\n",
            "Test Loss:  5.34478759765625\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  528\n",
            "Train Loss:  3.7786765098571777\n",
            "Test Loss:  5.344883441925049\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  529\n",
            "Train Loss:  3.7778244018554688\n",
            "Test Loss:  5.344980239868164\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  530\n",
            "Train Loss:  3.776973247528076\n",
            "Test Loss:  5.345080375671387\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  531\n",
            "Train Loss:  3.7761240005493164\n",
            "Test Loss:  5.345181465148926\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  532\n",
            "Train Loss:  3.7752766609191895\n",
            "Test Loss:  5.345285415649414\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  533\n",
            "Train Loss:  3.7744300365448\n",
            "Test Loss:  5.345391750335693\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  534\n",
            "Train Loss:  3.7735848426818848\n",
            "Test Loss:  5.345498085021973\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  535\n",
            "Train Loss:  3.772742748260498\n",
            "Test Loss:  5.34560489654541\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  536\n",
            "Train Loss:  3.7719008922576904\n",
            "Test Loss:  5.345714092254639\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  537\n",
            "Train Loss:  3.771061420440674\n",
            "Test Loss:  5.345820426940918\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  538\n",
            "Train Loss:  3.7702226638793945\n",
            "Test Loss:  5.345928192138672\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  539\n",
            "Train Loss:  3.769385576248169\n",
            "Test Loss:  5.346036911010742\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  540\n",
            "Train Loss:  3.768550395965576\n",
            "Test Loss:  5.346147537231445\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  541\n",
            "Train Loss:  3.7677175998687744\n",
            "Test Loss:  5.346260070800781\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  542\n",
            "Train Loss:  3.7668862342834473\n",
            "Test Loss:  5.34637451171875\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  543\n",
            "Train Loss:  3.766056537628174\n",
            "Test Loss:  5.346488952636719\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  544\n",
            "Train Loss:  3.7652273178100586\n",
            "Test Loss:  5.3466033935546875\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  545\n",
            "Train Loss:  3.7643990516662598\n",
            "Test Loss:  5.346721649169922\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  546\n",
            "Train Loss:  3.7635724544525146\n",
            "Test Loss:  5.346840858459473\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  547\n",
            "Train Loss:  3.762749195098877\n",
            "Test Loss:  5.346960544586182\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  548\n",
            "Train Loss:  3.7619271278381348\n",
            "Test Loss:  5.347081184387207\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  549\n",
            "Train Loss:  3.7611069679260254\n",
            "Test Loss:  5.347202301025391\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  550\n",
            "Train Loss:  3.7602882385253906\n",
            "Test Loss:  5.347323417663574\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  551\n",
            "Train Loss:  3.7594728469848633\n",
            "Test Loss:  5.347443103790283\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  552\n",
            "Train Loss:  3.758660316467285\n",
            "Test Loss:  5.347567558288574\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  553\n",
            "Train Loss:  3.757850170135498\n",
            "Test Loss:  5.3476881980896\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  554\n",
            "Train Loss:  3.757042407989502\n",
            "Test Loss:  5.347809791564941\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  555\n",
            "Train Loss:  3.7562367916107178\n",
            "Test Loss:  5.347931385040283\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  556\n",
            "Train Loss:  3.7554354667663574\n",
            "Test Loss:  5.348052024841309\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  557\n",
            "Train Loss:  3.754635810852051\n",
            "Test Loss:  5.348174095153809\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  558\n",
            "Train Loss:  3.7538394927978516\n",
            "Test Loss:  5.348295211791992\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  559\n",
            "Train Loss:  3.753045082092285\n",
            "Test Loss:  5.348416328430176\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  560\n",
            "Train Loss:  3.7522530555725098\n",
            "Test Loss:  5.348540306091309\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  561\n",
            "Train Loss:  3.7514636516571045\n",
            "Test Loss:  5.348660945892334\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  562\n",
            "Train Loss:  3.7506752014160156\n",
            "Test Loss:  5.348783493041992\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  563\n",
            "Train Loss:  3.749889373779297\n",
            "Test Loss:  5.348905563354492\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  564\n",
            "Train Loss:  3.749105930328369\n",
            "Test Loss:  5.349030017852783\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  565\n",
            "Train Loss:  3.748323440551758\n",
            "Test Loss:  5.349156856536865\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  566\n",
            "Train Loss:  3.747544288635254\n",
            "Test Loss:  5.349282264709473\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  567\n",
            "Train Loss:  3.7467684745788574\n",
            "Test Loss:  5.34940767288208\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  568\n",
            "Train Loss:  3.745995044708252\n",
            "Test Loss:  5.349535942077637\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  569\n",
            "Train Loss:  3.7452242374420166\n",
            "Test Loss:  5.349664688110352\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  570\n",
            "Train Loss:  3.7444558143615723\n",
            "Test Loss:  5.349795818328857\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  571\n",
            "Train Loss:  3.7436904907226562\n",
            "Test Loss:  5.34992790222168\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  572\n",
            "Train Loss:  3.742926597595215\n",
            "Test Loss:  5.350060939788818\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  573\n",
            "Train Loss:  3.742166042327881\n",
            "Test Loss:  5.350193023681641\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  574\n",
            "Train Loss:  3.7414088249206543\n",
            "Test Loss:  5.3503241539001465\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  575\n",
            "Train Loss:  3.7406535148620605\n",
            "Test Loss:  5.350457191467285\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  576\n",
            "Train Loss:  3.739901542663574\n",
            "Test Loss:  5.350588798522949\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  577\n",
            "Train Loss:  3.7391510009765625\n",
            "Test Loss:  5.35072135925293\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  578\n",
            "Train Loss:  3.738401412963867\n",
            "Test Loss:  5.350851058959961\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  579\n",
            "Train Loss:  3.7376551628112793\n",
            "Test Loss:  5.350979804992676\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  580\n",
            "Train Loss:  3.736910820007324\n",
            "Test Loss:  5.351108551025391\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  581\n",
            "Train Loss:  3.736168384552002\n",
            "Test Loss:  5.3512372970581055\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  582\n",
            "Train Loss:  3.73542857170105\n",
            "Test Loss:  5.351367950439453\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  583\n",
            "Train Loss:  3.734692335128784\n",
            "Test Loss:  5.351498603820801\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  584\n",
            "Train Loss:  3.733957529067993\n",
            "Test Loss:  5.351633071899414\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  585\n",
            "Train Loss:  3.7332265377044678\n",
            "Test Loss:  5.351767063140869\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  586\n",
            "Train Loss:  3.732497215270996\n",
            "Test Loss:  5.351902008056641\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  587\n",
            "Train Loss:  3.731771945953369\n",
            "Test Loss:  5.352039337158203\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  588\n",
            "Train Loss:  3.7310492992401123\n",
            "Test Loss:  5.352176666259766\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  589\n",
            "Train Loss:  3.7303271293640137\n",
            "Test Loss:  5.352316856384277\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  590\n",
            "Train Loss:  3.729607105255127\n",
            "Test Loss:  5.352456569671631\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  591\n",
            "Train Loss:  3.728888511657715\n",
            "Test Loss:  5.352599143981934\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  592\n",
            "Train Loss:  3.728172540664673\n",
            "Test Loss:  5.3527421951293945\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  593\n",
            "Train Loss:  3.7274580001831055\n",
            "Test Loss:  5.352887153625488\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  594\n",
            "Train Loss:  3.7267463207244873\n",
            "Test Loss:  5.353033065795898\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  595\n",
            "Train Loss:  3.7260355949401855\n",
            "Test Loss:  5.353178977966309\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  596\n",
            "Train Loss:  3.725325584411621\n",
            "Test Loss:  5.353323936462402\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  597\n",
            "Train Loss:  3.7246193885803223\n",
            "Test Loss:  5.353468894958496\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  598\n",
            "Train Loss:  3.72391414642334\n",
            "Test Loss:  5.353611946105957\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  599\n",
            "Train Loss:  3.723212480545044\n",
            "Test Loss:  5.35375452041626\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  600\n",
            "Train Loss:  3.7225136756896973\n",
            "Test Loss:  5.353896141052246\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  601\n",
            "Train Loss:  3.7218151092529297\n",
            "Test Loss:  5.354037284851074\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  602\n",
            "Train Loss:  3.721118450164795\n",
            "Test Loss:  5.354178428649902\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  603\n",
            "Train Loss:  3.7204253673553467\n",
            "Test Loss:  5.3543195724487305\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  604\n",
            "Train Loss:  3.719733715057373\n",
            "Test Loss:  5.354462623596191\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  605\n",
            "Train Loss:  3.7190449237823486\n",
            "Test Loss:  5.354604721069336\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  606\n",
            "Train Loss:  3.718358278274536\n",
            "Test Loss:  5.354746341705322\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  607\n",
            "Train Loss:  3.7176733016967773\n",
            "Test Loss:  5.354887962341309\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  608\n",
            "Train Loss:  3.716991662979126\n",
            "Test Loss:  5.35502815246582\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  609\n",
            "Train Loss:  3.71631121635437\n",
            "Test Loss:  5.355169296264648\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  610\n",
            "Train Loss:  3.715632915496826\n",
            "Test Loss:  5.355310440063477\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  611\n",
            "Train Loss:  3.7149558067321777\n",
            "Test Loss:  5.3554511070251465\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  612\n",
            "Train Loss:  3.7142813205718994\n",
            "Test Loss:  5.3555908203125\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  613\n",
            "Train Loss:  3.7136077880859375\n",
            "Test Loss:  5.355731010437012\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  614\n",
            "Train Loss:  3.7129383087158203\n",
            "Test Loss:  5.355869293212891\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  615\n",
            "Train Loss:  3.712270736694336\n",
            "Test Loss:  5.3560075759887695\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  616\n",
            "Train Loss:  3.7116050720214844\n",
            "Test Loss:  5.356144905090332\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  617\n",
            "Train Loss:  3.71094012260437\n",
            "Test Loss:  5.356283187866211\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  618\n",
            "Train Loss:  3.710278034210205\n",
            "Test Loss:  5.356420516967773\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  619\n",
            "Train Loss:  3.7096171379089355\n",
            "Test Loss:  5.356557369232178\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  620\n",
            "Train Loss:  3.7089576721191406\n",
            "Test Loss:  5.356692790985107\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  621\n",
            "Train Loss:  3.708299160003662\n",
            "Test Loss:  5.356827735900879\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  622\n",
            "Train Loss:  3.7076425552368164\n",
            "Test Loss:  5.356963157653809\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  623\n",
            "Train Loss:  3.7069880962371826\n",
            "Test Loss:  5.357099533081055\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  624\n",
            "Train Loss:  3.7063357830047607\n",
            "Test Loss:  5.357235908508301\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  625\n",
            "Train Loss:  3.705684185028076\n",
            "Test Loss:  5.35737419128418\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  626\n",
            "Train Loss:  3.70503568649292\n",
            "Test Loss:  5.357514381408691\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  627\n",
            "Train Loss:  3.704388380050659\n",
            "Test Loss:  5.357651710510254\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  628\n",
            "Train Loss:  3.7037434577941895\n",
            "Test Loss:  5.357789993286133\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  629\n",
            "Train Loss:  3.7030997276306152\n",
            "Test Loss:  5.357929229736328\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  630\n",
            "Train Loss:  3.702458143234253\n",
            "Test Loss:  5.358067035675049\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  631\n",
            "Train Loss:  3.701817035675049\n",
            "Test Loss:  5.358203887939453\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  632\n",
            "Train Loss:  3.7011783123016357\n",
            "Test Loss:  5.35833740234375\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  633\n",
            "Train Loss:  3.7005419731140137\n",
            "Test Loss:  5.358469009399414\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  634\n",
            "Train Loss:  3.6999080181121826\n",
            "Test Loss:  5.358598709106445\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  635\n",
            "Train Loss:  3.6992757320404053\n",
            "Test Loss:  5.358726501464844\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  636\n",
            "Train Loss:  3.6986441612243652\n",
            "Test Loss:  5.358851432800293\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  637\n",
            "Train Loss:  3.698014497756958\n",
            "Test Loss:  5.358977317810059\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  638\n",
            "Train Loss:  3.6973862648010254\n",
            "Test Loss:  5.359100341796875\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  639\n",
            "Train Loss:  3.696758508682251\n",
            "Test Loss:  5.359224319458008\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  640\n",
            "Train Loss:  3.6961328983306885\n",
            "Test Loss:  5.359349250793457\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  641\n",
            "Train Loss:  3.695507049560547\n",
            "Test Loss:  5.3594746589660645\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  642\n",
            "Train Loss:  3.694882869720459\n",
            "Test Loss:  5.359600067138672\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  643\n",
            "Train Loss:  3.6942596435546875\n",
            "Test Loss:  5.359724998474121\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  644\n",
            "Train Loss:  3.693638801574707\n",
            "Test Loss:  5.359850883483887\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  645\n",
            "Train Loss:  3.693018913269043\n",
            "Test Loss:  5.359973907470703\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  646\n",
            "Train Loss:  3.692401647567749\n",
            "Test Loss:  5.360097408294678\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  647\n",
            "Train Loss:  3.6917855739593506\n",
            "Test Loss:  5.360221862792969\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  648\n",
            "Train Loss:  3.691171169281006\n",
            "Test Loss:  5.360347747802734\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  649\n",
            "Train Loss:  3.6905570030212402\n",
            "Test Loss:  5.360474109649658\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  650\n",
            "Train Loss:  3.6899430751800537\n",
            "Test Loss:  5.360599517822266\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  651\n",
            "Train Loss:  3.6893310546875\n",
            "Test Loss:  5.360724449157715\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  652\n",
            "Train Loss:  3.6887197494506836\n",
            "Test Loss:  5.360845565795898\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  653\n",
            "Train Loss:  3.6881096363067627\n",
            "Test Loss:  5.360966682434082\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  654\n",
            "Train Loss:  3.6875\n",
            "Test Loss:  5.361086845397949\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  655\n",
            "Train Loss:  3.686892032623291\n",
            "Test Loss:  5.361203193664551\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  656\n",
            "Train Loss:  3.6862852573394775\n",
            "Test Loss:  5.361319541931152\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  657\n",
            "Train Loss:  3.685678720474243\n",
            "Test Loss:  5.361435890197754\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  658\n",
            "Train Loss:  3.6850733757019043\n",
            "Test Loss:  5.3615498542785645\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  659\n",
            "Train Loss:  3.6844687461853027\n",
            "Test Loss:  5.361663818359375\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  660\n",
            "Train Loss:  3.6838650703430176\n",
            "Test Loss:  5.361777305603027\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  661\n",
            "Train Loss:  3.683262348175049\n",
            "Test Loss:  5.361888408660889\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  662\n",
            "Train Loss:  3.68265962600708\n",
            "Test Loss:  5.36199951171875\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  663\n",
            "Train Loss:  3.682058811187744\n",
            "Test Loss:  5.3621110916137695\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  664\n",
            "Train Loss:  3.6814589500427246\n",
            "Test Loss:  5.362222671508789\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  665\n",
            "Train Loss:  3.6808605194091797\n",
            "Test Loss:  5.362333297729492\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  666\n",
            "Train Loss:  3.6802635192871094\n",
            "Test Loss:  5.3624444007873535\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  667\n",
            "Train Loss:  3.679666519165039\n",
            "Test Loss:  5.36255407333374\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  668\n",
            "Train Loss:  3.6790695190429688\n",
            "Test Loss:  5.362663745880127\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  669\n",
            "Train Loss:  3.6784732341766357\n",
            "Test Loss:  5.362773418426514\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  670\n",
            "Train Loss:  3.6778762340545654\n",
            "Test Loss:  5.362883567810059\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  671\n",
            "Train Loss:  3.6772799491882324\n",
            "Test Loss:  5.362995147705078\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  672\n",
            "Train Loss:  3.6766836643218994\n",
            "Test Loss:  5.363105773925781\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  673\n",
            "Train Loss:  3.676088333129883\n",
            "Test Loss:  5.363215446472168\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  674\n",
            "Train Loss:  3.6754934787750244\n",
            "Test Loss:  5.3633222579956055\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  675\n",
            "Train Loss:  3.674900531768799\n",
            "Test Loss:  5.36342716217041\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  676\n",
            "Train Loss:  3.6743075847625732\n",
            "Test Loss:  5.363533020019531\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  677\n",
            "Train Loss:  3.673715353012085\n",
            "Test Loss:  5.363639831542969\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  678\n",
            "Train Loss:  3.673123359680176\n",
            "Test Loss:  5.36374568939209\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  679\n",
            "Train Loss:  3.672532796859741\n",
            "Test Loss:  5.36385440826416\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  680\n",
            "Train Loss:  3.671943187713623\n",
            "Test Loss:  5.363965034484863\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  681\n",
            "Train Loss:  3.671353816986084\n",
            "Test Loss:  5.36407470703125\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  682\n",
            "Train Loss:  3.6707661151885986\n",
            "Test Loss:  5.36418342590332\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  683\n",
            "Train Loss:  3.670179605484009\n",
            "Test Loss:  5.364290237426758\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  684\n",
            "Train Loss:  3.66959285736084\n",
            "Test Loss:  5.364396572113037\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  685\n",
            "Train Loss:  3.6690073013305664\n",
            "Test Loss:  5.364501953125\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  686\n",
            "Train Loss:  3.668422222137451\n",
            "Test Loss:  5.36460542678833\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  687\n",
            "Train Loss:  3.6678366661071777\n",
            "Test Loss:  5.364708423614502\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  688\n",
            "Train Loss:  3.667252540588379\n",
            "Test Loss:  5.364809989929199\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  689\n",
            "Train Loss:  3.6666693687438965\n",
            "Test Loss:  5.364912033081055\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  690\n",
            "Train Loss:  3.666086196899414\n",
            "Test Loss:  5.365013599395752\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  691\n",
            "Train Loss:  3.66550350189209\n",
            "Test Loss:  5.365113258361816\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  692\n",
            "Train Loss:  3.6649200916290283\n",
            "Test Loss:  5.365211486816406\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  693\n",
            "Train Loss:  3.664337635040283\n",
            "Test Loss:  5.365309715270996\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  694\n",
            "Train Loss:  3.663755416870117\n",
            "Test Loss:  5.365407466888428\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  695\n",
            "Train Loss:  3.663175106048584\n",
            "Test Loss:  5.365506172180176\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  696\n",
            "Train Loss:  3.662594795227051\n",
            "Test Loss:  5.365602493286133\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  697\n",
            "Train Loss:  3.662015438079834\n",
            "Test Loss:  5.365698337554932\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  698\n",
            "Train Loss:  3.661437511444092\n",
            "Test Loss:  5.365795135498047\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  699\n",
            "Train Loss:  3.660862445831299\n",
            "Test Loss:  5.365890026092529\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  700\n",
            "Train Loss:  3.6602869033813477\n",
            "Test Loss:  5.365983963012695\n",
            "Recall : 0.16952380952380952\n",
            "\n",
            "0.1649183673469388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yc5ZXo8d9R16gXd8mW3HC3wcKYbrqBBIcECCQbQmBhE8Km3RSz2ZBANpvsplwgy1JyKYFQQonBEBOaqTbFNjbuRbZla2TLlq0ujaQpz/3jfWc8kkbWyCozmjnfz0cfz7xtzojh6JnzPkWMMSillIpdCZEOQCml1ODSRK+UUjFOE71SSsU4TfRKKRXjNNErpVSMS4p0AF0VFhaakpKSSIehlFLDyrp1644YY0aE2hd1ib6kpIS1a9dGOgyllBpWRGRfT/u0dKOUUjFOE71SSsU4TfRKKRXjoq5GH4rb7cbpdNLW1hbpUCImLS2NoqIikpOTIx2KUmqYGRaJ3ul0kpWVRUlJCSIS6XCGnDGGo0eP4nQ6KS0tjXQ4SqlhZliUbtra2igoKIjLJA8gIhQUFMT1Nxql1IkbFokeiNsk7xfv718pdeKGRelGKTW0qhvaeGbNfpIShOvPKCE7Lbx7Q/uPtvLCp06MMbR5fKQnJ2KMISstmRvPKiUxIbwGyyZnA29sreaC6aOYW5zbn7cS0Njm5vHVFXR4fMwal8PFM0d3ei2/1OREvnFmCY6U2EmPsfNOBlliYiKzZ8/G4/FQWlrKE088QW7uwHwA4dhAscLCQjIzM2lubh6wayvVV09/sp973toFwMjsNK4pKw7rvEdW7eWx1RUh9508PpeykvywrvO713fw7s4a1lfW88RNp4V1Tm/+sbma372+E4DstCQ22on+t6/v4L2dNYiAf3mOCQUOPjdn7IC8bjQYNqWbSEtPT2fDhg1s3ryZ/Px87rvvvkiHpNSgqaxrpTAzlQQBZ50r7POcda1MG53F8tvODGx78wfn2vvCv05lXav1b21r2Of0GlttKwkCP158Eo1tHhpc7sD2y2ePYe+vL2fznZfYrxt+rMOBJvoTcPrpp1NVVQXA7t27Wbx4MfPnz+fss89m+/btABw6dIgrr7ySuXPnMnfuXFavXg3AF77wBebPn8/MmTN56KGHIvYelDoeZ52LiYUZjM5OY9/RFjxeX4/Htrm9uDqsn/21rRTlOSjKcwT2F+WlA7DnSAvtHm+P1zHG4Orw0trhocr+o1BV76Kl3XPc847H5zOB2PbVtjImJ53SggwAdtc009rhwVnvCsSYmZpEniO51/c83Ay70s2dL29h64HGAb3mjLHZ/PzzM8M61uv18tZbb3HTTTcBcMstt/DAAw8wZcoUPv74Y2699VZWrlzJd77zHc4991yWLVuG1+sNlGIeeeQR8vPzcblcnHrqqXzpS1+ioKBgQN+PUv1VVefitNJ8ROClDQd4f9cR3v/xeWSkdk4ZL392gH99en2nbWdNHkGew6rpZ6UlkZacyMisVO59axf/s3IXf75xAWdP6T731u1/28QzayoDz2eMyWbrwUZm/vw1khKEF751Rp/r9Tc/vpa3th8OPF84MZ/ifOuP0Bf/d3Vge1H+sT9M4/MdPLOmkpXbD/P+T84jNSmxT68ZjYZdoo8Ul8vFvHnzqKqqYvr06Vx00UU0NzezevVqrr766sBx7e3tAKxcuZLHH38csOr7OTk5ANx7770sW7YMgMrKSnbt2qWJXkUVt9fHwQarlXvjWaU8trqC59c5qTjawsyxOZ2OXb+/nrTkBL534VQAEgQ+N2csIsIztywMJNW7vzyPDc56/vsfO9jobAiZ6Nftq2Pa6Cy+cPI4khMTWDxrNK9trqbB5eaet3axsaqhz4l+e3UTc4pyuGz2GADOmlzIzLHZ/OaLs6m3SzfJiQksmXesHn/nklk8umovL204QFWdi4kjMvv0mtFo2CX6cFveA81fo29tbeWSSy7hvvvu44YbbiA3N5cNGzaEdY133nmHN998kw8//BCHw8GiRYu0b7yKOgfr2/AZKMpzMGtcDl8/vYTn1zlx1rm6JXpnXSvj8x1889xJ3a6zcOKxBswZkws5Y3Ihj3ywF2dd97q7MQZnnYuvnDa+07VuPKsUn89w/zu7Q57Xm0aXm4tnjuoW37ULxvd4zrziXL562gRe2nDAKmHFQKIPq0YvIotFZIeIlIvI0hD7zxGRT0XEIyJXBW0/T0Q2BP20icgXBvINDDWHw8G9997L73//exwOB6WlpTz33HOA9WH97LPPALjgggu4//77Aavc09DQQENDA3l5eTgcDrZv385HH30UsfehVCgdHh8/et76DBflW3Vrf/3aWefi9S3V/GL5lsDP+sr6TvX43ozLc/D0J5V8sre20/balg5cbm/gtYIlJAjj8tJ5c+sh7np5K/uOtoT1Wl6foandE3bX0GD+OP70/h5+sXwLd768hfLDTX2+TrToNdGLSCJwH3ApMAO4TkRmdDlsP3AD8FTwRmPM28aYecaYecD5QCvw+gDEHVEnn3wyc+bM4emnn+bJJ5/k4YcfZu7cucycOZOXXnoJgHvuuYe3336b2bNnM3/+fLZu3crixYvxeDxMnz6dpUuXsnDhwgi/E6U6W7uvlo/tJDx9dDYAuY5kMlIScda18utXt/PUx/tZtr6KZeur6PD4OGdKYdjXP+8kq2Tzx5W7Om3398jp6Y/G+dNGcqS5g0dW7e1Uxz+e5jYPANnpfU/0o7LTmFuUw0ZnA8vWV/HY6gr+8tH+Pl8nWoRTulkAlBtj9gCIyDPAEmCr/wBjTIW973i3qa8CXjXGDFx/qSHUtV/7yy+/HHj8j3/8o9vxo0aNCiT9YK+++mrI61dUVPT4WkoNFX/Cfe9H55GXkQJYo7KL8hzsP9pKVZ2Lb5xVwu2XTj+h63/vwqnsOtTMtoOdO1T4u1OGatED/OxzM/jZ52Zw7m/fDrubZmObVYPPTut7hToxQXjptrMCzy+95/0TKh1Fi3B+A+OA4D+hTuBERjBcC/wh1A4RuQW4BWD8+J5rZ0qp/qlt6cDdpdtgTnoyaclWz5Id1U2IwJjctE7HFOWls76yng6vr0+lmlCK8tJ5Y9shqhva8M/ssaO6KbCvt3O3d/kj4fb6qG3p6Hbs3iNWiedEWvShXnfvkRYONXa+p5aekhh2aehIcztenyEtKZEcR3LIfUkJQkFmar/j7WpIbsaKyBhgNvBaqP3GmIeAhwDKysrMUMSkVLx5b2cN1z/ySbftEwocvPuj82hu9/DwB3sZkZVKcmJCl2MyAt0UJ+T3L9FPKMigw+Nj4a/f6rS9ICOFrF6S5ticdFaVH+XdnTWcO9UqA938+Fre2VHT4zn59jeTfsWc7+CNrYc47T87x5yUILz9w0WB3kU9eWlDFd99xuq0IQIrvnM208dYpbFn11by4+c3AtaN4Be/fWaP1zlR4ST6KiB4/HORva0vrgGWGWPcfTwvwBgT1xN7GaN//1T/bLHHn/xyyUwSE6xEvqr8CH/fdJCmNjf7jlqliavnF3U791uLJjF1VCZpyYmcMal/3YGXzBtLcqLg9nb+TJ80uvfeLd9cNInn1jnZeqAxkOg3VzVyWmk+S+aN63Z8Rmoip4zP61e8AP9y7iQmj8zEFxTywQYXf1xZzo7qpl4T/ZYDjaQkJfDdC6bw29d2sO1gYyDRb6lqICMlkZ9ePoOCzP7/UQolnES/BpgiIqVYCf5a4Ct9fJ3rgNv7eE5AWloaR48ejdupiv3z0aelpfV+sFI9cNa1kudI5munlwS2Zacn8fdNB6mqdwVq0P4+58FGZKUet0tiX2SkJnF1mHPndDVpRCZ5juRArK4OL0ea27nhjAl85bTBK/uGev9Hmtv548rysGr3zrpWivLSuemsUn772o5O9xkq61yML8gY1Ph7TfTGGI+I3IZVdkkEHjHGbBGRu4C1xpjlInIqsAzIAz4vIncaY2YCiEgJ1jeCd080yKKiIpxOJzU1PX89i3X+FaaUCuWRD/ayuarhuMd8tOdot/q6//l/vLKNpnaPve34dfJIK8pz8Pb2w/zgrxto6fAEtg21gowU0pITePqTSjY6j/+7/2RvLTPG5gRGCb+4oYoK+x7C+v11YU/2dqLCqtEbY1YAK7psuyPo8Rqskk6ocyuwbuiesOTkZF1ZSakeeH2GX7+6jfTk7jf5giUmSrfW+tRRmcwrzmVfrZV0zp82kpwBuHk5mC6bPYanPtnHmn1WN9CTRmUxf0L/yzN9JSIsmTuO1XuOBGLpSXpKIpfMHAXA5+eO5fWt1YFzstKSuXjGqMGNNdpqv2VlZWbt2rWRDkOpYeNAvYszfrOSX105i6+eNiHS4agIEZF1xpiyUPuG3RQIKrT61g5qWzooLcyIuvsYrg4vlXWt5KQn4+rwMqHAEXUxDqXmdg/VDS5KCzPDXogDrJkY9xxpwdelcbblgFU2iET5Qg0PmuhjgDGGC37/LkdbOvjDNXP54inRVcu/9cl1vB3U/e1P15dx0SB/VY1mX3v4Y9bvr+cHF03lOxdMCfu8Jz/Zz89e3Nzjfv/0u0p1pYk+BjS6PBy1B4xU9WFxh6HiHwzjt/NQU9wmemMM2w9av48dh/o2d8rO6iay0pL4zRfndNuXl5HM+AJt0avQNNHHgMqg7l3+Yd/Rwu31Ud1lNOFwHkreX3WtblxuaxGNvqy4BNZ/5wkFDi6f0737o1LHo4k+ij26ai8f7DoCwKGmNhZNHcnummb+9fwpzBibHTguOHHurmnh5y9t5t8unx6RBRN+8+p2Ko608JNLp1FamEF1Q1unQSYFGSl9TnCxYvXuI/zxrXIACjNT2FHdyE2PrQnsP2VCHt8+b3LIcw/Uu3hnRw2L7XVOleoLTfRR7IF3d+OxRw8ebelgc5U1srGkMKNLorcS58isVFbaw9RPn1TA4llD2/JrbvfwwLu7AZg/IY+bz5kYWPPzJ4unUX7YWrpte/Xwne61P55b62Td/joWlOZz3YJiHl1VwaEm69vOocZ2Vu8+yq2LJoW8Uf3uTusexxmTdZEa1Xea6KNUu8fLocZ2vn/hVETgD2/sDOw7UN+5Reysc5GVmkRRXjqHm6wVrlraT2yNzf6o6jTarzUQG8Dls8cwvsDBr1/dxlvbDuPzGRL60OMkFjjrWjm5OJe//svpAFx58rGb5o+u2sudL2+ltqUj5KRWlbWtJCUIXxmg0akqvmiij0Jtbm9glGNRXjpHW9o77fcnzza3ly0HGthQWc+4vPROA10+3V/HlFGZzBqb02NCdXt9bK5qwOszlBZm9Dpr3oF6F7UtHbR7vMwcm0NKYgJbDjQGFm5ev78+cOy2g41sO9jIK5sOAsdmQyzKc9Dh9XG4qZ3ROb1P6VBV78LnM73OJeK3o7qJpjY3M8Zm40gZ2o/34aY29h89VkbLdSQzeWQWxhi2HGik4mgr54RYQg+OdY18a9thJo7o3ntm84FGxuSmkZQY1lpBSnWiiT4K3fjYGlbvPgpYiX5UdueE6K/J3/PWLu5/xyqVXDh9FIVBEyI9+fF+nvx4Pw9+bT6X9FDXffqT/dzx0hYATi3J47lvntFjTBVHWlj0u3cCz7993iTmFedx8+OdB7clCJwxqZAPyo9w6T3vA1BamBGYDfHYakWtvSZ6Ywxn/mYlALv/87Je+5zvPNTEJXe/B8D1p0/griWzjnv8QLv+4U86laVEYNVPzmfHoSa+8ahViw+VxIO3//iFjT1ef9FJof9IKNUbTfRRyJ/kwVqdflxuOv/1pdn85IVNgFXPbXN7KT98bIGSorx0vn/RVC6fM4bM1CTqW91847E1lB9u5pIeltktP9xMVmoSp00sYF0vQ7grgpZvy0xNovxwM5mp1jeIR24oCyTywsxUxuSk8fw6J//x920APH7jgsC5xXbL1Vnnoqzk+L+H4DnGDze1MSbn+HOw+H8f/viGks9n2FPTwufnjuWasiJ2Hmrml69sZU9NC7vtWB7+ehlnTg69GtOkEZksv+1MGlw995ryz3aoVF9poo9yo+3W/LlTR3bafqDeFbjRCdYqOjnpyZwdVBrorYeLs85Fcb6D+RPyeHPbIZrbPWSmhv5IHG48Vj46eXwuzjoXBZmp5GekcP607n3iL5k5OpDog8suwS363lQG1/xrXb0mev81y0ry2FMT3rqiA6WmuZ0Or48FpfmcPWUEpYUZ/PKVrTjrWgP3UM6fNvK4I4LnFOUOYcQqnmiijyKPf1jRbQEFf7liZFbn+vn5v+88GWhKUvfabVFeOq9uPkj54SZ2VDdx0uisTvu3HmjkzMmFgeR79QMfUpyXTl3rsZZ0WUk+l88e06mkUFKQwcd7ajlQ7+qxdt5TWSYtOZHCzFQe/3Af7+6sIS05kd9fPZeR2Wk88WEFyz87EDi2vvVY6/b2v20MLCCRmpTIr66cxYQuI0GddS6y05KYMSab93bWcPUDqwP7po3O5pdfGLxSjrPLUnijs9NITBD+uLIcl9vLuLz0uJ72QUWWJvoo4q+X+/3sc8fWYE9IEH50yUlMHZXFf67YFlgm7cGvzeeNrYc6zTHu99WFE3hxfRUH6l00tnnYVNXQaRGGucW5XF1WzLziXLLSkgI3UKeNziI/I4X9ta08umovyfYfmzE5ady6aBLTxmSz155zZcm8sSHfS3JiAt+/cCqnlnafVfCms0p5f1cNbW4v7+86wkd7a7li7lie+qSSmqY2po6y/iCNyEpl6ugsEkQ42mx9o/D4DB+UH+H9XUdCJvqiPAeXzhrDJvsmM8DBhjae+Ggf/3bZdNJTBmdsgf+bU7Gd6JMSE7j57IlsdFo3qHWQk4okTfRRoussoqHmg/EPppkxNjtwk/KSmaN7vNl6TVkx15QVs2y9k+//9TOmjsriqZsXhjz2zzcu4Iv/a7WAf3XlbOZPyOOxVXv5xctb+czZwNicNFbffkHg+L/8c+/LBn/3wtDzuHxr0SS+tWgSLe0eZv78NZx1rRhjcNa28sVTxnHncW6i+nyGk372asiSlLOulZKCDGYX5fDETcfi8y/jVlXfyuSRWd3OGwj+Mtq43GPfcJZeOm1QXkupvtK+WlGg/HAzKzZVd9p2vMUfRmX1bfHg0dm9LyQR/Hr+Vqm/y9/aitpBmRkxIzWJ/IwU1lbU8ermapraPb2+TkKCMC43nQ2VdWwKWuyh/HATOw81hzzf/94+DLrJPdCcdS4KM1MG7RuDUv2hiT7CjDF8+cEP+fZTn3bafrx+4/6+1LPH5YT1GhPsya4Wz+p5+PyIzFQSxOoSWGj3p5880lrDs6XDy5RRva/neSImj8xk5fbD3Pqk9f7DeZ3JI7P4aE8tS+77gNqWDowxgW8joc4vsUs89729ewAj78xfNlIqGmnpJsL8M0/edFYp15QVU5CZQpvb22PvF7/Pfn4xqSFuwIYyNjedT356AYUZPX8TEBE+tEsz/gFWJYUZvP3DRTS63N1u5A6UP32tLNB1My05kalhJPq7r53Hs2squeuVrew72gJk0Njm4UunFHFNiLVICzJTuXzOGN7YcmjQRuQ661qZFeYfXqWGmib6CPNPFXBqSV6fkmlfl3sbmdX7KNSuA7PAGuw0mHIcycx19K1bYWZqUqA/urPOFeiZdPHMUT0OqlpYms/fNx7kSHM7I0O8z/7w+QxV9a4hn1tIqXBpoo+gw01tXPm/qwBdHaivxtl197te2UqKXcoqPs7v0P/7vfrBD0lNSmDhxALuWjILV4eXbzz2CbUtHVx/egn/tLDnpfie+GgfT3xYgddn2F3TEvj24fUZ3F4T9Ytqq/iliT6C1u+vx+01LCjJH7TSSKzKTE3iO+dPZpc96nTRSSOOW98/tTSfq+YX0dLuYeehJp5dW8mdV8xkx6EmPtpTiwi8/NmB4yb617dUU9PUTp3dv9+RksQYe7zArHE5nD9tZI/nKhVJmugjyN9F8MGvzQ9MIaDC94OLTwr72MzUJH539VyAQLfRoy0dgW6R00dn9zpPfmObh9lFubxnTxn8b5dNZ0Fp/glGr9TQ0UQ/hGqa2llVfoTZRTnUt7r5YFcNmalJ5Dr6Vm9X/eMv41TWtvL3jdbsmqdNzOfPqyv426dORCA3PYXzurTQm1zuQNdT6zpaqlHDgyb6IfR/39zJUx/vZ9a4bHYdaqbd42P+hDwdGj/EivKtBL27poV/bLHGL5RNyOfRVRX84NnPAse9+YNzOg2wamxzk52ezA1nlPDY6oqQN6+Vikaa6IfQPrsboX+lqB9dchI3nlkayZDikr9F//EeawDVXUtmctns0axaej5uj4/t1U188y/rqDhybCStMYZGl4fstGR+fMlJLL10Wq/TJisVLTTRD6GuNeC5Rbk6kjICMlOTyHMk89FeK9FPG52NiDXiFiAzzfrfIniGzXaPjw6vj5z0ZBIShLQE/e+mhg+9AxgGYwxfun81r2+p7v3gHvh8hgP1rsAoVTjWRVANvaI8B5W1Lvtx5/8OBRkppCQm8IuXtwbWan12bSUA2enaNlLDT1iJXkQWi8gOESkXkaUh9p8jIp+KiEdEruqyb7yIvC4i20Rkq4iUDEzoQ6emuZ11++r47jMbTvgaTW0e3F7DlSeP44YzSvjO+ZMpKdC+85Hy3Qum8OWyYr5/4dRAF0k/EeHnV1gzh36wy0r0n+6rA6yVvJQabnptnohIInAfcBHgBNaIyHJjzNagw/YDNwA/DHGJx4FfGWPeEJFMwNfvqIeYv+TSn9ZcY5vV97ooz8H3Lizq5Wg12C6cMYoLZ/SctL962gQe+WBvoNXvrHOxcGK+3oBVw1I4LfoFQLkxZo8xpgN4BlgSfIAxpsIYs5EuSVxEZgBJxpg37OOajTG9Ly0UZfx9rbPTeu4GubummWXrnT2unORfIi47Tb/6DxfF+Q42H2jgz6sr2F3TfNyRt0pFs3CyzjigMui5E+h9MnLLVKBeRP4GlAJvAkuNMd7gg0TkFuAWgPHjx4d56aHjb9FnHSdJXxC04lPFby7vtr/Rn+j7OEeNipw543J4Z0cNP19uLQgzp0gnLVPD02A3L5OAs4GTsco7f8Uq8TwcfJAx5iHgIYCysrLOK3BEAX+i969YdCL8pZvjfStQ0eX7F03lG2eWYoAEgVxHSqRDUuqEhFO6qQKC534tsreFwwlssMs+HuBF4JS+hRh5/nJMY5sn5P4OT++3HRpd1rnaa2P4EBHyMlLIz0jRJK+GtXAS/RpgioiUikgKcC2wPMzrrwFyRWSE/fx8YOtxjo9KVXaL3l9nD/bCOidT//3VbtuC/ezFzfz0xU2Alm6UUkOv10Rvt8RvA14DtgHPGmO2iMhdInIFgIicKiJO4GrgQRHZYp/rxeqJ85aIbAIE+NPgvJXB4y+71LZ00ObudHuB//PcsSHzJ4+35lVfu6+20zHv7aqhtDCDXy6ZqaUbpdSQC6uOYIxZAazosu2OoMdrsEo6oc59A5jTjxgjrrXDS0FGCkdbOjhQ72LiiNDT4d577cnc9vT6QJc8sOr6B+pd/PPZE/na6SVDFLFSSh2jBeMuth5oZPXuI/zTwgmkJSdijMHl9jJ7XA5H99bywLu7GZmVRmZaUrfVl8bkpFGcl84rGw+yevcRzphUyOGmNtxeo13zlFIRo4m+i5+8sJFNVQ2UFGRw4YxRtHt8GAPzinPZcaiJZ9c6ezw3KTGBU0vyeWXjQX66bDNv/3ARBxvaALqNvlRKqaGic910cbDBKrv413Jt7bBq8mNy0vj03y/iqZs7DyE4tSSv0/Ovn1HCzWeXUlXnwucz2n9eKRVxmuiDGGNosrtQVta68Pqssg1AekoiCQnC+PzOJZhZ47oPohlfkEGH10dNc3ugS2aOdqtUSkVI3Cf6w41tlCz9O29tO8Sjqypot/vEP7JqL5P+bQUvrreGDKSnWIl6TE7nmQ5njbUS/dzi3MC24qCFqwMteu1to5SKkLhvZm49aC0C8uiqisAUwqeMz+XT/fXAsVkLHcnW/OOJCcLjNy7AALsONXH5nDFkpyczf8KxEs4ZkwoBcNa20jg2G9DSjVIqcuI+0acmWQm83eOlsc1DSYGDWeNyAon+UJN1M9URtEDIOVOt8V/n2v9e1GUWxJSkBK5bMJ7Xt1TT6PKQkphAalLcf3lSSkVI3Cd6/2pwayrqKMxsYWxueqeFKKob2gFI6+NKUEV56Rxt6eCdHYfJTk/SdWGVUhET983MDu+xeWqONHeQk55MWUk+eY5ke5uV6DNS+vY3cUFpPrmOZCprWzmttGDgAlZKqT6K+xZ9u7vzhGTZacmcMj6P9XdczDUPfMgnFdZ0Bjl9rLGfWpLPhjsuHrA4lVLqRMV9i769y8yTwXPOB99A1VknlVLDlSZ6T+dJyjJTgxO99TgpQUhP7luNXimlokXcN1P9LfpvnjuJCQUOLpg+MrDPP21BRqreTFVKDV+a6O2Rr7ecM5H8jM6LSxTZE5G5OrzdzlNKqeFCSzd2iz5UP3d/N8vgnjlKKTXcaIv+OIl+1tgcThqVxSUzR3Xbp5RSw4Umeo+XxAQhKbF7os/LSOG1758TgaiUUmrgxH3p5lBjO4kJeqNVKRW74jrRe7w+nl/nRPO8UiqWxXWib7F701w2a0yEI1FKqcET14m+ze5aOb/LKlFKKRVL4jrR+5cJdPRxZkqllBpO4jzRW8v8pSfHfecjpVQMi+tE7x/xmq4teqVUDIvvRO/W0o1SKvbFdaL31+h1ZkqlVCyL60Tv0puxSqk4EN+J3q01eqVU7Asr0YvIYhHZISLlIrI0xP5zRORTEfGIyFVd9nlFZIP9s3ygAu+vQ41t3P63TQA4tNeNUiqG9ZrhRCQRuA+4CHACa0RkuTFma9Bh+4EbgB+GuITLGDNvAGIdUHe/uTPwODNNE71SKnaFk+EWAOXGmD0AIvIMsAQIJHpjTIW9b9hM3J6adKxco5OaKaViWTilm3FAZdBzp70tXGkislZEPhKRL4Q6QERusY9ZW1NT04dLn7gsbcUrpeLEUNyMnWCMKQO+AtwtIpO6HmCMecgYU8nF5+QAAA9TSURBVGaMKRsxYsQQhHRsnpt5xblD8npKKRUp4ST6KqA46HmRvS0sxpgq+989wDvAyX2Ib9A0ujykJCbw9M0LIx2KUkoNqnAS/RpgioiUikgKcC0QVu8ZEckTkVT7cSFwJkG1/UhqcLmZUODQrpVKqZjXa6HaGOMRkduA14BE4BFjzBYRuQtYa4xZLiKnAsuAPODzInKnMWYmMB140L5JmwD8pktvnSG1vbqRHz+/kd2Hm0lMEKaMyopUKEopNWTCuiNpjFkBrOiy7Y6gx2uwSjpdz1sNzO5njAPmvZ01bHQ2BJ4XZqZEMBqllBoacTUy1lnn6vS8OM8RoUiUUmroxE2i9/kMKzYd7LStOF8TvVIq9sVNol9fWceR5o5O26ZqjV4pFQfiZtRQTZOV5F/41hlMHpFJU7ubIi3dKKXiQNwk+sY2NwAjs1LJcSST40iOcERKKTU04qZ00+iyEn12uiZ4pVR8iZ9E3+ZBBLJS4+ZLjFJKAfGU6F1uMlOTSNCZKpVScSZ+En2bm+w0LdsopeJP3CT65jaPTk2slIpLcZPoO7w+UpLi5u0qpVRA3GS+Do+PlMS4ebtKKRUQN5nP7fWRrIleKRWH4ibzdXi0dKOUik9xk/k6vEZb9EqpuBQ3mc/t9ZGqLXqlVByKm8zX4fGRnKiDpZRS8SduEr3ejFVKxau4yXx6M1YpFa/iJvN1aIteKRWn4ibz6c1YpVS8ipvMZ92MjZu3q5RSAXGR+bw+g8+giV4pFZfiIvN1eHwAejNWKRWX4iLzdXitRK/96JVS8SguEr3bTvR6M1YpFY/iIvO1a+lGKRXHwsp8IrJYRHaISLmILA2x/xwR+VREPCJyVYj92SLiFJH/GYig+6q6wQXAyOy0SLy8UkpFVK+JXkQSgfuAS4EZwHUiMqPLYfuBG4CnerjML4H3TjzM/nHWWYm+OC89UiEopVTEhNOiXwCUG2P2GGM6gGeAJcEHGGMqjDEbAV/Xk0VkPjAKeH0A4j0h/kQ/LtcRqRCUUipiwkn044DKoOdOe1uvRCQB+D3ww16Ou0VE1orI2pqamnAu3SfOulYKM1NIT0kc8GsrpVS0G+y7k7cCK4wxzuMdZIx5yBhTZowpGzFixIAH4axzMS5PW/NKqfiUFMYxVUBx0PMie1s4TgfOFpFbgUwgRUSajTHdbugOJmedixljs4fyJZVSKmqEk+jXAFNEpBQrwV8LfCWcixtjvup/LCI3AGVDneR9PkNVnYuLZ44aypdVSqmo0WvpxhjjAW4DXgO2Ac8aY7aIyF0icgWAiJwqIk7gauBBEdkymEH3RU1zOx1eH0VaulFKxalwWvQYY1YAK7psuyPo8Rqsks7xrvEY8FifI+ynytpWQLtWKqXiV8wPFfV3rdQWvVIqXsV8oq9t6QCgICMlwpEopVRkxHyi9/jsmSt1nhulVJyK+ezn9hpApyhWSsWvOEj0dos+IebfqlJKhRTz2c/jNSQIJCRoi14pFZ9iPtG7vboouFIqvsV8BnR7jSZ6pVRci/kM6PH5SNIbsUqpOBbziV5LN0qpeBfzGdDtNSTrjVilVByL+UTv8fpI0ha9UiqOxXwGtG7GaoteKRW/4iDRa41eKRXfYj4Dur3a60YpFd9iPtF7fNqPXikV32I+A7q9Pp3nRikV12I+A7q9huQkLd0opeJXzCd6j9dHkrbolVJxLOYzoHavVErFuzhI9Nq9UikV32I+A3p8RkfGKqXiWsxnwJZ2DxkpiZEOQymlIibmE31jm5vs9ORIh6GUUhET04m+3eOlze0jOy0p0qEopVTExHSib2rzAGiLXikV12I60Te63ABkp2miV0rFr7ASvYgsFpEdIlIuIktD7D9HRD4VEY+IXBW0fYK9fYOIbBGRbw5k8L1pDLTotXSjlIpfvWZAEUkE7gMuApzAGhFZbozZGnTYfuAG4IddTj8InG6MaReRTGCzfe6BAYm+F/e/Uw5oi14pFd/CaeouAMqNMXsAROQZYAkQSPTGmAp7ny/4RGNMR9DTVIa4VFTT1A7A7KKcoXxZpZSKKuEk3nFAZdBzp70tLCJSLCIb7Wv811C15sEq3Vw2ezSpSdqPXikVvwa9hW2MqTTGzAEmA18XkVFdjxGRW0RkrYisrampGbDXbnS5tWyjlIp74ST6KqA46HmRva1P7Jb8ZuDsEPseMsaUGWPKRowY0ddL90gHSymlVHiJfg0wRURKRSQFuBZYHs7FRaRIRNLtx3nAWcCOEw22L3SwlFJKWXpN9MYYD3Ab8BqwDXjWGLNFRO4SkSsARORUEXECVwMPisgW+/TpwMci8hnwLvA7Y8ymwXgjXelgKaWUsoTV3DXGrABWdNl2R9DjNVglna7nvQHM6WeMJ6RBB0sppRQQwyNjqxvaABiVnRbhSJRSKrJiNtE761oBKMpLj3AkSikVWTGc6F0kJghjcrRFr5SKbzGb6CtrWxmdnaarSyml4l7MZkFnnUvLNkopRQwn+r1HWijOd0Q6DKWUiriYTPQvbajiaEuHtuiVUooYTfS7DzcD8NXTJkQ4EqWUiryYTPQut5f05ERGZKVGOhSllIq4mEz0rR1eHCk6NbFSSkGMJnpXh5d0TfRKKQXEaqK3SzdKKaViMNF7vD6a2jxaulFKKVtMTda+vbqRxXe/D8C4XO1aqZRSEGMt+u0HmwKPq+pdEYxEKaWiR0wl+hyHzj2vlFJdxVSi93hNpENQSqmoE1OJvt3jDTy++8vzIhiJUkpFj5i6Gdvu9gHw7o8WMaEgI8LRKKVUdIixFr2V6NO0D71SSgXEWKK3SjepSTH1tpRSql9iKiP6W/SpSdqiV0opv9hK9HaNPkVb9EopFRBTGbHd4yU5UUhMkEiHopRSUSPGEr1PyzZKKdVFjCV6r96IVUqpLmIqK7a7fZrolVKqi5jKiu0eH6nah14ppToJK9GLyGIR2SEi5SKyNMT+c0TkUxHxiMhVQdvniciHIrJFRDaKyJcHMviuWju8OlhKKaW66DXRi0gicB9wKTADuE5EZnQ5bD9wA/BUl+2twPXGmJnAYuBuEcntb9A9cbl1wRGllOoqnLluFgDlxpg9ACLyDLAE2Oo/wBhTYe/zBZ9ojNkZ9PiAiBwGRgD1/Y48BFeHl4zUmJq+Ryml+i2c0s04oDLoudPe1icisgBIAXaH2HeLiKwVkbU1NTV9vXSAlm6UUqq7IbkZKyJjgCeAbxhjfF33G2MeMsaUGWPKRowYccKv43J7tXSjlFJdhJPoq4DioOdF9rawiEg28Hfgp8aYj/oWXt+0dmiiV0qprsJJ9GuAKSJSKiIpwLXA8nAubh+/DHjcGPP8iYcZnjYt3SilVDe9JnpjjAe4DXgN2AY8a4zZIiJ3icgVACJyqog4gauBB0Vki336NcA5wA0issH+GZSln4wxtGrpRimlugmri4oxZgWwosu2O4Ier8Eq6XQ97y/AX/oZY1g6vD68PoMjRXvdKKVUsJgZGevqsBYd0dKNUkp1FjOJXhA+N2cMk0dmRjoUpZSKKjFT58hxJPM/Xzkl0mEopVTUiZkWvVJKqdA00SulVIzTRK+UUjFOE71SSsU4TfRKKRXjNNErpVSM00SvlFIxThO9UkrFODHGRDqGTkSkBtjXj0sUAkcGKJzBNpxiheEV73CKFYZXvMMpVhhe8fYn1gnGmJALekRdou8vEVlrjCmLdBzhGE6xwvCKdzjFCsMr3uEUKwyveAcrVi3dKKVUjNNEr5RSMS4WE/1DkQ6gD4ZTrDC84h1OscLwinc4xQrDK95BiTXmavRKKaU6i8UWvVJKqSCa6JVSKsbFTKIXkcUiskNEykVkaaTjARCRR0TksIhsDtqWLyJviMgu+988e7uIyL12/BtFZEhXURGRYhF5W0S2isgWEflulMebJiKfiMhndrx32ttLReRjO66/ikiKvT3Vfl5u7y8ZynjtGBJFZL2IvDIMYq0QkU0iskFE1trbovWzkCsiz4vIdhHZJiKnR3GsJ9m/U/9Po4h8b9DjNcYM+x8gEdgNTARSgM+AGVEQ1znAKcDmoG3/DSy1Hy8F/st+fBnwKiDAQuDjIY51DHCK/TgL2AnMiOJ4Bci0HycDH9txPAtca29/APiW/fhW4AH78bXAXyPwefgB8BTwiv08mmOtAAq7bIvWz8KfgX+2H6cAudEaa5e4E4FqYMJgxxuRNzgIv7DTgdeCnt8O3B7puOxYSrok+h3AGPvxGGCH/fhB4LpQx0Uo7peAi4ZDvIAD+BQ4DWtUYVLXzwXwGnC6/TjJPk6GMMYi4C3gfOAV+3/cqIzVft1QiT7qPgtADrC36+8nGmMNEfvFwKqhiDdWSjfjgMqg5057WzQaZYw5aD+uBkbZj6PmPdilgpOxWslRG69dCtkAHAbewPpWV2+M8YSIKRCvvb8BKBjCcO8Gfgz47OcFRG+sAAZ4XUTWicgt9rZo/CyUAjXAo3ZZ7P+JSEaUxtrVtcDT9uNBjTdWEv2wZKw/0VHVv1VEMoEXgO8ZYxqD90VbvMYYrzFmHlZreQEwLcIhhSQinwMOG2PWRTqWPjjLGHMKcCnwbRE5J3hnFH0WkrDKo/cbY04GWrBKHwFRFGuAfT/mCuC5rvsGI95YSfRVQHHQ8yJ7WzQ6JCJjAOx/D9vbI/4eRCQZK8k/aYz5m705auP1M8bUA29jlT9yRSQpREyBeO39OcDRIQrxTOAKEakAnsEq39wTpbECYIypsv89DCzD+kMajZ8FJ+A0xnxsP38eK/FHY6zBLgU+NcYcsp8ParyxkujXAFPsXgwpWF+Jlkc4pp4sB75uP/46Vi3cv/16+y77QqAh6KvcoBMRAR4Gthlj/jAM4h0hIrn243Ss+wnbsBL+VT3E638fVwEr7ZbToDPG3G6MKTLGlGB9NlcaY74ajbECiEiGiGT5H2PVkjcThZ8FY0w1UCkiJ9mbLgC2RmOsXVzHsbKNP67BizcSNyEG6cbGZVg9RXYDP410PHZMTwMHATdWy+MmrFrrW8Au4E0g3z5WgPvs+DcBZUMc61lYXxc3Ahvsn8uiON45wHo73s3AHfb2icAnQDnW1+JUe3ua/bzc3j8xQp+JRRzrdROVsdpxfWb/bPH//xTFn4V5wFr7s/AikBetsdoxZGB9Q8sJ2jao8eoUCEopFeNipXSjlFKqB5rolVIqxmmiV0qpGKeJXimlYpwmeqWUinGa6JVSKsZpoldKqRj3/wE92YG5iqgmjgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c8b5c563ae0a41d48344646efa6944a2",
            "1f8484db479e40e8b95dd8d9b3433798",
            "057ab59ef19e454a9ee3da401dd49e82",
            "f5ed57283e5e48378630adfb8f186da2",
            "3fb87713508044239033661b70881392",
            "aea5d4202dc94e6f94d820636ecb3eac",
            "63098e9858524743845e41bf86ba8ca4",
            "8a7cb606dd0649e6a6cb5535b676e592"
          ]
        },
        "id": "vgc0glDLUSAp",
        "outputId": "ce04800d-db86-4641-f8b7-c7b5575f470c"
      },
      "source": [
        "run(path=\"resnet152.npy\",runs=1,epochs=700,k=1,temp=15,type=1,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8b5c563ae0a41d48344646efa6944a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.471701622009277\n",
            "Test Loss:  6.384171485900879\n",
            "Recall : 0.11428571428571428\n",
            "Epoch  2\n",
            "Train Loss:  7.397970199584961\n",
            "Test Loss:  6.34316349029541\n",
            "Recall : 0.11714285714285715\n",
            "Epoch  3\n",
            "Train Loss:  7.325364112854004\n",
            "Test Loss:  6.30318546295166\n",
            "Recall : 0.11714285714285715\n",
            "Epoch  4\n",
            "Train Loss:  7.253933429718018\n",
            "Test Loss:  6.264240741729736\n",
            "Recall : 0.11904761904761904\n",
            "Epoch  5\n",
            "Train Loss:  7.183741092681885\n",
            "Test Loss:  6.22642707824707\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  6\n",
            "Train Loss:  7.114833831787109\n",
            "Test Loss:  6.189775466918945\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  7\n",
            "Train Loss:  7.047266006469727\n",
            "Test Loss:  6.154356956481934\n",
            "Recall : 0.1219047619047619\n",
            "Epoch  8\n",
            "Train Loss:  6.9810943603515625\n",
            "Test Loss:  6.120136260986328\n",
            "Recall : 0.12571428571428572\n",
            "Epoch  9\n",
            "Train Loss:  6.9163384437561035\n",
            "Test Loss:  6.087116241455078\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  10\n",
            "Train Loss:  6.852999687194824\n",
            "Test Loss:  6.055340766906738\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  11\n",
            "Train Loss:  6.791059494018555\n",
            "Test Loss:  6.024829864501953\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  12\n",
            "Train Loss:  6.7305097579956055\n",
            "Test Loss:  5.995567321777344\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  13\n",
            "Train Loss:  6.671343803405762\n",
            "Test Loss:  5.967545986175537\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  14\n",
            "Train Loss:  6.613537788391113\n",
            "Test Loss:  5.940732955932617\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  15\n",
            "Train Loss:  6.557100296020508\n",
            "Test Loss:  5.915078163146973\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  16\n",
            "Train Loss:  6.501996040344238\n",
            "Test Loss:  5.890592098236084\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  17\n",
            "Train Loss:  6.448195457458496\n",
            "Test Loss:  5.867223739624023\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  18\n",
            "Train Loss:  6.395658493041992\n",
            "Test Loss:  5.844943046569824\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  19\n",
            "Train Loss:  6.34432315826416\n",
            "Test Loss:  5.823676109313965\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  20\n",
            "Train Loss:  6.294161796569824\n",
            "Test Loss:  5.803402423858643\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  21\n",
            "Train Loss:  6.245136737823486\n",
            "Test Loss:  5.784062385559082\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  22\n",
            "Train Loss:  6.197213649749756\n",
            "Test Loss:  5.7656145095825195\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  23\n",
            "Train Loss:  6.1503448486328125\n",
            "Test Loss:  5.748050689697266\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  24\n",
            "Train Loss:  6.104475975036621\n",
            "Test Loss:  5.731271743774414\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  25\n",
            "Train Loss:  6.059558868408203\n",
            "Test Loss:  5.715248107910156\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  26\n",
            "Train Loss:  6.015570640563965\n",
            "Test Loss:  5.699939250946045\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  27\n",
            "Train Loss:  5.9724860191345215\n",
            "Test Loss:  5.685285568237305\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  28\n",
            "Train Loss:  5.930253505706787\n",
            "Test Loss:  5.671280860900879\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  29\n",
            "Train Loss:  5.888845443725586\n",
            "Test Loss:  5.6579060554504395\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  30\n",
            "Train Loss:  5.848220348358154\n",
            "Test Loss:  5.645078659057617\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  31\n",
            "Train Loss:  5.808347702026367\n",
            "Test Loss:  5.632783889770508\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  32\n",
            "Train Loss:  5.769197463989258\n",
            "Test Loss:  5.621009826660156\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  33\n",
            "Train Loss:  5.730747222900391\n",
            "Test Loss:  5.609724044799805\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  34\n",
            "Train Loss:  5.69295597076416\n",
            "Test Loss:  5.598892688751221\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  35\n",
            "Train Loss:  5.655808448791504\n",
            "Test Loss:  5.588481903076172\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  36\n",
            "Train Loss:  5.619275093078613\n",
            "Test Loss:  5.578482627868652\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  37\n",
            "Train Loss:  5.583349704742432\n",
            "Test Loss:  5.568887710571289\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  38\n",
            "Train Loss:  5.548012733459473\n",
            "Test Loss:  5.559699058532715\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  39\n",
            "Train Loss:  5.513233184814453\n",
            "Test Loss:  5.550882339477539\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  40\n",
            "Train Loss:  5.479010105133057\n",
            "Test Loss:  5.542430877685547\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  41\n",
            "Train Loss:  5.445322036743164\n",
            "Test Loss:  5.534325122833252\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  42\n",
            "Train Loss:  5.412145137786865\n",
            "Test Loss:  5.5265350341796875\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  43\n",
            "Train Loss:  5.3794684410095215\n",
            "Test Loss:  5.519057273864746\n",
            "Recall : 0.16\n",
            "Epoch  44\n",
            "Train Loss:  5.3472747802734375\n",
            "Test Loss:  5.511848449707031\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  45\n",
            "Train Loss:  5.315547943115234\n",
            "Test Loss:  5.504903793334961\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  46\n",
            "Train Loss:  5.2842817306518555\n",
            "Test Loss:  5.498228073120117\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  47\n",
            "Train Loss:  5.253477096557617\n",
            "Test Loss:  5.491803169250488\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  48\n",
            "Train Loss:  5.223118782043457\n",
            "Test Loss:  5.485603332519531\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  49\n",
            "Train Loss:  5.193194389343262\n",
            "Test Loss:  5.479635238647461\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  50\n",
            "Train Loss:  5.163707733154297\n",
            "Test Loss:  5.473910331726074\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  51\n",
            "Train Loss:  5.134649276733398\n",
            "Test Loss:  5.468413352966309\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  52\n",
            "Train Loss:  5.106006622314453\n",
            "Test Loss:  5.46311092376709\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  53\n",
            "Train Loss:  5.077771186828613\n",
            "Test Loss:  5.458009719848633\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  54\n",
            "Train Loss:  5.049932479858398\n",
            "Test Loss:  5.4530839920043945\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  55\n",
            "Train Loss:  5.022489547729492\n",
            "Test Loss:  5.4483418464660645\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  56\n",
            "Train Loss:  4.995429992675781\n",
            "Test Loss:  5.443795204162598\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  57\n",
            "Train Loss:  4.968749046325684\n",
            "Test Loss:  5.439419269561768\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  58\n",
            "Train Loss:  4.942436218261719\n",
            "Test Loss:  5.435207366943359\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  59\n",
            "Train Loss:  4.916487693786621\n",
            "Test Loss:  5.431161880493164\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  60\n",
            "Train Loss:  4.890895843505859\n",
            "Test Loss:  5.427271842956543\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  61\n",
            "Train Loss:  4.865658283233643\n",
            "Test Loss:  5.423529624938965\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  62\n",
            "Train Loss:  4.840766906738281\n",
            "Test Loss:  5.419936180114746\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  63\n",
            "Train Loss:  4.816208839416504\n",
            "Test Loss:  5.416491508483887\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  64\n",
            "Train Loss:  4.791991233825684\n",
            "Test Loss:  5.4131669998168945\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  65\n",
            "Train Loss:  4.7681074142456055\n",
            "Test Loss:  5.409963607788086\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  66\n",
            "Train Loss:  4.74455451965332\n",
            "Test Loss:  5.406883239746094\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  67\n",
            "Train Loss:  4.721323013305664\n",
            "Test Loss:  5.403934001922607\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  68\n",
            "Train Loss:  4.698407173156738\n",
            "Test Loss:  5.401087760925293\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  69\n",
            "Train Loss:  4.675797939300537\n",
            "Test Loss:  5.39832878112793\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  70\n",
            "Train Loss:  4.6534857749938965\n",
            "Test Loss:  5.39566707611084\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  71\n",
            "Train Loss:  4.631473541259766\n",
            "Test Loss:  5.393100738525391\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  72\n",
            "Train Loss:  4.609757900238037\n",
            "Test Loss:  5.390625\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  73\n",
            "Train Loss:  4.58834171295166\n",
            "Test Loss:  5.3882527351379395\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  74\n",
            "Train Loss:  4.5672197341918945\n",
            "Test Loss:  5.385979652404785\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  75\n",
            "Train Loss:  4.546380043029785\n",
            "Test Loss:  5.383798599243164\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  76\n",
            "Train Loss:  4.525820732116699\n",
            "Test Loss:  5.3817138671875\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  77\n",
            "Train Loss:  4.505537986755371\n",
            "Test Loss:  5.379722595214844\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  78\n",
            "Train Loss:  4.4855265617370605\n",
            "Test Loss:  5.377836227416992\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  79\n",
            "Train Loss:  4.4657769203186035\n",
            "Test Loss:  5.376030921936035\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  80\n",
            "Train Loss:  4.446293830871582\n",
            "Test Loss:  5.374298095703125\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  81\n",
            "Train Loss:  4.427076816558838\n",
            "Test Loss:  5.372624397277832\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  82\n",
            "Train Loss:  4.408110618591309\n",
            "Test Loss:  5.37101411819458\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  83\n",
            "Train Loss:  4.389392852783203\n",
            "Test Loss:  5.369464874267578\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  84\n",
            "Train Loss:  4.370920658111572\n",
            "Test Loss:  5.367966651916504\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  85\n",
            "Train Loss:  4.352688789367676\n",
            "Test Loss:  5.366548538208008\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  86\n",
            "Train Loss:  4.3347015380859375\n",
            "Test Loss:  5.365194320678711\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  87\n",
            "Train Loss:  4.316960334777832\n",
            "Test Loss:  5.3639044761657715\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  88\n",
            "Train Loss:  4.299459457397461\n",
            "Test Loss:  5.362689971923828\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  89\n",
            "Train Loss:  4.282179832458496\n",
            "Test Loss:  5.361519813537598\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  90\n",
            "Train Loss:  4.265125274658203\n",
            "Test Loss:  5.360403060913086\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  91\n",
            "Train Loss:  4.248294830322266\n",
            "Test Loss:  5.359358787536621\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  92\n",
            "Train Loss:  4.231681823730469\n",
            "Test Loss:  5.358366012573242\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  93\n",
            "Train Loss:  4.215280532836914\n",
            "Test Loss:  5.3574371337890625\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  94\n",
            "Train Loss:  4.199085712432861\n",
            "Test Loss:  5.3565826416015625\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  95\n",
            "Train Loss:  4.183095932006836\n",
            "Test Loss:  5.355782508850098\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  96\n",
            "Train Loss:  4.167309761047363\n",
            "Test Loss:  5.355030059814453\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  97\n",
            "Train Loss:  4.151732921600342\n",
            "Test Loss:  5.354325294494629\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  98\n",
            "Train Loss:  4.136359691619873\n",
            "Test Loss:  5.35366678237915\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  99\n",
            "Train Loss:  4.121180534362793\n",
            "Test Loss:  5.353052616119385\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  100\n",
            "Train Loss:  4.106191158294678\n",
            "Test Loss:  5.352480888366699\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  101\n",
            "Train Loss:  4.091388702392578\n",
            "Test Loss:  5.351945877075195\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  102\n",
            "Train Loss:  4.076767921447754\n",
            "Test Loss:  5.351454734802246\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  103\n",
            "Train Loss:  4.062328815460205\n",
            "Test Loss:  5.351017475128174\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  104\n",
            "Train Loss:  4.04807186126709\n",
            "Test Loss:  5.350634574890137\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  105\n",
            "Train Loss:  4.033990383148193\n",
            "Test Loss:  5.350296974182129\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  106\n",
            "Train Loss:  4.020079612731934\n",
            "Test Loss:  5.350004196166992\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  107\n",
            "Train Loss:  4.006343841552734\n",
            "Test Loss:  5.349753379821777\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  108\n",
            "Train Loss:  3.992774486541748\n",
            "Test Loss:  5.349542617797852\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  109\n",
            "Train Loss:  3.9793758392333984\n",
            "Test Loss:  5.3493781089782715\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  110\n",
            "Train Loss:  3.9661507606506348\n",
            "Test Loss:  5.349270343780518\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  111\n",
            "Train Loss:  3.953094482421875\n",
            "Test Loss:  5.349213600158691\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  112\n",
            "Train Loss:  3.9401915073394775\n",
            "Test Loss:  5.349192142486572\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  113\n",
            "Train Loss:  3.927445650100708\n",
            "Test Loss:  5.349210262298584\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  114\n",
            "Train Loss:  3.914865016937256\n",
            "Test Loss:  5.349252700805664\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  115\n",
            "Train Loss:  3.90244197845459\n",
            "Test Loss:  5.349332809448242\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  116\n",
            "Train Loss:  3.890164852142334\n",
            "Test Loss:  5.3494415283203125\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  117\n",
            "Train Loss:  3.8780336380004883\n",
            "Test Loss:  5.349573135375977\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  118\n",
            "Train Loss:  3.866049289703369\n",
            "Test Loss:  5.3497209548950195\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  119\n",
            "Train Loss:  3.854210615158081\n",
            "Test Loss:  5.349884033203125\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  120\n",
            "Train Loss:  3.842517375946045\n",
            "Test Loss:  5.350068092346191\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  121\n",
            "Train Loss:  3.83096981048584\n",
            "Test Loss:  5.350263595581055\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  122\n",
            "Train Loss:  3.81956148147583\n",
            "Test Loss:  5.350468635559082\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  123\n",
            "Train Loss:  3.8082971572875977\n",
            "Test Loss:  5.350690841674805\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  124\n",
            "Train Loss:  3.7971689701080322\n",
            "Test Loss:  5.3509321212768555\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  125\n",
            "Train Loss:  3.7861807346343994\n",
            "Test Loss:  5.3512067794799805\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  126\n",
            "Train Loss:  3.7753262519836426\n",
            "Test Loss:  5.351534843444824\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  127\n",
            "Train Loss:  3.7646055221557617\n",
            "Test Loss:  5.351899147033691\n",
            "Recall : 0.18\n",
            "Epoch  128\n",
            "Train Loss:  3.754014015197754\n",
            "Test Loss:  5.352297782897949\n",
            "Recall : 0.18\n",
            "Epoch  129\n",
            "Train Loss:  3.74355411529541\n",
            "Test Loss:  5.352723121643066\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  130\n",
            "Train Loss:  3.7332262992858887\n",
            "Test Loss:  5.353193283081055\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  131\n",
            "Train Loss:  3.7230281829833984\n",
            "Test Loss:  5.353693008422852\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  132\n",
            "Train Loss:  3.712956428527832\n",
            "Test Loss:  5.354227066040039\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  133\n",
            "Train Loss:  3.7030043601989746\n",
            "Test Loss:  5.354811191558838\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  134\n",
            "Train Loss:  3.6931653022766113\n",
            "Test Loss:  5.355442047119141\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  135\n",
            "Train Loss:  3.683440685272217\n",
            "Test Loss:  5.356108665466309\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  136\n",
            "Train Loss:  3.673828601837158\n",
            "Test Loss:  5.356806755065918\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  137\n",
            "Train Loss:  3.6643240451812744\n",
            "Test Loss:  5.357545375823975\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  138\n",
            "Train Loss:  3.654932975769043\n",
            "Test Loss:  5.358315467834473\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  139\n",
            "Train Loss:  3.645646572113037\n",
            "Test Loss:  5.359103202819824\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  140\n",
            "Train Loss:  3.6364595890045166\n",
            "Test Loss:  5.359914779663086\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  141\n",
            "Train Loss:  3.62738037109375\n",
            "Test Loss:  5.360751628875732\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  142\n",
            "Train Loss:  3.618401050567627\n",
            "Test Loss:  5.36159086227417\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  143\n",
            "Train Loss:  3.6095199584960938\n",
            "Test Loss:  5.362445831298828\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  144\n",
            "Train Loss:  3.6007399559020996\n",
            "Test Loss:  5.363315582275391\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  145\n",
            "Train Loss:  3.5920662879943848\n",
            "Test Loss:  5.364198684692383\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  146\n",
            "Train Loss:  3.583500385284424\n",
            "Test Loss:  5.3651018142700195\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  147\n",
            "Train Loss:  3.5750322341918945\n",
            "Test Loss:  5.366024971008301\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  148\n",
            "Train Loss:  3.566661834716797\n",
            "Test Loss:  5.366957664489746\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  149\n",
            "Train Loss:  3.55838680267334\n",
            "Test Loss:  5.367890357971191\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  150\n",
            "Train Loss:  3.55021333694458\n",
            "Test Loss:  5.368828296661377\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  151\n",
            "Train Loss:  3.542135238647461\n",
            "Test Loss:  5.369776725769043\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  152\n",
            "Train Loss:  3.534147024154663\n",
            "Test Loss:  5.370739936828613\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  153\n",
            "Train Loss:  3.526242971420288\n",
            "Test Loss:  5.371703147888184\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  154\n",
            "Train Loss:  3.518425941467285\n",
            "Test Loss:  5.372679710388184\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  155\n",
            "Train Loss:  3.5106966495513916\n",
            "Test Loss:  5.3736701011657715\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  156\n",
            "Train Loss:  3.503053665161133\n",
            "Test Loss:  5.374668598175049\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  157\n",
            "Train Loss:  3.4955015182495117\n",
            "Test Loss:  5.37567138671875\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  158\n",
            "Train Loss:  3.488034248352051\n",
            "Test Loss:  5.376676559448242\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  159\n",
            "Train Loss:  3.480649471282959\n",
            "Test Loss:  5.377702713012695\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  160\n",
            "Train Loss:  3.473339557647705\n",
            "Test Loss:  5.378746032714844\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  161\n",
            "Train Loss:  3.4661028385162354\n",
            "Test Loss:  5.379800796508789\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  162\n",
            "Train Loss:  3.4589409828186035\n",
            "Test Loss:  5.380865097045898\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  163\n",
            "Train Loss:  3.4518537521362305\n",
            "Test Loss:  5.381931304931641\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  164\n",
            "Train Loss:  3.4448394775390625\n",
            "Test Loss:  5.382997512817383\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  165\n",
            "Train Loss:  3.4378936290740967\n",
            "Test Loss:  5.38406229019165\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  166\n",
            "Train Loss:  3.4310178756713867\n",
            "Test Loss:  5.385138034820557\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  167\n",
            "Train Loss:  3.424210786819458\n",
            "Test Loss:  5.386219024658203\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  168\n",
            "Train Loss:  3.4174752235412598\n",
            "Test Loss:  5.387310028076172\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  169\n",
            "Train Loss:  3.410811424255371\n",
            "Test Loss:  5.388404369354248\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  170\n",
            "Train Loss:  3.4042129516601562\n",
            "Test Loss:  5.389500617980957\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  171\n",
            "Train Loss:  3.397679328918457\n",
            "Test Loss:  5.390598773956299\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  172\n",
            "Train Loss:  3.3912081718444824\n",
            "Test Loss:  5.39171838760376\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  173\n",
            "Train Loss:  3.3847920894622803\n",
            "Test Loss:  5.392871379852295\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  174\n",
            "Train Loss:  3.3784430027008057\n",
            "Test Loss:  5.3940510749816895\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  175\n",
            "Train Loss:  3.3721559047698975\n",
            "Test Loss:  5.395251750946045\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  176\n",
            "Train Loss:  3.3659353256225586\n",
            "Test Loss:  5.3964667320251465\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  177\n",
            "Train Loss:  3.3597757816314697\n",
            "Test Loss:  5.397692680358887\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  178\n",
            "Train Loss:  3.353677749633789\n",
            "Test Loss:  5.398916721343994\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  179\n",
            "Train Loss:  3.3476343154907227\n",
            "Test Loss:  5.400162696838379\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  180\n",
            "Train Loss:  3.3416528701782227\n",
            "Test Loss:  5.4014105796813965\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  181\n",
            "Train Loss:  3.3357367515563965\n",
            "Test Loss:  5.402667999267578\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  182\n",
            "Train Loss:  3.329878091812134\n",
            "Test Loss:  5.403941631317139\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  183\n",
            "Train Loss:  3.3240745067596436\n",
            "Test Loss:  5.4052252769470215\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  184\n",
            "Train Loss:  3.318324565887451\n",
            "Test Loss:  5.4065165519714355\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  185\n",
            "Train Loss:  3.3126235008239746\n",
            "Test Loss:  5.407806396484375\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  186\n",
            "Train Loss:  3.306973457336426\n",
            "Test Loss:  5.409099578857422\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  187\n",
            "Train Loss:  3.3013787269592285\n",
            "Test Loss:  5.410400867462158\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  188\n",
            "Train Loss:  3.2958314418792725\n",
            "Test Loss:  5.411695957183838\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  189\n",
            "Train Loss:  3.2903332710266113\n",
            "Test Loss:  5.412975311279297\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  190\n",
            "Train Loss:  3.284883975982666\n",
            "Test Loss:  5.414251327514648\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  191\n",
            "Train Loss:  3.279484510421753\n",
            "Test Loss:  5.41551399230957\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  192\n",
            "Train Loss:  3.2741384506225586\n",
            "Test Loss:  5.416769981384277\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  193\n",
            "Train Loss:  3.2688417434692383\n",
            "Test Loss:  5.418024063110352\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  194\n",
            "Train Loss:  3.2635884284973145\n",
            "Test Loss:  5.419290542602539\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  195\n",
            "Train Loss:  3.258378744125366\n",
            "Test Loss:  5.420584678649902\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  196\n",
            "Train Loss:  3.2532143592834473\n",
            "Test Loss:  5.421895980834961\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  197\n",
            "Train Loss:  3.2480976581573486\n",
            "Test Loss:  5.423232078552246\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  198\n",
            "Train Loss:  3.24302339553833\n",
            "Test Loss:  5.424592018127441\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  199\n",
            "Train Loss:  3.2379865646362305\n",
            "Test Loss:  5.425943374633789\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  200\n",
            "Train Loss:  3.232990026473999\n",
            "Test Loss:  5.427306652069092\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  201\n",
            "Train Loss:  3.228034019470215\n",
            "Test Loss:  5.428664207458496\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  202\n",
            "Train Loss:  3.223118305206299\n",
            "Test Loss:  5.430017471313477\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  203\n",
            "Train Loss:  3.21824312210083\n",
            "Test Loss:  5.431378364562988\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  204\n",
            "Train Loss:  3.2134041786193848\n",
            "Test Loss:  5.432750701904297\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  205\n",
            "Train Loss:  3.2086026668548584\n",
            "Test Loss:  5.4341278076171875\n",
            "Recall : 0.18\n",
            "Epoch  206\n",
            "Train Loss:  3.2038369178771973\n",
            "Test Loss:  5.435516834259033\n",
            "Recall : 0.18\n",
            "Epoch  207\n",
            "Train Loss:  3.1991100311279297\n",
            "Test Loss:  5.436919212341309\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  208\n",
            "Train Loss:  3.1944220066070557\n",
            "Test Loss:  5.438327789306641\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  209\n",
            "Train Loss:  3.1897714138031006\n",
            "Test Loss:  5.439734935760498\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  210\n",
            "Train Loss:  3.18516206741333\n",
            "Test Loss:  5.441136360168457\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  211\n",
            "Train Loss:  3.1805896759033203\n",
            "Test Loss:  5.442525863647461\n",
            "Recall : 0.18\n",
            "Epoch  212\n",
            "Train Loss:  3.176053524017334\n",
            "Test Loss:  5.4439191818237305\n",
            "Recall : 0.18\n",
            "Epoch  213\n",
            "Train Loss:  3.1715502738952637\n",
            "Test Loss:  5.445303916931152\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  214\n",
            "Train Loss:  3.167079210281372\n",
            "Test Loss:  5.446683883666992\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  215\n",
            "Train Loss:  3.162644386291504\n",
            "Test Loss:  5.448055267333984\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  216\n",
            "Train Loss:  3.15824556350708\n",
            "Test Loss:  5.449412822723389\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  217\n",
            "Train Loss:  3.1538829803466797\n",
            "Test Loss:  5.450761795043945\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  218\n",
            "Train Loss:  3.1495556831359863\n",
            "Test Loss:  5.452122688293457\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  219\n",
            "Train Loss:  3.1452581882476807\n",
            "Test Loss:  5.453495025634766\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  220\n",
            "Train Loss:  3.140995740890503\n",
            "Test Loss:  5.454866886138916\n",
            "Recall : 0.18\n",
            "Epoch  221\n",
            "Train Loss:  3.1367664337158203\n",
            "Test Loss:  5.456236839294434\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  222\n",
            "Train Loss:  3.1325693130493164\n",
            "Test Loss:  5.457610130310059\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  223\n",
            "Train Loss:  3.1284008026123047\n",
            "Test Loss:  5.459001541137695\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  224\n",
            "Train Loss:  3.1242594718933105\n",
            "Test Loss:  5.460405349731445\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  225\n",
            "Train Loss:  3.120147228240967\n",
            "Test Loss:  5.461817741394043\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  226\n",
            "Train Loss:  3.1160683631896973\n",
            "Test Loss:  5.463251113891602\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  227\n",
            "Train Loss:  3.112015962600708\n",
            "Test Loss:  5.464714050292969\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  228\n",
            "Train Loss:  3.1079959869384766\n",
            "Test Loss:  5.466200828552246\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  229\n",
            "Train Loss:  3.1040091514587402\n",
            "Test Loss:  5.467702388763428\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  230\n",
            "Train Loss:  3.1000523567199707\n",
            "Test Loss:  5.469211578369141\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  231\n",
            "Train Loss:  3.0961241722106934\n",
            "Test Loss:  5.4707231521606445\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  232\n",
            "Train Loss:  3.0922205448150635\n",
            "Test Loss:  5.472243309020996\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  233\n",
            "Train Loss:  3.088344097137451\n",
            "Test Loss:  5.473767280578613\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  234\n",
            "Train Loss:  3.084493637084961\n",
            "Test Loss:  5.475302696228027\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  235\n",
            "Train Loss:  3.0806689262390137\n",
            "Test Loss:  5.476845741271973\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  236\n",
            "Train Loss:  3.076869010925293\n",
            "Test Loss:  5.478384971618652\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  237\n",
            "Train Loss:  3.073091506958008\n",
            "Test Loss:  5.479935646057129\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  238\n",
            "Train Loss:  3.0693373680114746\n",
            "Test Loss:  5.481480598449707\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  239\n",
            "Train Loss:  3.0656023025512695\n",
            "Test Loss:  5.4830217361450195\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  240\n",
            "Train Loss:  3.0618884563446045\n",
            "Test Loss:  5.484557628631592\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  241\n",
            "Train Loss:  3.058198928833008\n",
            "Test Loss:  5.486091613769531\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  242\n",
            "Train Loss:  3.0545318126678467\n",
            "Test Loss:  5.487628936767578\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  243\n",
            "Train Loss:  3.050882339477539\n",
            "Test Loss:  5.489189624786377\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  244\n",
            "Train Loss:  3.047253131866455\n",
            "Test Loss:  5.490781784057617\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  245\n",
            "Train Loss:  3.043640375137329\n",
            "Test Loss:  5.49240779876709\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  246\n",
            "Train Loss:  3.0400443077087402\n",
            "Test Loss:  5.494053363800049\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  247\n",
            "Train Loss:  3.036468505859375\n",
            "Test Loss:  5.495709419250488\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  248\n",
            "Train Loss:  3.0329127311706543\n",
            "Test Loss:  5.497366905212402\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  249\n",
            "Train Loss:  3.029379367828369\n",
            "Test Loss:  5.499027252197266\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  250\n",
            "Train Loss:  3.025865077972412\n",
            "Test Loss:  5.500683784484863\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  251\n",
            "Train Loss:  3.022369861602783\n",
            "Test Loss:  5.502348899841309\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  252\n",
            "Train Loss:  3.0188915729522705\n",
            "Test Loss:  5.504011154174805\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  253\n",
            "Train Loss:  3.015432834625244\n",
            "Test Loss:  5.5056610107421875\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  254\n",
            "Train Loss:  3.011995553970337\n",
            "Test Loss:  5.507310390472412\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  255\n",
            "Train Loss:  3.008577823638916\n",
            "Test Loss:  5.508954048156738\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  256\n",
            "Train Loss:  3.0051779747009277\n",
            "Test Loss:  5.510595321655273\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  257\n",
            "Train Loss:  3.0017952919006348\n",
            "Test Loss:  5.5122270584106445\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  258\n",
            "Train Loss:  2.998426914215088\n",
            "Test Loss:  5.513845443725586\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  259\n",
            "Train Loss:  2.995077610015869\n",
            "Test Loss:  5.515435218811035\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  260\n",
            "Train Loss:  2.9917502403259277\n",
            "Test Loss:  5.517007827758789\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  261\n",
            "Train Loss:  2.9884440898895264\n",
            "Test Loss:  5.518558502197266\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  262\n",
            "Train Loss:  2.985156536102295\n",
            "Test Loss:  5.520084381103516\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  263\n",
            "Train Loss:  2.981881618499756\n",
            "Test Loss:  5.52162504196167\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  264\n",
            "Train Loss:  2.9786229133605957\n",
            "Test Loss:  5.523175239562988\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  265\n",
            "Train Loss:  2.975383996963501\n",
            "Test Loss:  5.524753093719482\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  266\n",
            "Train Loss:  2.972160816192627\n",
            "Test Loss:  5.5263447761535645\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  267\n",
            "Train Loss:  2.968956232070923\n",
            "Test Loss:  5.527923107147217\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  268\n",
            "Train Loss:  2.9657702445983887\n",
            "Test Loss:  5.52951717376709\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  269\n",
            "Train Loss:  2.9626049995422363\n",
            "Test Loss:  5.531121253967285\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  270\n",
            "Train Loss:  2.9594545364379883\n",
            "Test Loss:  5.532723426818848\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  271\n",
            "Train Loss:  2.956315040588379\n",
            "Test Loss:  5.53431510925293\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  272\n",
            "Train Loss:  2.953188419342041\n",
            "Test Loss:  5.535906791687012\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  273\n",
            "Train Loss:  2.950077533721924\n",
            "Test Loss:  5.537497043609619\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  274\n",
            "Train Loss:  2.946983814239502\n",
            "Test Loss:  5.539085388183594\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  275\n",
            "Train Loss:  2.94390606880188\n",
            "Test Loss:  5.5406694412231445\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  276\n",
            "Train Loss:  2.9408442974090576\n",
            "Test Loss:  5.542255878448486\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  277\n",
            "Train Loss:  2.937793493270874\n",
            "Test Loss:  5.543858051300049\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  278\n",
            "Train Loss:  2.9347524642944336\n",
            "Test Loss:  5.545470237731934\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  279\n",
            "Train Loss:  2.93172550201416\n",
            "Test Loss:  5.547091484069824\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  280\n",
            "Train Loss:  2.9287095069885254\n",
            "Test Loss:  5.548722743988037\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  281\n",
            "Train Loss:  2.925706386566162\n",
            "Test Loss:  5.550372123718262\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  282\n",
            "Train Loss:  2.9227166175842285\n",
            "Test Loss:  5.552038192749023\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  283\n",
            "Train Loss:  2.919745445251465\n",
            "Test Loss:  5.553730010986328\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  284\n",
            "Train Loss:  2.916797161102295\n",
            "Test Loss:  5.555429935455322\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  285\n",
            "Train Loss:  2.9138681888580322\n",
            "Test Loss:  5.557132720947266\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  286\n",
            "Train Loss:  2.910959243774414\n",
            "Test Loss:  5.55885124206543\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  287\n",
            "Train Loss:  2.9080684185028076\n",
            "Test Loss:  5.560585021972656\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  288\n",
            "Train Loss:  2.9051880836486816\n",
            "Test Loss:  5.562341690063477\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  289\n",
            "Train Loss:  2.9023165702819824\n",
            "Test Loss:  5.5641093254089355\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  290\n",
            "Train Loss:  2.899458408355713\n",
            "Test Loss:  5.565885066986084\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  291\n",
            "Train Loss:  2.8966116905212402\n",
            "Test Loss:  5.567667007446289\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  292\n",
            "Train Loss:  2.8937783241271973\n",
            "Test Loss:  5.569453239440918\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  293\n",
            "Train Loss:  2.8909592628479004\n",
            "Test Loss:  5.5712103843688965\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  294\n",
            "Train Loss:  2.8881542682647705\n",
            "Test Loss:  5.572934150695801\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  295\n",
            "Train Loss:  2.885362148284912\n",
            "Test Loss:  5.574642181396484\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  296\n",
            "Train Loss:  2.882575273513794\n",
            "Test Loss:  5.576354026794434\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  297\n",
            "Train Loss:  2.879794120788574\n",
            "Test Loss:  5.578082084655762\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  298\n",
            "Train Loss:  2.8770222663879395\n",
            "Test Loss:  5.5798163414001465\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  299\n",
            "Train Loss:  2.874260425567627\n",
            "Test Loss:  5.581544876098633\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  300\n",
            "Train Loss:  2.8715109825134277\n",
            "Test Loss:  5.583270072937012\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  301\n",
            "Train Loss:  2.8687705993652344\n",
            "Test Loss:  5.585004806518555\n",
            "Recall : 0.18476190476190477\n",
            "Epoch  302\n",
            "Train Loss:  2.866037368774414\n",
            "Test Loss:  5.586751937866211\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  303\n",
            "Train Loss:  2.863312244415283\n",
            "Test Loss:  5.588521957397461\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  304\n",
            "Train Loss:  2.8605995178222656\n",
            "Test Loss:  5.590301513671875\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  305\n",
            "Train Loss:  2.8578972816467285\n",
            "Test Loss:  5.59210205078125\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  306\n",
            "Train Loss:  2.8552098274230957\n",
            "Test Loss:  5.5939178466796875\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  307\n",
            "Train Loss:  2.8525354862213135\n",
            "Test Loss:  5.595715522766113\n",
            "Recall : 0.1838095238095238\n",
            "Epoch  308\n",
            "Train Loss:  2.8498706817626953\n",
            "Test Loss:  5.597503662109375\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  309\n",
            "Train Loss:  2.8472156524658203\n",
            "Test Loss:  5.599266052246094\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  310\n",
            "Train Loss:  2.844573497772217\n",
            "Test Loss:  5.6010284423828125\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  311\n",
            "Train Loss:  2.8419456481933594\n",
            "Test Loss:  5.602823257446289\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  312\n",
            "Train Loss:  2.8393290042877197\n",
            "Test Loss:  5.6046576499938965\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  313\n",
            "Train Loss:  2.8367207050323486\n",
            "Test Loss:  5.60650634765625\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  314\n",
            "Train Loss:  2.834118366241455\n",
            "Test Loss:  5.608375072479248\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  315\n",
            "Train Loss:  2.83152437210083\n",
            "Test Loss:  5.610260009765625\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  316\n",
            "Train Loss:  2.828939437866211\n",
            "Test Loss:  5.612145900726318\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  317\n",
            "Train Loss:  2.826364040374756\n",
            "Test Loss:  5.614025115966797\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  318\n",
            "Train Loss:  2.823795795440674\n",
            "Test Loss:  5.615886211395264\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  319\n",
            "Train Loss:  2.8212356567382812\n",
            "Test Loss:  5.617758750915527\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  320\n",
            "Train Loss:  2.8186821937561035\n",
            "Test Loss:  5.619630813598633\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  321\n",
            "Train Loss:  2.8161392211914062\n",
            "Test Loss:  5.62150764465332\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  322\n",
            "Train Loss:  2.8136062622070312\n",
            "Test Loss:  5.623390197753906\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  323\n",
            "Train Loss:  2.8110852241516113\n",
            "Test Loss:  5.625258445739746\n",
            "Recall : 0.18285714285714286\n",
            "Epoch  324\n",
            "Train Loss:  2.80857515335083\n",
            "Test Loss:  5.6271257400512695\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  325\n",
            "Train Loss:  2.8060734272003174\n",
            "Test Loss:  5.628996849060059\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  326\n",
            "Train Loss:  2.8035809993743896\n",
            "Test Loss:  5.630854606628418\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  327\n",
            "Train Loss:  2.801098346710205\n",
            "Test Loss:  5.6327128410339355\n",
            "Recall : 0.18\n",
            "Epoch  328\n",
            "Train Loss:  2.7986221313476562\n",
            "Test Loss:  5.634568214416504\n",
            "Recall : 0.18\n",
            "Epoch  329\n",
            "Train Loss:  2.796151638031006\n",
            "Test Loss:  5.636419296264648\n",
            "Recall : 0.18\n",
            "Epoch  330\n",
            "Train Loss:  2.793686866760254\n",
            "Test Loss:  5.638291358947754\n",
            "Recall : 0.18\n",
            "Epoch  331\n",
            "Train Loss:  2.7912285327911377\n",
            "Test Loss:  5.64019775390625\n",
            "Recall : 0.18\n",
            "Epoch  332\n",
            "Train Loss:  2.7887768745422363\n",
            "Test Loss:  5.642126560211182\n",
            "Recall : 0.18\n",
            "Epoch  333\n",
            "Train Loss:  2.7863364219665527\n",
            "Test Loss:  5.644070148468018\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  334\n",
            "Train Loss:  2.7839012145996094\n",
            "Test Loss:  5.646056652069092\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  335\n",
            "Train Loss:  2.7814748287200928\n",
            "Test Loss:  5.648097515106201\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  336\n",
            "Train Loss:  2.779053211212158\n",
            "Test Loss:  5.650153160095215\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  337\n",
            "Train Loss:  2.7766380310058594\n",
            "Test Loss:  5.652181625366211\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  338\n",
            "Train Loss:  2.774230718612671\n",
            "Test Loss:  5.654172420501709\n",
            "Recall : 0.18\n",
            "Epoch  339\n",
            "Train Loss:  2.7718276977539062\n",
            "Test Loss:  5.656118869781494\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  340\n",
            "Train Loss:  2.7694289684295654\n",
            "Test Loss:  5.658036231994629\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  341\n",
            "Train Loss:  2.7670340538024902\n",
            "Test Loss:  5.65995979309082\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  342\n",
            "Train Loss:  2.7646467685699463\n",
            "Test Loss:  5.661935329437256\n",
            "Recall : 0.18\n",
            "Epoch  343\n",
            "Train Loss:  2.762266159057617\n",
            "Test Loss:  5.663956165313721\n",
            "Recall : 0.18\n",
            "Epoch  344\n",
            "Train Loss:  2.759889602661133\n",
            "Test Loss:  5.6659932136535645\n",
            "Recall : 0.18\n",
            "Epoch  345\n",
            "Train Loss:  2.7575173377990723\n",
            "Test Loss:  5.668041706085205\n",
            "Recall : 0.18\n",
            "Epoch  346\n",
            "Train Loss:  2.755147933959961\n",
            "Test Loss:  5.670088768005371\n",
            "Recall : 0.18\n",
            "Epoch  347\n",
            "Train Loss:  2.752784013748169\n",
            "Test Loss:  5.67211389541626\n",
            "Recall : 0.18\n",
            "Epoch  348\n",
            "Train Loss:  2.7504234313964844\n",
            "Test Loss:  5.674137115478516\n",
            "Recall : 0.18\n",
            "Epoch  349\n",
            "Train Loss:  2.7480669021606445\n",
            "Test Loss:  5.676156997680664\n",
            "Recall : 0.18\n",
            "Epoch  350\n",
            "Train Loss:  2.7457194328308105\n",
            "Test Loss:  5.678155899047852\n",
            "Recall : 0.18\n",
            "Epoch  351\n",
            "Train Loss:  2.7433791160583496\n",
            "Test Loss:  5.680153846740723\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  352\n",
            "Train Loss:  2.741049289703369\n",
            "Test Loss:  5.682151794433594\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  353\n",
            "Train Loss:  2.7387309074401855\n",
            "Test Loss:  5.684159755706787\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  354\n",
            "Train Loss:  2.736421585083008\n",
            "Test Loss:  5.6861724853515625\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  355\n",
            "Train Loss:  2.7341179847717285\n",
            "Test Loss:  5.688193321228027\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  356\n",
            "Train Loss:  2.7318203449249268\n",
            "Test Loss:  5.690229415893555\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  357\n",
            "Train Loss:  2.729529857635498\n",
            "Test Loss:  5.6922807693481445\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  358\n",
            "Train Loss:  2.727247714996338\n",
            "Test Loss:  5.6943511962890625\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  359\n",
            "Train Loss:  2.724968194961548\n",
            "Test Loss:  5.69644832611084\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  360\n",
            "Train Loss:  2.7226972579956055\n",
            "Test Loss:  5.698581218719482\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  361\n",
            "Train Loss:  2.7204349040985107\n",
            "Test Loss:  5.7007527351379395\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  362\n",
            "Train Loss:  2.71817684173584\n",
            "Test Loss:  5.702930450439453\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  363\n",
            "Train Loss:  2.715924024581909\n",
            "Test Loss:  5.7051005363464355\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  364\n",
            "Train Loss:  2.713669776916504\n",
            "Test Loss:  5.707284927368164\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  365\n",
            "Train Loss:  2.711413621902466\n",
            "Test Loss:  5.7094879150390625\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  366\n",
            "Train Loss:  2.709160804748535\n",
            "Test Loss:  5.711688995361328\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  367\n",
            "Train Loss:  2.7069196701049805\n",
            "Test Loss:  5.713896751403809\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  368\n",
            "Train Loss:  2.704688549041748\n",
            "Test Loss:  5.716090202331543\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  369\n",
            "Train Loss:  2.702467918395996\n",
            "Test Loss:  5.718250274658203\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  370\n",
            "Train Loss:  2.7002575397491455\n",
            "Test Loss:  5.720393180847168\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  371\n",
            "Train Loss:  2.6980550289154053\n",
            "Test Loss:  5.7225494384765625\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  372\n",
            "Train Loss:  2.6958630084991455\n",
            "Test Loss:  5.724710464477539\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  373\n",
            "Train Loss:  2.6936798095703125\n",
            "Test Loss:  5.7268524169921875\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  374\n",
            "Train Loss:  2.691507577896118\n",
            "Test Loss:  5.728960037231445\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  375\n",
            "Train Loss:  2.689345359802246\n",
            "Test Loss:  5.7310333251953125\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  376\n",
            "Train Loss:  2.687190055847168\n",
            "Test Loss:  5.733095169067383\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  377\n",
            "Train Loss:  2.685041904449463\n",
            "Test Loss:  5.7351884841918945\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  378\n",
            "Train Loss:  2.6829023361206055\n",
            "Test Loss:  5.73731803894043\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  379\n",
            "Train Loss:  2.6807656288146973\n",
            "Test Loss:  5.739457130432129\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  380\n",
            "Train Loss:  2.6786317825317383\n",
            "Test Loss:  5.741604804992676\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  381\n",
            "Train Loss:  2.6765036582946777\n",
            "Test Loss:  5.7437334060668945\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  382\n",
            "Train Loss:  2.6743834018707275\n",
            "Test Loss:  5.745821475982666\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  383\n",
            "Train Loss:  2.6722679138183594\n",
            "Test Loss:  5.747871398925781\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  384\n",
            "Train Loss:  2.6701602935791016\n",
            "Test Loss:  5.749890327453613\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  385\n",
            "Train Loss:  2.6680588722229004\n",
            "Test Loss:  5.751925468444824\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  386\n",
            "Train Loss:  2.6659634113311768\n",
            "Test Loss:  5.753972053527832\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  387\n",
            "Train Loss:  2.663874387741089\n",
            "Test Loss:  5.756053924560547\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  388\n",
            "Train Loss:  2.6617958545684814\n",
            "Test Loss:  5.758160591125488\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  389\n",
            "Train Loss:  2.659724712371826\n",
            "Test Loss:  5.760278701782227\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  390\n",
            "Train Loss:  2.657658576965332\n",
            "Test Loss:  5.762388229370117\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  391\n",
            "Train Loss:  2.6555967330932617\n",
            "Test Loss:  5.764472961425781\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  392\n",
            "Train Loss:  2.653542995452881\n",
            "Test Loss:  5.766539096832275\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  393\n",
            "Train Loss:  2.6514952182769775\n",
            "Test Loss:  5.76857852935791\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  394\n",
            "Train Loss:  2.6494550704956055\n",
            "Test Loss:  5.770593643188477\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  395\n",
            "Train Loss:  2.6474246978759766\n",
            "Test Loss:  5.772609710693359\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  396\n",
            "Train Loss:  2.645399570465088\n",
            "Test Loss:  5.774635314941406\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  397\n",
            "Train Loss:  2.643378973007202\n",
            "Test Loss:  5.776660442352295\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  398\n",
            "Train Loss:  2.6413655281066895\n",
            "Test Loss:  5.778716564178467\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  399\n",
            "Train Loss:  2.639359951019287\n",
            "Test Loss:  5.780848503112793\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  400\n",
            "Train Loss:  2.6373579502105713\n",
            "Test Loss:  5.783030986785889\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  401\n",
            "Train Loss:  2.6353583335876465\n",
            "Test Loss:  5.785236358642578\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  402\n",
            "Train Loss:  2.633363723754883\n",
            "Test Loss:  5.787419319152832\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  403\n",
            "Train Loss:  2.6313741207122803\n",
            "Test Loss:  5.78954553604126\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  404\n",
            "Train Loss:  2.6293835639953613\n",
            "Test Loss:  5.7916646003723145\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  405\n",
            "Train Loss:  2.6273980140686035\n",
            "Test Loss:  5.793781757354736\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  406\n",
            "Train Loss:  2.6254186630249023\n",
            "Test Loss:  5.795882225036621\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  407\n",
            "Train Loss:  2.623445510864258\n",
            "Test Loss:  5.797937393188477\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  408\n",
            "Train Loss:  2.6214733123779297\n",
            "Test Loss:  5.799953937530518\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  409\n",
            "Train Loss:  2.619511604309082\n",
            "Test Loss:  5.8019256591796875\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  410\n",
            "Train Loss:  2.617558479309082\n",
            "Test Loss:  5.803881645202637\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  411\n",
            "Train Loss:  2.6156039237976074\n",
            "Test Loss:  5.805826187133789\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  412\n",
            "Train Loss:  2.613659381866455\n",
            "Test Loss:  5.80776309967041\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  413\n",
            "Train Loss:  2.611720561981201\n",
            "Test Loss:  5.809699058532715\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  414\n",
            "Train Loss:  2.6097893714904785\n",
            "Test Loss:  5.811655044555664\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  415\n",
            "Train Loss:  2.607865810394287\n",
            "Test Loss:  5.813634872436523\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  416\n",
            "Train Loss:  2.6059393882751465\n",
            "Test Loss:  5.815664291381836\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  417\n",
            "Train Loss:  2.604020595550537\n",
            "Test Loss:  5.817742347717285\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  418\n",
            "Train Loss:  2.6021065711975098\n",
            "Test Loss:  5.819832801818848\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  419\n",
            "Train Loss:  2.600198268890381\n",
            "Test Loss:  5.821928024291992\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  420\n",
            "Train Loss:  2.5982980728149414\n",
            "Test Loss:  5.824007987976074\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  421\n",
            "Train Loss:  2.5963990688323975\n",
            "Test Loss:  5.826056480407715\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  422\n",
            "Train Loss:  2.59450364112854\n",
            "Test Loss:  5.8280487060546875\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  423\n",
            "Train Loss:  2.5926132202148438\n",
            "Test Loss:  5.830022811889648\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  424\n",
            "Train Loss:  2.5907225608825684\n",
            "Test Loss:  5.831986427307129\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  425\n",
            "Train Loss:  2.588839054107666\n",
            "Test Loss:  5.833954811096191\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  426\n",
            "Train Loss:  2.586967706680298\n",
            "Test Loss:  5.835958480834961\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  427\n",
            "Train Loss:  2.5850987434387207\n",
            "Test Loss:  5.837951183319092\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  428\n",
            "Train Loss:  2.583242893218994\n",
            "Test Loss:  5.839951515197754\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  429\n",
            "Train Loss:  2.5813937187194824\n",
            "Test Loss:  5.842036247253418\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  430\n",
            "Train Loss:  2.5795507431030273\n",
            "Test Loss:  5.844123840332031\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  431\n",
            "Train Loss:  2.57771897315979\n",
            "Test Loss:  5.8461737632751465\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  432\n",
            "Train Loss:  2.57590913772583\n",
            "Test Loss:  5.848302364349365\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  433\n",
            "Train Loss:  2.5740811824798584\n",
            "Test Loss:  5.85038948059082\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  434\n",
            "Train Loss:  2.572280168533325\n",
            "Test Loss:  5.852404594421387\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  435\n",
            "Train Loss:  2.570444345474243\n",
            "Test Loss:  5.854430198669434\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  436\n",
            "Train Loss:  2.568608045578003\n",
            "Test Loss:  5.8565263748168945\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  437\n",
            "Train Loss:  2.5667905807495117\n",
            "Test Loss:  5.858585357666016\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  438\n",
            "Train Loss:  2.565001964569092\n",
            "Test Loss:  5.860642433166504\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  439\n",
            "Train Loss:  2.5632359981536865\n",
            "Test Loss:  5.862574577331543\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  440\n",
            "Train Loss:  2.5614943504333496\n",
            "Test Loss:  5.864572048187256\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  441\n",
            "Train Loss:  2.5597009658813477\n",
            "Test Loss:  5.866555213928223\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  442\n",
            "Train Loss:  2.5579237937927246\n",
            "Test Loss:  5.868560791015625\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  443\n",
            "Train Loss:  2.556166648864746\n",
            "Test Loss:  5.870579719543457\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  444\n",
            "Train Loss:  2.5543880462646484\n",
            "Test Loss:  5.872636795043945\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  445\n",
            "Train Loss:  2.5526559352874756\n",
            "Test Loss:  5.874661445617676\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  446\n",
            "Train Loss:  2.5509469509124756\n",
            "Test Loss:  5.876656532287598\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  447\n",
            "Train Loss:  2.549365520477295\n",
            "Test Loss:  5.878532409667969\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  448\n",
            "Train Loss:  2.547847270965576\n",
            "Test Loss:  5.880353927612305\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  449\n",
            "Train Loss:  2.5460362434387207\n",
            "Test Loss:  5.882214546203613\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  450\n",
            "Train Loss:  2.5443902015686035\n",
            "Test Loss:  5.884122848510742\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  451\n",
            "Train Loss:  2.5427465438842773\n",
            "Test Loss:  5.886100769042969\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  452\n",
            "Train Loss:  2.5410068035125732\n",
            "Test Loss:  5.888129234313965\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  453\n",
            "Train Loss:  2.539303779602051\n",
            "Test Loss:  5.890155792236328\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  454\n",
            "Train Loss:  2.537609577178955\n",
            "Test Loss:  5.892110824584961\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  455\n",
            "Train Loss:  2.5359580516815186\n",
            "Test Loss:  5.89407205581665\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  456\n",
            "Train Loss:  2.5342557430267334\n",
            "Test Loss:  5.895945072174072\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  457\n",
            "Train Loss:  2.5325727462768555\n",
            "Test Loss:  5.897853851318359\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  458\n",
            "Train Loss:  2.530913829803467\n",
            "Test Loss:  5.8998003005981445\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  459\n",
            "Train Loss:  2.5292344093322754\n",
            "Test Loss:  5.901708602905273\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  460\n",
            "Train Loss:  2.5276236534118652\n",
            "Test Loss:  5.903633117675781\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  461\n",
            "Train Loss:  2.525974750518799\n",
            "Test Loss:  5.905420303344727\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  462\n",
            "Train Loss:  2.524346351623535\n",
            "Test Loss:  5.907231330871582\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  463\n",
            "Train Loss:  2.522709846496582\n",
            "Test Loss:  5.9091033935546875\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  464\n",
            "Train Loss:  2.521073341369629\n",
            "Test Loss:  5.911032676696777\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  465\n",
            "Train Loss:  2.5194873809814453\n",
            "Test Loss:  5.912954330444336\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  466\n",
            "Train Loss:  2.5178890228271484\n",
            "Test Loss:  5.914775371551514\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  467\n",
            "Train Loss:  2.5162930488586426\n",
            "Test Loss:  5.916700839996338\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  468\n",
            "Train Loss:  2.514702320098877\n",
            "Test Loss:  5.918639183044434\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  469\n",
            "Train Loss:  2.5130553245544434\n",
            "Test Loss:  5.920555114746094\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  470\n",
            "Train Loss:  2.5114827156066895\n",
            "Test Loss:  5.922482013702393\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  471\n",
            "Train Loss:  2.50993013381958\n",
            "Test Loss:  5.924249649047852\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  472\n",
            "Train Loss:  2.5084829330444336\n",
            "Test Loss:  5.926105499267578\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  473\n",
            "Train Loss:  2.506885290145874\n",
            "Test Loss:  5.927931785583496\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  474\n",
            "Train Loss:  2.505312919616699\n",
            "Test Loss:  5.9297285079956055\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  475\n",
            "Train Loss:  2.503726005554199\n",
            "Test Loss:  5.931552886962891\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  476\n",
            "Train Loss:  2.5022315979003906\n",
            "Test Loss:  5.933362007141113\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  477\n",
            "Train Loss:  2.5007152557373047\n",
            "Test Loss:  5.9351606369018555\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  478\n",
            "Train Loss:  2.499103546142578\n",
            "Test Loss:  5.936993598937988\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  479\n",
            "Train Loss:  2.4975948333740234\n",
            "Test Loss:  5.93888521194458\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  480\n",
            "Train Loss:  2.4960968494415283\n",
            "Test Loss:  5.94068717956543\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  481\n",
            "Train Loss:  2.4944934844970703\n",
            "Test Loss:  5.942446708679199\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  482\n",
            "Train Loss:  2.4929590225219727\n",
            "Test Loss:  5.9442853927612305\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  483\n",
            "Train Loss:  2.491387367248535\n",
            "Test Loss:  5.946194648742676\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  484\n",
            "Train Loss:  2.489814519882202\n",
            "Test Loss:  5.948132514953613\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  485\n",
            "Train Loss:  2.488278865814209\n",
            "Test Loss:  5.950135707855225\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  486\n",
            "Train Loss:  2.486802577972412\n",
            "Test Loss:  5.952033042907715\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  487\n",
            "Train Loss:  2.4852559566497803\n",
            "Test Loss:  5.9540114402771\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  488\n",
            "Train Loss:  2.4836974143981934\n",
            "Test Loss:  5.956020355224609\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  489\n",
            "Train Loss:  2.482226848602295\n",
            "Test Loss:  5.958004951477051\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  490\n",
            "Train Loss:  2.4806318283081055\n",
            "Test Loss:  5.960004806518555\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  491\n",
            "Train Loss:  2.4791533946990967\n",
            "Test Loss:  5.962050437927246\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  492\n",
            "Train Loss:  2.477677345275879\n",
            "Test Loss:  5.964056015014648\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  493\n",
            "Train Loss:  2.4762887954711914\n",
            "Test Loss:  5.965944766998291\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  494\n",
            "Train Loss:  2.4748013019561768\n",
            "Test Loss:  5.967814922332764\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  495\n",
            "Train Loss:  2.473304271697998\n",
            "Test Loss:  5.969582557678223\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  496\n",
            "Train Loss:  2.4718143939971924\n",
            "Test Loss:  5.971375465393066\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  497\n",
            "Train Loss:  2.470320224761963\n",
            "Test Loss:  5.9732584953308105\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  498\n",
            "Train Loss:  2.4688196182250977\n",
            "Test Loss:  5.975139617919922\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  499\n",
            "Train Loss:  2.4673733711242676\n",
            "Test Loss:  5.977065563201904\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  500\n",
            "Train Loss:  2.466064453125\n",
            "Test Loss:  5.978728294372559\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  501\n",
            "Train Loss:  2.4646477699279785\n",
            "Test Loss:  5.980499267578125\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  502\n",
            "Train Loss:  2.4631428718566895\n",
            "Test Loss:  5.982328414916992\n",
            "Recall : 0.16\n",
            "Epoch  503\n",
            "Train Loss:  2.461764335632324\n",
            "Test Loss:  5.984271049499512\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  504\n",
            "Train Loss:  2.4603424072265625\n",
            "Test Loss:  5.986259460449219\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  505\n",
            "Train Loss:  2.4590659141540527\n",
            "Test Loss:  5.988117694854736\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  506\n",
            "Train Loss:  2.4575490951538086\n",
            "Test Loss:  5.989922523498535\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  507\n",
            "Train Loss:  2.45621919631958\n",
            "Test Loss:  5.991667747497559\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  508\n",
            "Train Loss:  2.4548325538635254\n",
            "Test Loss:  5.993406772613525\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  509\n",
            "Train Loss:  2.4534013271331787\n",
            "Test Loss:  5.995262145996094\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  510\n",
            "Train Loss:  2.452005386352539\n",
            "Test Loss:  5.997101783752441\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  511\n",
            "Train Loss:  2.45059871673584\n",
            "Test Loss:  5.998884201049805\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  512\n",
            "Train Loss:  2.4491477012634277\n",
            "Test Loss:  6.000715255737305\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  513\n",
            "Train Loss:  2.4477343559265137\n",
            "Test Loss:  6.002510070800781\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  514\n",
            "Train Loss:  2.446403980255127\n",
            "Test Loss:  6.004279136657715\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  515\n",
            "Train Loss:  2.4451303482055664\n",
            "Test Loss:  6.006078720092773\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  516\n",
            "Train Loss:  2.443671703338623\n",
            "Test Loss:  6.007745742797852\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  517\n",
            "Train Loss:  2.442319869995117\n",
            "Test Loss:  6.009451866149902\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  518\n",
            "Train Loss:  2.440920829772949\n",
            "Test Loss:  6.011171340942383\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  519\n",
            "Train Loss:  2.439540386199951\n",
            "Test Loss:  6.013006210327148\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  520\n",
            "Train Loss:  2.4381661415100098\n",
            "Test Loss:  6.014920234680176\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  521\n",
            "Train Loss:  2.4369256496429443\n",
            "Test Loss:  6.016615867614746\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  522\n",
            "Train Loss:  2.4356815814971924\n",
            "Test Loss:  6.0182881355285645\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  523\n",
            "Train Loss:  2.43430757522583\n",
            "Test Loss:  6.019983768463135\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  524\n",
            "Train Loss:  2.432896375656128\n",
            "Test Loss:  6.021561622619629\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  525\n",
            "Train Loss:  2.431595802307129\n",
            "Test Loss:  6.023232460021973\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  526\n",
            "Train Loss:  2.4302053451538086\n",
            "Test Loss:  6.025096893310547\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  527\n",
            "Train Loss:  2.4288716316223145\n",
            "Test Loss:  6.0269856452941895\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  528\n",
            "Train Loss:  2.427590847015381\n",
            "Test Loss:  6.02874755859375\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  529\n",
            "Train Loss:  2.426323175430298\n",
            "Test Loss:  6.0304460525512695\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  530\n",
            "Train Loss:  2.4249868392944336\n",
            "Test Loss:  6.0320892333984375\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  531\n",
            "Train Loss:  2.423750877380371\n",
            "Test Loss:  6.0337653160095215\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  532\n",
            "Train Loss:  2.4224541187286377\n",
            "Test Loss:  6.035472869873047\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  533\n",
            "Train Loss:  2.421135902404785\n",
            "Test Loss:  6.03712272644043\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  534\n",
            "Train Loss:  2.4198555946350098\n",
            "Test Loss:  6.0387420654296875\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  535\n",
            "Train Loss:  2.4185774326324463\n",
            "Test Loss:  6.040500640869141\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  536\n",
            "Train Loss:  2.417375087738037\n",
            "Test Loss:  6.042048931121826\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  537\n",
            "Train Loss:  2.4160704612731934\n",
            "Test Loss:  6.043708324432373\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  538\n",
            "Train Loss:  2.4147286415100098\n",
            "Test Loss:  6.045314311981201\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  539\n",
            "Train Loss:  2.4135165214538574\n",
            "Test Loss:  6.047037124633789\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  540\n",
            "Train Loss:  2.4122402667999268\n",
            "Test Loss:  6.0487823486328125\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  541\n",
            "Train Loss:  2.411144256591797\n",
            "Test Loss:  6.050417900085449\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  542\n",
            "Train Loss:  2.410004138946533\n",
            "Test Loss:  6.051884174346924\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  543\n",
            "Train Loss:  2.4088428020477295\n",
            "Test Loss:  6.053436279296875\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  544\n",
            "Train Loss:  2.4076218605041504\n",
            "Test Loss:  6.054893493652344\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  545\n",
            "Train Loss:  2.406315326690674\n",
            "Test Loss:  6.056464195251465\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  546\n",
            "Train Loss:  2.405139684677124\n",
            "Test Loss:  6.0581254959106445\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  547\n",
            "Train Loss:  2.4038727283477783\n",
            "Test Loss:  6.059828758239746\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  548\n",
            "Train Loss:  2.402573585510254\n",
            "Test Loss:  6.061559200286865\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  549\n",
            "Train Loss:  2.401353359222412\n",
            "Test Loss:  6.063251495361328\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  550\n",
            "Train Loss:  2.4002113342285156\n",
            "Test Loss:  6.064908027648926\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  551\n",
            "Train Loss:  2.3989369869232178\n",
            "Test Loss:  6.066575527191162\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  552\n",
            "Train Loss:  2.3977386951446533\n",
            "Test Loss:  6.068151473999023\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  553\n",
            "Train Loss:  2.396533489227295\n",
            "Test Loss:  6.069864273071289\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  554\n",
            "Train Loss:  2.395303964614868\n",
            "Test Loss:  6.071544647216797\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  555\n",
            "Train Loss:  2.394143581390381\n",
            "Test Loss:  6.073199272155762\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  556\n",
            "Train Loss:  2.392894744873047\n",
            "Test Loss:  6.074747562408447\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  557\n",
            "Train Loss:  2.3917641639709473\n",
            "Test Loss:  6.076307773590088\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  558\n",
            "Train Loss:  2.3906123638153076\n",
            "Test Loss:  6.077872276306152\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  559\n",
            "Train Loss:  2.389382839202881\n",
            "Test Loss:  6.079355716705322\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  560\n",
            "Train Loss:  2.388150691986084\n",
            "Test Loss:  6.080842018127441\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  561\n",
            "Train Loss:  2.3870320320129395\n",
            "Test Loss:  6.0824971199035645\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  562\n",
            "Train Loss:  2.3860559463500977\n",
            "Test Loss:  6.084017753601074\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  563\n",
            "Train Loss:  2.385058641433716\n",
            "Test Loss:  6.085453987121582\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  564\n",
            "Train Loss:  2.3839454650878906\n",
            "Test Loss:  6.087014198303223\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  565\n",
            "Train Loss:  2.382775068283081\n",
            "Test Loss:  6.088749885559082\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  566\n",
            "Train Loss:  2.3815808296203613\n",
            "Test Loss:  6.090384006500244\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  567\n",
            "Train Loss:  2.3803720474243164\n",
            "Test Loss:  6.092064380645752\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  568\n",
            "Train Loss:  2.379171848297119\n",
            "Test Loss:  6.093639373779297\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  569\n",
            "Train Loss:  2.3780672550201416\n",
            "Test Loss:  6.095146179199219\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  570\n",
            "Train Loss:  2.3768911361694336\n",
            "Test Loss:  6.096759796142578\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  571\n",
            "Train Loss:  2.3757598400115967\n",
            "Test Loss:  6.098300933837891\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  572\n",
            "Train Loss:  2.3747096061706543\n",
            "Test Loss:  6.099722862243652\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  573\n",
            "Train Loss:  2.3736767768859863\n",
            "Test Loss:  6.101249694824219\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  574\n",
            "Train Loss:  2.372589349746704\n",
            "Test Loss:  6.102718353271484\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  575\n",
            "Train Loss:  2.3714637756347656\n",
            "Test Loss:  6.104118347167969\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  576\n",
            "Train Loss:  2.3704349994659424\n",
            "Test Loss:  6.105774402618408\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  577\n",
            "Train Loss:  2.3693625926971436\n",
            "Test Loss:  6.107314586639404\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  578\n",
            "Train Loss:  2.3680968284606934\n",
            "Test Loss:  6.108986854553223\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  579\n",
            "Train Loss:  2.3670718669891357\n",
            "Test Loss:  6.110782623291016\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  580\n",
            "Train Loss:  2.3659157752990723\n",
            "Test Loss:  6.112447738647461\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  581\n",
            "Train Loss:  2.36484694480896\n",
            "Test Loss:  6.114038467407227\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  582\n",
            "Train Loss:  2.363834857940674\n",
            "Test Loss:  6.115550994873047\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  583\n",
            "Train Loss:  2.363055467605591\n",
            "Test Loss:  6.11724853515625\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  584\n",
            "Train Loss:  2.362185001373291\n",
            "Test Loss:  6.11882209777832\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  585\n",
            "Train Loss:  2.361083507537842\n",
            "Test Loss:  6.120156764984131\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  586\n",
            "Train Loss:  2.3600993156433105\n",
            "Test Loss:  6.1214470863342285\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  587\n",
            "Train Loss:  2.358977794647217\n",
            "Test Loss:  6.12289571762085\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  588\n",
            "Train Loss:  2.357883930206299\n",
            "Test Loss:  6.124451637268066\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  589\n",
            "Train Loss:  2.356776237487793\n",
            "Test Loss:  6.126084327697754\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  590\n",
            "Train Loss:  2.35571551322937\n",
            "Test Loss:  6.12788724899292\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  591\n",
            "Train Loss:  2.3547310829162598\n",
            "Test Loss:  6.129253387451172\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  592\n",
            "Train Loss:  2.3538618087768555\n",
            "Test Loss:  6.130731582641602\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  593\n",
            "Train Loss:  2.352815628051758\n",
            "Test Loss:  6.132336616516113\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  594\n",
            "Train Loss:  2.3519577980041504\n",
            "Test Loss:  6.133747577667236\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  595\n",
            "Train Loss:  2.3508620262145996\n",
            "Test Loss:  6.135158538818359\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  596\n",
            "Train Loss:  2.3497352600097656\n",
            "Test Loss:  6.136605262756348\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  597\n",
            "Train Loss:  2.348691463470459\n",
            "Test Loss:  6.138130187988281\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  598\n",
            "Train Loss:  2.3476712703704834\n",
            "Test Loss:  6.13974666595459\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  599\n",
            "Train Loss:  2.346656322479248\n",
            "Test Loss:  6.141244411468506\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  600\n",
            "Train Loss:  2.345613479614258\n",
            "Test Loss:  6.142698764801025\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  601\n",
            "Train Loss:  2.3445844650268555\n",
            "Test Loss:  6.144052028656006\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  602\n",
            "Train Loss:  2.3437399864196777\n",
            "Test Loss:  6.145461082458496\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  603\n",
            "Train Loss:  2.3428304195404053\n",
            "Test Loss:  6.146890640258789\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  604\n",
            "Train Loss:  2.341841459274292\n",
            "Test Loss:  6.148373603820801\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  605\n",
            "Train Loss:  2.340743064880371\n",
            "Test Loss:  6.149696350097656\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  606\n",
            "Train Loss:  2.3398759365081787\n",
            "Test Loss:  6.151060104370117\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  607\n",
            "Train Loss:  2.338869571685791\n",
            "Test Loss:  6.15252685546875\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  608\n",
            "Train Loss:  2.337852716445923\n",
            "Test Loss:  6.154008388519287\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  609\n",
            "Train Loss:  2.3368875980377197\n",
            "Test Loss:  6.155254364013672\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  610\n",
            "Train Loss:  2.3358044624328613\n",
            "Test Loss:  6.156712055206299\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  611\n",
            "Train Loss:  2.334782600402832\n",
            "Test Loss:  6.158241271972656\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  612\n",
            "Train Loss:  2.333862781524658\n",
            "Test Loss:  6.159718990325928\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  613\n",
            "Train Loss:  2.3331174850463867\n",
            "Test Loss:  6.161264419555664\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  614\n",
            "Train Loss:  2.3323535919189453\n",
            "Test Loss:  6.162344455718994\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  615\n",
            "Train Loss:  2.3315324783325195\n",
            "Test Loss:  6.163722038269043\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  616\n",
            "Train Loss:  2.3304290771484375\n",
            "Test Loss:  6.165246486663818\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  617\n",
            "Train Loss:  2.329521656036377\n",
            "Test Loss:  6.1666412353515625\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  618\n",
            "Train Loss:  2.328511953353882\n",
            "Test Loss:  6.168024063110352\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  619\n",
            "Train Loss:  2.3276796340942383\n",
            "Test Loss:  6.169522285461426\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  620\n",
            "Train Loss:  2.326841115951538\n",
            "Test Loss:  6.170823097229004\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  621\n",
            "Train Loss:  2.32597279548645\n",
            "Test Loss:  6.171963691711426\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  622\n",
            "Train Loss:  2.32495379447937\n",
            "Test Loss:  6.173266410827637\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  623\n",
            "Train Loss:  2.3239245414733887\n",
            "Test Loss:  6.174924850463867\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  624\n",
            "Train Loss:  2.3230881690979004\n",
            "Test Loss:  6.176347732543945\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  625\n",
            "Train Loss:  2.3221912384033203\n",
            "Test Loss:  6.177661895751953\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  626\n",
            "Train Loss:  2.321180820465088\n",
            "Test Loss:  6.179163932800293\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  627\n",
            "Train Loss:  2.320347309112549\n",
            "Test Loss:  6.180440902709961\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  628\n",
            "Train Loss:  2.3195831775665283\n",
            "Test Loss:  6.181567668914795\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  629\n",
            "Train Loss:  2.319002151489258\n",
            "Test Loss:  6.182890892028809\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  630\n",
            "Train Loss:  2.317934513092041\n",
            "Test Loss:  6.184082984924316\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  631\n",
            "Train Loss:  2.3171112537384033\n",
            "Test Loss:  6.185183525085449\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  632\n",
            "Train Loss:  2.316174030303955\n",
            "Test Loss:  6.186525344848633\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  633\n",
            "Train Loss:  2.315277576446533\n",
            "Test Loss:  6.1879377365112305\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  634\n",
            "Train Loss:  2.314380407333374\n",
            "Test Loss:  6.189284801483154\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  635\n",
            "Train Loss:  2.3135857582092285\n",
            "Test Loss:  6.1906418800354\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  636\n",
            "Train Loss:  2.312837600708008\n",
            "Test Loss:  6.192018032073975\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  637\n",
            "Train Loss:  2.311927318572998\n",
            "Test Loss:  6.193167686462402\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  638\n",
            "Train Loss:  2.3110270500183105\n",
            "Test Loss:  6.194591522216797\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  639\n",
            "Train Loss:  2.3102502822875977\n",
            "Test Loss:  6.195849418640137\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  640\n",
            "Train Loss:  2.309408664703369\n",
            "Test Loss:  6.1974287033081055\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  641\n",
            "Train Loss:  2.3085379600524902\n",
            "Test Loss:  6.198796272277832\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  642\n",
            "Train Loss:  2.3076515197753906\n",
            "Test Loss:  6.200201988220215\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  643\n",
            "Train Loss:  2.3068900108337402\n",
            "Test Loss:  6.201397895812988\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  644\n",
            "Train Loss:  2.3061559200286865\n",
            "Test Loss:  6.202815532684326\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  645\n",
            "Train Loss:  2.305514097213745\n",
            "Test Loss:  6.204118728637695\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  646\n",
            "Train Loss:  2.3047256469726562\n",
            "Test Loss:  6.205354690551758\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  647\n",
            "Train Loss:  2.3038012981414795\n",
            "Test Loss:  6.206550121307373\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  648\n",
            "Train Loss:  2.302924156188965\n",
            "Test Loss:  6.207710266113281\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  649\n",
            "Train Loss:  2.302124500274658\n",
            "Test Loss:  6.208902359008789\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  650\n",
            "Train Loss:  2.3013598918914795\n",
            "Test Loss:  6.209897041320801\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  651\n",
            "Train Loss:  2.3006460666656494\n",
            "Test Loss:  6.211085319519043\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  652\n",
            "Train Loss:  2.2997212409973145\n",
            "Test Loss:  6.212251663208008\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  653\n",
            "Train Loss:  2.2989978790283203\n",
            "Test Loss:  6.213207244873047\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  654\n",
            "Train Loss:  2.29824161529541\n",
            "Test Loss:  6.214529037475586\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  655\n",
            "Train Loss:  2.2976884841918945\n",
            "Test Loss:  6.215505599975586\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  656\n",
            "Train Loss:  2.297184944152832\n",
            "Test Loss:  6.21671724319458\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  657\n",
            "Train Loss:  2.2962207794189453\n",
            "Test Loss:  6.217888832092285\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  658\n",
            "Train Loss:  2.295473098754883\n",
            "Test Loss:  6.219027519226074\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  659\n",
            "Train Loss:  2.2946925163269043\n",
            "Test Loss:  6.220010757446289\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  660\n",
            "Train Loss:  2.293926954269409\n",
            "Test Loss:  6.221312046051025\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  661\n",
            "Train Loss:  2.293074369430542\n",
            "Test Loss:  6.222443580627441\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  662\n",
            "Train Loss:  2.292159080505371\n",
            "Test Loss:  6.223541259765625\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  663\n",
            "Train Loss:  2.291536808013916\n",
            "Test Loss:  6.225091934204102\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  664\n",
            "Train Loss:  2.290870189666748\n",
            "Test Loss:  6.22648286819458\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  665\n",
            "Train Loss:  2.2902166843414307\n",
            "Test Loss:  6.227480888366699\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  666\n",
            "Train Loss:  2.2895355224609375\n",
            "Test Loss:  6.228740692138672\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  667\n",
            "Train Loss:  2.2889013290405273\n",
            "Test Loss:  6.229667663574219\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  668\n",
            "Train Loss:  2.288161039352417\n",
            "Test Loss:  6.230586051940918\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  669\n",
            "Train Loss:  2.287381649017334\n",
            "Test Loss:  6.231884002685547\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  670\n",
            "Train Loss:  2.286698818206787\n",
            "Test Loss:  6.2332258224487305\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  671\n",
            "Train Loss:  2.2858691215515137\n",
            "Test Loss:  6.234389781951904\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  672\n",
            "Train Loss:  2.2851433753967285\n",
            "Test Loss:  6.235448837280273\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  673\n",
            "Train Loss:  2.2844669818878174\n",
            "Test Loss:  6.236489295959473\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  674\n",
            "Train Loss:  2.2835681438446045\n",
            "Test Loss:  6.237696647644043\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  675\n",
            "Train Loss:  2.2827320098876953\n",
            "Test Loss:  6.239049434661865\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  676\n",
            "Train Loss:  2.2820253372192383\n",
            "Test Loss:  6.240145683288574\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  677\n",
            "Train Loss:  2.28139066696167\n",
            "Test Loss:  6.241435527801514\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  678\n",
            "Train Loss:  2.2808451652526855\n",
            "Test Loss:  6.2425031661987305\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  679\n",
            "Train Loss:  2.2801432609558105\n",
            "Test Loss:  6.243439197540283\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  680\n",
            "Train Loss:  2.2796247005462646\n",
            "Test Loss:  6.24428653717041\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  681\n",
            "Train Loss:  2.278698444366455\n",
            "Test Loss:  6.2452826499938965\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  682\n",
            "Train Loss:  2.2778382301330566\n",
            "Test Loss:  6.246435165405273\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  683\n",
            "Train Loss:  2.276991128921509\n",
            "Test Loss:  6.2473649978637695\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  684\n",
            "Train Loss:  2.276299476623535\n",
            "Test Loss:  6.248431205749512\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  685\n",
            "Train Loss:  2.2756948471069336\n",
            "Test Loss:  6.249643325805664\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  686\n",
            "Train Loss:  2.2749176025390625\n",
            "Test Loss:  6.250868797302246\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  687\n",
            "Train Loss:  2.274256944656372\n",
            "Test Loss:  6.251898765563965\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  688\n",
            "Train Loss:  2.2737088203430176\n",
            "Test Loss:  6.253208160400391\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  689\n",
            "Train Loss:  2.2732179164886475\n",
            "Test Loss:  6.254265308380127\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  690\n",
            "Train Loss:  2.2724084854125977\n",
            "Test Loss:  6.25535249710083\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  691\n",
            "Train Loss:  2.271634101867676\n",
            "Test Loss:  6.256326675415039\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  692\n",
            "Train Loss:  2.270984411239624\n",
            "Test Loss:  6.257413864135742\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  693\n",
            "Train Loss:  2.2704057693481445\n",
            "Test Loss:  6.258298873901367\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  694\n",
            "Train Loss:  2.269836187362671\n",
            "Test Loss:  6.259325981140137\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  695\n",
            "Train Loss:  2.2691376209259033\n",
            "Test Loss:  6.260392189025879\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  696\n",
            "Train Loss:  2.268554210662842\n",
            "Test Loss:  6.261439323425293\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  697\n",
            "Train Loss:  2.267989158630371\n",
            "Test Loss:  6.262519359588623\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  698\n",
            "Train Loss:  2.267165184020996\n",
            "Test Loss:  6.263739109039307\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  699\n",
            "Train Loss:  2.2664990425109863\n",
            "Test Loss:  6.264771461486816\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  700\n",
            "Train Loss:  2.265857219696045\n",
            "Test Loss:  6.265783786773682\n",
            "Recall : 0.14285714285714285\n",
            "\n",
            "0.16581224489795918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bcb8ce3fec734f17a02a8d8a1086b8fd",
            "3385243b20d5438a810f7b423601a4cc",
            "31abb6f8f00d461da73196901dd05702",
            "9073d12e24d74f0cb9be9ced76bb21db",
            "323c4c4efffe4ac196642fcf53fd2083",
            "dcb92620fe6d4d2d8f147edcddeaff57",
            "fad12bf5044a4196ab87356ff0f0270f",
            "fe608ab4998f4ef8815b075488a359d0"
          ]
        },
        "id": "szcczkz-N0Nq",
        "outputId": "799a4b4f-53e7-4e6c-f56b-c6f64d530a5c"
      },
      "source": [
        "run(path=\"resnet152.npy\",runs=1,epochs=700,k=1,temp=15,type=2,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcb8ce3fec734f17a02a8d8a1086b8fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.44481086730957\n",
            "Test Loss:  6.324102401733398\n",
            "Recall : 0.12\n",
            "Epoch  2\n",
            "Train Loss:  7.372014999389648\n",
            "Test Loss:  6.285968780517578\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  3\n",
            "Train Loss:  7.302770614624023\n",
            "Test Loss:  6.248893737792969\n",
            "Recall : 0.12285714285714286\n",
            "Epoch  4\n",
            "Train Loss:  7.235110282897949\n",
            "Test Loss:  6.212578773498535\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  5\n",
            "Train Loss:  7.168423652648926\n",
            "Test Loss:  6.176889896392822\n",
            "Recall : 0.12476190476190477\n",
            "Epoch  6\n",
            "Train Loss:  7.102505207061768\n",
            "Test Loss:  6.14178466796875\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  7\n",
            "Train Loss:  7.037295341491699\n",
            "Test Loss:  6.107322692871094\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  8\n",
            "Train Loss:  6.972789764404297\n",
            "Test Loss:  6.073550224304199\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  9\n",
            "Train Loss:  6.909060478210449\n",
            "Test Loss:  6.040458679199219\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  10\n",
            "Train Loss:  6.84616231918335\n",
            "Test Loss:  6.008126258850098\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  11\n",
            "Train Loss:  6.784167289733887\n",
            "Test Loss:  5.976614475250244\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  12\n",
            "Train Loss:  6.723153114318848\n",
            "Test Loss:  5.945986747741699\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  13\n",
            "Train Loss:  6.663169860839844\n",
            "Test Loss:  5.916311264038086\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  14\n",
            "Train Loss:  6.604289531707764\n",
            "Test Loss:  5.887591361999512\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  15\n",
            "Train Loss:  6.5465898513793945\n",
            "Test Loss:  5.859882354736328\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  16\n",
            "Train Loss:  6.490142822265625\n",
            "Test Loss:  5.833208084106445\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  17\n",
            "Train Loss:  6.434992790222168\n",
            "Test Loss:  5.807580947875977\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  18\n",
            "Train Loss:  6.381190299987793\n",
            "Test Loss:  5.783069610595703\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  19\n",
            "Train Loss:  6.328799724578857\n",
            "Test Loss:  5.759644031524658\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  20\n",
            "Train Loss:  6.277828216552734\n",
            "Test Loss:  5.7372636795043945\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  21\n",
            "Train Loss:  6.228311538696289\n",
            "Test Loss:  5.715933799743652\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  22\n",
            "Train Loss:  6.180278301239014\n",
            "Test Loss:  5.6956281661987305\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  23\n",
            "Train Loss:  6.133709907531738\n",
            "Test Loss:  5.67635440826416\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  24\n",
            "Train Loss:  6.088592052459717\n",
            "Test Loss:  5.6581010818481445\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  25\n",
            "Train Loss:  6.044919967651367\n",
            "Test Loss:  5.640778541564941\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  26\n",
            "Train Loss:  6.002617359161377\n",
            "Test Loss:  5.624428749084473\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  27\n",
            "Train Loss:  5.961678981781006\n",
            "Test Loss:  5.609001636505127\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  28\n",
            "Train Loss:  5.9221014976501465\n",
            "Test Loss:  5.594529628753662\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  29\n",
            "Train Loss:  5.883877754211426\n",
            "Test Loss:  5.58089017868042\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  30\n",
            "Train Loss:  5.846954345703125\n",
            "Test Loss:  5.568097114562988\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  31\n",
            "Train Loss:  5.811273574829102\n",
            "Test Loss:  5.556092739105225\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  32\n",
            "Train Loss:  5.776803970336914\n",
            "Test Loss:  5.54478645324707\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  33\n",
            "Train Loss:  5.7435221672058105\n",
            "Test Loss:  5.534136772155762\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  34\n",
            "Train Loss:  5.711389541625977\n",
            "Test Loss:  5.524123191833496\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  35\n",
            "Train Loss:  5.680349349975586\n",
            "Test Loss:  5.514747619628906\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  36\n",
            "Train Loss:  5.650374889373779\n",
            "Test Loss:  5.5059709548950195\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  37\n",
            "Train Loss:  5.62139368057251\n",
            "Test Loss:  5.497776031494141\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  38\n",
            "Train Loss:  5.593377113342285\n",
            "Test Loss:  5.49012565612793\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  39\n",
            "Train Loss:  5.566267013549805\n",
            "Test Loss:  5.482967376708984\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  40\n",
            "Train Loss:  5.540067672729492\n",
            "Test Loss:  5.476249694824219\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  41\n",
            "Train Loss:  5.514713287353516\n",
            "Test Loss:  5.469911098480225\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  42\n",
            "Train Loss:  5.49015998840332\n",
            "Test Loss:  5.463977336883545\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  43\n",
            "Train Loss:  5.466352462768555\n",
            "Test Loss:  5.458382606506348\n",
            "Recall : 0.16\n",
            "Epoch  44\n",
            "Train Loss:  5.443272590637207\n",
            "Test Loss:  5.453117370605469\n",
            "Recall : 0.16\n",
            "Epoch  45\n",
            "Train Loss:  5.42090368270874\n",
            "Test Loss:  5.448188781738281\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  46\n",
            "Train Loss:  5.39919900894165\n",
            "Test Loss:  5.4435930252075195\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  47\n",
            "Train Loss:  5.3781232833862305\n",
            "Test Loss:  5.439236164093018\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  48\n",
            "Train Loss:  5.357611179351807\n",
            "Test Loss:  5.435077667236328\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  49\n",
            "Train Loss:  5.337676048278809\n",
            "Test Loss:  5.431112766265869\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  50\n",
            "Train Loss:  5.31826639175415\n",
            "Test Loss:  5.427333354949951\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  51\n",
            "Train Loss:  5.299350738525391\n",
            "Test Loss:  5.4237470626831055\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  52\n",
            "Train Loss:  5.280915260314941\n",
            "Test Loss:  5.420290470123291\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  53\n",
            "Train Loss:  5.262964725494385\n",
            "Test Loss:  5.416987895965576\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  54\n",
            "Train Loss:  5.245452880859375\n",
            "Test Loss:  5.413822650909424\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  55\n",
            "Train Loss:  5.228363990783691\n",
            "Test Loss:  5.410794258117676\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  56\n",
            "Train Loss:  5.211686134338379\n",
            "Test Loss:  5.407858848571777\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  57\n",
            "Train Loss:  5.1954240798950195\n",
            "Test Loss:  5.405025959014893\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  58\n",
            "Train Loss:  5.179555892944336\n",
            "Test Loss:  5.40228796005249\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  59\n",
            "Train Loss:  5.164056301116943\n",
            "Test Loss:  5.399633407592773\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  60\n",
            "Train Loss:  5.148916721343994\n",
            "Test Loss:  5.39705228805542\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  61\n",
            "Train Loss:  5.134123802185059\n",
            "Test Loss:  5.394559860229492\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  62\n",
            "Train Loss:  5.119657516479492\n",
            "Test Loss:  5.392181873321533\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  63\n",
            "Train Loss:  5.105525970458984\n",
            "Test Loss:  5.389847278594971\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  64\n",
            "Train Loss:  5.091721534729004\n",
            "Test Loss:  5.387601852416992\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  65\n",
            "Train Loss:  5.078237533569336\n",
            "Test Loss:  5.385467529296875\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  66\n",
            "Train Loss:  5.06505012512207\n",
            "Test Loss:  5.3834075927734375\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  67\n",
            "Train Loss:  5.052164077758789\n",
            "Test Loss:  5.381402015686035\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  68\n",
            "Train Loss:  5.039590835571289\n",
            "Test Loss:  5.379427909851074\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  69\n",
            "Train Loss:  5.027307033538818\n",
            "Test Loss:  5.377499103546143\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  70\n",
            "Train Loss:  5.015289306640625\n",
            "Test Loss:  5.37559175491333\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  71\n",
            "Train Loss:  5.0035295486450195\n",
            "Test Loss:  5.373692035675049\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  72\n",
            "Train Loss:  4.992023468017578\n",
            "Test Loss:  5.371848106384277\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  73\n",
            "Train Loss:  4.9807634353637695\n",
            "Test Loss:  5.37007999420166\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  74\n",
            "Train Loss:  4.969725608825684\n",
            "Test Loss:  5.3683576583862305\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  75\n",
            "Train Loss:  4.958930015563965\n",
            "Test Loss:  5.366683006286621\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  76\n",
            "Train Loss:  4.948360443115234\n",
            "Test Loss:  5.365063667297363\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  77\n",
            "Train Loss:  4.938018798828125\n",
            "Test Loss:  5.363487720489502\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  78\n",
            "Train Loss:  4.927889823913574\n",
            "Test Loss:  5.361949920654297\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  79\n",
            "Train Loss:  4.917962074279785\n",
            "Test Loss:  5.360475540161133\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  80\n",
            "Train Loss:  4.908220291137695\n",
            "Test Loss:  5.3590474128723145\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  81\n",
            "Train Loss:  4.89866828918457\n",
            "Test Loss:  5.35764217376709\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  82\n",
            "Train Loss:  4.889314651489258\n",
            "Test Loss:  5.356244087219238\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  83\n",
            "Train Loss:  4.880141258239746\n",
            "Test Loss:  5.354892730712891\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  84\n",
            "Train Loss:  4.8711419105529785\n",
            "Test Loss:  5.353577613830566\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  85\n",
            "Train Loss:  4.862301826477051\n",
            "Test Loss:  5.352301597595215\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  86\n",
            "Train Loss:  4.853631019592285\n",
            "Test Loss:  5.351053237915039\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  87\n",
            "Train Loss:  4.845113277435303\n",
            "Test Loss:  5.349813461303711\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  88\n",
            "Train Loss:  4.836744785308838\n",
            "Test Loss:  5.348598480224609\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  89\n",
            "Train Loss:  4.828526973724365\n",
            "Test Loss:  5.347434997558594\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  90\n",
            "Train Loss:  4.820448875427246\n",
            "Test Loss:  5.346307754516602\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  91\n",
            "Train Loss:  4.812499523162842\n",
            "Test Loss:  5.345219612121582\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  92\n",
            "Train Loss:  4.804673194885254\n",
            "Test Loss:  5.344159126281738\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  93\n",
            "Train Loss:  4.796969413757324\n",
            "Test Loss:  5.343134880065918\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  94\n",
            "Train Loss:  4.789379119873047\n",
            "Test Loss:  5.342119216918945\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  95\n",
            "Train Loss:  4.781887054443359\n",
            "Test Loss:  5.341115474700928\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  96\n",
            "Train Loss:  4.7744855880737305\n",
            "Test Loss:  5.340121269226074\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  97\n",
            "Train Loss:  4.767184734344482\n",
            "Test Loss:  5.3391876220703125\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  98\n",
            "Train Loss:  4.759975433349609\n",
            "Test Loss:  5.338284492492676\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  99\n",
            "Train Loss:  4.752846717834473\n",
            "Test Loss:  5.337389945983887\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  100\n",
            "Train Loss:  4.745794296264648\n",
            "Test Loss:  5.336511611938477\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  101\n",
            "Train Loss:  4.738812446594238\n",
            "Test Loss:  5.335672378540039\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  102\n",
            "Train Loss:  4.731895446777344\n",
            "Test Loss:  5.334839820861816\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  103\n",
            "Train Loss:  4.725035667419434\n",
            "Test Loss:  5.334033012390137\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  104\n",
            "Train Loss:  4.718234062194824\n",
            "Test Loss:  5.333246231079102\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  105\n",
            "Train Loss:  4.711490631103516\n",
            "Test Loss:  5.33249568939209\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  106\n",
            "Train Loss:  4.704812049865723\n",
            "Test Loss:  5.331784248352051\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  107\n",
            "Train Loss:  4.698188304901123\n",
            "Test Loss:  5.331118583679199\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  108\n",
            "Train Loss:  4.691620349884033\n",
            "Test Loss:  5.3304619789123535\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  109\n",
            "Train Loss:  4.68510627746582\n",
            "Test Loss:  5.329836845397949\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  110\n",
            "Train Loss:  4.678643703460693\n",
            "Test Loss:  5.329249382019043\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  111\n",
            "Train Loss:  4.672242164611816\n",
            "Test Loss:  5.328691482543945\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  112\n",
            "Train Loss:  4.665892601013184\n",
            "Test Loss:  5.328128814697266\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  113\n",
            "Train Loss:  4.659598350524902\n",
            "Test Loss:  5.3275885581970215\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  114\n",
            "Train Loss:  4.653357028961182\n",
            "Test Loss:  5.327065944671631\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  115\n",
            "Train Loss:  4.6471757888793945\n",
            "Test Loss:  5.326571464538574\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  116\n",
            "Train Loss:  4.641051292419434\n",
            "Test Loss:  5.326104164123535\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  117\n",
            "Train Loss:  4.634978294372559\n",
            "Test Loss:  5.32565450668335\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  118\n",
            "Train Loss:  4.628959655761719\n",
            "Test Loss:  5.325217247009277\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  119\n",
            "Train Loss:  4.622989654541016\n",
            "Test Loss:  5.324785232543945\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  120\n",
            "Train Loss:  4.617073059082031\n",
            "Test Loss:  5.324371814727783\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  121\n",
            "Train Loss:  4.611208915710449\n",
            "Test Loss:  5.323966026306152\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  122\n",
            "Train Loss:  4.60539436340332\n",
            "Test Loss:  5.323575973510742\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  123\n",
            "Train Loss:  4.59963321685791\n",
            "Test Loss:  5.323211669921875\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  124\n",
            "Train Loss:  4.593930244445801\n",
            "Test Loss:  5.322876930236816\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  125\n",
            "Train Loss:  4.58828592300415\n",
            "Test Loss:  5.322556018829346\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  126\n",
            "Train Loss:  4.582698822021484\n",
            "Test Loss:  5.322246551513672\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  127\n",
            "Train Loss:  4.577173233032227\n",
            "Test Loss:  5.321932792663574\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  128\n",
            "Train Loss:  4.571699142456055\n",
            "Test Loss:  5.32161808013916\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  129\n",
            "Train Loss:  4.566272258758545\n",
            "Test Loss:  5.321314811706543\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  130\n",
            "Train Loss:  4.560894012451172\n",
            "Test Loss:  5.3210272789001465\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  131\n",
            "Train Loss:  4.5555572509765625\n",
            "Test Loss:  5.320743560791016\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  132\n",
            "Train Loss:  4.55026388168335\n",
            "Test Loss:  5.320469379425049\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  133\n",
            "Train Loss:  4.545009613037109\n",
            "Test Loss:  5.320196151733398\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  134\n",
            "Train Loss:  4.539801597595215\n",
            "Test Loss:  5.319925785064697\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  135\n",
            "Train Loss:  4.534632682800293\n",
            "Test Loss:  5.319669723510742\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  136\n",
            "Train Loss:  4.529502868652344\n",
            "Test Loss:  5.319415092468262\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  137\n",
            "Train Loss:  4.524410724639893\n",
            "Test Loss:  5.31917142868042\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  138\n",
            "Train Loss:  4.519350051879883\n",
            "Test Loss:  5.318958282470703\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  139\n",
            "Train Loss:  4.514319896697998\n",
            "Test Loss:  5.3187575340271\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  140\n",
            "Train Loss:  4.509322166442871\n",
            "Test Loss:  5.318570613861084\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  141\n",
            "Train Loss:  4.50436544418335\n",
            "Test Loss:  5.318383693695068\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  142\n",
            "Train Loss:  4.4994425773620605\n",
            "Test Loss:  5.318181991577148\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  143\n",
            "Train Loss:  4.49454927444458\n",
            "Test Loss:  5.317961692810059\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  144\n",
            "Train Loss:  4.489689826965332\n",
            "Test Loss:  5.317736625671387\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  145\n",
            "Train Loss:  4.484856128692627\n",
            "Test Loss:  5.317523956298828\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  146\n",
            "Train Loss:  4.480050563812256\n",
            "Test Loss:  5.317322731018066\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  147\n",
            "Train Loss:  4.475273132324219\n",
            "Test Loss:  5.317128658294678\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  148\n",
            "Train Loss:  4.470523834228516\n",
            "Test Loss:  5.316936492919922\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  149\n",
            "Train Loss:  4.465801239013672\n",
            "Test Loss:  5.316747665405273\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  150\n",
            "Train Loss:  4.461106300354004\n",
            "Test Loss:  5.316553115844727\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  151\n",
            "Train Loss:  4.4564337730407715\n",
            "Test Loss:  5.316368103027344\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  152\n",
            "Train Loss:  4.451784133911133\n",
            "Test Loss:  5.31618595123291\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  153\n",
            "Train Loss:  4.4471588134765625\n",
            "Test Loss:  5.316001892089844\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  154\n",
            "Train Loss:  4.442553520202637\n",
            "Test Loss:  5.315820693969727\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  155\n",
            "Train Loss:  4.437972068786621\n",
            "Test Loss:  5.31564474105835\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  156\n",
            "Train Loss:  4.433414459228516\n",
            "Test Loss:  5.315457820892334\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  157\n",
            "Train Loss:  4.42888069152832\n",
            "Test Loss:  5.315258979797363\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  158\n",
            "Train Loss:  4.424374103546143\n",
            "Test Loss:  5.31505823135376\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  159\n",
            "Train Loss:  4.419896125793457\n",
            "Test Loss:  5.3148603439331055\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  160\n",
            "Train Loss:  4.415441513061523\n",
            "Test Loss:  5.314673900604248\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  161\n",
            "Train Loss:  4.411009788513184\n",
            "Test Loss:  5.314477443695068\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  162\n",
            "Train Loss:  4.4066009521484375\n",
            "Test Loss:  5.314274787902832\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  163\n",
            "Train Loss:  4.402216911315918\n",
            "Test Loss:  5.314067840576172\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  164\n",
            "Train Loss:  4.397856712341309\n",
            "Test Loss:  5.313851833343506\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  165\n",
            "Train Loss:  4.39351749420166\n",
            "Test Loss:  5.313637733459473\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  166\n",
            "Train Loss:  4.389198303222656\n",
            "Test Loss:  5.313426971435547\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  167\n",
            "Train Loss:  4.384909152984619\n",
            "Test Loss:  5.313220977783203\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  168\n",
            "Train Loss:  4.380649089813232\n",
            "Test Loss:  5.313014030456543\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  169\n",
            "Train Loss:  4.376416206359863\n",
            "Test Loss:  5.312808513641357\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  170\n",
            "Train Loss:  4.372213363647461\n",
            "Test Loss:  5.312610626220703\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  171\n",
            "Train Loss:  4.368037223815918\n",
            "Test Loss:  5.312417030334473\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  172\n",
            "Train Loss:  4.3638811111450195\n",
            "Test Loss:  5.312220573425293\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  173\n",
            "Train Loss:  4.359748840332031\n",
            "Test Loss:  5.312018394470215\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  174\n",
            "Train Loss:  4.355635643005371\n",
            "Test Loss:  5.311821937561035\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  175\n",
            "Train Loss:  4.351550102233887\n",
            "Test Loss:  5.311614990234375\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  176\n",
            "Train Loss:  4.347492218017578\n",
            "Test Loss:  5.311402320861816\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  177\n",
            "Train Loss:  4.3434648513793945\n",
            "Test Loss:  5.311193466186523\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  178\n",
            "Train Loss:  4.3394622802734375\n",
            "Test Loss:  5.310970783233643\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  179\n",
            "Train Loss:  4.335487365722656\n",
            "Test Loss:  5.310755729675293\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  180\n",
            "Train Loss:  4.331544876098633\n",
            "Test Loss:  5.310550689697266\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  181\n",
            "Train Loss:  4.327625274658203\n",
            "Test Loss:  5.3103532791137695\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  182\n",
            "Train Loss:  4.323732852935791\n",
            "Test Loss:  5.31016731262207\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  183\n",
            "Train Loss:  4.319862365722656\n",
            "Test Loss:  5.309974193572998\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  184\n",
            "Train Loss:  4.316020965576172\n",
            "Test Loss:  5.309787750244141\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  185\n",
            "Train Loss:  4.312206268310547\n",
            "Test Loss:  5.309594631195068\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  186\n",
            "Train Loss:  4.3084187507629395\n",
            "Test Loss:  5.3094000816345215\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  187\n",
            "Train Loss:  4.304656028747559\n",
            "Test Loss:  5.309199810028076\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  188\n",
            "Train Loss:  4.3009185791015625\n",
            "Test Loss:  5.308993339538574\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  189\n",
            "Train Loss:  4.2972092628479\n",
            "Test Loss:  5.3087873458862305\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  190\n",
            "Train Loss:  4.293533802032471\n",
            "Test Loss:  5.308588981628418\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  191\n",
            "Train Loss:  4.289888381958008\n",
            "Test Loss:  5.308391094207764\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  192\n",
            "Train Loss:  4.28627347946167\n",
            "Test Loss:  5.308191299438477\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  193\n",
            "Train Loss:  4.282683372497559\n",
            "Test Loss:  5.3079915046691895\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  194\n",
            "Train Loss:  4.279116630554199\n",
            "Test Loss:  5.307790756225586\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  195\n",
            "Train Loss:  4.275583267211914\n",
            "Test Loss:  5.307590961456299\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  196\n",
            "Train Loss:  4.272085189819336\n",
            "Test Loss:  5.307394981384277\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  197\n",
            "Train Loss:  4.268622398376465\n",
            "Test Loss:  5.3072052001953125\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  198\n",
            "Train Loss:  4.265194892883301\n",
            "Test Loss:  5.307007789611816\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  199\n",
            "Train Loss:  4.261800765991211\n",
            "Test Loss:  5.306801795959473\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  200\n",
            "Train Loss:  4.2584381103515625\n",
            "Test Loss:  5.306595802307129\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  201\n",
            "Train Loss:  4.2551069259643555\n",
            "Test Loss:  5.306394577026367\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  202\n",
            "Train Loss:  4.251805782318115\n",
            "Test Loss:  5.30618953704834\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  203\n",
            "Train Loss:  4.24853515625\n",
            "Test Loss:  5.305988788604736\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  204\n",
            "Train Loss:  4.245293617248535\n",
            "Test Loss:  5.305788516998291\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  205\n",
            "Train Loss:  4.2420806884765625\n",
            "Test Loss:  5.305586338043213\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  206\n",
            "Train Loss:  4.238898277282715\n",
            "Test Loss:  5.305386543273926\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  207\n",
            "Train Loss:  4.235744953155518\n",
            "Test Loss:  5.30518913269043\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  208\n",
            "Train Loss:  4.232621192932129\n",
            "Test Loss:  5.304994583129883\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  209\n",
            "Train Loss:  4.229524612426758\n",
            "Test Loss:  5.304793834686279\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  210\n",
            "Train Loss:  4.226454257965088\n",
            "Test Loss:  5.304590702056885\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  211\n",
            "Train Loss:  4.223408222198486\n",
            "Test Loss:  5.304384231567383\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  212\n",
            "Train Loss:  4.220388889312744\n",
            "Test Loss:  5.304180145263672\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  213\n",
            "Train Loss:  4.217397689819336\n",
            "Test Loss:  5.3039751052856445\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  214\n",
            "Train Loss:  4.214432716369629\n",
            "Test Loss:  5.303766250610352\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  215\n",
            "Train Loss:  4.211492538452148\n",
            "Test Loss:  5.303565979003906\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  216\n",
            "Train Loss:  4.208576202392578\n",
            "Test Loss:  5.303373336791992\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  217\n",
            "Train Loss:  4.205684185028076\n",
            "Test Loss:  5.303184509277344\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  218\n",
            "Train Loss:  4.202814102172852\n",
            "Test Loss:  5.303004264831543\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  219\n",
            "Train Loss:  4.199970245361328\n",
            "Test Loss:  5.302827835083008\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  220\n",
            "Train Loss:  4.197146415710449\n",
            "Test Loss:  5.302659511566162\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  221\n",
            "Train Loss:  4.194347858428955\n",
            "Test Loss:  5.302497863769531\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  222\n",
            "Train Loss:  4.191569805145264\n",
            "Test Loss:  5.302338123321533\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  223\n",
            "Train Loss:  4.188811302185059\n",
            "Test Loss:  5.302176475524902\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  224\n",
            "Train Loss:  4.186075687408447\n",
            "Test Loss:  5.302018165588379\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  225\n",
            "Train Loss:  4.1833577156066895\n",
            "Test Loss:  5.301868915557861\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  226\n",
            "Train Loss:  4.180660247802734\n",
            "Test Loss:  5.301733493804932\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  227\n",
            "Train Loss:  4.177979946136475\n",
            "Test Loss:  5.3016037940979\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  228\n",
            "Train Loss:  4.175314903259277\n",
            "Test Loss:  5.30147647857666\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  229\n",
            "Train Loss:  4.172663688659668\n",
            "Test Loss:  5.301352024078369\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  230\n",
            "Train Loss:  4.1700310707092285\n",
            "Test Loss:  5.301229000091553\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  231\n",
            "Train Loss:  4.167415618896484\n",
            "Test Loss:  5.3010993003845215\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  232\n",
            "Train Loss:  4.164816379547119\n",
            "Test Loss:  5.300971031188965\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  233\n",
            "Train Loss:  4.162231922149658\n",
            "Test Loss:  5.300850868225098\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  234\n",
            "Train Loss:  4.159663200378418\n",
            "Test Loss:  5.30072546005249\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  235\n",
            "Train Loss:  4.15710973739624\n",
            "Test Loss:  5.300609111785889\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  236\n",
            "Train Loss:  4.154569625854492\n",
            "Test Loss:  5.3004961013793945\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  237\n",
            "Train Loss:  4.152042388916016\n",
            "Test Loss:  5.300382614135742\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  238\n",
            "Train Loss:  4.149531364440918\n",
            "Test Loss:  5.3002753257751465\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  239\n",
            "Train Loss:  4.147035121917725\n",
            "Test Loss:  5.300169944763184\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  240\n",
            "Train Loss:  4.144550323486328\n",
            "Test Loss:  5.300067901611328\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  241\n",
            "Train Loss:  4.142080307006836\n",
            "Test Loss:  5.299959182739258\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  242\n",
            "Train Loss:  4.139616966247559\n",
            "Test Loss:  5.299848556518555\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  243\n",
            "Train Loss:  4.137166976928711\n",
            "Test Loss:  5.299737930297852\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  244\n",
            "Train Loss:  4.134726524353027\n",
            "Test Loss:  5.299629211425781\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  245\n",
            "Train Loss:  4.132296085357666\n",
            "Test Loss:  5.299518585205078\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  246\n",
            "Train Loss:  4.129873275756836\n",
            "Test Loss:  5.299404144287109\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  247\n",
            "Train Loss:  4.127459526062012\n",
            "Test Loss:  5.299290657043457\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  248\n",
            "Train Loss:  4.125054836273193\n",
            "Test Loss:  5.299172401428223\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  249\n",
            "Train Loss:  4.122659683227539\n",
            "Test Loss:  5.299053192138672\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  250\n",
            "Train Loss:  4.120273113250732\n",
            "Test Loss:  5.29893159866333\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  251\n",
            "Train Loss:  4.117895126342773\n",
            "Test Loss:  5.298814296722412\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  252\n",
            "Train Loss:  4.115528106689453\n",
            "Test Loss:  5.298701286315918\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  253\n",
            "Train Loss:  4.113169193267822\n",
            "Test Loss:  5.298588752746582\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  254\n",
            "Train Loss:  4.110819339752197\n",
            "Test Loss:  5.298476219177246\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  255\n",
            "Train Loss:  4.108476638793945\n",
            "Test Loss:  5.298356056213379\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  256\n",
            "Train Loss:  4.106141090393066\n",
            "Test Loss:  5.2982378005981445\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  257\n",
            "Train Loss:  4.103815078735352\n",
            "Test Loss:  5.2981181144714355\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  258\n",
            "Train Loss:  4.101496696472168\n",
            "Test Loss:  5.298003196716309\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  259\n",
            "Train Loss:  4.099186897277832\n",
            "Test Loss:  5.297886848449707\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  260\n",
            "Train Loss:  4.096888542175293\n",
            "Test Loss:  5.297769546508789\n",
            "Recall : 0.18095238095238095\n",
            "Epoch  261\n",
            "Train Loss:  4.094599723815918\n",
            "Test Loss:  5.297650337219238\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  262\n",
            "Train Loss:  4.092319488525391\n",
            "Test Loss:  5.297529220581055\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  263\n",
            "Train Loss:  4.0900468826293945\n",
            "Test Loss:  5.2974090576171875\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  264\n",
            "Train Loss:  4.087787628173828\n",
            "Test Loss:  5.2972917556762695\n",
            "Recall : 0.1819047619047619\n",
            "Epoch  265\n",
            "Train Loss:  4.085538864135742\n",
            "Test Loss:  5.297177314758301\n",
            "Recall : 0.18\n",
            "Epoch  266\n",
            "Train Loss:  4.08329963684082\n",
            "Test Loss:  5.297072410583496\n",
            "Recall : 0.18\n",
            "Epoch  267\n",
            "Train Loss:  4.0810699462890625\n",
            "Test Loss:  5.296970367431641\n",
            "Recall : 0.18\n",
            "Epoch  268\n",
            "Train Loss:  4.078851222991943\n",
            "Test Loss:  5.296863555908203\n",
            "Recall : 0.18\n",
            "Epoch  269\n",
            "Train Loss:  4.076642990112305\n",
            "Test Loss:  5.2967529296875\n",
            "Recall : 0.18\n",
            "Epoch  270\n",
            "Train Loss:  4.074444770812988\n",
            "Test Loss:  5.296646595001221\n",
            "Recall : 0.18\n",
            "Epoch  271\n",
            "Train Loss:  4.072257041931152\n",
            "Test Loss:  5.296542167663574\n",
            "Recall : 0.18\n",
            "Epoch  272\n",
            "Train Loss:  4.070080757141113\n",
            "Test Loss:  5.296439170837402\n",
            "Recall : 0.18\n",
            "Epoch  273\n",
            "Train Loss:  4.067910194396973\n",
            "Test Loss:  5.296336650848389\n",
            "Recall : 0.18\n",
            "Epoch  274\n",
            "Train Loss:  4.065748691558838\n",
            "Test Loss:  5.296233654022217\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  275\n",
            "Train Loss:  4.063595771789551\n",
            "Test Loss:  5.2961320877075195\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  276\n",
            "Train Loss:  4.061452865600586\n",
            "Test Loss:  5.296031951904297\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  277\n",
            "Train Loss:  4.059320449829102\n",
            "Test Loss:  5.295934200286865\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  278\n",
            "Train Loss:  4.057197570800781\n",
            "Test Loss:  5.295840263366699\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  279\n",
            "Train Loss:  4.055086135864258\n",
            "Test Loss:  5.29573917388916\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  280\n",
            "Train Loss:  4.052984237670898\n",
            "Test Loss:  5.295637130737305\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  281\n",
            "Train Loss:  4.050894737243652\n",
            "Test Loss:  5.295535087585449\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  282\n",
            "Train Loss:  4.048815727233887\n",
            "Test Loss:  5.295431137084961\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  283\n",
            "Train Loss:  4.046745300292969\n",
            "Test Loss:  5.295328617095947\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  284\n",
            "Train Loss:  4.044686794281006\n",
            "Test Loss:  5.29523229598999\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  285\n",
            "Train Loss:  4.042637825012207\n",
            "Test Loss:  5.295139312744141\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  286\n",
            "Train Loss:  4.04060173034668\n",
            "Test Loss:  5.295051097869873\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  287\n",
            "Train Loss:  4.038576602935791\n",
            "Test Loss:  5.294966220855713\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  288\n",
            "Train Loss:  4.036564826965332\n",
            "Test Loss:  5.294881343841553\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  289\n",
            "Train Loss:  4.034564018249512\n",
            "Test Loss:  5.294795989990234\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  290\n",
            "Train Loss:  4.032573699951172\n",
            "Test Loss:  5.294716835021973\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  291\n",
            "Train Loss:  4.030595779418945\n",
            "Test Loss:  5.294639587402344\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  292\n",
            "Train Loss:  4.028629779815674\n",
            "Test Loss:  5.294569492340088\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  293\n",
            "Train Loss:  4.026674270629883\n",
            "Test Loss:  5.29449987411499\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  294\n",
            "Train Loss:  4.024730205535889\n",
            "Test Loss:  5.294430732727051\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  295\n",
            "Train Loss:  4.022796630859375\n",
            "Test Loss:  5.29435920715332\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  296\n",
            "Train Loss:  4.020876884460449\n",
            "Test Loss:  5.294289588928223\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  297\n",
            "Train Loss:  4.018964767456055\n",
            "Test Loss:  5.294220924377441\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  298\n",
            "Train Loss:  4.017062187194824\n",
            "Test Loss:  5.294153690338135\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  299\n",
            "Train Loss:  4.015169143676758\n",
            "Test Loss:  5.294087886810303\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  300\n",
            "Train Loss:  4.013284683227539\n",
            "Test Loss:  5.294025421142578\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  301\n",
            "Train Loss:  4.011408805847168\n",
            "Test Loss:  5.293962478637695\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  302\n",
            "Train Loss:  4.009542465209961\n",
            "Test Loss:  5.29389762878418\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  303\n",
            "Train Loss:  4.007688522338867\n",
            "Test Loss:  5.293834686279297\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  304\n",
            "Train Loss:  4.0058441162109375\n",
            "Test Loss:  5.293776988983154\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  305\n",
            "Train Loss:  4.00400972366333\n",
            "Test Loss:  5.293718338012695\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  306\n",
            "Train Loss:  4.002186298370361\n",
            "Test Loss:  5.2936625480651855\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  307\n",
            "Train Loss:  4.000371932983398\n",
            "Test Loss:  5.293610095977783\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  308\n",
            "Train Loss:  3.998565673828125\n",
            "Test Loss:  5.293557167053223\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  309\n",
            "Train Loss:  3.9967663288116455\n",
            "Test Loss:  5.293508529663086\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  310\n",
            "Train Loss:  3.9949777126312256\n",
            "Test Loss:  5.293460369110107\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  311\n",
            "Train Loss:  3.9931998252868652\n",
            "Test Loss:  5.293417930603027\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  312\n",
            "Train Loss:  3.9914331436157227\n",
            "Test Loss:  5.293378829956055\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  313\n",
            "Train Loss:  3.9896764755249023\n",
            "Test Loss:  5.293339729309082\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  314\n",
            "Train Loss:  3.9879281520843506\n",
            "Test Loss:  5.293306350708008\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  315\n",
            "Train Loss:  3.986192226409912\n",
            "Test Loss:  5.29327392578125\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  316\n",
            "Train Loss:  3.984464645385742\n",
            "Test Loss:  5.293242931365967\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  317\n",
            "Train Loss:  3.9827451705932617\n",
            "Test Loss:  5.293211936950684\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  318\n",
            "Train Loss:  3.981034278869629\n",
            "Test Loss:  5.293187141418457\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  319\n",
            "Train Loss:  3.9793338775634766\n",
            "Test Loss:  5.293166160583496\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  320\n",
            "Train Loss:  3.977644443511963\n",
            "Test Loss:  5.293148040771484\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  321\n",
            "Train Loss:  3.975966215133667\n",
            "Test Loss:  5.293128967285156\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  322\n",
            "Train Loss:  3.9742980003356934\n",
            "Test Loss:  5.293116569519043\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  323\n",
            "Train Loss:  3.9726369380950928\n",
            "Test Loss:  5.293107032775879\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  324\n",
            "Train Loss:  3.970984697341919\n",
            "Test Loss:  5.2931013107299805\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  325\n",
            "Train Loss:  3.9693410396575928\n",
            "Test Loss:  5.293100833892822\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  326\n",
            "Train Loss:  3.9677059650421143\n",
            "Test Loss:  5.293108940124512\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  327\n",
            "Train Loss:  3.9660816192626953\n",
            "Test Loss:  5.293125152587891\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  328\n",
            "Train Loss:  3.9644641876220703\n",
            "Test Loss:  5.293144226074219\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  329\n",
            "Train Loss:  3.9628567695617676\n",
            "Test Loss:  5.2931671142578125\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  330\n",
            "Train Loss:  3.9612574577331543\n",
            "Test Loss:  5.293194770812988\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  331\n",
            "Train Loss:  3.9596660137176514\n",
            "Test Loss:  5.293219566345215\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  332\n",
            "Train Loss:  3.958085536956787\n",
            "Test Loss:  5.293245315551758\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  333\n",
            "Train Loss:  3.956514596939087\n",
            "Test Loss:  5.293274879455566\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  334\n",
            "Train Loss:  3.954951286315918\n",
            "Test Loss:  5.293306350708008\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  335\n",
            "Train Loss:  3.953396797180176\n",
            "Test Loss:  5.293332576751709\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  336\n",
            "Train Loss:  3.9518496990203857\n",
            "Test Loss:  5.293361186981201\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  337\n",
            "Train Loss:  3.950310230255127\n",
            "Test Loss:  5.293393611907959\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  338\n",
            "Train Loss:  3.9487767219543457\n",
            "Test Loss:  5.293420791625977\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  339\n",
            "Train Loss:  3.9472503662109375\n",
            "Test Loss:  5.293455123901367\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  340\n",
            "Train Loss:  3.945730686187744\n",
            "Test Loss:  5.293497562408447\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  341\n",
            "Train Loss:  3.9442191123962402\n",
            "Test Loss:  5.293542861938477\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  342\n",
            "Train Loss:  3.9427146911621094\n",
            "Test Loss:  5.293588161468506\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  343\n",
            "Train Loss:  3.9412169456481934\n",
            "Test Loss:  5.293634414672852\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  344\n",
            "Train Loss:  3.9397268295288086\n",
            "Test Loss:  5.2936811447143555\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  345\n",
            "Train Loss:  3.9382436275482178\n",
            "Test Loss:  5.293725490570068\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  346\n",
            "Train Loss:  3.9367668628692627\n",
            "Test Loss:  5.293769836425781\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  347\n",
            "Train Loss:  3.9352946281433105\n",
            "Test Loss:  5.293813705444336\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  348\n",
            "Train Loss:  3.933828830718994\n",
            "Test Loss:  5.293859481811523\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  349\n",
            "Train Loss:  3.932370185852051\n",
            "Test Loss:  5.293903350830078\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  350\n",
            "Train Loss:  3.930919647216797\n",
            "Test Loss:  5.293951988220215\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  351\n",
            "Train Loss:  3.9294731616973877\n",
            "Test Loss:  5.294002056121826\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  352\n",
            "Train Loss:  3.928032398223877\n",
            "Test Loss:  5.294056415557861\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  353\n",
            "Train Loss:  3.926597833633423\n",
            "Test Loss:  5.294109344482422\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  354\n",
            "Train Loss:  3.9251675605773926\n",
            "Test Loss:  5.294160842895508\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  355\n",
            "Train Loss:  3.9237422943115234\n",
            "Test Loss:  5.29421329498291\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  356\n",
            "Train Loss:  3.9223215579986572\n",
            "Test Loss:  5.29426908493042\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  357\n",
            "Train Loss:  3.9209048748016357\n",
            "Test Loss:  5.294328689575195\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  358\n",
            "Train Loss:  3.9194939136505127\n",
            "Test Loss:  5.294388771057129\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  359\n",
            "Train Loss:  3.918086051940918\n",
            "Test Loss:  5.294452667236328\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  360\n",
            "Train Loss:  3.916682243347168\n",
            "Test Loss:  5.294515609741211\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  361\n",
            "Train Loss:  3.915282726287842\n",
            "Test Loss:  5.294581413269043\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  362\n",
            "Train Loss:  3.9138872623443604\n",
            "Test Loss:  5.294650077819824\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  363\n",
            "Train Loss:  3.9124960899353027\n",
            "Test Loss:  5.294717788696289\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  364\n",
            "Train Loss:  3.9111077785491943\n",
            "Test Loss:  5.294782638549805\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  365\n",
            "Train Loss:  3.9097228050231934\n",
            "Test Loss:  5.294846057891846\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  366\n",
            "Train Loss:  3.908342123031616\n",
            "Test Loss:  5.294913291931152\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  367\n",
            "Train Loss:  3.9069669246673584\n",
            "Test Loss:  5.294977188110352\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  368\n",
            "Train Loss:  3.905595302581787\n",
            "Test Loss:  5.295041561126709\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  369\n",
            "Train Loss:  3.9042277336120605\n",
            "Test Loss:  5.29510498046875\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  370\n",
            "Train Loss:  3.9028661251068115\n",
            "Test Loss:  5.295168399810791\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  371\n",
            "Train Loss:  3.9015085697174072\n",
            "Test Loss:  5.295228004455566\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  372\n",
            "Train Loss:  3.900156021118164\n",
            "Test Loss:  5.295289516448975\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  373\n",
            "Train Loss:  3.8988070487976074\n",
            "Test Loss:  5.295351505279541\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  374\n",
            "Train Loss:  3.8974618911743164\n",
            "Test Loss:  5.295413017272949\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  375\n",
            "Train Loss:  3.896121025085449\n",
            "Test Loss:  5.295473575592041\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  376\n",
            "Train Loss:  3.894782543182373\n",
            "Test Loss:  5.295533180236816\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  377\n",
            "Train Loss:  3.893446922302246\n",
            "Test Loss:  5.295590400695801\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  378\n",
            "Train Loss:  3.8921151161193848\n",
            "Test Loss:  5.295647144317627\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  379\n",
            "Train Loss:  3.8907856941223145\n",
            "Test Loss:  5.295701026916504\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  380\n",
            "Train Loss:  3.889458417892456\n",
            "Test Loss:  5.295755386352539\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  381\n",
            "Train Loss:  3.8881330490112305\n",
            "Test Loss:  5.295809268951416\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  382\n",
            "Train Loss:  3.886812210083008\n",
            "Test Loss:  5.295862197875977\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  383\n",
            "Train Loss:  3.8854939937591553\n",
            "Test Loss:  5.295912742614746\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  384\n",
            "Train Loss:  3.8841798305511475\n",
            "Test Loss:  5.295960426330566\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  385\n",
            "Train Loss:  3.8828697204589844\n",
            "Test Loss:  5.296006202697754\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  386\n",
            "Train Loss:  3.881564140319824\n",
            "Test Loss:  5.2960524559021\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  387\n",
            "Train Loss:  3.880260467529297\n",
            "Test Loss:  5.296097278594971\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  388\n",
            "Train Loss:  3.878962516784668\n",
            "Test Loss:  5.296143531799316\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  389\n",
            "Train Loss:  3.8776702880859375\n",
            "Test Loss:  5.29619026184082\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  390\n",
            "Train Loss:  3.8763833045959473\n",
            "Test Loss:  5.296238899230957\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  391\n",
            "Train Loss:  3.8750998973846436\n",
            "Test Loss:  5.296288013458252\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  392\n",
            "Train Loss:  3.8738205432891846\n",
            "Test Loss:  5.296338081359863\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  393\n",
            "Train Loss:  3.8725438117980957\n",
            "Test Loss:  5.296390533447266\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  394\n",
            "Train Loss:  3.8712708950042725\n",
            "Test Loss:  5.296445846557617\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  395\n",
            "Train Loss:  3.869999885559082\n",
            "Test Loss:  5.296502113342285\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  396\n",
            "Train Loss:  3.8687312602996826\n",
            "Test Loss:  5.296563625335693\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  397\n",
            "Train Loss:  3.8674654960632324\n",
            "Test Loss:  5.296624660491943\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  398\n",
            "Train Loss:  3.8662028312683105\n",
            "Test Loss:  5.296682834625244\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  399\n",
            "Train Loss:  3.864943742752075\n",
            "Test Loss:  5.296741008758545\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  400\n",
            "Train Loss:  3.863689422607422\n",
            "Test Loss:  5.2967987060546875\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  401\n",
            "Train Loss:  3.862438917160034\n",
            "Test Loss:  5.2968525886535645\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  402\n",
            "Train Loss:  3.8611927032470703\n",
            "Test Loss:  5.296904563903809\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  403\n",
            "Train Loss:  3.8599495887756348\n",
            "Test Loss:  5.296957969665527\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  404\n",
            "Train Loss:  3.858710289001465\n",
            "Test Loss:  5.297012805938721\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  405\n",
            "Train Loss:  3.857473373413086\n",
            "Test Loss:  5.297067165374756\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  406\n",
            "Train Loss:  3.856240749359131\n",
            "Test Loss:  5.297121047973633\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  407\n",
            "Train Loss:  3.8550124168395996\n",
            "Test Loss:  5.297176361083984\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  408\n",
            "Train Loss:  3.8537864685058594\n",
            "Test Loss:  5.297231674194336\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  409\n",
            "Train Loss:  3.852564811706543\n",
            "Test Loss:  5.297286033630371\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  410\n",
            "Train Loss:  3.851348876953125\n",
            "Test Loss:  5.297342300415039\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  411\n",
            "Train Loss:  3.8501343727111816\n",
            "Test Loss:  5.297393798828125\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  412\n",
            "Train Loss:  3.848924160003662\n",
            "Test Loss:  5.297443389892578\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  413\n",
            "Train Loss:  3.84771728515625\n",
            "Test Loss:  5.297494411468506\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  414\n",
            "Train Loss:  3.8465137481689453\n",
            "Test Loss:  5.297544479370117\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  415\n",
            "Train Loss:  3.8453128337860107\n",
            "Test Loss:  5.2975969314575195\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  416\n",
            "Train Loss:  3.844113826751709\n",
            "Test Loss:  5.297650337219238\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  417\n",
            "Train Loss:  3.8429174423217773\n",
            "Test Loss:  5.297700881958008\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  418\n",
            "Train Loss:  3.8417229652404785\n",
            "Test Loss:  5.297752380371094\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  419\n",
            "Train Loss:  3.840531349182129\n",
            "Test Loss:  5.297804832458496\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  420\n",
            "Train Loss:  3.839341402053833\n",
            "Test Loss:  5.297856330871582\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  421\n",
            "Train Loss:  3.83815336227417\n",
            "Test Loss:  5.297910213470459\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  422\n",
            "Train Loss:  3.836968421936035\n",
            "Test Loss:  5.297967433929443\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  423\n",
            "Train Loss:  3.835787773132324\n",
            "Test Loss:  5.298026084899902\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  424\n",
            "Train Loss:  3.8346099853515625\n",
            "Test Loss:  5.298087120056152\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  425\n",
            "Train Loss:  3.8334360122680664\n",
            "Test Loss:  5.298144340515137\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  426\n",
            "Train Loss:  3.8322641849517822\n",
            "Test Loss:  5.29820442199707\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  427\n",
            "Train Loss:  3.8310954570770264\n",
            "Test Loss:  5.298264503479004\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  428\n",
            "Train Loss:  3.829929828643799\n",
            "Test Loss:  5.298325061798096\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  429\n",
            "Train Loss:  3.828766345977783\n",
            "Test Loss:  5.298386573791504\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  430\n",
            "Train Loss:  3.8276052474975586\n",
            "Test Loss:  5.298453330993652\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  431\n",
            "Train Loss:  3.8264474868774414\n",
            "Test Loss:  5.298519611358643\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  432\n",
            "Train Loss:  3.82529354095459\n",
            "Test Loss:  5.298583030700684\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  433\n",
            "Train Loss:  3.824143886566162\n",
            "Test Loss:  5.298647880554199\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  434\n",
            "Train Loss:  3.8229973316192627\n",
            "Test Loss:  5.298710823059082\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  435\n",
            "Train Loss:  3.82185435295105\n",
            "Test Loss:  5.298769950866699\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  436\n",
            "Train Loss:  3.8207149505615234\n",
            "Test Loss:  5.298827171325684\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  437\n",
            "Train Loss:  3.819579601287842\n",
            "Test Loss:  5.298884868621826\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  438\n",
            "Train Loss:  3.818448066711426\n",
            "Test Loss:  5.298940658569336\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  439\n",
            "Train Loss:  3.8173201084136963\n",
            "Test Loss:  5.298996448516846\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  440\n",
            "Train Loss:  3.816196918487549\n",
            "Test Loss:  5.299050331115723\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  441\n",
            "Train Loss:  3.815077304840088\n",
            "Test Loss:  5.2991042137146\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  442\n",
            "Train Loss:  3.813959836959839\n",
            "Test Loss:  5.299160003662109\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  443\n",
            "Train Loss:  3.8128461837768555\n",
            "Test Loss:  5.299219608306885\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  444\n",
            "Train Loss:  3.811734914779663\n",
            "Test Loss:  5.299279689788818\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  445\n",
            "Train Loss:  3.8106284141540527\n",
            "Test Loss:  5.299337387084961\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  446\n",
            "Train Loss:  3.80952787399292\n",
            "Test Loss:  5.299395561218262\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  447\n",
            "Train Loss:  3.80842924118042\n",
            "Test Loss:  5.299454689025879\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  448\n",
            "Train Loss:  3.8073341846466064\n",
            "Test Loss:  5.29951286315918\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  449\n",
            "Train Loss:  3.806244373321533\n",
            "Test Loss:  5.2995758056640625\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  450\n",
            "Train Loss:  3.8051586151123047\n",
            "Test Loss:  5.2996416091918945\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  451\n",
            "Train Loss:  3.8040759563446045\n",
            "Test Loss:  5.29970645904541\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  452\n",
            "Train Loss:  3.802997350692749\n",
            "Test Loss:  5.299772262573242\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  453\n",
            "Train Loss:  3.801921844482422\n",
            "Test Loss:  5.299838542938232\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  454\n",
            "Train Loss:  3.8008503913879395\n",
            "Test Loss:  5.2999043464660645\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  455\n",
            "Train Loss:  3.799783229827881\n",
            "Test Loss:  5.299969673156738\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  456\n",
            "Train Loss:  3.798717737197876\n",
            "Test Loss:  5.300037860870361\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  457\n",
            "Train Loss:  3.7976555824279785\n",
            "Test Loss:  5.300109386444092\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  458\n",
            "Train Loss:  3.796595573425293\n",
            "Test Loss:  5.3001837730407715\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  459\n",
            "Train Loss:  3.795539379119873\n",
            "Test Loss:  5.300259590148926\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  460\n",
            "Train Loss:  3.794487237930298\n",
            "Test Loss:  5.3003315925598145\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  461\n",
            "Train Loss:  3.793438196182251\n",
            "Test Loss:  5.300406455993652\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  462\n",
            "Train Loss:  3.792393922805786\n",
            "Test Loss:  5.300480365753174\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  463\n",
            "Train Loss:  3.791353464126587\n",
            "Test Loss:  5.300553321838379\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  464\n",
            "Train Loss:  3.790318012237549\n",
            "Test Loss:  5.300624847412109\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  465\n",
            "Train Loss:  3.7892868518829346\n",
            "Test Loss:  5.30069637298584\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  466\n",
            "Train Loss:  3.788259744644165\n",
            "Test Loss:  5.30076789855957\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  467\n",
            "Train Loss:  3.787236213684082\n",
            "Test Loss:  5.300837993621826\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  468\n",
            "Train Loss:  3.7862164974212646\n",
            "Test Loss:  5.300907135009766\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  469\n",
            "Train Loss:  3.785200834274292\n",
            "Test Loss:  5.300975322723389\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  470\n",
            "Train Loss:  3.784189224243164\n",
            "Test Loss:  5.301042556762695\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  471\n",
            "Train Loss:  3.7831826210021973\n",
            "Test Loss:  5.301112174987793\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  472\n",
            "Train Loss:  3.782180070877075\n",
            "Test Loss:  5.301184177398682\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  473\n",
            "Train Loss:  3.7811813354492188\n",
            "Test Loss:  5.301255226135254\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  474\n",
            "Train Loss:  3.7801876068115234\n",
            "Test Loss:  5.301326751708984\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  475\n",
            "Train Loss:  3.77919864654541\n",
            "Test Loss:  5.301398277282715\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  476\n",
            "Train Loss:  3.778214693069458\n",
            "Test Loss:  5.301467418670654\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  477\n",
            "Train Loss:  3.7772350311279297\n",
            "Test Loss:  5.301534652709961\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  478\n",
            "Train Loss:  3.7762606143951416\n",
            "Test Loss:  5.301603317260742\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  479\n",
            "Train Loss:  3.775290012359619\n",
            "Test Loss:  5.301671028137207\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  480\n",
            "Train Loss:  3.774322509765625\n",
            "Test Loss:  5.30173921585083\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  481\n",
            "Train Loss:  3.7733588218688965\n",
            "Test Loss:  5.301807403564453\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  482\n",
            "Train Loss:  3.7723987102508545\n",
            "Test Loss:  5.301877021789551\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  483\n",
            "Train Loss:  3.7714433670043945\n",
            "Test Loss:  5.30194616317749\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  484\n",
            "Train Loss:  3.7704920768737793\n",
            "Test Loss:  5.30201530456543\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  485\n",
            "Train Loss:  3.769544839859009\n",
            "Test Loss:  5.302083492279053\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  486\n",
            "Train Loss:  3.7686026096343994\n",
            "Test Loss:  5.302152156829834\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  487\n",
            "Train Loss:  3.7676637172698975\n",
            "Test Loss:  5.302220344543457\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  488\n",
            "Train Loss:  3.7667295932769775\n",
            "Test Loss:  5.302289962768555\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  489\n",
            "Train Loss:  3.7658002376556396\n",
            "Test Loss:  5.302361488342285\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  490\n",
            "Train Loss:  3.7648754119873047\n",
            "Test Loss:  5.30243444442749\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  491\n",
            "Train Loss:  3.76395320892334\n",
            "Test Loss:  5.302509307861328\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  492\n",
            "Train Loss:  3.7630367279052734\n",
            "Test Loss:  5.302585601806641\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  493\n",
            "Train Loss:  3.762125015258789\n",
            "Test Loss:  5.3026628494262695\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  494\n",
            "Train Loss:  3.761216640472412\n",
            "Test Loss:  5.302744388580322\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  495\n",
            "Train Loss:  3.7603132724761963\n",
            "Test Loss:  5.302829742431641\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  496\n",
            "Train Loss:  3.7594118118286133\n",
            "Test Loss:  5.30291223526001\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  497\n",
            "Train Loss:  3.7585160732269287\n",
            "Test Loss:  5.302998065948486\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  498\n",
            "Train Loss:  3.7576241493225098\n",
            "Test Loss:  5.303084850311279\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  499\n",
            "Train Loss:  3.7567365169525146\n",
            "Test Loss:  5.303169250488281\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  500\n",
            "Train Loss:  3.7558541297912598\n",
            "Test Loss:  5.30325174331665\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  501\n",
            "Train Loss:  3.7549736499786377\n",
            "Test Loss:  5.303335666656494\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  502\n",
            "Train Loss:  3.754098415374756\n",
            "Test Loss:  5.303418159484863\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  503\n",
            "Train Loss:  3.7532272338867188\n",
            "Test Loss:  5.303502082824707\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  504\n",
            "Train Loss:  3.7523584365844727\n",
            "Test Loss:  5.3035888671875\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  505\n",
            "Train Loss:  3.751492500305176\n",
            "Test Loss:  5.303676605224609\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  506\n",
            "Train Loss:  3.750631093978882\n",
            "Test Loss:  5.303765773773193\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  507\n",
            "Train Loss:  3.7497737407684326\n",
            "Test Loss:  5.303854465484619\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  508\n",
            "Train Loss:  3.74891996383667\n",
            "Test Loss:  5.30394172668457\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  509\n",
            "Train Loss:  3.7480690479278564\n",
            "Test Loss:  5.304028511047363\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  510\n",
            "Train Loss:  3.7472238540649414\n",
            "Test Loss:  5.304113388061523\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  511\n",
            "Train Loss:  3.7463817596435547\n",
            "Test Loss:  5.304200172424316\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  512\n",
            "Train Loss:  3.7455434799194336\n",
            "Test Loss:  5.304286956787109\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  513\n",
            "Train Loss:  3.7447099685668945\n",
            "Test Loss:  5.304372310638428\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  514\n",
            "Train Loss:  3.7438788414001465\n",
            "Test Loss:  5.304457664489746\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  515\n",
            "Train Loss:  3.7430505752563477\n",
            "Test Loss:  5.304543495178223\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  516\n",
            "Train Loss:  3.7422242164611816\n",
            "Test Loss:  5.304629802703857\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  517\n",
            "Train Loss:  3.7414021492004395\n",
            "Test Loss:  5.3047194480896\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  518\n",
            "Train Loss:  3.7405834197998047\n",
            "Test Loss:  5.3048095703125\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  519\n",
            "Train Loss:  3.7397682666778564\n",
            "Test Loss:  5.304899215698242\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  520\n",
            "Train Loss:  3.738957405090332\n",
            "Test Loss:  5.304986000061035\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  521\n",
            "Train Loss:  3.738150119781494\n",
            "Test Loss:  5.305074691772461\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  522\n",
            "Train Loss:  3.737346649169922\n",
            "Test Loss:  5.305166244506836\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  523\n",
            "Train Loss:  3.7365477085113525\n",
            "Test Loss:  5.305257797241211\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  524\n",
            "Train Loss:  3.735752582550049\n",
            "Test Loss:  5.305353164672852\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  525\n",
            "Train Loss:  3.7349600791931152\n",
            "Test Loss:  5.305449962615967\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  526\n",
            "Train Loss:  3.734168767929077\n",
            "Test Loss:  5.305547714233398\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  527\n",
            "Train Loss:  3.7333803176879883\n",
            "Test Loss:  5.305646896362305\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  528\n",
            "Train Loss:  3.732595443725586\n",
            "Test Loss:  5.305747985839844\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  529\n",
            "Train Loss:  3.731813669204712\n",
            "Test Loss:  5.305848121643066\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  530\n",
            "Train Loss:  3.7310357093811035\n",
            "Test Loss:  5.305948257446289\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  531\n",
            "Train Loss:  3.73026180267334\n",
            "Test Loss:  5.306050777435303\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  532\n",
            "Train Loss:  3.7294907569885254\n",
            "Test Loss:  5.306150436401367\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  533\n",
            "Train Loss:  3.7287235260009766\n",
            "Test Loss:  5.306249141693115\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  534\n",
            "Train Loss:  3.727959632873535\n",
            "Test Loss:  5.306347370147705\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  535\n",
            "Train Loss:  3.727199077606201\n",
            "Test Loss:  5.306445598602295\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  536\n",
            "Train Loss:  3.7264411449432373\n",
            "Test Loss:  5.306541919708252\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  537\n",
            "Train Loss:  3.725686550140381\n",
            "Test Loss:  5.306636810302734\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  538\n",
            "Train Loss:  3.7249348163604736\n",
            "Test Loss:  5.306731224060059\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  539\n",
            "Train Loss:  3.724184989929199\n",
            "Test Loss:  5.306824684143066\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  540\n",
            "Train Loss:  3.723437786102295\n",
            "Test Loss:  5.306916236877441\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  541\n",
            "Train Loss:  3.7226929664611816\n",
            "Test Loss:  5.3070068359375\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  542\n",
            "Train Loss:  3.721952199935913\n",
            "Test Loss:  5.307098865509033\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  543\n",
            "Train Loss:  3.721212148666382\n",
            "Test Loss:  5.307192325592041\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  544\n",
            "Train Loss:  3.7204742431640625\n",
            "Test Loss:  5.307283401489258\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  545\n",
            "Train Loss:  3.719738483428955\n",
            "Test Loss:  5.307374000549316\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  546\n",
            "Train Loss:  3.7190046310424805\n",
            "Test Loss:  5.307462692260742\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  547\n",
            "Train Loss:  3.718273401260376\n",
            "Test Loss:  5.30755090713501\n",
            "Recall : 0.17904761904761904\n",
            "Epoch  548\n",
            "Train Loss:  3.717543125152588\n",
            "Test Loss:  5.307638168334961\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  549\n",
            "Train Loss:  3.7168149948120117\n",
            "Test Loss:  5.30772590637207\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  550\n",
            "Train Loss:  3.71608829498291\n",
            "Test Loss:  5.30781364440918\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  551\n",
            "Train Loss:  3.7153635025024414\n",
            "Test Loss:  5.307901382446289\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  552\n",
            "Train Loss:  3.7146410942077637\n",
            "Test Loss:  5.307989597320557\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  553\n",
            "Train Loss:  3.713921546936035\n",
            "Test Loss:  5.308076858520508\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  554\n",
            "Train Loss:  3.7132039070129395\n",
            "Test Loss:  5.308164596557617\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  555\n",
            "Train Loss:  3.7124886512756348\n",
            "Test Loss:  5.30825138092041\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  556\n",
            "Train Loss:  3.7117762565612793\n",
            "Test Loss:  5.3083391189575195\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  557\n",
            "Train Loss:  3.711066246032715\n",
            "Test Loss:  5.308426856994629\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  558\n",
            "Train Loss:  3.710358142852783\n",
            "Test Loss:  5.30851411819458\n",
            "Recall : 0.17809523809523808\n",
            "Epoch  559\n",
            "Train Loss:  3.7096524238586426\n",
            "Test Loss:  5.308599948883057\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  560\n",
            "Train Loss:  3.7089481353759766\n",
            "Test Loss:  5.308686256408691\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  561\n",
            "Train Loss:  3.7082464694976807\n",
            "Test Loss:  5.308772563934326\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  562\n",
            "Train Loss:  3.707545280456543\n",
            "Test Loss:  5.308856964111328\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  563\n",
            "Train Loss:  3.706846237182617\n",
            "Test Loss:  5.308940887451172\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  564\n",
            "Train Loss:  3.7061502933502197\n",
            "Test Loss:  5.309024810791016\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  565\n",
            "Train Loss:  3.7054555416107178\n",
            "Test Loss:  5.309108734130859\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  566\n",
            "Train Loss:  3.7047624588012695\n",
            "Test Loss:  5.30919075012207\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  567\n",
            "Train Loss:  3.704070568084717\n",
            "Test Loss:  5.309272289276123\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  568\n",
            "Train Loss:  3.703381061553955\n",
            "Test Loss:  5.309354782104492\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  569\n",
            "Train Loss:  3.702692985534668\n",
            "Test Loss:  5.309438705444336\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  570\n",
            "Train Loss:  3.7020058631896973\n",
            "Test Loss:  5.309523582458496\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  571\n",
            "Train Loss:  3.701320171356201\n",
            "Test Loss:  5.309607982635498\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  572\n",
            "Train Loss:  3.700636863708496\n",
            "Test Loss:  5.309695243835449\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  573\n",
            "Train Loss:  3.699953556060791\n",
            "Test Loss:  5.3097825050354\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  574\n",
            "Train Loss:  3.6992721557617188\n",
            "Test Loss:  5.309869766235352\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  575\n",
            "Train Loss:  3.698591947555542\n",
            "Test Loss:  5.309954643249512\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  576\n",
            "Train Loss:  3.6979122161865234\n",
            "Test Loss:  5.310038089752197\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  577\n",
            "Train Loss:  3.697235584259033\n",
            "Test Loss:  5.310120582580566\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  578\n",
            "Train Loss:  3.6965599060058594\n",
            "Test Loss:  5.31020450592041\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  579\n",
            "Train Loss:  3.695885181427002\n",
            "Test Loss:  5.310285568237305\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  580\n",
            "Train Loss:  3.695211410522461\n",
            "Test Loss:  5.310368537902832\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  581\n",
            "Train Loss:  3.694538116455078\n",
            "Test Loss:  5.310450553894043\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  582\n",
            "Train Loss:  3.6938672065734863\n",
            "Test Loss:  5.3105316162109375\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  583\n",
            "Train Loss:  3.6931962966918945\n",
            "Test Loss:  5.310612678527832\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  584\n",
            "Train Loss:  3.6925272941589355\n",
            "Test Loss:  5.310693740844727\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  585\n",
            "Train Loss:  3.6918582916259766\n",
            "Test Loss:  5.310773849487305\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  586\n",
            "Train Loss:  3.691190242767334\n",
            "Test Loss:  5.310854911804199\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  587\n",
            "Train Loss:  3.690523147583008\n",
            "Test Loss:  5.3109354972839355\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  588\n",
            "Train Loss:  3.6898560523986816\n",
            "Test Loss:  5.3110151290893555\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  589\n",
            "Train Loss:  3.6891894340515137\n",
            "Test Loss:  5.311092376708984\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  590\n",
            "Train Loss:  3.68852162361145\n",
            "Test Loss:  5.311169624328613\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  591\n",
            "Train Loss:  3.6878552436828613\n",
            "Test Loss:  5.311245918273926\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  592\n",
            "Train Loss:  3.6871891021728516\n",
            "Test Loss:  5.311323165893555\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  593\n",
            "Train Loss:  3.686523675918579\n",
            "Test Loss:  5.311402320861816\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  594\n",
            "Train Loss:  3.6858582496643066\n",
            "Test Loss:  5.311479568481445\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  595\n",
            "Train Loss:  3.685192584991455\n",
            "Test Loss:  5.311556816101074\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  596\n",
            "Train Loss:  3.684528350830078\n",
            "Test Loss:  5.3116350173950195\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  597\n",
            "Train Loss:  3.6838645935058594\n",
            "Test Loss:  5.311713218688965\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  598\n",
            "Train Loss:  3.6832022666931152\n",
            "Test Loss:  5.31179141998291\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  599\n",
            "Train Loss:  3.6825408935546875\n",
            "Test Loss:  5.311868667602539\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  600\n",
            "Train Loss:  3.681880474090576\n",
            "Test Loss:  5.311944961547852\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  601\n",
            "Train Loss:  3.681220054626465\n",
            "Test Loss:  5.312024116516113\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  602\n",
            "Train Loss:  3.6805601119995117\n",
            "Test Loss:  5.312105178833008\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  603\n",
            "Train Loss:  3.679901123046875\n",
            "Test Loss:  5.312185764312744\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  604\n",
            "Train Loss:  3.67924165725708\n",
            "Test Loss:  5.312267780303955\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  605\n",
            "Train Loss:  3.678581714630127\n",
            "Test Loss:  5.312350273132324\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  606\n",
            "Train Loss:  3.6779232025146484\n",
            "Test Loss:  5.312435150146484\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  607\n",
            "Train Loss:  3.67726469039917\n",
            "Test Loss:  5.3125200271606445\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  608\n",
            "Train Loss:  3.676605701446533\n",
            "Test Loss:  5.312603950500488\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  609\n",
            "Train Loss:  3.6759493350982666\n",
            "Test Loss:  5.312689304351807\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  610\n",
            "Train Loss:  3.675293445587158\n",
            "Test Loss:  5.312772274017334\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  611\n",
            "Train Loss:  3.6746370792388916\n",
            "Test Loss:  5.312856674194336\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  612\n",
            "Train Loss:  3.673981189727783\n",
            "Test Loss:  5.3129401206970215\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  613\n",
            "Train Loss:  3.673325777053833\n",
            "Test Loss:  5.313023567199707\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  614\n",
            "Train Loss:  3.6726696491241455\n",
            "Test Loss:  5.313106536865234\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  615\n",
            "Train Loss:  3.67201566696167\n",
            "Test Loss:  5.313187599182129\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  616\n",
            "Train Loss:  3.6713614463806152\n",
            "Test Loss:  5.31326961517334\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  617\n",
            "Train Loss:  3.670708179473877\n",
            "Test Loss:  5.313349723815918\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  618\n",
            "Train Loss:  3.670055389404297\n",
            "Test Loss:  5.313429355621338\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  619\n",
            "Train Loss:  3.6694023609161377\n",
            "Test Loss:  5.3135085105896\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  620\n",
            "Train Loss:  3.6687495708465576\n",
            "Test Loss:  5.313588619232178\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  621\n",
            "Train Loss:  3.668097734451294\n",
            "Test Loss:  5.313666343688965\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  622\n",
            "Train Loss:  3.667445182800293\n",
            "Test Loss:  5.313745021820068\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  623\n",
            "Train Loss:  3.6667938232421875\n",
            "Test Loss:  5.313823699951172\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  624\n",
            "Train Loss:  3.666142463684082\n",
            "Test Loss:  5.313898086547852\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  625\n",
            "Train Loss:  3.6654913425445557\n",
            "Test Loss:  5.313973426818848\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  626\n",
            "Train Loss:  3.6648406982421875\n",
            "Test Loss:  5.3140482902526855\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  627\n",
            "Train Loss:  3.6641910076141357\n",
            "Test Loss:  5.31412410736084\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  628\n",
            "Train Loss:  3.6635403633117676\n",
            "Test Loss:  5.314201354980469\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  629\n",
            "Train Loss:  3.662890911102295\n",
            "Test Loss:  5.314277648925781\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  630\n",
            "Train Loss:  3.6622419357299805\n",
            "Test Loss:  5.314352989196777\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  631\n",
            "Train Loss:  3.661593437194824\n",
            "Test Loss:  5.314425468444824\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  632\n",
            "Train Loss:  3.6609458923339844\n",
            "Test Loss:  5.3144989013671875\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  633\n",
            "Train Loss:  3.6603012084960938\n",
            "Test Loss:  5.314571380615234\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  634\n",
            "Train Loss:  3.6596546173095703\n",
            "Test Loss:  5.314642906188965\n",
            "Recall : 0.17714285714285713\n",
            "Epoch  635\n",
            "Train Loss:  3.659010410308838\n",
            "Test Loss:  5.314715385437012\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  636\n",
            "Train Loss:  3.65836763381958\n",
            "Test Loss:  5.314786911010742\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  637\n",
            "Train Loss:  3.6577258110046387\n",
            "Test Loss:  5.314857482910156\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  638\n",
            "Train Loss:  3.657083511352539\n",
            "Test Loss:  5.3149285316467285\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  639\n",
            "Train Loss:  3.6564435958862305\n",
            "Test Loss:  5.314998626708984\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  640\n",
            "Train Loss:  3.6558034420013428\n",
            "Test Loss:  5.315068244934082\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  641\n",
            "Train Loss:  3.655165195465088\n",
            "Test Loss:  5.315136432647705\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  642\n",
            "Train Loss:  3.654526710510254\n",
            "Test Loss:  5.315202713012695\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  643\n",
            "Train Loss:  3.6538894176483154\n",
            "Test Loss:  5.315269470214844\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  644\n",
            "Train Loss:  3.653252363204956\n",
            "Test Loss:  5.315336227416992\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  645\n",
            "Train Loss:  3.6526169776916504\n",
            "Test Loss:  5.315402507781982\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  646\n",
            "Train Loss:  3.6519837379455566\n",
            "Test Loss:  5.315467834472656\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  647\n",
            "Train Loss:  3.651350736618042\n",
            "Test Loss:  5.315532684326172\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  648\n",
            "Train Loss:  3.650719165802002\n",
            "Test Loss:  5.315597057342529\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  649\n",
            "Train Loss:  3.6500887870788574\n",
            "Test Loss:  5.31566047668457\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  650\n",
            "Train Loss:  3.64945912361145\n",
            "Test Loss:  5.315726280212402\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  651\n",
            "Train Loss:  3.648829936981201\n",
            "Test Loss:  5.315792083740234\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  652\n",
            "Train Loss:  3.648202657699585\n",
            "Test Loss:  5.315857887268066\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  653\n",
            "Train Loss:  3.647576332092285\n",
            "Test Loss:  5.315924644470215\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  654\n",
            "Train Loss:  3.646951198577881\n",
            "Test Loss:  5.315991401672363\n",
            "Recall : 0.1761904761904762\n",
            "Epoch  655\n",
            "Train Loss:  3.646327018737793\n",
            "Test Loss:  5.316056251525879\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  656\n",
            "Train Loss:  3.6457037925720215\n",
            "Test Loss:  5.316122055053711\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  657\n",
            "Train Loss:  3.6450812816619873\n",
            "Test Loss:  5.316190719604492\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  658\n",
            "Train Loss:  3.6444602012634277\n",
            "Test Loss:  5.316259384155273\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  659\n",
            "Train Loss:  3.64384126663208\n",
            "Test Loss:  5.316329002380371\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  660\n",
            "Train Loss:  3.6432228088378906\n",
            "Test Loss:  5.316396713256836\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  661\n",
            "Train Loss:  3.6426055431365967\n",
            "Test Loss:  5.316462516784668\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  662\n",
            "Train Loss:  3.6419897079467773\n",
            "Test Loss:  5.316526412963867\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  663\n",
            "Train Loss:  3.6413774490356445\n",
            "Test Loss:  5.316589832305908\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  664\n",
            "Train Loss:  3.6407644748687744\n",
            "Test Loss:  5.316655158996582\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  665\n",
            "Train Loss:  3.6401519775390625\n",
            "Test Loss:  5.316718101501465\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  666\n",
            "Train Loss:  3.6395411491394043\n",
            "Test Loss:  5.316778182983398\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  667\n",
            "Train Loss:  3.638929843902588\n",
            "Test Loss:  5.316838264465332\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  668\n",
            "Train Loss:  3.638319492340088\n",
            "Test Loss:  5.316898345947266\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  669\n",
            "Train Loss:  3.637712001800537\n",
            "Test Loss:  5.31696081161499\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  670\n",
            "Train Loss:  3.637104034423828\n",
            "Test Loss:  5.317022323608398\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  671\n",
            "Train Loss:  3.6364970207214355\n",
            "Test Loss:  5.317086219787598\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  672\n",
            "Train Loss:  3.6358909606933594\n",
            "Test Loss:  5.317151069641113\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  673\n",
            "Train Loss:  3.635286331176758\n",
            "Test Loss:  5.317215442657471\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  674\n",
            "Train Loss:  3.634683609008789\n",
            "Test Loss:  5.317280292510986\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  675\n",
            "Train Loss:  3.6340832710266113\n",
            "Test Loss:  5.31734561920166\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  676\n",
            "Train Loss:  3.633483648300171\n",
            "Test Loss:  5.317408561706543\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  677\n",
            "Train Loss:  3.632884979248047\n",
            "Test Loss:  5.317468643188477\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  678\n",
            "Train Loss:  3.63228702545166\n",
            "Test Loss:  5.317530632019043\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  679\n",
            "Train Loss:  3.63169002532959\n",
            "Test Loss:  5.31758975982666\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  680\n",
            "Train Loss:  3.631094455718994\n",
            "Test Loss:  5.317651271820068\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  681\n",
            "Train Loss:  3.630499839782715\n",
            "Test Loss:  5.31771183013916\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  682\n",
            "Train Loss:  3.6299076080322266\n",
            "Test Loss:  5.31777286529541\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  683\n",
            "Train Loss:  3.6293158531188965\n",
            "Test Loss:  5.317832946777344\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  684\n",
            "Train Loss:  3.628725528717041\n",
            "Test Loss:  5.3178911209106445\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  685\n",
            "Train Loss:  3.62813663482666\n",
            "Test Loss:  5.317952632904053\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  686\n",
            "Train Loss:  3.627549648284912\n",
            "Test Loss:  5.318012714385986\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  687\n",
            "Train Loss:  3.626962661743164\n",
            "Test Loss:  5.318070411682129\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  688\n",
            "Train Loss:  3.6263771057128906\n",
            "Test Loss:  5.318126678466797\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  689\n",
            "Train Loss:  3.6257920265197754\n",
            "Test Loss:  5.318182945251465\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  690\n",
            "Train Loss:  3.625209331512451\n",
            "Test Loss:  5.318238258361816\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  691\n",
            "Train Loss:  3.6246273517608643\n",
            "Test Loss:  5.318291187286377\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  692\n",
            "Train Loss:  3.6240460872650146\n",
            "Test Loss:  5.318343162536621\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  693\n",
            "Train Loss:  3.623466968536377\n",
            "Test Loss:  5.318396091461182\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  694\n",
            "Train Loss:  3.6228880882263184\n",
            "Test Loss:  5.318448066711426\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  695\n",
            "Train Loss:  3.622311592102051\n",
            "Test Loss:  5.318498611450195\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  696\n",
            "Train Loss:  3.621736526489258\n",
            "Test Loss:  5.318548202514648\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  697\n",
            "Train Loss:  3.6211624145507812\n",
            "Test Loss:  5.318597793579102\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  698\n",
            "Train Loss:  3.620589256286621\n",
            "Test Loss:  5.318645477294922\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  699\n",
            "Train Loss:  3.620018482208252\n",
            "Test Loss:  5.318695068359375\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  700\n",
            "Train Loss:  3.6194489002227783\n",
            "Test Loss:  5.318741321563721\n",
            "Recall : 0.1742857142857143\n",
            "\n",
            "0.17171564625850314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d70e5edad5684fe3b353a88a62c4345c",
            "baad53051f0940cfb30a35e881345366",
            "829cb304f4a44153bf848e4597becf4c",
            "8ed039f72fd14db98475ff58941c2ba4",
            "970a9f83209c4a3e98f5523b4363d205",
            "1f372c6e9bc14eeaaf57242d7b05fd4c",
            "ea9a0eaab10b4399802f9fd58ef4290d",
            "598d4317644842fb9cb3829fd0fa36e5"
          ]
        },
        "id": "sGUb-EWHXp1u",
        "outputId": "0f764588-c221-45df-f4e6-def5620475f0"
      },
      "source": [
        "run(path=\"resnet34.npy\",runs=1,epochs=700,k=1,temp=15,type=1,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d70e5edad5684fe3b353a88a62c4345c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.439854145050049\n",
            "Test Loss:  6.318024635314941\n",
            "Recall : 0.11904761904761904\n",
            "Epoch  2\n",
            "Train Loss:  7.367676734924316\n",
            "Test Loss:  6.281444549560547\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  3\n",
            "Train Loss:  7.296570777893066\n",
            "Test Loss:  6.245761871337891\n",
            "Recall : 0.12285714285714286\n",
            "Epoch  4\n",
            "Train Loss:  7.2265825271606445\n",
            "Test Loss:  6.21104621887207\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  5\n",
            "Train Loss:  7.157779216766357\n",
            "Test Loss:  6.1773786544799805\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  6\n",
            "Train Loss:  7.090193748474121\n",
            "Test Loss:  6.144777297973633\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  7\n",
            "Train Loss:  7.023855209350586\n",
            "Test Loss:  6.113231182098389\n",
            "Recall : 0.12666666666666668\n",
            "Epoch  8\n",
            "Train Loss:  6.958826065063477\n",
            "Test Loss:  6.082775115966797\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  9\n",
            "Train Loss:  6.895119667053223\n",
            "Test Loss:  6.053440093994141\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  10\n",
            "Train Loss:  6.832751750946045\n",
            "Test Loss:  6.025219440460205\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  11\n",
            "Train Loss:  6.771722793579102\n",
            "Test Loss:  5.99808931350708\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  12\n",
            "Train Loss:  6.712028980255127\n",
            "Test Loss:  5.972017288208008\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  13\n",
            "Train Loss:  6.653678894042969\n",
            "Test Loss:  5.947027206420898\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  14\n",
            "Train Loss:  6.596628189086914\n",
            "Test Loss:  5.9231462478637695\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  15\n",
            "Train Loss:  6.540879249572754\n",
            "Test Loss:  5.900336265563965\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  16\n",
            "Train Loss:  6.486390113830566\n",
            "Test Loss:  5.878572463989258\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  17\n",
            "Train Loss:  6.43315315246582\n",
            "Test Loss:  5.857794284820557\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  18\n",
            "Train Loss:  6.38114070892334\n",
            "Test Loss:  5.838011741638184\n",
            "Recall : 0.14\n",
            "Epoch  19\n",
            "Train Loss:  6.330323219299316\n",
            "Test Loss:  5.819205284118652\n",
            "Recall : 0.13904761904761906\n",
            "Epoch  20\n",
            "Train Loss:  6.280656814575195\n",
            "Test Loss:  5.801303863525391\n",
            "Recall : 0.14\n",
            "Epoch  21\n",
            "Train Loss:  6.232105255126953\n",
            "Test Loss:  5.784273147583008\n",
            "Recall : 0.14\n",
            "Epoch  22\n",
            "Train Loss:  6.184629917144775\n",
            "Test Loss:  5.768095970153809\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  23\n",
            "Train Loss:  6.138171195983887\n",
            "Test Loss:  5.752725601196289\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  24\n",
            "Train Loss:  6.0926971435546875\n",
            "Test Loss:  5.738096237182617\n",
            "Recall : 0.14\n",
            "Epoch  25\n",
            "Train Loss:  6.048159122467041\n",
            "Test Loss:  5.724167823791504\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  26\n",
            "Train Loss:  6.004537582397461\n",
            "Test Loss:  5.710932731628418\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  27\n",
            "Train Loss:  5.961787223815918\n",
            "Test Loss:  5.698348045349121\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  28\n",
            "Train Loss:  5.919868469238281\n",
            "Test Loss:  5.686359405517578\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  29\n",
            "Train Loss:  5.878752708435059\n",
            "Test Loss:  5.674946308135986\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  30\n",
            "Train Loss:  5.838412284851074\n",
            "Test Loss:  5.664090156555176\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  31\n",
            "Train Loss:  5.798815727233887\n",
            "Test Loss:  5.653707027435303\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  32\n",
            "Train Loss:  5.759940147399902\n",
            "Test Loss:  5.643820762634277\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  33\n",
            "Train Loss:  5.721756935119629\n",
            "Test Loss:  5.634394645690918\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  34\n",
            "Train Loss:  5.684225082397461\n",
            "Test Loss:  5.625386714935303\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  35\n",
            "Train Loss:  5.647319793701172\n",
            "Test Loss:  5.616772651672363\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  36\n",
            "Train Loss:  5.611021041870117\n",
            "Test Loss:  5.608527183532715\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  37\n",
            "Train Loss:  5.575314521789551\n",
            "Test Loss:  5.600620269775391\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  38\n",
            "Train Loss:  5.540167331695557\n",
            "Test Loss:  5.593076229095459\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  39\n",
            "Train Loss:  5.505565643310547\n",
            "Test Loss:  5.585856914520264\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  40\n",
            "Train Loss:  5.471503257751465\n",
            "Test Loss:  5.578961372375488\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  41\n",
            "Train Loss:  5.437948703765869\n",
            "Test Loss:  5.5723724365234375\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  42\n",
            "Train Loss:  5.404900550842285\n",
            "Test Loss:  5.566079139709473\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  43\n",
            "Train Loss:  5.372361183166504\n",
            "Test Loss:  5.560060501098633\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  44\n",
            "Train Loss:  5.340330600738525\n",
            "Test Loss:  5.5543060302734375\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  45\n",
            "Train Loss:  5.308789253234863\n",
            "Test Loss:  5.5488128662109375\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  46\n",
            "Train Loss:  5.277727127075195\n",
            "Test Loss:  5.543557167053223\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  47\n",
            "Train Loss:  5.2471160888671875\n",
            "Test Loss:  5.538558483123779\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  48\n",
            "Train Loss:  5.21694278717041\n",
            "Test Loss:  5.53377628326416\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  49\n",
            "Train Loss:  5.1872029304504395\n",
            "Test Loss:  5.529151916503906\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  50\n",
            "Train Loss:  5.157892227172852\n",
            "Test Loss:  5.524727821350098\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  51\n",
            "Train Loss:  5.129001140594482\n",
            "Test Loss:  5.520491600036621\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  52\n",
            "Train Loss:  5.100521087646484\n",
            "Test Loss:  5.516439437866211\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  53\n",
            "Train Loss:  5.07244873046875\n",
            "Test Loss:  5.512560844421387\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  54\n",
            "Train Loss:  5.0447845458984375\n",
            "Test Loss:  5.508851051330566\n",
            "Recall : 0.16\n",
            "Epoch  55\n",
            "Train Loss:  5.017522811889648\n",
            "Test Loss:  5.505304336547852\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  56\n",
            "Train Loss:  4.990646839141846\n",
            "Test Loss:  5.501900672912598\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  57\n",
            "Train Loss:  4.964144706726074\n",
            "Test Loss:  5.498654365539551\n",
            "Recall : 0.16\n",
            "Epoch  58\n",
            "Train Loss:  4.938007354736328\n",
            "Test Loss:  5.495550632476807\n",
            "Recall : 0.16\n",
            "Epoch  59\n",
            "Train Loss:  4.912240505218506\n",
            "Test Loss:  5.49258279800415\n",
            "Recall : 0.16\n",
            "Epoch  60\n",
            "Train Loss:  4.8868255615234375\n",
            "Test Loss:  5.489729881286621\n",
            "Recall : 0.16\n",
            "Epoch  61\n",
            "Train Loss:  4.861757278442383\n",
            "Test Loss:  5.486997604370117\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  62\n",
            "Train Loss:  4.8370466232299805\n",
            "Test Loss:  5.48438835144043\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  63\n",
            "Train Loss:  4.812694072723389\n",
            "Test Loss:  5.481864929199219\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  64\n",
            "Train Loss:  4.78868293762207\n",
            "Test Loss:  5.479458332061768\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  65\n",
            "Train Loss:  4.7649970054626465\n",
            "Test Loss:  5.477169990539551\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  66\n",
            "Train Loss:  4.741640090942383\n",
            "Test Loss:  5.474997520446777\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  67\n",
            "Train Loss:  4.718598365783691\n",
            "Test Loss:  5.472917556762695\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  68\n",
            "Train Loss:  4.695874214172363\n",
            "Test Loss:  5.470961570739746\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  69\n",
            "Train Loss:  4.673468112945557\n",
            "Test Loss:  5.46911096572876\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  70\n",
            "Train Loss:  4.651369094848633\n",
            "Test Loss:  5.467360973358154\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  71\n",
            "Train Loss:  4.629575252532959\n",
            "Test Loss:  5.465693950653076\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  72\n",
            "Train Loss:  4.608077049255371\n",
            "Test Loss:  5.464103698730469\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  73\n",
            "Train Loss:  4.586875915527344\n",
            "Test Loss:  5.462578773498535\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  74\n",
            "Train Loss:  4.565967559814453\n",
            "Test Loss:  5.4611406326293945\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  75\n",
            "Train Loss:  4.545347213745117\n",
            "Test Loss:  5.459780693054199\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  76\n",
            "Train Loss:  4.5250115394592285\n",
            "Test Loss:  5.458477020263672\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  77\n",
            "Train Loss:  4.504961013793945\n",
            "Test Loss:  5.457240104675293\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  78\n",
            "Train Loss:  4.48517370223999\n",
            "Test Loss:  5.456088066101074\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  79\n",
            "Train Loss:  4.465664863586426\n",
            "Test Loss:  5.455020904541016\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  80\n",
            "Train Loss:  4.4464311599731445\n",
            "Test Loss:  5.454022407531738\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  81\n",
            "Train Loss:  4.427463531494141\n",
            "Test Loss:  5.4530839920043945\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  82\n",
            "Train Loss:  4.408750534057617\n",
            "Test Loss:  5.452209949493408\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  83\n",
            "Train Loss:  4.390292167663574\n",
            "Test Loss:  5.451414108276367\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  84\n",
            "Train Loss:  4.372084617614746\n",
            "Test Loss:  5.450685501098633\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  85\n",
            "Train Loss:  4.354129791259766\n",
            "Test Loss:  5.4500274658203125\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  86\n",
            "Train Loss:  4.336416244506836\n",
            "Test Loss:  5.449432373046875\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  87\n",
            "Train Loss:  4.3189496994018555\n",
            "Test Loss:  5.448911666870117\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  88\n",
            "Train Loss:  4.301722526550293\n",
            "Test Loss:  5.448451042175293\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  89\n",
            "Train Loss:  4.284733772277832\n",
            "Test Loss:  5.448048114776611\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  90\n",
            "Train Loss:  4.267984867095947\n",
            "Test Loss:  5.447714805603027\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  91\n",
            "Train Loss:  4.2514777183532715\n",
            "Test Loss:  5.447420120239258\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  92\n",
            "Train Loss:  4.235199928283691\n",
            "Test Loss:  5.447173118591309\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  93\n",
            "Train Loss:  4.219147682189941\n",
            "Test Loss:  5.446989059448242\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  94\n",
            "Train Loss:  4.20330810546875\n",
            "Test Loss:  5.446843147277832\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  95\n",
            "Train Loss:  4.187685012817383\n",
            "Test Loss:  5.44674015045166\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  96\n",
            "Train Loss:  4.172280788421631\n",
            "Test Loss:  5.4466657638549805\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  97\n",
            "Train Loss:  4.15708589553833\n",
            "Test Loss:  5.446621894836426\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  98\n",
            "Train Loss:  4.142096996307373\n",
            "Test Loss:  5.446596622467041\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  99\n",
            "Train Loss:  4.127313613891602\n",
            "Test Loss:  5.446606636047363\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  100\n",
            "Train Loss:  4.112731456756592\n",
            "Test Loss:  5.446650505065918\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  101\n",
            "Train Loss:  4.0983405113220215\n",
            "Test Loss:  5.44674015045166\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  102\n",
            "Train Loss:  4.084146499633789\n",
            "Test Loss:  5.446871757507324\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  103\n",
            "Train Loss:  4.07014274597168\n",
            "Test Loss:  5.447030067443848\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  104\n",
            "Train Loss:  4.056324005126953\n",
            "Test Loss:  5.4472198486328125\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  105\n",
            "Train Loss:  4.042688846588135\n",
            "Test Loss:  5.447445392608643\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  106\n",
            "Train Loss:  4.029236316680908\n",
            "Test Loss:  5.447722911834717\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  107\n",
            "Train Loss:  4.015962600708008\n",
            "Test Loss:  5.44803524017334\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  108\n",
            "Train Loss:  4.002872943878174\n",
            "Test Loss:  5.448369979858398\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  109\n",
            "Train Loss:  3.9899587631225586\n",
            "Test Loss:  5.448737144470215\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  110\n",
            "Train Loss:  3.9772191047668457\n",
            "Test Loss:  5.449131965637207\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  111\n",
            "Train Loss:  3.9646477699279785\n",
            "Test Loss:  5.449549674987793\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  112\n",
            "Train Loss:  3.952241897583008\n",
            "Test Loss:  5.44998836517334\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  113\n",
            "Train Loss:  3.939995050430298\n",
            "Test Loss:  5.4504570960998535\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  114\n",
            "Train Loss:  3.9279110431671143\n",
            "Test Loss:  5.450957298278809\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  115\n",
            "Train Loss:  3.915984630584717\n",
            "Test Loss:  5.4514923095703125\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  116\n",
            "Train Loss:  3.9042160511016846\n",
            "Test Loss:  5.452061653137207\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  117\n",
            "Train Loss:  3.892597198486328\n",
            "Test Loss:  5.452653884887695\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  118\n",
            "Train Loss:  3.881119966506958\n",
            "Test Loss:  5.453274250030518\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  119\n",
            "Train Loss:  3.869795799255371\n",
            "Test Loss:  5.453917503356934\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  120\n",
            "Train Loss:  3.858616352081299\n",
            "Test Loss:  5.454573631286621\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  121\n",
            "Train Loss:  3.8475708961486816\n",
            "Test Loss:  5.4552459716796875\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  122\n",
            "Train Loss:  3.8366639614105225\n",
            "Test Loss:  5.455926895141602\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  123\n",
            "Train Loss:  3.8258986473083496\n",
            "Test Loss:  5.456618309020996\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  124\n",
            "Train Loss:  3.8152670860290527\n",
            "Test Loss:  5.457326889038086\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  125\n",
            "Train Loss:  3.804774284362793\n",
            "Test Loss:  5.458030700683594\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  126\n",
            "Train Loss:  3.7944071292877197\n",
            "Test Loss:  5.458734035491943\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  127\n",
            "Train Loss:  3.7841668128967285\n",
            "Test Loss:  5.4594407081604\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  128\n",
            "Train Loss:  3.774050712585449\n",
            "Test Loss:  5.460144996643066\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  129\n",
            "Train Loss:  3.7640602588653564\n",
            "Test Loss:  5.4608473777771\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  130\n",
            "Train Loss:  3.754192352294922\n",
            "Test Loss:  5.4615559577941895\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  131\n",
            "Train Loss:  3.744452714920044\n",
            "Test Loss:  5.462283134460449\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  132\n",
            "Train Loss:  3.734830856323242\n",
            "Test Loss:  5.463022232055664\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  133\n",
            "Train Loss:  3.725327491760254\n",
            "Test Loss:  5.463769435882568\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  134\n",
            "Train Loss:  3.7159502506256104\n",
            "Test Loss:  5.464522361755371\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  135\n",
            "Train Loss:  3.7066898345947266\n",
            "Test Loss:  5.465301513671875\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  136\n",
            "Train Loss:  3.6975455284118652\n",
            "Test Loss:  5.466094493865967\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  137\n",
            "Train Loss:  3.6885182857513428\n",
            "Test Loss:  5.466901779174805\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  138\n",
            "Train Loss:  3.6796045303344727\n",
            "Test Loss:  5.467719078063965\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  139\n",
            "Train Loss:  3.6708011627197266\n",
            "Test Loss:  5.4685378074646\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  140\n",
            "Train Loss:  3.662107229232788\n",
            "Test Loss:  5.469357490539551\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  141\n",
            "Train Loss:  3.653519630432129\n",
            "Test Loss:  5.470187187194824\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  142\n",
            "Train Loss:  3.6450324058532715\n",
            "Test Loss:  5.471030235290527\n",
            "Recall : 0.16\n",
            "Epoch  143\n",
            "Train Loss:  3.6366515159606934\n",
            "Test Loss:  5.471895217895508\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  144\n",
            "Train Loss:  3.6283719539642334\n",
            "Test Loss:  5.472771644592285\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  145\n",
            "Train Loss:  3.620185375213623\n",
            "Test Loss:  5.473666191101074\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  146\n",
            "Train Loss:  3.612091541290283\n",
            "Test Loss:  5.474568843841553\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  147\n",
            "Train Loss:  3.6040892601013184\n",
            "Test Loss:  5.475480079650879\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  148\n",
            "Train Loss:  3.5961766242980957\n",
            "Test Loss:  5.476395606994629\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  149\n",
            "Train Loss:  3.5883612632751465\n",
            "Test Loss:  5.477315902709961\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  150\n",
            "Train Loss:  3.5806427001953125\n",
            "Test Loss:  5.478238105773926\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  151\n",
            "Train Loss:  3.573012351989746\n",
            "Test Loss:  5.479168891906738\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  152\n",
            "Train Loss:  3.5654749870300293\n",
            "Test Loss:  5.48011589050293\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  153\n",
            "Train Loss:  3.5580244064331055\n",
            "Test Loss:  5.481079578399658\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  154\n",
            "Train Loss:  3.550659656524658\n",
            "Test Loss:  5.482062339782715\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  155\n",
            "Train Loss:  3.5433788299560547\n",
            "Test Loss:  5.483072280883789\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  156\n",
            "Train Loss:  3.536180019378662\n",
            "Test Loss:  5.484087944030762\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  157\n",
            "Train Loss:  3.529067039489746\n",
            "Test Loss:  5.485113143920898\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  158\n",
            "Train Loss:  3.522034168243408\n",
            "Test Loss:  5.486148834228516\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  159\n",
            "Train Loss:  3.515082836151123\n",
            "Test Loss:  5.48719596862793\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  160\n",
            "Train Loss:  3.5082101821899414\n",
            "Test Loss:  5.488243579864502\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  161\n",
            "Train Loss:  3.5014140605926514\n",
            "Test Loss:  5.489295959472656\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  162\n",
            "Train Loss:  3.494694471359253\n",
            "Test Loss:  5.490361213684082\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  163\n",
            "Train Loss:  3.488050937652588\n",
            "Test Loss:  5.491430282592773\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  164\n",
            "Train Loss:  3.4814815521240234\n",
            "Test Loss:  5.492485046386719\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  165\n",
            "Train Loss:  3.4749867916107178\n",
            "Test Loss:  5.493556022644043\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  166\n",
            "Train Loss:  3.4685616493225098\n",
            "Test Loss:  5.494627952575684\n",
            "Recall : 0.16\n",
            "Epoch  167\n",
            "Train Loss:  3.4622068405151367\n",
            "Test Loss:  5.495715141296387\n",
            "Recall : 0.16\n",
            "Epoch  168\n",
            "Train Loss:  3.4559195041656494\n",
            "Test Loss:  5.496813774108887\n",
            "Recall : 0.16\n",
            "Epoch  169\n",
            "Train Loss:  3.449699640274048\n",
            "Test Loss:  5.497922897338867\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  170\n",
            "Train Loss:  3.4435462951660156\n",
            "Test Loss:  5.499049186706543\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  171\n",
            "Train Loss:  3.4374566078186035\n",
            "Test Loss:  5.500181198120117\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  172\n",
            "Train Loss:  3.431429862976074\n",
            "Test Loss:  5.501323699951172\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  173\n",
            "Train Loss:  3.4254672527313232\n",
            "Test Loss:  5.502482891082764\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  174\n",
            "Train Loss:  3.4195680618286133\n",
            "Test Loss:  5.503640174865723\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  175\n",
            "Train Loss:  3.413728713989258\n",
            "Test Loss:  5.50479793548584\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  176\n",
            "Train Loss:  3.4079442024230957\n",
            "Test Loss:  5.505963325500488\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  177\n",
            "Train Loss:  3.4022140502929688\n",
            "Test Loss:  5.507136344909668\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  178\n",
            "Train Loss:  3.396542549133301\n",
            "Test Loss:  5.508310317993164\n",
            "Recall : 0.16\n",
            "Epoch  179\n",
            "Train Loss:  3.390929698944092\n",
            "Test Loss:  5.509480953216553\n",
            "Recall : 0.16\n",
            "Epoch  180\n",
            "Train Loss:  3.3853721618652344\n",
            "Test Loss:  5.510644912719727\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  181\n",
            "Train Loss:  3.3798716068267822\n",
            "Test Loss:  5.5118021965026855\n",
            "Recall : 0.16\n",
            "Epoch  182\n",
            "Train Loss:  3.3744282722473145\n",
            "Test Loss:  5.512970447540283\n",
            "Recall : 0.16\n",
            "Epoch  183\n",
            "Train Loss:  3.3690381050109863\n",
            "Test Loss:  5.514147758483887\n",
            "Recall : 0.16\n",
            "Epoch  184\n",
            "Train Loss:  3.3637020587921143\n",
            "Test Loss:  5.515328884124756\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  185\n",
            "Train Loss:  3.3584184646606445\n",
            "Test Loss:  5.516510963439941\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  186\n",
            "Train Loss:  3.35318660736084\n",
            "Test Loss:  5.517688751220703\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  187\n",
            "Train Loss:  3.348006248474121\n",
            "Test Loss:  5.518864631652832\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  188\n",
            "Train Loss:  3.342876434326172\n",
            "Test Loss:  5.520033359527588\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  189\n",
            "Train Loss:  3.337803363800049\n",
            "Test Loss:  5.521193027496338\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  190\n",
            "Train Loss:  3.3327794075012207\n",
            "Test Loss:  5.522355079650879\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  191\n",
            "Train Loss:  3.327803134918213\n",
            "Test Loss:  5.523528099060059\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  192\n",
            "Train Loss:  3.3228678703308105\n",
            "Test Loss:  5.524699687957764\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  193\n",
            "Train Loss:  3.317979574203491\n",
            "Test Loss:  5.525862693786621\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  194\n",
            "Train Loss:  3.313138484954834\n",
            "Test Loss:  5.527026176452637\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  195\n",
            "Train Loss:  3.3083443641662598\n",
            "Test Loss:  5.5281829833984375\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  196\n",
            "Train Loss:  3.3035974502563477\n",
            "Test Loss:  5.529338836669922\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  197\n",
            "Train Loss:  3.298893928527832\n",
            "Test Loss:  5.530495643615723\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  198\n",
            "Train Loss:  3.2942347526550293\n",
            "Test Loss:  5.531674385070801\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  199\n",
            "Train Loss:  3.289618968963623\n",
            "Test Loss:  5.5328521728515625\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  200\n",
            "Train Loss:  3.285045862197876\n",
            "Test Loss:  5.534038543701172\n",
            "Recall : 0.16\n",
            "Epoch  201\n",
            "Train Loss:  3.280519485473633\n",
            "Test Loss:  5.535262584686279\n",
            "Recall : 0.16\n",
            "Epoch  202\n",
            "Train Loss:  3.2760331630706787\n",
            "Test Loss:  5.536512851715088\n",
            "Recall : 0.16\n",
            "Epoch  203\n",
            "Train Loss:  3.2715859413146973\n",
            "Test Loss:  5.537783622741699\n",
            "Recall : 0.16\n",
            "Epoch  204\n",
            "Train Loss:  3.267179489135742\n",
            "Test Loss:  5.539072036743164\n",
            "Recall : 0.16\n",
            "Epoch  205\n",
            "Train Loss:  3.262814998626709\n",
            "Test Loss:  5.540375709533691\n",
            "Recall : 0.16\n",
            "Epoch  206\n",
            "Train Loss:  3.2584898471832275\n",
            "Test Loss:  5.541708469390869\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  207\n",
            "Train Loss:  3.2542014122009277\n",
            "Test Loss:  5.543064117431641\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  208\n",
            "Train Loss:  3.2499520778656006\n",
            "Test Loss:  5.544440746307373\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  209\n",
            "Train Loss:  3.245744228363037\n",
            "Test Loss:  5.545825958251953\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  210\n",
            "Train Loss:  3.2415757179260254\n",
            "Test Loss:  5.547192573547363\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  211\n",
            "Train Loss:  3.2374446392059326\n",
            "Test Loss:  5.548539161682129\n",
            "Recall : 0.16\n",
            "Epoch  212\n",
            "Train Loss:  3.2333498001098633\n",
            "Test Loss:  5.549869537353516\n",
            "Recall : 0.16\n",
            "Epoch  213\n",
            "Train Loss:  3.2292885780334473\n",
            "Test Loss:  5.551198959350586\n",
            "Recall : 0.16\n",
            "Epoch  214\n",
            "Train Loss:  3.2252609729766846\n",
            "Test Loss:  5.552520751953125\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  215\n",
            "Train Loss:  3.221269130706787\n",
            "Test Loss:  5.553853988647461\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  216\n",
            "Train Loss:  3.2173123359680176\n",
            "Test Loss:  5.555178642272949\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  217\n",
            "Train Loss:  3.213383674621582\n",
            "Test Loss:  5.556500434875488\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  218\n",
            "Train Loss:  3.2094836235046387\n",
            "Test Loss:  5.55781364440918\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  219\n",
            "Train Loss:  3.2056150436401367\n",
            "Test Loss:  5.559111595153809\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  220\n",
            "Train Loss:  3.201779842376709\n",
            "Test Loss:  5.560395240783691\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  221\n",
            "Train Loss:  3.1979751586914062\n",
            "Test Loss:  5.561667442321777\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  222\n",
            "Train Loss:  3.1942005157470703\n",
            "Test Loss:  5.562936305999756\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  223\n",
            "Train Loss:  3.190452814102173\n",
            "Test Loss:  5.56419563293457\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  224\n",
            "Train Loss:  3.1867294311523438\n",
            "Test Loss:  5.565449237823486\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  225\n",
            "Train Loss:  3.183030128479004\n",
            "Test Loss:  5.5667009353637695\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  226\n",
            "Train Loss:  3.1793551445007324\n",
            "Test Loss:  5.567970275878906\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  227\n",
            "Train Loss:  3.175706148147583\n",
            "Test Loss:  5.569255828857422\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  228\n",
            "Train Loss:  3.172083854675293\n",
            "Test Loss:  5.570559501647949\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  229\n",
            "Train Loss:  3.168484926223755\n",
            "Test Loss:  5.571873664855957\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  230\n",
            "Train Loss:  3.1649088859558105\n",
            "Test Loss:  5.5731916427612305\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  231\n",
            "Train Loss:  3.161362409591675\n",
            "Test Loss:  5.57450008392334\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  232\n",
            "Train Loss:  3.1578421592712402\n",
            "Test Loss:  5.575802326202393\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  233\n",
            "Train Loss:  3.1543450355529785\n",
            "Test Loss:  5.577094078063965\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  234\n",
            "Train Loss:  3.1508684158325195\n",
            "Test Loss:  5.578367233276367\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  235\n",
            "Train Loss:  3.1474180221557617\n",
            "Test Loss:  5.579625129699707\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  236\n",
            "Train Loss:  3.1439871788024902\n",
            "Test Loss:  5.580877304077148\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  237\n",
            "Train Loss:  3.1405789852142334\n",
            "Test Loss:  5.582125663757324\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  238\n",
            "Train Loss:  3.1371941566467285\n",
            "Test Loss:  5.583380699157715\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  239\n",
            "Train Loss:  3.1338319778442383\n",
            "Test Loss:  5.584647178649902\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  240\n",
            "Train Loss:  3.130491256713867\n",
            "Test Loss:  5.585920333862305\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  241\n",
            "Train Loss:  3.1271700859069824\n",
            "Test Loss:  5.587212562561035\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  242\n",
            "Train Loss:  3.1238698959350586\n",
            "Test Loss:  5.588518142700195\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  243\n",
            "Train Loss:  3.1205897331237793\n",
            "Test Loss:  5.589838027954102\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  244\n",
            "Train Loss:  3.117327928543091\n",
            "Test Loss:  5.591169357299805\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  245\n",
            "Train Loss:  3.1140878200531006\n",
            "Test Loss:  5.592499732971191\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  246\n",
            "Train Loss:  3.1108651161193848\n",
            "Test Loss:  5.593824863433838\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  247\n",
            "Train Loss:  3.1076574325561523\n",
            "Test Loss:  5.595144748687744\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  248\n",
            "Train Loss:  3.104468822479248\n",
            "Test Loss:  5.596470355987549\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  249\n",
            "Train Loss:  3.1013002395629883\n",
            "Test Loss:  5.59779167175293\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  250\n",
            "Train Loss:  3.098154067993164\n",
            "Test Loss:  5.599124908447266\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  251\n",
            "Train Loss:  3.095027208328247\n",
            "Test Loss:  5.600464820861816\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  252\n",
            "Train Loss:  3.0919206142425537\n",
            "Test Loss:  5.601812362670898\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  253\n",
            "Train Loss:  3.0888333320617676\n",
            "Test Loss:  5.603181838989258\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  254\n",
            "Train Loss:  3.085761547088623\n",
            "Test Loss:  5.604568004608154\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  255\n",
            "Train Loss:  3.082709789276123\n",
            "Test Loss:  5.605961322784424\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  256\n",
            "Train Loss:  3.0796751976013184\n",
            "Test Loss:  5.6073503494262695\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  257\n",
            "Train Loss:  3.0766615867614746\n",
            "Test Loss:  5.608729362487793\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  258\n",
            "Train Loss:  3.0736703872680664\n",
            "Test Loss:  5.610111236572266\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  259\n",
            "Train Loss:  3.0706939697265625\n",
            "Test Loss:  5.611503601074219\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  260\n",
            "Train Loss:  3.067732095718384\n",
            "Test Loss:  5.6128997802734375\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  261\n",
            "Train Loss:  3.064784526824951\n",
            "Test Loss:  5.614311218261719\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  262\n",
            "Train Loss:  3.061850070953369\n",
            "Test Loss:  5.615734100341797\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  263\n",
            "Train Loss:  3.058934211730957\n",
            "Test Loss:  5.617162704467773\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  264\n",
            "Train Loss:  3.056037425994873\n",
            "Test Loss:  5.618596076965332\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  265\n",
            "Train Loss:  3.053159475326538\n",
            "Test Loss:  5.620028495788574\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  266\n",
            "Train Loss:  3.050297737121582\n",
            "Test Loss:  5.621456146240234\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  267\n",
            "Train Loss:  3.04744815826416\n",
            "Test Loss:  5.622880458831787\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  268\n",
            "Train Loss:  3.044612407684326\n",
            "Test Loss:  5.624310493469238\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  269\n",
            "Train Loss:  3.041785717010498\n",
            "Test Loss:  5.625754356384277\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  270\n",
            "Train Loss:  3.0389742851257324\n",
            "Test Loss:  5.627213478088379\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  271\n",
            "Train Loss:  3.036177635192871\n",
            "Test Loss:  5.628688812255859\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  272\n",
            "Train Loss:  3.0333943367004395\n",
            "Test Loss:  5.630189895629883\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  273\n",
            "Train Loss:  3.030623435974121\n",
            "Test Loss:  5.631712913513184\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  274\n",
            "Train Loss:  3.027865409851074\n",
            "Test Loss:  5.633235931396484\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  275\n",
            "Train Loss:  3.025120735168457\n",
            "Test Loss:  5.634753227233887\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  276\n",
            "Train Loss:  3.022387981414795\n",
            "Test Loss:  5.636287689208984\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  277\n",
            "Train Loss:  3.0196685791015625\n",
            "Test Loss:  5.637831687927246\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  278\n",
            "Train Loss:  3.016961097717285\n",
            "Test Loss:  5.639374732971191\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  279\n",
            "Train Loss:  3.014270305633545\n",
            "Test Loss:  5.6409196853637695\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  280\n",
            "Train Loss:  3.0115933418273926\n",
            "Test Loss:  5.6424880027771\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  281\n",
            "Train Loss:  3.0089304447174072\n",
            "Test Loss:  5.644063949584961\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  282\n",
            "Train Loss:  3.0062828063964844\n",
            "Test Loss:  5.6456451416015625\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  283\n",
            "Train Loss:  3.0036511421203613\n",
            "Test Loss:  5.647226333618164\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  284\n",
            "Train Loss:  3.0010359287261963\n",
            "Test Loss:  5.648802757263184\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  285\n",
            "Train Loss:  2.998433828353882\n",
            "Test Loss:  5.6503705978393555\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  286\n",
            "Train Loss:  2.9958462715148926\n",
            "Test Loss:  5.6519389152526855\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  287\n",
            "Train Loss:  2.9932708740234375\n",
            "Test Loss:  5.653509140014648\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  288\n",
            "Train Loss:  2.990713119506836\n",
            "Test Loss:  5.655083656311035\n",
            "Recall : 0.15428571428571428\n",
            "Epoch  289\n",
            "Train Loss:  2.9881691932678223\n",
            "Test Loss:  5.656661033630371\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  290\n",
            "Train Loss:  2.9856367111206055\n",
            "Test Loss:  5.658239841461182\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  291\n",
            "Train Loss:  2.983119487762451\n",
            "Test Loss:  5.659801006317139\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  292\n",
            "Train Loss:  2.9806175231933594\n",
            "Test Loss:  5.661355018615723\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  293\n",
            "Train Loss:  2.978132724761963\n",
            "Test Loss:  5.662907600402832\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  294\n",
            "Train Loss:  2.975663185119629\n",
            "Test Loss:  5.664457321166992\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  295\n",
            "Train Loss:  2.9732069969177246\n",
            "Test Loss:  5.666001319885254\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  296\n",
            "Train Loss:  2.9707610607147217\n",
            "Test Loss:  5.667543411254883\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  297\n",
            "Train Loss:  2.9683237075805664\n",
            "Test Loss:  5.669098854064941\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  298\n",
            "Train Loss:  2.9658942222595215\n",
            "Test Loss:  5.670676231384277\n",
            "Recall : 0.15333333333333332\n",
            "Epoch  299\n",
            "Train Loss:  2.9634764194488525\n",
            "Test Loss:  5.672280311584473\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  300\n",
            "Train Loss:  2.9610698223114014\n",
            "Test Loss:  5.673892021179199\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  301\n",
            "Train Loss:  2.9586739540100098\n",
            "Test Loss:  5.675512790679932\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  302\n",
            "Train Loss:  2.9562883377075195\n",
            "Test Loss:  5.677136421203613\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  303\n",
            "Train Loss:  2.953914165496826\n",
            "Test Loss:  5.678756237030029\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  304\n",
            "Train Loss:  2.9515514373779297\n",
            "Test Loss:  5.680372714996338\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  305\n",
            "Train Loss:  2.9492006301879883\n",
            "Test Loss:  5.681971073150635\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  306\n",
            "Train Loss:  2.946859836578369\n",
            "Test Loss:  5.683535575866699\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  307\n",
            "Train Loss:  2.944532871246338\n",
            "Test Loss:  5.685065269470215\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  308\n",
            "Train Loss:  2.9422173500061035\n",
            "Test Loss:  5.686572074890137\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  309\n",
            "Train Loss:  2.939913749694824\n",
            "Test Loss:  5.688071250915527\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  310\n",
            "Train Loss:  2.9376184940338135\n",
            "Test Loss:  5.689584732055664\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  311\n",
            "Train Loss:  2.9353349208831787\n",
            "Test Loss:  5.691117286682129\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  312\n",
            "Train Loss:  2.93306303024292\n",
            "Test Loss:  5.692660331726074\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  313\n",
            "Train Loss:  2.930802345275879\n",
            "Test Loss:  5.694205284118652\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  314\n",
            "Train Loss:  2.928555965423584\n",
            "Test Loss:  5.69575309753418\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  315\n",
            "Train Loss:  2.9263222217559814\n",
            "Test Loss:  5.697304725646973\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  316\n",
            "Train Loss:  2.9241013526916504\n",
            "Test Loss:  5.698864459991455\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  317\n",
            "Train Loss:  2.921888828277588\n",
            "Test Loss:  5.700414180755615\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  318\n",
            "Train Loss:  2.9196815490722656\n",
            "Test Loss:  5.701961517333984\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  319\n",
            "Train Loss:  2.9174818992614746\n",
            "Test Loss:  5.70351505279541\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  320\n",
            "Train Loss:  2.915292739868164\n",
            "Test Loss:  5.705079078674316\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  321\n",
            "Train Loss:  2.9131126403808594\n",
            "Test Loss:  5.706644058227539\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  322\n",
            "Train Loss:  2.9109416007995605\n",
            "Test Loss:  5.708216667175293\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  323\n",
            "Train Loss:  2.908780097961426\n",
            "Test Loss:  5.7097883224487305\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  324\n",
            "Train Loss:  2.906630754470825\n",
            "Test Loss:  5.711360931396484\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  325\n",
            "Train Loss:  2.904489040374756\n",
            "Test Loss:  5.712944030761719\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  326\n",
            "Train Loss:  2.9023571014404297\n",
            "Test Loss:  5.714555740356445\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  327\n",
            "Train Loss:  2.9002318382263184\n",
            "Test Loss:  5.716192722320557\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  328\n",
            "Train Loss:  2.8981096744537354\n",
            "Test Loss:  5.717842102050781\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  329\n",
            "Train Loss:  2.895993709564209\n",
            "Test Loss:  5.719491958618164\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  330\n",
            "Train Loss:  2.8938889503479004\n",
            "Test Loss:  5.721129417419434\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  331\n",
            "Train Loss:  2.8917956352233887\n",
            "Test Loss:  5.722764492034912\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  332\n",
            "Train Loss:  2.8897125720977783\n",
            "Test Loss:  5.724399566650391\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  333\n",
            "Train Loss:  2.8876380920410156\n",
            "Test Loss:  5.726019382476807\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  334\n",
            "Train Loss:  2.885573625564575\n",
            "Test Loss:  5.727622985839844\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  335\n",
            "Train Loss:  2.883519411087036\n",
            "Test Loss:  5.729237079620361\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  336\n",
            "Train Loss:  2.881471633911133\n",
            "Test Loss:  5.730862140655518\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  337\n",
            "Train Loss:  2.8794336318969727\n",
            "Test Loss:  5.732492446899414\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  338\n",
            "Train Loss:  2.8774027824401855\n",
            "Test Loss:  5.734128952026367\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  339\n",
            "Train Loss:  2.8753786087036133\n",
            "Test Loss:  5.735749244689941\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  340\n",
            "Train Loss:  2.873363971710205\n",
            "Test Loss:  5.737369537353516\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  341\n",
            "Train Loss:  2.8713555335998535\n",
            "Test Loss:  5.738986492156982\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  342\n",
            "Train Loss:  2.869356155395508\n",
            "Test Loss:  5.740609645843506\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  343\n",
            "Train Loss:  2.8673672676086426\n",
            "Test Loss:  5.74220609664917\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  344\n",
            "Train Loss:  2.865385055541992\n",
            "Test Loss:  5.743792533874512\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  345\n",
            "Train Loss:  2.8634109497070312\n",
            "Test Loss:  5.74537467956543\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  346\n",
            "Train Loss:  2.861441135406494\n",
            "Test Loss:  5.7469482421875\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  347\n",
            "Train Loss:  2.859473705291748\n",
            "Test Loss:  5.748499870300293\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  348\n",
            "Train Loss:  2.8575119972229004\n",
            "Test Loss:  5.750049591064453\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  349\n",
            "Train Loss:  2.8555588722229004\n",
            "Test Loss:  5.751587867736816\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  350\n",
            "Train Loss:  2.8536128997802734\n",
            "Test Loss:  5.753139495849609\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  351\n",
            "Train Loss:  2.8516740798950195\n",
            "Test Loss:  5.754695892333984\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  352\n",
            "Train Loss:  2.849745035171509\n",
            "Test Loss:  5.756256103515625\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  353\n",
            "Train Loss:  2.8478245735168457\n",
            "Test Loss:  5.757831573486328\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  354\n",
            "Train Loss:  2.845913887023926\n",
            "Test Loss:  5.759427547454834\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  355\n",
            "Train Loss:  2.844013214111328\n",
            "Test Loss:  5.7610554695129395\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  356\n",
            "Train Loss:  2.8421216011047363\n",
            "Test Loss:  5.762714385986328\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  357\n",
            "Train Loss:  2.840238571166992\n",
            "Test Loss:  5.764395236968994\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  358\n",
            "Train Loss:  2.838362693786621\n",
            "Test Loss:  5.76611328125\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  359\n",
            "Train Loss:  2.8364930152893066\n",
            "Test Loss:  5.767834663391113\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  360\n",
            "Train Loss:  2.8346285820007324\n",
            "Test Loss:  5.769534111022949\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  361\n",
            "Train Loss:  2.8327713012695312\n",
            "Test Loss:  5.771212100982666\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  362\n",
            "Train Loss:  2.830923318862915\n",
            "Test Loss:  5.772887706756592\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  363\n",
            "Train Loss:  2.8290822505950928\n",
            "Test Loss:  5.774557113647461\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  364\n",
            "Train Loss:  2.827249050140381\n",
            "Test Loss:  5.7762274742126465\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  365\n",
            "Train Loss:  2.8254218101501465\n",
            "Test Loss:  5.777896881103516\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  366\n",
            "Train Loss:  2.823596477508545\n",
            "Test Loss:  5.7795538902282715\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  367\n",
            "Train Loss:  2.821774482727051\n",
            "Test Loss:  5.781211853027344\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  368\n",
            "Train Loss:  2.819955348968506\n",
            "Test Loss:  5.782857418060303\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  369\n",
            "Train Loss:  2.818136692047119\n",
            "Test Loss:  5.784496784210205\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  370\n",
            "Train Loss:  2.8163235187530518\n",
            "Test Loss:  5.786138534545898\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  371\n",
            "Train Loss:  2.814518451690674\n",
            "Test Loss:  5.787792205810547\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  372\n",
            "Train Loss:  2.812716007232666\n",
            "Test Loss:  5.789456367492676\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  373\n",
            "Train Loss:  2.8109185695648193\n",
            "Test Loss:  5.791130065917969\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  374\n",
            "Train Loss:  2.809124708175659\n",
            "Test Loss:  5.792819976806641\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  375\n",
            "Train Loss:  2.8073363304138184\n",
            "Test Loss:  5.794550895690918\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  376\n",
            "Train Loss:  2.8055553436279297\n",
            "Test Loss:  5.796303749084473\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  377\n",
            "Train Loss:  2.803781270980835\n",
            "Test Loss:  5.798046112060547\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  378\n",
            "Train Loss:  2.802014112472534\n",
            "Test Loss:  5.799764633178711\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  379\n",
            "Train Loss:  2.8002572059631348\n",
            "Test Loss:  5.801482677459717\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  380\n",
            "Train Loss:  2.7985076904296875\n",
            "Test Loss:  5.803201675415039\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  381\n",
            "Train Loss:  2.796762704849243\n",
            "Test Loss:  5.804905891418457\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  382\n",
            "Train Loss:  2.7950236797332764\n",
            "Test Loss:  5.8065876960754395\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  383\n",
            "Train Loss:  2.7932896614074707\n",
            "Test Loss:  5.808242321014404\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  384\n",
            "Train Loss:  2.7915611267089844\n",
            "Test Loss:  5.809869766235352\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  385\n",
            "Train Loss:  2.7898402214050293\n",
            "Test Loss:  5.811478614807129\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  386\n",
            "Train Loss:  2.7881226539611816\n",
            "Test Loss:  5.8130974769592285\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  387\n",
            "Train Loss:  2.786407947540283\n",
            "Test Loss:  5.814726829528809\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  388\n",
            "Train Loss:  2.784701108932495\n",
            "Test Loss:  5.816383361816406\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  389\n",
            "Train Loss:  2.7830002307891846\n",
            "Test Loss:  5.818051338195801\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  390\n",
            "Train Loss:  2.7813057899475098\n",
            "Test Loss:  5.819731712341309\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  391\n",
            "Train Loss:  2.7796201705932617\n",
            "Test Loss:  5.821428298950195\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  392\n",
            "Train Loss:  2.777940273284912\n",
            "Test Loss:  5.823147773742676\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  393\n",
            "Train Loss:  2.7762651443481445\n",
            "Test Loss:  5.824869155883789\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  394\n",
            "Train Loss:  2.7745981216430664\n",
            "Test Loss:  5.8265790939331055\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  395\n",
            "Train Loss:  2.7729384899139404\n",
            "Test Loss:  5.828274250030518\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  396\n",
            "Train Loss:  2.771279811859131\n",
            "Test Loss:  5.8299479484558105\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  397\n",
            "Train Loss:  2.769623279571533\n",
            "Test Loss:  5.831595420837402\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  398\n",
            "Train Loss:  2.7679672241210938\n",
            "Test Loss:  5.833226203918457\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  399\n",
            "Train Loss:  2.7663121223449707\n",
            "Test Loss:  5.834875106811523\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  400\n",
            "Train Loss:  2.7646591663360596\n",
            "Test Loss:  5.836574554443359\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  401\n",
            "Train Loss:  2.7630114555358887\n",
            "Test Loss:  5.838306427001953\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  402\n",
            "Train Loss:  2.7613682746887207\n",
            "Test Loss:  5.840036392211914\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  403\n",
            "Train Loss:  2.7597241401672363\n",
            "Test Loss:  5.841748237609863\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  404\n",
            "Train Loss:  2.7580838203430176\n",
            "Test Loss:  5.843420028686523\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  405\n",
            "Train Loss:  2.756446599960327\n",
            "Test Loss:  5.845060348510742\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  406\n",
            "Train Loss:  2.754817485809326\n",
            "Test Loss:  5.846679210662842\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  407\n",
            "Train Loss:  2.753195285797119\n",
            "Test Loss:  5.848289489746094\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  408\n",
            "Train Loss:  2.7515788078308105\n",
            "Test Loss:  5.849953651428223\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  409\n",
            "Train Loss:  2.749969005584717\n",
            "Test Loss:  5.851685523986816\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  410\n",
            "Train Loss:  2.7483627796173096\n",
            "Test Loss:  5.853437423706055\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  411\n",
            "Train Loss:  2.7467596530914307\n",
            "Test Loss:  5.855170249938965\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  412\n",
            "Train Loss:  2.7451577186584473\n",
            "Test Loss:  5.856865882873535\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  413\n",
            "Train Loss:  2.743560314178467\n",
            "Test Loss:  5.85854434967041\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  414\n",
            "Train Loss:  2.7419724464416504\n",
            "Test Loss:  5.860235691070557\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  415\n",
            "Train Loss:  2.7403926849365234\n",
            "Test Loss:  5.861961364746094\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  416\n",
            "Train Loss:  2.738816261291504\n",
            "Test Loss:  5.863680839538574\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  417\n",
            "Train Loss:  2.7372419834136963\n",
            "Test Loss:  5.865391254425049\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  418\n",
            "Train Loss:  2.735671043395996\n",
            "Test Loss:  5.867096424102783\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  419\n",
            "Train Loss:  2.7341055870056152\n",
            "Test Loss:  5.868827819824219\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  420\n",
            "Train Loss:  2.732546806335449\n",
            "Test Loss:  5.870579719543457\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  421\n",
            "Train Loss:  2.7309937477111816\n",
            "Test Loss:  5.8723978996276855\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  422\n",
            "Train Loss:  2.729440689086914\n",
            "Test Loss:  5.87424373626709\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  423\n",
            "Train Loss:  2.727886915206909\n",
            "Test Loss:  5.8761115074157715\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  424\n",
            "Train Loss:  2.726329803466797\n",
            "Test Loss:  5.87800931930542\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  425\n",
            "Train Loss:  2.724776268005371\n",
            "Test Loss:  5.879927635192871\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  426\n",
            "Train Loss:  2.7232279777526855\n",
            "Test Loss:  5.881837844848633\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  427\n",
            "Train Loss:  2.7216858863830566\n",
            "Test Loss:  5.883726119995117\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  428\n",
            "Train Loss:  2.7201499938964844\n",
            "Test Loss:  5.88559103012085\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  429\n",
            "Train Loss:  2.7186222076416016\n",
            "Test Loss:  5.887444972991943\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  430\n",
            "Train Loss:  2.717092990875244\n",
            "Test Loss:  5.889309883117676\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  431\n",
            "Train Loss:  2.715562105178833\n",
            "Test Loss:  5.89116907119751\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  432\n",
            "Train Loss:  2.7140331268310547\n",
            "Test Loss:  5.893003463745117\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  433\n",
            "Train Loss:  2.71250581741333\n",
            "Test Loss:  5.894785404205322\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  434\n",
            "Train Loss:  2.710984706878662\n",
            "Test Loss:  5.896538257598877\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  435\n",
            "Train Loss:  2.709470748901367\n",
            "Test Loss:  5.898310661315918\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  436\n",
            "Train Loss:  2.7079598903656006\n",
            "Test Loss:  5.900094985961914\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  437\n",
            "Train Loss:  2.7064504623413086\n",
            "Test Loss:  5.9018707275390625\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  438\n",
            "Train Loss:  2.7049431800842285\n",
            "Test Loss:  5.903635025024414\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  439\n",
            "Train Loss:  2.7034358978271484\n",
            "Test Loss:  5.905414581298828\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  440\n",
            "Train Loss:  2.7019295692443848\n",
            "Test Loss:  5.907193660736084\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  441\n",
            "Train Loss:  2.700427770614624\n",
            "Test Loss:  5.908966064453125\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  442\n",
            "Train Loss:  2.6989283561706543\n",
            "Test Loss:  5.910750865936279\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  443\n",
            "Train Loss:  2.697439193725586\n",
            "Test Loss:  5.912553787231445\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  444\n",
            "Train Loss:  2.695963144302368\n",
            "Test Loss:  5.914374351501465\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  445\n",
            "Train Loss:  2.694493055343628\n",
            "Test Loss:  5.916198253631592\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  446\n",
            "Train Loss:  2.69303297996521\n",
            "Test Loss:  5.918024063110352\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  447\n",
            "Train Loss:  2.691577434539795\n",
            "Test Loss:  5.919858455657959\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  448\n",
            "Train Loss:  2.69012451171875\n",
            "Test Loss:  5.921694755554199\n",
            "Recall : 0.14857142857142858\n",
            "Epoch  449\n",
            "Train Loss:  2.6886789798736572\n",
            "Test Loss:  5.923531532287598\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  450\n",
            "Train Loss:  2.6872358322143555\n",
            "Test Loss:  5.9253740310668945\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  451\n",
            "Train Loss:  2.685793399810791\n",
            "Test Loss:  5.927220344543457\n",
            "Recall : 0.14761904761904762\n",
            "Epoch  452\n",
            "Train Loss:  2.684356927871704\n",
            "Test Loss:  5.929045677185059\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  453\n",
            "Train Loss:  2.682927131652832\n",
            "Test Loss:  5.930863380432129\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  454\n",
            "Train Loss:  2.6815011501312256\n",
            "Test Loss:  5.932708263397217\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  455\n",
            "Train Loss:  2.6800732612609863\n",
            "Test Loss:  5.93455696105957\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  456\n",
            "Train Loss:  2.678647994995117\n",
            "Test Loss:  5.936396598815918\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  457\n",
            "Train Loss:  2.6772260665893555\n",
            "Test Loss:  5.938229560852051\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  458\n",
            "Train Loss:  2.675802230834961\n",
            "Test Loss:  5.940056324005127\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  459\n",
            "Train Loss:  2.6743788719177246\n",
            "Test Loss:  5.941891670227051\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  460\n",
            "Train Loss:  2.6729609966278076\n",
            "Test Loss:  5.9437360763549805\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  461\n",
            "Train Loss:  2.6715469360351562\n",
            "Test Loss:  5.945606708526611\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  462\n",
            "Train Loss:  2.6701319217681885\n",
            "Test Loss:  5.947454452514648\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  463\n",
            "Train Loss:  2.6687209606170654\n",
            "Test Loss:  5.94929838180542\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  464\n",
            "Train Loss:  2.667318105697632\n",
            "Test Loss:  5.951155662536621\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  465\n",
            "Train Loss:  2.665919303894043\n",
            "Test Loss:  5.953042984008789\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  466\n",
            "Train Loss:  2.6645312309265137\n",
            "Test Loss:  5.954941749572754\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  467\n",
            "Train Loss:  2.6631503105163574\n",
            "Test Loss:  5.9568376541137695\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  468\n",
            "Train Loss:  2.661776065826416\n",
            "Test Loss:  5.958738327026367\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  469\n",
            "Train Loss:  2.6604037284851074\n",
            "Test Loss:  5.960629463195801\n",
            "Recall : 0.1457142857142857\n",
            "Epoch  470\n",
            "Train Loss:  2.6590332984924316\n",
            "Test Loss:  5.962520599365234\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  471\n",
            "Train Loss:  2.657663345336914\n",
            "Test Loss:  5.964387893676758\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  472\n",
            "Train Loss:  2.6563000679016113\n",
            "Test Loss:  5.966256141662598\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  473\n",
            "Train Loss:  2.6549429893493652\n",
            "Test Loss:  5.968105792999268\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  474\n",
            "Train Loss:  2.6535913944244385\n",
            "Test Loss:  5.96995735168457\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  475\n",
            "Train Loss:  2.6522393226623535\n",
            "Test Loss:  5.9718217849731445\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  476\n",
            "Train Loss:  2.650893211364746\n",
            "Test Loss:  5.97368049621582\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  477\n",
            "Train Loss:  2.649549961090088\n",
            "Test Loss:  5.975513458251953\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  478\n",
            "Train Loss:  2.648206949234009\n",
            "Test Loss:  5.977365970611572\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  479\n",
            "Train Loss:  2.6468658447265625\n",
            "Test Loss:  5.979220390319824\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  480\n",
            "Train Loss:  2.64552903175354\n",
            "Test Loss:  5.981086730957031\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  481\n",
            "Train Loss:  2.644196033477783\n",
            "Test Loss:  5.982938289642334\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  482\n",
            "Train Loss:  2.642868995666504\n",
            "Test Loss:  5.984787940979004\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  483\n",
            "Train Loss:  2.641544818878174\n",
            "Test Loss:  5.986637115478516\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  484\n",
            "Train Loss:  2.6402244567871094\n",
            "Test Loss:  5.988488674163818\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  485\n",
            "Train Loss:  2.638904571533203\n",
            "Test Loss:  5.990278244018555\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  486\n",
            "Train Loss:  2.6375856399536133\n",
            "Test Loss:  5.992040157318115\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  487\n",
            "Train Loss:  2.6362712383270264\n",
            "Test Loss:  5.993817329406738\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  488\n",
            "Train Loss:  2.634957790374756\n",
            "Test Loss:  5.995575904846191\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  489\n",
            "Train Loss:  2.633646011352539\n",
            "Test Loss:  5.997328281402588\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  490\n",
            "Train Loss:  2.6323416233062744\n",
            "Test Loss:  5.999077796936035\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  491\n",
            "Train Loss:  2.6310434341430664\n",
            "Test Loss:  6.000814437866211\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  492\n",
            "Train Loss:  2.629748821258545\n",
            "Test Loss:  6.002572059631348\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  493\n",
            "Train Loss:  2.6284594535827637\n",
            "Test Loss:  6.004359245300293\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  494\n",
            "Train Loss:  2.627175807952881\n",
            "Test Loss:  6.006164073944092\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  495\n",
            "Train Loss:  2.6258909702301025\n",
            "Test Loss:  6.007934093475342\n",
            "Recall : 0.14476190476190476\n",
            "Epoch  496\n",
            "Train Loss:  2.624612331390381\n",
            "Test Loss:  6.009693145751953\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  497\n",
            "Train Loss:  2.623338460922241\n",
            "Test Loss:  6.011460304260254\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  498\n",
            "Train Loss:  2.622067451477051\n",
            "Test Loss:  6.013216972351074\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  499\n",
            "Train Loss:  2.6208043098449707\n",
            "Test Loss:  6.015000343322754\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  500\n",
            "Train Loss:  2.6195480823516846\n",
            "Test Loss:  6.0168232917785645\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  501\n",
            "Train Loss:  2.6182966232299805\n",
            "Test Loss:  6.01865291595459\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  502\n",
            "Train Loss:  2.6170525550842285\n",
            "Test Loss:  6.0204267501831055\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  503\n",
            "Train Loss:  2.615814685821533\n",
            "Test Loss:  6.022195816040039\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  504\n",
            "Train Loss:  2.614579200744629\n",
            "Test Loss:  6.023998260498047\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  505\n",
            "Train Loss:  2.613348960876465\n",
            "Test Loss:  6.025757789611816\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  506\n",
            "Train Loss:  2.6121230125427246\n",
            "Test Loss:  6.027416229248047\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  507\n",
            "Train Loss:  2.610901355743408\n",
            "Test Loss:  6.029099464416504\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  508\n",
            "Train Loss:  2.6096842288970947\n",
            "Test Loss:  6.030791282653809\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  509\n",
            "Train Loss:  2.6084723472595215\n",
            "Test Loss:  6.0324296951293945\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  510\n",
            "Train Loss:  2.607264518737793\n",
            "Test Loss:  6.0341033935546875\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  511\n",
            "Train Loss:  2.6060709953308105\n",
            "Test Loss:  6.0357794761657715\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  512\n",
            "Train Loss:  2.6049633026123047\n",
            "Test Loss:  6.037437438964844\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  513\n",
            "Train Loss:  2.6038105487823486\n",
            "Test Loss:  6.039039611816406\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  514\n",
            "Train Loss:  2.6026015281677246\n",
            "Test Loss:  6.040709018707275\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  515\n",
            "Train Loss:  2.6014599800109863\n",
            "Test Loss:  6.042346000671387\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  516\n",
            "Train Loss:  2.6002755165100098\n",
            "Test Loss:  6.043926239013672\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  517\n",
            "Train Loss:  2.5990493297576904\n",
            "Test Loss:  6.045528411865234\n",
            "Recall : 0.1438095238095238\n",
            "Epoch  518\n",
            "Train Loss:  2.597874164581299\n",
            "Test Loss:  6.04711389541626\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  519\n",
            "Train Loss:  2.596680164337158\n",
            "Test Loss:  6.048765182495117\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  520\n",
            "Train Loss:  2.5954983234405518\n",
            "Test Loss:  6.050485610961914\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  521\n",
            "Train Loss:  2.5943312644958496\n",
            "Test Loss:  6.052057266235352\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  522\n",
            "Train Loss:  2.5931520462036133\n",
            "Test Loss:  6.053557395935059\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  523\n",
            "Train Loss:  2.592010021209717\n",
            "Test Loss:  6.055111885070801\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  524\n",
            "Train Loss:  2.5908432006835938\n",
            "Test Loss:  6.056684494018555\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  525\n",
            "Train Loss:  2.5897209644317627\n",
            "Test Loss:  6.058263778686523\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  526\n",
            "Train Loss:  2.5885462760925293\n",
            "Test Loss:  6.059660911560059\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  527\n",
            "Train Loss:  2.5874195098876953\n",
            "Test Loss:  6.061190605163574\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  528\n",
            "Train Loss:  2.5862815380096436\n",
            "Test Loss:  6.062674522399902\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  529\n",
            "Train Loss:  2.5851335525512695\n",
            "Test Loss:  6.06422233581543\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  530\n",
            "Train Loss:  2.583991050720215\n",
            "Test Loss:  6.065731048583984\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  531\n",
            "Train Loss:  2.582854747772217\n",
            "Test Loss:  6.067270278930664\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  532\n",
            "Train Loss:  2.5817394256591797\n",
            "Test Loss:  6.06885290145874\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  533\n",
            "Train Loss:  2.5806055068969727\n",
            "Test Loss:  6.070462226867676\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  534\n",
            "Train Loss:  2.5794901847839355\n",
            "Test Loss:  6.072027206420898\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  535\n",
            "Train Loss:  2.578335762023926\n",
            "Test Loss:  6.073673725128174\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  536\n",
            "Train Loss:  2.577181577682495\n",
            "Test Loss:  6.075309753417969\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  537\n",
            "Train Loss:  2.5760488510131836\n",
            "Test Loss:  6.076872825622559\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  538\n",
            "Train Loss:  2.5749337673187256\n",
            "Test Loss:  6.078520774841309\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  539\n",
            "Train Loss:  2.5738184452056885\n",
            "Test Loss:  6.080229759216309\n",
            "Recall : 0.14\n",
            "Epoch  540\n",
            "Train Loss:  2.5727133750915527\n",
            "Test Loss:  6.081798553466797\n",
            "Recall : 0.14\n",
            "Epoch  541\n",
            "Train Loss:  2.5716257095336914\n",
            "Test Loss:  6.083370208740234\n",
            "Recall : 0.14\n",
            "Epoch  542\n",
            "Train Loss:  2.570558547973633\n",
            "Test Loss:  6.0848588943481445\n",
            "Recall : 0.14\n",
            "Epoch  543\n",
            "Train Loss:  2.5694501399993896\n",
            "Test Loss:  6.086456775665283\n",
            "Recall : 0.14\n",
            "Epoch  544\n",
            "Train Loss:  2.568361282348633\n",
            "Test Loss:  6.0880231857299805\n",
            "Recall : 0.14\n",
            "Epoch  545\n",
            "Train Loss:  2.5672788619995117\n",
            "Test Loss:  6.089577674865723\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  546\n",
            "Train Loss:  2.5661873817443848\n",
            "Test Loss:  6.091190338134766\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  547\n",
            "Train Loss:  2.565115451812744\n",
            "Test Loss:  6.09279727935791\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  548\n",
            "Train Loss:  2.5640172958374023\n",
            "Test Loss:  6.0944013595581055\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  549\n",
            "Train Loss:  2.5629642009735107\n",
            "Test Loss:  6.095913887023926\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  550\n",
            "Train Loss:  2.5619139671325684\n",
            "Test Loss:  6.0975022315979\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  551\n",
            "Train Loss:  2.560842275619507\n",
            "Test Loss:  6.099031448364258\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  552\n",
            "Train Loss:  2.559793710708618\n",
            "Test Loss:  6.100522041320801\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  553\n",
            "Train Loss:  2.5587422847747803\n",
            "Test Loss:  6.102120399475098\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  554\n",
            "Train Loss:  2.557729959487915\n",
            "Test Loss:  6.103565216064453\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  555\n",
            "Train Loss:  2.5567471981048584\n",
            "Test Loss:  6.105016708374023\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  556\n",
            "Train Loss:  2.555704116821289\n",
            "Test Loss:  6.106485366821289\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  557\n",
            "Train Loss:  2.554682731628418\n",
            "Test Loss:  6.107929229736328\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  558\n",
            "Train Loss:  2.553651809692383\n",
            "Test Loss:  6.109297752380371\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  559\n",
            "Train Loss:  2.552664279937744\n",
            "Test Loss:  6.110784530639648\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  560\n",
            "Train Loss:  2.5516765117645264\n",
            "Test Loss:  6.112261772155762\n",
            "Recall : 0.14285714285714285\n",
            "Epoch  561\n",
            "Train Loss:  2.550661325454712\n",
            "Test Loss:  6.113735198974609\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  562\n",
            "Train Loss:  2.5496158599853516\n",
            "Test Loss:  6.115267753601074\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  563\n",
            "Train Loss:  2.548614978790283\n",
            "Test Loss:  6.116739749908447\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  564\n",
            "Train Loss:  2.5476062297821045\n",
            "Test Loss:  6.11818790435791\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  565\n",
            "Train Loss:  2.5466480255126953\n",
            "Test Loss:  6.119698524475098\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  566\n",
            "Train Loss:  2.5457468032836914\n",
            "Test Loss:  6.121179580688477\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  567\n",
            "Train Loss:  2.544773817062378\n",
            "Test Loss:  6.12270450592041\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  568\n",
            "Train Loss:  2.543806552886963\n",
            "Test Loss:  6.124114990234375\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  569\n",
            "Train Loss:  2.542771100997925\n",
            "Test Loss:  6.125710487365723\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  570\n",
            "Train Loss:  2.5418033599853516\n",
            "Test Loss:  6.127243995666504\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  571\n",
            "Train Loss:  2.54081130027771\n",
            "Test Loss:  6.128750324249268\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  572\n",
            "Train Loss:  2.5397987365722656\n",
            "Test Loss:  6.130328178405762\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  573\n",
            "Train Loss:  2.538832664489746\n",
            "Test Loss:  6.1320037841796875\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  574\n",
            "Train Loss:  2.537867546081543\n",
            "Test Loss:  6.133728981018066\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  575\n",
            "Train Loss:  2.536914825439453\n",
            "Test Loss:  6.13520622253418\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  576\n",
            "Train Loss:  2.5359392166137695\n",
            "Test Loss:  6.136831283569336\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  577\n",
            "Train Loss:  2.535017490386963\n",
            "Test Loss:  6.138410568237305\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  578\n",
            "Train Loss:  2.534090042114258\n",
            "Test Loss:  6.139966011047363\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  579\n",
            "Train Loss:  2.5331244468688965\n",
            "Test Loss:  6.141515731811523\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  580\n",
            "Train Loss:  2.5321693420410156\n",
            "Test Loss:  6.14313268661499\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  581\n",
            "Train Loss:  2.5312442779541016\n",
            "Test Loss:  6.144752502441406\n",
            "Recall : 0.1419047619047619\n",
            "Epoch  582\n",
            "Train Loss:  2.530280351638794\n",
            "Test Loss:  6.14644718170166\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  583\n",
            "Train Loss:  2.5293171405792236\n",
            "Test Loss:  6.1480607986450195\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  584\n",
            "Train Loss:  2.528397560119629\n",
            "Test Loss:  6.149684906005859\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  585\n",
            "Train Loss:  2.5274713039398193\n",
            "Test Loss:  6.151358604431152\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  586\n",
            "Train Loss:  2.526573896408081\n",
            "Test Loss:  6.152939796447754\n",
            "Recall : 0.14\n",
            "Epoch  587\n",
            "Train Loss:  2.525742769241333\n",
            "Test Loss:  6.154606342315674\n",
            "Recall : 0.14\n",
            "Epoch  588\n",
            "Train Loss:  2.5249035358428955\n",
            "Test Loss:  6.156173229217529\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  589\n",
            "Train Loss:  2.523993968963623\n",
            "Test Loss:  6.157804489135742\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  590\n",
            "Train Loss:  2.523101329803467\n",
            "Test Loss:  6.159339904785156\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  591\n",
            "Train Loss:  2.5221238136291504\n",
            "Test Loss:  6.160895347595215\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  592\n",
            "Train Loss:  2.521186351776123\n",
            "Test Loss:  6.162542343139648\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  593\n",
            "Train Loss:  2.5202789306640625\n",
            "Test Loss:  6.164254188537598\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  594\n",
            "Train Loss:  2.5193002223968506\n",
            "Test Loss:  6.165884971618652\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  595\n",
            "Train Loss:  2.5184152126312256\n",
            "Test Loss:  6.167520523071289\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  596\n",
            "Train Loss:  2.5175976753234863\n",
            "Test Loss:  6.169071674346924\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  597\n",
            "Train Loss:  2.516810178756714\n",
            "Test Loss:  6.170566558837891\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  598\n",
            "Train Loss:  2.5159854888916016\n",
            "Test Loss:  6.172072887420654\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  599\n",
            "Train Loss:  2.5150177478790283\n",
            "Test Loss:  6.173745632171631\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  600\n",
            "Train Loss:  2.51411771774292\n",
            "Test Loss:  6.175402641296387\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  601\n",
            "Train Loss:  2.513214349746704\n",
            "Test Loss:  6.176929473876953\n",
            "Recall : 0.1380952380952381\n",
            "Epoch  602\n",
            "Train Loss:  2.512326240539551\n",
            "Test Loss:  6.178397178649902\n",
            "Recall : 0.13714285714285715\n",
            "Epoch  603\n",
            "Train Loss:  2.5114340782165527\n",
            "Test Loss:  6.179962158203125\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  604\n",
            "Train Loss:  2.5105297565460205\n",
            "Test Loss:  6.181474685668945\n",
            "Recall : 0.1361904761904762\n",
            "Epoch  605\n",
            "Train Loss:  2.509639263153076\n",
            "Test Loss:  6.182961463928223\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  606\n",
            "Train Loss:  2.50876522064209\n",
            "Test Loss:  6.184406280517578\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  607\n",
            "Train Loss:  2.507892608642578\n",
            "Test Loss:  6.185860633850098\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  608\n",
            "Train Loss:  2.5070290565490723\n",
            "Test Loss:  6.187351226806641\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  609\n",
            "Train Loss:  2.5062122344970703\n",
            "Test Loss:  6.188813209533691\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  610\n",
            "Train Loss:  2.5053300857543945\n",
            "Test Loss:  6.190304279327393\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  611\n",
            "Train Loss:  2.5045218467712402\n",
            "Test Loss:  6.1916913986206055\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  612\n",
            "Train Loss:  2.503673791885376\n",
            "Test Loss:  6.193100929260254\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  613\n",
            "Train Loss:  2.5027623176574707\n",
            "Test Loss:  6.194594383239746\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  614\n",
            "Train Loss:  2.50197696685791\n",
            "Test Loss:  6.195943355560303\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  615\n",
            "Train Loss:  2.5011324882507324\n",
            "Test Loss:  6.197360038757324\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  616\n",
            "Train Loss:  2.5002646446228027\n",
            "Test Loss:  6.198781967163086\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  617\n",
            "Train Loss:  2.4994797706604004\n",
            "Test Loss:  6.2002410888671875\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  618\n",
            "Train Loss:  2.4986605644226074\n",
            "Test Loss:  6.201694488525391\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  619\n",
            "Train Loss:  2.4977731704711914\n",
            "Test Loss:  6.203153133392334\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  620\n",
            "Train Loss:  2.497018337249756\n",
            "Test Loss:  6.204553604125977\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  621\n",
            "Train Loss:  2.496218204498291\n",
            "Test Loss:  6.20603084564209\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  622\n",
            "Train Loss:  2.495481491088867\n",
            "Test Loss:  6.207482814788818\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  623\n",
            "Train Loss:  2.494649887084961\n",
            "Test Loss:  6.209042072296143\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  624\n",
            "Train Loss:  2.4937896728515625\n",
            "Test Loss:  6.210384368896484\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  625\n",
            "Train Loss:  2.49294114112854\n",
            "Test Loss:  6.211923122406006\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  626\n",
            "Train Loss:  2.4920995235443115\n",
            "Test Loss:  6.213367462158203\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  627\n",
            "Train Loss:  2.4912662506103516\n",
            "Test Loss:  6.214788436889648\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  628\n",
            "Train Loss:  2.490506649017334\n",
            "Test Loss:  6.216204643249512\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  629\n",
            "Train Loss:  2.489781379699707\n",
            "Test Loss:  6.217504024505615\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  630\n",
            "Train Loss:  2.488903284072876\n",
            "Test Loss:  6.218886375427246\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  631\n",
            "Train Loss:  2.4882071018218994\n",
            "Test Loss:  6.220113754272461\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  632\n",
            "Train Loss:  2.4873576164245605\n",
            "Test Loss:  6.2215728759765625\n",
            "Recall : 0.13523809523809524\n",
            "Epoch  633\n",
            "Train Loss:  2.486565113067627\n",
            "Test Loss:  6.223103046417236\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  634\n",
            "Train Loss:  2.485828399658203\n",
            "Test Loss:  6.224549770355225\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  635\n",
            "Train Loss:  2.485001802444458\n",
            "Test Loss:  6.226027488708496\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  636\n",
            "Train Loss:  2.4841372966766357\n",
            "Test Loss:  6.22752571105957\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  637\n",
            "Train Loss:  2.4833199977874756\n",
            "Test Loss:  6.229025840759277\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  638\n",
            "Train Loss:  2.482574939727783\n",
            "Test Loss:  6.230278968811035\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  639\n",
            "Train Loss:  2.4817769527435303\n",
            "Test Loss:  6.231679439544678\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  640\n",
            "Train Loss:  2.4811043739318848\n",
            "Test Loss:  6.233006000518799\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  641\n",
            "Train Loss:  2.480302572250366\n",
            "Test Loss:  6.23435115814209\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  642\n",
            "Train Loss:  2.4795682430267334\n",
            "Test Loss:  6.235799312591553\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  643\n",
            "Train Loss:  2.4787445068359375\n",
            "Test Loss:  6.237076282501221\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  644\n",
            "Train Loss:  2.477952003479004\n",
            "Test Loss:  6.23848819732666\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  645\n",
            "Train Loss:  2.4772119522094727\n",
            "Test Loss:  6.2400360107421875\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  646\n",
            "Train Loss:  2.476438045501709\n",
            "Test Loss:  6.241546630859375\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  647\n",
            "Train Loss:  2.475832223892212\n",
            "Test Loss:  6.242940902709961\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  648\n",
            "Train Loss:  2.4751477241516113\n",
            "Test Loss:  6.244245529174805\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  649\n",
            "Train Loss:  2.4742794036865234\n",
            "Test Loss:  6.2456512451171875\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  650\n",
            "Train Loss:  2.4734854698181152\n",
            "Test Loss:  6.246953964233398\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  651\n",
            "Train Loss:  2.472742795944214\n",
            "Test Loss:  6.248180389404297\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  652\n",
            "Train Loss:  2.471956253051758\n",
            "Test Loss:  6.249328136444092\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  653\n",
            "Train Loss:  2.471212863922119\n",
            "Test Loss:  6.250659942626953\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  654\n",
            "Train Loss:  2.4704935550689697\n",
            "Test Loss:  6.251948356628418\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  655\n",
            "Train Loss:  2.4696969985961914\n",
            "Test Loss:  6.253344535827637\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  656\n",
            "Train Loss:  2.4690418243408203\n",
            "Test Loss:  6.254635334014893\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  657\n",
            "Train Loss:  2.4682860374450684\n",
            "Test Loss:  6.255969047546387\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  658\n",
            "Train Loss:  2.4676804542541504\n",
            "Test Loss:  6.257213592529297\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  659\n",
            "Train Loss:  2.467068672180176\n",
            "Test Loss:  6.258329391479492\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  660\n",
            "Train Loss:  2.4663429260253906\n",
            "Test Loss:  6.259593963623047\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  661\n",
            "Train Loss:  2.4654035568237305\n",
            "Test Loss:  6.260911464691162\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  662\n",
            "Train Loss:  2.4646897315979004\n",
            "Test Loss:  6.262239456176758\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  663\n",
            "Train Loss:  2.463953733444214\n",
            "Test Loss:  6.263668060302734\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  664\n",
            "Train Loss:  2.4632508754730225\n",
            "Test Loss:  6.265018939971924\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  665\n",
            "Train Loss:  2.4624850749969482\n",
            "Test Loss:  6.26618766784668\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  666\n",
            "Train Loss:  2.4617490768432617\n",
            "Test Loss:  6.267297267913818\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  667\n",
            "Train Loss:  2.4610557556152344\n",
            "Test Loss:  6.26851749420166\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  668\n",
            "Train Loss:  2.4603395462036133\n",
            "Test Loss:  6.269868850708008\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  669\n",
            "Train Loss:  2.459632396697998\n",
            "Test Loss:  6.2709641456604\n",
            "Recall : 0.13238095238095238\n",
            "Epoch  670\n",
            "Train Loss:  2.458930492401123\n",
            "Test Loss:  6.272214889526367\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  671\n",
            "Train Loss:  2.458279609680176\n",
            "Test Loss:  6.273270606994629\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  672\n",
            "Train Loss:  2.457627296447754\n",
            "Test Loss:  6.274690628051758\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  673\n",
            "Train Loss:  2.456798553466797\n",
            "Test Loss:  6.276072025299072\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  674\n",
            "Train Loss:  2.456112861633301\n",
            "Test Loss:  6.277304649353027\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  675\n",
            "Train Loss:  2.4553885459899902\n",
            "Test Loss:  6.278721809387207\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  676\n",
            "Train Loss:  2.454631805419922\n",
            "Test Loss:  6.279907703399658\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  677\n",
            "Train Loss:  2.453900098800659\n",
            "Test Loss:  6.281255722045898\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  678\n",
            "Train Loss:  2.453249931335449\n",
            "Test Loss:  6.282528877258301\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  679\n",
            "Train Loss:  2.4525644779205322\n",
            "Test Loss:  6.2837395668029785\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  680\n",
            "Train Loss:  2.4519248008728027\n",
            "Test Loss:  6.284890174865723\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  681\n",
            "Train Loss:  2.4512429237365723\n",
            "Test Loss:  6.286131381988525\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  682\n",
            "Train Loss:  2.4508371353149414\n",
            "Test Loss:  6.287450790405273\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  683\n",
            "Train Loss:  2.4503207206726074\n",
            "Test Loss:  6.28841495513916\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  684\n",
            "Train Loss:  2.449563980102539\n",
            "Test Loss:  6.289518356323242\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  685\n",
            "Train Loss:  2.448942184448242\n",
            "Test Loss:  6.2907891273498535\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  686\n",
            "Train Loss:  2.448152542114258\n",
            "Test Loss:  6.29216194152832\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  687\n",
            "Train Loss:  2.447415828704834\n",
            "Test Loss:  6.293604373931885\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  688\n",
            "Train Loss:  2.446624755859375\n",
            "Test Loss:  6.294968605041504\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  689\n",
            "Train Loss:  2.445953369140625\n",
            "Test Loss:  6.2963409423828125\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  690\n",
            "Train Loss:  2.445281505584717\n",
            "Test Loss:  6.297643661499023\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  691\n",
            "Train Loss:  2.4446027278900146\n",
            "Test Loss:  6.298990249633789\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  692\n",
            "Train Loss:  2.4439616203308105\n",
            "Test Loss:  6.30034065246582\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  693\n",
            "Train Loss:  2.443476676940918\n",
            "Test Loss:  6.301569938659668\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  694\n",
            "Train Loss:  2.4428138732910156\n",
            "Test Loss:  6.302859306335449\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  695\n",
            "Train Loss:  2.4423470497131348\n",
            "Test Loss:  6.3040771484375\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  696\n",
            "Train Loss:  2.4416439533233643\n",
            "Test Loss:  6.30535364151001\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  697\n",
            "Train Loss:  2.441009521484375\n",
            "Test Loss:  6.306617736816406\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  698\n",
            "Train Loss:  2.440282106399536\n",
            "Test Loss:  6.307848930358887\n",
            "Recall : 0.1295238095238095\n",
            "Epoch  699\n",
            "Train Loss:  2.4396939277648926\n",
            "Test Loss:  6.308994293212891\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  700\n",
            "Train Loss:  2.438962936401367\n",
            "Test Loss:  6.310329437255859\n",
            "Recall : 0.13047619047619047\n",
            "\n",
            "0.14909795918367388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dc3M8lMkpnJvi8kYYcAASKrC1RFkbrWViytoteq1Yra24dLvb21rf1VW9u6VOu1Xlt721qsrbhWWpXNDSQIyBaWkEAgZN/XSfL9/XEmGwSSkEzmJPN5Ph7zmDPnnJn5JAzvfOd7vud7lNYaIYQQ5hXg6wKEEEKcmQS1EEKYnAS1EEKYnAS1EEKYnAS1EEKYnNUbLxodHa3T0tK88dJCCDEq5eTklGmtY3rb5pWgTktLY+vWrd54aSGEGJWUUgWn2yZdH0IIYXIS1EIIYXIS1EIIYXJe6aMWQpiT2+2msLCQpqYmX5fit+x2O8nJyQQGBvb7ORLUQviRwsJCnE4naWlpKKV8XY7f0VpTXl5OYWEh6enp/X6edH0I4UeampqIioqSkPYRpRRRUVED/kYjQS2En5GQ9q2z+f2bJqhb29p5Zt1BNu4v9XUpQghhKqYJakuA4vmNeby7+4SvSxFCeEl5eTlZWVlkZWURHx9PUlJS5+OWlpYzPnfr1q2sWrWqz/dYsGDBkNS6fv16vvzlLw/Jaw2WaQ4mKqUYF+vgYEmdr0sRQnhJVFQU27dvB+Dhhx/G4XDwve99r3N7a2srVmvvsZSdnU12dnaf7/Hxxx8PTbEmYpoWNcDYmFDySiWohfAnK1eu5Pbbb2fu3Lncd999bNmyhfnz5zNz5kwWLFhAbm4u0LOF+/DDD3PzzTezaNEiMjIyeOqppzpfz+FwdO6/aNEirr32WiZNmsSKFSvouKLVO++8w6RJk5g9ezarVq3qs+VcUVHBVVddxfTp05k3bx47d+4EYMOGDZ3fCGbOnEltbS1FRUWcf/75ZGVlkZmZyaZNmwb9OzJNixpgXKyDV7YWUtXQQnhIkK/LEWJU+9Gbu9lzvGZIX3NKoosfXj51wM8rLCzk448/xmKxUFNTw6ZNm7Barbz33nt8//vf5+9///spz9m3bx/r1q2jtraWiRMn8u1vf/uUscmff/45u3fvJjExkYULF/LRRx+RnZ3NbbfdxsaNG0lPT+f666/vs74f/vCHzJw5kzVr1vDBBx9www03sH37dh5//HGeeeYZFi5cSF1dHXa7neeff55LLrmEhx56iLa2NhoaGgb8+ziZ6YIa4GBJHdlpkT6uRggxXL761a9isVgAqK6u5sYbb+TAgQMopXC73b0+Z9myZdhsNmw2G7GxsRQXF5OcnNxjnzlz5nSuy8rKIj8/H4fDQUZGRuc45uuvv57nn3/+jPV9+OGHnX8svvSlL1FeXk5NTQ0LFy7ku9/9LitWrOCaa64hOTmZc845h5tvvhm3281VV11FVlbWoH43YLagjnECcKhUgloIbzublq+3hIaGdi7/4Ac/YPHixbz22mvk5+ezaNGiXp9js9k6ly0WC62trWe1z2A88MADLFu2jHfeeYeFCxeydu1azj//fDZu3Mjbb7/NypUr+e53v8sNN9wwqPcxVR91UkQwQdYAOaAohB+rrq4mKSkJgD/84Q9D/voTJ04kLy+P/Px8AFavXt3nc8477zz+/Oc/A0bfd3R0NC6Xi0OHDjFt2jTuv/9+zjnnHPbt20dBQQFxcXF861vf4pZbbmHbtm2DrtlUQW0JUGREh0pQC+HH7rvvPh588EFmzpw55C1ggODgYJ599lkuvfRSZs+ejdPpJCws7IzPefjhh8nJyWH69Ok88MADvPTSSwA88cQTZGZmMn36dAIDA1m6dCnr169nxowZzJw5k9WrV3P33XcPumbVcRR0KGVnZ+uzvXDAd/6yjZ2F1Wy8b/EQVyWE2Lt3L5MnT/Z1GT5XV1eHw+FAa82dd97J+PHjuffee4ft/Xv7d1BK5Witex1/aKoWNcDYGAdHKxtocrf5uhQhxCj1u9/9jqysLKZOnUp1dTW33Xabr0s6I1MdTARj5IfWcLisnskJLl+XI4QYhe69995hbUEPlula1N2H6AkhhDBhUKdHh6KUBLUQQnQwXVDbAy2kRIRwSE4lF0IIoB9BrZSaqJTa3u1Wo5S6x5tFyeRMQgjRpc+g1lrnaq2ztNZZwGygAXjNm0WNi3WQV1ZPW/vQDx0UQvjOYKY5BeNkk+6z4z333HP88Y9/HJLaFi1axNkOK/a2gY76uBA4pLUu8EYxHcbGhNLS2k5hZQNjokL7foIQYkToa5rTvqxfvx6Hw9E55/Ttt9/ulTrNZqB91MuBl71RSHcT4ow5P3JP1Hr7rYQQPpaTk8MFF1zA7NmzueSSSygqKgLgqaeeYsqUKUyfPp3ly5eTn5/Pc889x69//WuysrLYtGkTDz/8MI8//jhgtIjvv/9+5syZw4QJEzqnF21oaOBrX/saU6ZM4eqrr2bu3Ll9tpxffvllpk2bRmZmJvfffz8AbW1trFy5kszMTKZNm8avf/3rXuv0hn63qJVSQcAVwIOn2X4rcCtAamrqoIrqCOp9J2pZMjV+UK8lhDiNfz4AJ74Y2teMnwZLH+337lpr7rrrLl5//XViYmJYvXo1Dz30EC+++CKPPvoohw8fxmazUVVVRXh4OLfffnuPVvj777/f4/VaW1vZsmUL77zzDj/60Y947733ePbZZ4mIiGDPnj3s2rWrz9nsjh8/zv33309OTg4REREsWbKENWvWkJKSwrFjx9i1axcAVVVVAKfU6Q0DaVEvBbZprYt726i1fl5rna21zo6JiRlUUaE2K6mRIdKiFmKUa25uZteuXVx88cVkZWXxyCOPUFhYCMD06dNZsWIFf/rTn0571ZeTXXPNNQDMnj27c9KlDz/8sLOl2zEvx5l89tlnLFq0iJiYGKxWKytWrGDjxo1kZGSQl5fHXXfdxbvvvovL5TrrOgdqIK96PcPQ7dFhUryTfSeGdlJzIUQ3A2j5eovWmqlTp/LJJ5+csu3tt99m48aNvPnmm/z0pz/liy/6bv13TGvqjSlNIyIi2LFjB2vXruW5557jlVde4cUXX+y1zqEO7H61qJVSocDFwD+G9N3PYFK8k/xymfNDiNHMZrNRWlraGdRut5vdu3fT3t7O0aNHWbx4MY899hjV1dXU1dXhdDqprR3YN+2FCxfyyiuvALBnz54+A3/OnDls2LCBsrIy2traePnll7ngggsoKyujvb2dr3zlKzzyyCNs27bttHUOtX7Fvta6Hoga8nc/g4nxLtraNQdL6shMOvMUhEKIkSkgIIBXX32VVatWUV1dTWtrK/fccw8TJkzgG9/4BtXV1WitWbVqFeHh4Vx++eVce+21vP766zz99NP9eo877riDG2+8kSlTpjBp0iSmTp16xmlNExISePTRR1m8eDFaa5YtW8aVV17Jjh07uOmmm2hvbwfgZz/7GW1tbb3WOdRMN81ph4MldVz0qw08/tUZXDs7ue8nCCH65I/TnLa1teF2u7Hb7Rw6dIiLLrqI3NxcgoJ8d13WgU5zarrZ8zqkRYUQZA0gV/qphRCD0NDQwOLFi3G73WitefbZZ30a0mfDtEFttQQwPtbBPhn5IYQYBKfTadozDvvLdJMydTcx3ilD9IQYYt7o7hT9dza/f1MH9aR4JyW1zVTU9z0HgBCib3a7nfLycglrH9FaU15ejt1uH9DzTNv1ATAp3hhQvu9EDQvGRvu4GiFGvuTkZAoLCyktLfV1KX7LbreTnDywARKmDuqOS3HtOS5BLcRQCAwMJD093ddliAEydddHjNNGnMvGrmPVvi5FCCF8xtRBDTAtKYxdx2WInhDCf5k+qDOTwjhUWkd989Cety+EECOF+YM6MQytYW+RtKqFEP7J9EE9Ldk4J/8L6acWQvgp0wd1nMtOjNPGrmPSohZC+CfTBzVAZqJLRn4IIfzWiAjqaUlhHCippbFF5qYWQvifERHUmUlhtGvYKzPpCSH80IgJakC6P4QQfmlEBHVCmJ1oh43tR71zhV8hhDCzERHUSilmpobz+REJaiGE/xkRQQ0wKzWCw2X1MuWpEMLvmCuoq45C9bFeN81KNS4Yuf1o5XBWJIQQPmeeaU5bGuDp2TDnW3DJT0/ZPC05DEuAYltBFV+aFOeDAoUQfq+9HeqKoboQagqN+45bzTFQFvjW+0P+tuYJ6qAQyLgA9r4BSx4BpXpsDgmyMjnBybYj0qIWQniB1tBU3RW63QO4c/k4tLt7Pi/ICWFJ4EqCSO/M9W2eoAaYfDkc+Bec+AISpp+yeVZqBH/PKaStXWMJUL28gBBCnIbWRmu44jBUHja6WmsKje7WjkBuqev5nAAruBLBlQwpcyEs+dSbPczrpZsrqCdeBupu2PfWaYP6j58UkHuilimJLh8UKIQwtTY3VB+FijxPIOd3BXNlPrgbeu4fGmu0hmMmwNgvGcthyUYwhyWBIw4CLL74SXowV1CHRkPqfNj7Jiz+/imbZ3oOKH5+tFKCWgh/1VLfFb4n31cdBd1tqgmrHSLSICIdMhYZ95Hpxn14ClhtPvohBsZcQQ1G98e7D0D5IYga22NTamQIUaFB5BRUsmLuGB8VKITwKq2hvqz3IK44DPUlPfcPjjCCN2k2ZF7bFcSR6eCIhwBzDW47G+YL6knLjKDe+yace0+PTUopstMi+Cy/wkfFCSGGRHub0S/caxjnQ0ttt52V0U8ckQ4TlkBkRs+WcXC4r36KYWO+oA5PhYQs2P3aKUENMDc9irW7izlW1UhSeLAPChRC9Iu7sWcfcff7qiM9R09YgiB8jBG+qQt6torDx0Cg3Wc/hhmYL6gBpl8Hax+Ekn0QO6nHprkZkQBszivnmlnJvqhOCNGhoeLU1nDH49rjPfe1uYz+4vhpMOWKnq1iV6IpDtqZlTmDetq18K//gh0vw8U/6rFpUrwLl93K5rwKCWohvK293Qjc0x28azppRktHvBG+GYt6tooj0iEk8pTzI0T/9CuolVLhwAtAJqCBm7XWn3itKkcsjLsIdr4CF/53j7+0lgDFnPQoNh8u99rbC+F3Giqg/CCUHTDuyw8YB/Qr8qC1qWu/ACuEpRj9xMnZPYM4Is04cU0Muf62qJ8E3tVaX6uUCgK8/6+RdT38bS0c3mCMb+xmXkYk7+0t5kR1E/Fh/t13JUS/tTYbwdsjkD3Ljd0O0AdYjeCNHm/834vM6ArjsBSwmPOL+GjW529cKRUGnA+sBNBatwDen8JuwlJj2M3WF08J6rnpUQBsPlzOlVlJXi9FiBHF3QRl+6E0F0r3dd0q8kC3d+3niIeocUZ/cdR4Yzl6vHFA3xLou/rFKfrzpzEdKAV+r5SaAeQAd2ut67vvpJS6FbgVIDU1dfCVBdph9kr46EnjCHF412tOSXThtFn5NK9Cglr4r5YGo4uipCOMc6F0rzHSoiOQlcU4HyF2Cky9GqInQvQ4iBwLdjlpbKToT1BbgVnAXVrrzUqpJ4EHgB9030lr/TzwPEB2drYekurOuQU+egq2/A6W/KRztSVAcU56JJvzpJ9a+IGWBijLNYK4ZG9XS7kyH+OQEUZ3RdQ4Y0TFtK9BzESInWwEsjXIl9WLIdCfoC4ECrXWmz2PX8UIau8LSzbOVNz2Eix6AIJCOzctHBfNB/tKKKxsIDlCDmCIUaC5riuQS/d1tZSrjtAVyIFG90RiFsxYDjGTjFvUWOmuGMX6DGqt9Qml1FGl1EStdS5wIbDH+6V5zL8T9qyBz16AhXd3rj5vfDQAHx4oY/mcIehqEWK4NNdC6X6jm6Kjy6JkH1Qf6drHEmT0Gydnw8xvdAVyZLoEsh/q7+Hbu4A/e0Z85AE3ea+kk6TMMYbqffgEzL6ps19tfKyDOJeNTQclqIUJaW3MXVy23zOyYr/ndsCYTrODxQbREyB1LsTc4AnkycZQNxldITz69UnQWm8Hsr1cy+ktfgh+txg+/S0suh8w5v04b3wM7+0tlvmphe+4m4zRFB0h3BHI5Qd7zm1scxldFmnnGfexk41QjkiTM/JEn0bGn+ykWTDpy/Dx0zDrm8bpphjdH6/mFLLrWDUzUkb/xCzCR7SGhvKereKO5coCOvuPAcJSjSBOnWfcR08wbo44OStPnLWREdQAF/8YfrsA/nkfXPcnAM4dZ/RTbzpQKkEtBq+pBioOGWfklR/yLB80lpuquvazBhtD3JJmw/TlXYEcNbbHAW8hhsrICeqosXDBffD+j2Hf2zBpGVEOG5lJLjYeKOM7Xxrv6wrFSOBu7Do7rzOMPbce8xwrY9RRZAZkXuNpGXsC2ZU8KuY4FiPHyAlqgAWrYNc/4I1VkDgTXImcNz6G323Mo7bJjdMuR8MF0NrimV6zI4QPepbzjGvkdeeIM8YfT7jEuI8aa4w9jkyHQJlGV5jDyApqSyBc+3vjwOLfVsLKt1k8MZbfrj/Exv1lLJue4OsKxXBpbzPGF3cEcGcYHzTWdz9VOjjSCOC0cz1hnGHcR2aAzem7n0GIfhpZQQ3GRSiveBpevQneWMWsy58mPCSQ9/cWS1CPNu3tUFvUs6+4o7uiMh/auk05E+Q0AjhptnFmXtTYrjAOifTZjyDEUBh5QQ1Gn2HZAVj//7DanCyecD3rcktkmN5I1HF9vM4WcUdXRZ6x3NrYta/VbgRvzETjivXduyocsTKqQoxaIzOowTiw2FwDn/yGe8eU8mbDVWw7Usk5adJ6Mp02t3F9vKojUH3UGNJWkdcVzM01Xft2TLEZNdYz+XxGV+vYmSgH8YRfGrlBrRQseQSCQknd8Bh/CNrPxzujOCftXF9X5n9am3sGcdWRbrejxhVCuvcZqwBjXuOoscZ8FZFju/qOw1LljDwhTjKy/0coBYu/D+FjmPP6PUz9/Osw6QXjSsVi6LibPEFccJogLqLHSR8qwBjCFp4K6edDeIqx3HFzJcl8FUIMwMgO6g4zV/BWcSyTP76XiL981Zhx7+KfGEOsRN/cjUbgVh0xJgY6OYjrTvTcX1mMMcbhqTB2cc8QDksxzhyVIBZiyIyOoAayz1nIxet/wl+mfMbsg7+H/WuNr9ULVhknKvgrd5PR9VB9zJgkqOaY5+ZZrj4GDWU9nxNg7Qri8RdB+BgjgDvC2Jkg3RNCDKNR878tNSqEMXGR/Lzxclbf9R3Y8HPY/hfY9n+Qfh5Mvw4mXzG6rmrhbuoWuseNkzlqOkLZs/7kEAawhxldE65ESMjqGcLhqeCMl4mChDCRURPUAJdmJvD0BwcoUTOJvfwJY9a9rS/Czr/C63fCW/dCylzj63r6IojPBKvN12X3pLUxX3FdCdQVG90OdSVQ67nvfFxkTBR0Mnu40Rp2JRqTWXUEsivRWO9MAJtj+H8uIcRZU1oPzVWzusvOztZbt24d8tftS+6JWi55YiM/uSqTb84b07VBaziWA3teh7x1cOILY31AoDHdZMJ0YxhYRBqEpxkHv4IjB/f1vr0d3PXGVTuaa6Gx0rjSc0PFScsd91Vdy93HDncICDROd3bGGfeOOAhLMg7MuRI9gZwgkwIJMUIppXK01r1OJz2qWtQT4hxkxITyzs6inkGtlHGljGTP76CuBAo+guPboWiH0Z9dX3rqC9pcxpXQ7S4jKC2BnnvPr62tFdrdxjjh9lZjmFqLJ5iba+kxEuJkymKcMRccabxHeAokzICQCAiNPTWUgyPkhA4h/NSoCmqlFMumJfDMuoOU1TUT7ThNt4Yj1rgi89Sru9Y11xmjHCrzjaFo3Vu9zbU9A9ndaLTSLYHG2XI2pxHg1iBj2eYy7oMcnsdOCA43wjY40ghom0uCVwjRL6MqqAEum5bA0x8cZO3uE6yYO6bvJ3SwOSBuinETQggTGXXn406Kd5IRHco7XxT5uhQhhBgSoy6olVIsnRbPJ4fKKa9r9nU5QggxaKMuqAGWTUukXcM7u070vbMQQpjcqAzqyQlOJsY5eW1bYd87CyGEyY3KoFZKcfWsJLYdqSK/rN7X5QghxKCMyqAGuDIrEaXgtc+P+boUIYQYlFEb1AlhwczPiGLN9mN44+xLIYQYLqM2qAGumplEQXkD245U+boUIYQ4a6M6qJdmxmOzBvDa53JQUQgxco3qoHbaA1kyNZ43dxTR5G7zdTlCCHFWRnVQA1yXnUJ1o5u1u2VMtRBiZBr1Qb1gbBQpkcG8vOWIr0sRQoizMuqDOiBAsfycVD7NqyCvtM7X5QghxID1K6iVUvlKqS+UUtuVUsN/RYBB+ursZCwBitWfHfV1KUIIMWADaVEv1lpnne4KBGYW67Jz4aRYXs0ppKW13dflCCHEgIz6ro8O189Jpby+hff2Fvu6FCGEGJD+BrUG/qWUylFK3drbDkqpW5VSW5VSW0tLe7mslY+dPyGGpPBg/vhJvq9LEUKIAelvUJ+rtZ4FLAXuVEqdf/IOWuvntdbZWuvsmJiYIS1yKFgCFDfMH8OneRXsLarxdTlCCNFv/QpqrfUxz30J8Bowx5tFecvyc1IJDrTwh4/yfV2KEEL0W59BrZQKVUo5O5aBJcAubxfmDWEhgVw9K4k1249RUd/i63KEEKJf+tOijgM+VErtALYAb2ut3/VuWd6zckEaza3t/PUzOQFGCDEy9HkVcq11HjBjGGoZFhPinCwcF8X/fVLAt87LINDiNwNfhBAjlF+m1M0L0ymqbuLtnXKlciGE+fllUC+eGMuEOAe/XX9ILioghDA9vwzqgADF7ReMJbe4lnW5Jb4uRwghzsgvgxrg8hmJJIUH89v1h3xdihBCnJHfBnWgJYBvnZfOZ/mVfJZf4etyhBDitPw2qAG+dk4KESGBPLvuoK9LEUKI0/LroA4JsnLLeRmsyy1l25FKX5cjhBC98uugBuMEmKjQIH71r/2+LkUIIXrl90EdarNy+wVj+fBgGZvzyn1djhBCnMLvgxrgG/PGEOu08ct/75dx1UII05GgBoKDLNy5eBxbDlfw0UFpVQshzEWC2mP5nBQSw+z8Yu0+2tulVS2EMA8Jag+b1cJ3l0xkR2E1b+487utyhBCikwR1N9fMTCIzycVj/9xHk7vN1+UIIQQgQd1DQIDiv5ZN4Xh1Ey9syvN1OUIIAUhQn2JeRhSXTI3j2fWHKKlt8nU5QgghQd2bB5dOxt3WzuNrc31dihBCSFD3Ji06lJsXpvPK1kK2yoRNQggfk6A+jVUXjicxzM5Dr+3C3dbu63KEEH5Mgvo0Qm1WfnxlJrnFtbyw6bCvyxFC+DEJ6jO4aEocl0yN48n393O0osHX5Qgh/JQEdR8evmIqFqX4rzW7ZB4QIYRPSFD3ISEsmPsuncSG/aWs/uyor8sRQvghCep++Oa8MSwYG8VP3tojXSBCiGEnQd0PAQGKX3x1BgFK8Z+v7KBNJm0SQgwjCep+SgoP5odXTGVLfgX/+6GcXi6EGD4S1APwlVlJLJkSx+Nr97OzsMrX5Qgh/IQE9QAopXjsK9OJdgRx51+2Ud3o9nVJQgg/IEE9QBGhQTz99VkUVTVx36s7ZMieEMLrJKjPwuwxETywdBJrdxfzvx/KWYtCCO/qd1ArpSxKqc+VUm95s6CR4j/OTefiKXE8+s99fHyozNflCCFGsYG0qO8G9nqrkJFGKcUvvzaDtOhQ7vjzNvLL6n1dkhBilOpXUCulkoFlwAveLWdkcdkDeeGGbABu+eNWaprk4KIQYuj1t0X9BHAfcNr5PpVStyqltiqltpaWlg5JcSNBWnQoz66YRX5ZPate/pxWmRJVCDHE+gxqpdSXgRKtdc6Z9tNaP6+1ztZaZ8fExAxZgSPBgrHR/PjKTNbnlvLgP76QkSBCiCFl7cc+C4ErlFKXAXbApZT6k9b6G94tbWT5+txUimuaePL9A0Q5bDywdJKvSxJCjBJ9BrXW+kHgQQCl1CLgexLSvbvnovGU1zfz3IZDRDuCuOW8DF+XJIQYBfrTohb9pJTiR1dkUlnv5pG392KzBvDN+Wm+LksIMcINKKi11uuB9V6pZJSwBCh+fV0Wza1t/OD13WjgBglrIcQgyJmJXhBkDeDZFbO5aHIc//36bv74Sb6vSxJCjGAS1F5ihPUsLp5ihPULm2RqVCHE2ZGg9qIgawDPfH0WSzPjeeTtvfzsn3tl6J4QYsAkqL0syBrAb74+i2/MS+V/NuTxn3/bgVtOihFCDICM+hgGlgDFT67MJM5p55f/3k9ZXQu/+fpMXPZAX5cmhBgBpEU9TJRS3HXheB69ZhofHyzj6mc+4rBM5CSE6AcJ6mG2fE4q//cfc6lscHPlbz5kw37/mRdFCHF2JKh9YP7YKF6/cyGJ4cHc9PstPLPuIO1yZXMhxGlIUPtISmQI/7hjAcumJ/KLtbnc8OIWSmqbfF2WEMKEJKh9KCTIylPLs3jsK9PYWlDBZU9ukq4QIcQpJKh9TCnFdeek8uZ3ziUq1MaNL27h4Td209DS6uvShBAmIUFtEuPjnLz+nYWsXJDGHz7O59InNvFpXrmvyxJCmIAEtYnYAy08fMVUVt86D6Vg+fOf8oM1u6iVS3wJ4dckqE1obkYU7959PjcvTOdPmwu48JcbWPP5MTn9XAg/JUFtUsFBFv778im8dsdCEsLs3LN6O9c9/yn7TtT4ujQhxDCToDa5rJRwXrtjIT+7ZhoHimu57MlNPPiPnRTXyFA+IfyFBPUIEBCguH5OKuu+t4gb5qfxak4hF/xiHT9/dx/VjdJ/LcRop7zR75mdna23bt065K8rDEfKG/jVv3NZs/044SGB3Hb+WL45fwwOm8yxJcRIpZTK0Vpn97pNgnrk2nWsml+szWXD/lLCggO5eWE6KxemERYss/IJMdJIUI9y249W8ZsPDvLe3mKcNis3LBjDjQvSiHXafV2aEKKfJKj9xJ7jNTyz7iDv7CoiMCCAL09P4KaF6UxLDvN1aUKIPkhQ+5m80jpe+jifV3MKqW9pI3tMBDctTOeSqXFYLXL8WAgzkqD2UzVNbl757CgvfZLP0YpGYp02vjI7ma9lp5AeHerr8oQQ3QRg35UAAA1XSURBVEhQ+7m2ds0H+0r465YjrMstoV3DnPRIrstO4bJpCQQHWXxdohB+T4JadDpR3cTftxXyytajFJQ3EBpkYcnUeK6Ykci546MJlK4RIXxCglqcor1ds/lwBWs+P8Y/dxVR09RKREggS6clcMWMROakRRIQoHxdphB+Q4JanFFzaxsb95fxxo7jvLenmEZ3G3EuGxdPiWPJlHjmZUQRZJWWthDeJEEt+q2hpZV/7ynm3V0nWJ9bSqO7DafNyuJJsSyZGscFE2Jw2uWEGiGGmgS1OCtN7jY+OljGv3YX897eYsrrWwiyBDBvbBSLJsRwwcQYMqJDUUq6SIQYLAlqMWht7ZptRypZu+sEH+SWkFdaD0ByRDAXTIjhggkxLBgXLfONCHGWJKjFkDta0cCG/aVs2F/KxwfLqG9pI9CimD0mgvPGxzAvI4rpyWEyikSIfhpUUCul7MBGwAZYgVe11j8803MkqP1LS2s7OQWVbNhfyvrcEvadqAUgNMhCdlok88dGMT8jisykMCwykkSIXg02qBUQqrWuU0oFAh8Cd2utPz3dcySo/VtZXTOb8yr4JK+MTw6Vc8jTTeK0WZmTbgT3OWmRTEl0SYtbCI8zBXWfHYraSPI6z8NAz00u3idOK9phY9n0BJZNTwCgpKaJT/LK+TSvnE8OlfP+vhIA7IEBzEgOJzstgtljIpiVGkF4SJAvSxfClPrVR62UsgA5wDjgGa31/b3scytwK0BqaursgoKCIS5VjBYnqpvYWlBBTkElOQWV7D5eQ1u78TkcF+tgdqoR3DNSwhkX65DuEuEXhuxgolIqHHgNuEtrvet0+0nXhxiIhpZWdhZWdwZ3TkFl5yXGggMtZCa5mJYUzoyUMKYnhzMmMkTOmhSjzqC6PrrTWlcppdYBlwKnDWohBiIkyMq8jCjmZUQBxunth8vr2VlYxY6j1XxxrJq/bCngxY/aAXDarUxPDjPCOzmMKYkuUiIkvMXo1WdQK6ViALcnpIOBi4HHvF6Z8FsBAYqxMQ7Gxji4emYyAK1t7ewvruOLY1XsKKxmZ2EVL2zKo9XTZRIaZGFygovJCS6mJBr3E+OcMjOgGBX6M+pjOvASYMG4avkrWusfn+k50vUhhkOTu43cE7XsLaphb1ENe4pq2FtUS11zKwABCtKjQ08J74Qwu5xNKUxnsKM+dgIzh7wqIQbJHmhhRko4M1LCO9dprSmsbGT38a7w3n60ird2FnXu47RZGRfnYEKsk/FxDsbHOZkQ5yDeJQEuzEnOTBR+obrRzb6iGvaX1HGguJb9xbUcLKmjrK6lcx+n3cr4WAfjPQE+Ic7JuFiHtMDFsJBTyIU4jfK6Zg50hncdB0pqOVBcR3l9V4AHB1pIjw4lIyaUjBgHY2NCyYh2kB4TKnObiCEzZKM+hBhtohw2ohy2zhEnHcrrmtlfXMeh0jrySuvJK6tjZ2E173xRRHu3tk2s09YZ4BnRoYyNcZARE0pyRIiM/xZDRoJaiF5EOWzMd9iYP7ZngDe3tlFQ3kBeaR2HSus7Q/ztnUWdY78BAi2KlIgQxkSFMCYq1HNvLCdHBGOzymgU0X8S1EIMgM1qYUKckwlxzh7rtdZUNrjJ87TAD5XVcaS8gYLyBrYcrqC+pa1zX6UgMSy4R4inRYWQGmksh0p3ijiJfCKEGAJKKSJDg4gMjSQ7LbLHNq015fUtFJTXU1DeQH55A0fK68kvb2Dt7hNUdOsPB2OuFCO4Q0iOCCY5ous+Pswul0XzQxLUQniZUopoh41oh43ZYyJP2V7T5OZIeQP5niAv8IT45sMVrNne2KNPXCmId9lPCvCu5YSwYAnyUUiCWggfc9kDyUwKIzMp7JRt7rZ2TlQ3cbSygcLKRgorGzlW2UhhpdGl8no/gjwhLJiEMDsJ4XYSXMG4gq0y3HCEkaAWwsQCLQGkRIaQEhnS6/aOIC/0hHdHmHcE+Rs7mjpnJuwQHGgxQjvMTryrW4h7HieG2wkLDpQwNxEJaiFGsJ5BHnXK9ta2dkrrmjle1cSJ6iaKqhspqu5a/vhQGcU1TZyU5dgDA0gICybOZSPWae+8j+3+2GWXceTDRH7LQoxiVkuAp+sj+LT7tLa1U1bXwvHqRk+AN1FUZQR6cU0T249WUVLbRJO7/ZTnhgRZiHPZiXHaiHPZiXXajJvLRlSojShHENEOGxEhQdJ3PggS1EL4OaslgPgwO/Fh9tPuo7WmpqmV0tomimuaKaltoqSmuWu5tpkvCqsormmm0d3W62u47FbjBKPQIKIcQUSG2oh2BBEVGkSkw0Z0aBBRDhuRoUFEhARilcu0dZKgFkL0SSlFWHAgYcGBjIt1nnY/rTV1za2U1DZTUd9CeV0L5fXNlNe1UFHfQlmdsZxf1kBOQSUV9S2ndLsY7wcRIUFEhgZ1BntUqBHi4SGBxi04iLCQQMKDAwkPCcJlt47acJegFkIMGaUUTnsgTnsgY2P63r+tXVPd6Ka8rpkyT5iX13csG6FeXtdC7olayuvLqWpwn/H1nHZrZ4iHhxh/WE597An74EDCPOvMfqaoBLUQwmcsAR0nCgUxPq7v/dvaNTWNbqoa3VQ1tFDV6Ka6oWu5qsFNdbdtxyobO/ftreXeISTI4gnuIE8L3bi57IE47Vac9kBcwVactkBcwca6jntHkNXrVxeSoBZCjBiWAEVEaBARoUFAaL+f196uqWtp9YS6m6rGFs+9m+qGrmUj6Fs4WFJHVaObmkY3za2nHkTtTilw2Ky47IEkRQTzym3zB/lTnkqCWggx6gUEKFx2o4WccurJoWfU3NpGbVOr5+amptFz3+SmtqmVmkY3NU2t1DS5sXlpZIsEtRBCnIHNasHmsBDtsPmshtF5iFQIIUYRCWohhDA5CWohhDA5CWohhDA5CWohhDA5CWohhDA5CWohhDA5CWohhDA5pfUZToA/2xdVqhQoOMunRwNlQ1iON42kWmFk1TuSagWp15tGUq1w9vWO0Vr3OpWVV4J6MJRSW7XW2b6uoz9GUq0wsuodSbWC1OtNI6lW8E690vUhhBAmJ0EthBAmZ8agft7XBQzASKoVRla9I6lWkHq9aSTVCl6o13R91EIIIXoyY4taCCFENxLUQghhcqYJaqXUpUqpXKXUQaXUA76uB0Ap9aJSqkQptavbukil1L+VUgc89xGe9Uop9ZSn/p1KqVnDXGuKUmqdUmqPUmq3Uupuk9drV0ptUUrt8NT7I8/6dKXUZk9dq5VSQZ71Ns/jg57tacNZr6cGi1Lqc6XUWyOg1nyl1BdKqe1Kqa2edWb9LIQrpV5VSu1TSu1VSs03ca0TPb/TjluNUuoer9ertfb5DbAAh4AMIAjYAUwxQV3nA7OAXd3W/Rx4wLP8APCYZ/ky4J+AAuYBm4e51gRglmfZCewHppi4XgU4PMuBwGZPHa8Ayz3rnwO+7Vm+A3jOs7wcWO2Dz8N3gb8Ab3kem7nWfCD6pHVm/Sy8BNziWQ4Cws1a60l1W4ATwBhv1+uTH7CXH3g+sLbb4weBB31dl6eWtJOCOhdI8CwnALme5f8Bru9tPx/V/Tpw8UioFwgBtgFzMc7osp78uQDWAvM9y1bPfmoYa0wG3ge+BLzl+Y9nylo979tbUJvuswCEAYdP/v2YsdZeal8CfDQc9Zql6yMJONrtcaFnnRnFaa2LPMsngI6L3JvmZ/B81Z6J0Uo1bb2eroTtQAnwb4xvVVVa69Zeauqs17O9GogaxnKfAO4DOi5JHYV5awXQwL+UUjlKqVs968z4WUgHSoHfe7qVXlBKhZq01pMtB172LHu1XrME9YikjT+RphrfqJRyAH8H7tFa13TfZrZ6tdZtWussjNbqHGCSj0vqlVLqy0CJ1jrH17UMwLla61nAUuBOpdT53Tea6LNgxehe/K3WeiZQj9F10MlEtXbyHI+4Avjbydu8Ua9ZgvoYkNLtcbJnnRkVK6USADz3JZ71Pv8ZlFKBGCH9Z631PzyrTVtvB611FbAOo/sgXCll7aWmzno928OA8mEqcSFwhVIqH/grRvfHkyatFQCt9THPfQnwGsYfQjN+FgqBQq31Zs/jVzGC24y1drcU2Ka1LvY89mq9Zgnqz4DxnqPoQRhfKd7wcU2n8wZwo2f5Roy+4I71N3iO8s4Dqrt9FfI6pZQC/hfYq7X+1QioN0YpFe5ZDsboT9+LEdjXnqbejp/jWuADT8vF67TWD2qtk7XWaRifzQ+01ivMWCuAUipUKeXsWMboS92FCT8LWusTwFGl1ETPqguBPWas9STX09Xt0VGX9+r1RSf8aTrmL8MYqXAIeMjX9XhqehkoAtwYf/n/A6Ov8X3gAPAeEOnZVwHPeOr/Asge5lrPxfi6tRPY7rldZuJ6pwOfe+rdBfy3Z30GsAU4iPG10uZZb/c8PujZnuGjz8QiukZ9mLJWT107PLfdHf+fTPxZyAK2ej4La4AIs9bqqSEU4xtSWLd1Xq1XTiEXQgiTM0vXhxBCiNOQoBZCCJOToBZCCJOToBZCCJOToBZCCJOToBZCCJOToBZCCJP7/1ZCdoN3PR5kAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e75d65960a8246f5ae9a762643f8b199",
            "9db6d3d082ed4a329b60d4858eed62a6",
            "63df5cc5563545518375ad54a2665089",
            "5da98f0018c84d32847bafea2293d3a2",
            "82fe0d135850418181ae3cb9a0c9fd54",
            "7e013e4437314817be3cdaea9b9fb6c2",
            "70115ceeaa4f432382ffc78a4765378e",
            "0f998a9fa2e3455d95a3df7097910088"
          ]
        },
        "id": "6gaWzJcJahPi",
        "outputId": "8e3bc7c0-8ae4-43b9-db12-49302e7376a7"
      },
      "source": [
        "run(path=\"resnet34.npy\",runs=1,epochs=700,k=1,temp=15,type=2,spl=0.75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e75d65960a8246f5ae9a762643f8b199",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=700.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Train Loss:  7.423356056213379\n",
            "Test Loss:  6.325618743896484\n",
            "Recall : 0.12095238095238095\n",
            "Epoch  2\n",
            "Train Loss:  7.3509979248046875\n",
            "Test Loss:  6.289604187011719\n",
            "Recall : 0.12380952380952381\n",
            "Epoch  3\n",
            "Train Loss:  7.282127380371094\n",
            "Test Loss:  6.254668235778809\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  4\n",
            "Train Loss:  7.214826583862305\n",
            "Test Loss:  6.220484733581543\n",
            "Recall : 0.12761904761904763\n",
            "Epoch  5\n",
            "Train Loss:  7.148494243621826\n",
            "Test Loss:  6.186999320983887\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  6\n",
            "Train Loss:  7.082928657531738\n",
            "Test Loss:  6.1541428565979\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  7\n",
            "Train Loss:  7.0180277824401855\n",
            "Test Loss:  6.121931076049805\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  8\n",
            "Train Loss:  6.9537811279296875\n",
            "Test Loss:  6.090396881103516\n",
            "Recall : 0.12857142857142856\n",
            "Epoch  9\n",
            "Train Loss:  6.890247344970703\n",
            "Test Loss:  6.059609413146973\n",
            "Recall : 0.13047619047619047\n",
            "Epoch  10\n",
            "Train Loss:  6.827498435974121\n",
            "Test Loss:  6.029677391052246\n",
            "Recall : 0.13142857142857142\n",
            "Epoch  11\n",
            "Train Loss:  6.765586853027344\n",
            "Test Loss:  6.000624656677246\n",
            "Recall : 0.13333333333333333\n",
            "Epoch  12\n",
            "Train Loss:  6.704611778259277\n",
            "Test Loss:  5.972532749176025\n",
            "Recall : 0.13428571428571429\n",
            "Epoch  13\n",
            "Train Loss:  6.644650459289551\n",
            "Test Loss:  5.945407867431641\n",
            "Recall : 0.14095238095238094\n",
            "Epoch  14\n",
            "Train Loss:  6.585758686065674\n",
            "Test Loss:  5.919313907623291\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  15\n",
            "Train Loss:  6.528007507324219\n",
            "Test Loss:  5.89424991607666\n",
            "Recall : 0.14666666666666667\n",
            "Epoch  16\n",
            "Train Loss:  6.471479415893555\n",
            "Test Loss:  5.870241165161133\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  17\n",
            "Train Loss:  6.416205406188965\n",
            "Test Loss:  5.847316265106201\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  18\n",
            "Train Loss:  6.362235069274902\n",
            "Test Loss:  5.825457572937012\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  19\n",
            "Train Loss:  6.309642791748047\n",
            "Test Loss:  5.804656028747559\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  20\n",
            "Train Loss:  6.258454322814941\n",
            "Test Loss:  5.78492546081543\n",
            "Recall : 0.15047619047619049\n",
            "Epoch  21\n",
            "Train Loss:  6.208687782287598\n",
            "Test Loss:  5.766294479370117\n",
            "Recall : 0.14952380952380953\n",
            "Epoch  22\n",
            "Train Loss:  6.160353183746338\n",
            "Test Loss:  5.74873685836792\n",
            "Recall : 0.15142857142857144\n",
            "Epoch  23\n",
            "Train Loss:  6.113442420959473\n",
            "Test Loss:  5.732213973999023\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  24\n",
            "Train Loss:  6.067927360534668\n",
            "Test Loss:  5.716726303100586\n",
            "Recall : 0.1523809523809524\n",
            "Epoch  25\n",
            "Train Loss:  6.023800373077393\n",
            "Test Loss:  5.702315330505371\n",
            "Recall : 0.15619047619047619\n",
            "Epoch  26\n",
            "Train Loss:  5.981074333190918\n",
            "Test Loss:  5.688908100128174\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  27\n",
            "Train Loss:  5.939725399017334\n",
            "Test Loss:  5.676417350769043\n",
            "Recall : 0.15523809523809523\n",
            "Epoch  28\n",
            "Train Loss:  5.899741172790527\n",
            "Test Loss:  5.664775848388672\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  29\n",
            "Train Loss:  5.861101150512695\n",
            "Test Loss:  5.653951644897461\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  30\n",
            "Train Loss:  5.82371711730957\n",
            "Test Loss:  5.643881797790527\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  31\n",
            "Train Loss:  5.787585258483887\n",
            "Test Loss:  5.6345720291137695\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  32\n",
            "Train Loss:  5.752688407897949\n",
            "Test Loss:  5.625969886779785\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  33\n",
            "Train Loss:  5.71898078918457\n",
            "Test Loss:  5.618054389953613\n",
            "Recall : 0.16\n",
            "Epoch  34\n",
            "Train Loss:  5.686427116394043\n",
            "Test Loss:  5.610785007476807\n",
            "Recall : 0.16\n",
            "Epoch  35\n",
            "Train Loss:  5.6549787521362305\n",
            "Test Loss:  5.604074478149414\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  36\n",
            "Train Loss:  5.6245832443237305\n",
            "Test Loss:  5.597881317138672\n",
            "Recall : 0.15714285714285714\n",
            "Epoch  37\n",
            "Train Loss:  5.595181941986084\n",
            "Test Loss:  5.592229843139648\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  38\n",
            "Train Loss:  5.566791534423828\n",
            "Test Loss:  5.5870771408081055\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  39\n",
            "Train Loss:  5.539331436157227\n",
            "Test Loss:  5.582328796386719\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  40\n",
            "Train Loss:  5.512794494628906\n",
            "Test Loss:  5.57792854309082\n",
            "Recall : 0.1580952380952381\n",
            "Epoch  41\n",
            "Train Loss:  5.487117767333984\n",
            "Test Loss:  5.573847770690918\n",
            "Recall : 0.15904761904761905\n",
            "Epoch  42\n",
            "Train Loss:  5.462240695953369\n",
            "Test Loss:  5.570102691650391\n",
            "Recall : 0.16\n",
            "Epoch  43\n",
            "Train Loss:  5.43814754486084\n",
            "Test Loss:  5.566634178161621\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  44\n",
            "Train Loss:  5.414812088012695\n",
            "Test Loss:  5.563413619995117\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  45\n",
            "Train Loss:  5.392180442810059\n",
            "Test Loss:  5.5604248046875\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  46\n",
            "Train Loss:  5.370223045349121\n",
            "Test Loss:  5.557624340057373\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  47\n",
            "Train Loss:  5.348889350891113\n",
            "Test Loss:  5.554999351501465\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  48\n",
            "Train Loss:  5.328160285949707\n",
            "Test Loss:  5.552586555480957\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  49\n",
            "Train Loss:  5.308034896850586\n",
            "Test Loss:  5.550341606140137\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  50\n",
            "Train Loss:  5.288478851318359\n",
            "Test Loss:  5.548286437988281\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  51\n",
            "Train Loss:  5.269434452056885\n",
            "Test Loss:  5.546337127685547\n",
            "Recall : 0.16\n",
            "Epoch  52\n",
            "Train Loss:  5.250911712646484\n",
            "Test Loss:  5.544504165649414\n",
            "Recall : 0.16\n",
            "Epoch  53\n",
            "Train Loss:  5.232881546020508\n",
            "Test Loss:  5.542717933654785\n",
            "Recall : 0.16\n",
            "Epoch  54\n",
            "Train Loss:  5.215297222137451\n",
            "Test Loss:  5.540990829467773\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  55\n",
            "Train Loss:  5.198156356811523\n",
            "Test Loss:  5.53935432434082\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  56\n",
            "Train Loss:  5.181455612182617\n",
            "Test Loss:  5.537782669067383\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  57\n",
            "Train Loss:  5.165158748626709\n",
            "Test Loss:  5.5362443923950195\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  58\n",
            "Train Loss:  5.149245262145996\n",
            "Test Loss:  5.534727096557617\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  59\n",
            "Train Loss:  5.133711814880371\n",
            "Test Loss:  5.53319787979126\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  60\n",
            "Train Loss:  5.118533134460449\n",
            "Test Loss:  5.531683444976807\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  61\n",
            "Train Loss:  5.1036882400512695\n",
            "Test Loss:  5.530226707458496\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  62\n",
            "Train Loss:  5.089195251464844\n",
            "Test Loss:  5.5288004875183105\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  63\n",
            "Train Loss:  5.075024604797363\n",
            "Test Loss:  5.52741003036499\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  64\n",
            "Train Loss:  5.061158180236816\n",
            "Test Loss:  5.526049613952637\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  65\n",
            "Train Loss:  5.047605514526367\n",
            "Test Loss:  5.524718284606934\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  66\n",
            "Train Loss:  5.0343427658081055\n",
            "Test Loss:  5.523401260375977\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  67\n",
            "Train Loss:  5.021356582641602\n",
            "Test Loss:  5.522051811218262\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  68\n",
            "Train Loss:  5.008638381958008\n",
            "Test Loss:  5.520709037780762\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  69\n",
            "Train Loss:  4.996179580688477\n",
            "Test Loss:  5.519396781921387\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  70\n",
            "Train Loss:  4.983981609344482\n",
            "Test Loss:  5.5180559158325195\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  71\n",
            "Train Loss:  4.972027778625488\n",
            "Test Loss:  5.516744136810303\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  72\n",
            "Train Loss:  4.960304260253906\n",
            "Test Loss:  5.515445709228516\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  73\n",
            "Train Loss:  4.948807716369629\n",
            "Test Loss:  5.514167785644531\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  74\n",
            "Train Loss:  4.937519073486328\n",
            "Test Loss:  5.512894153594971\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  75\n",
            "Train Loss:  4.9264445304870605\n",
            "Test Loss:  5.511639595031738\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  76\n",
            "Train Loss:  4.915594100952148\n",
            "Test Loss:  5.510397434234619\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  77\n",
            "Train Loss:  4.904960632324219\n",
            "Test Loss:  5.509171485900879\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  78\n",
            "Train Loss:  4.89453125\n",
            "Test Loss:  5.5079193115234375\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  79\n",
            "Train Loss:  4.8842973709106445\n",
            "Test Loss:  5.506677627563477\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  80\n",
            "Train Loss:  4.874260902404785\n",
            "Test Loss:  5.505455017089844\n",
            "Recall : 0.16095238095238096\n",
            "Epoch  81\n",
            "Train Loss:  4.864418029785156\n",
            "Test Loss:  5.504289150238037\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  82\n",
            "Train Loss:  4.854772567749023\n",
            "Test Loss:  5.503127098083496\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  83\n",
            "Train Loss:  4.845312118530273\n",
            "Test Loss:  5.50201416015625\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  84\n",
            "Train Loss:  4.836028099060059\n",
            "Test Loss:  5.500938415527344\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  85\n",
            "Train Loss:  4.826921463012695\n",
            "Test Loss:  5.499899387359619\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  86\n",
            "Train Loss:  4.817997932434082\n",
            "Test Loss:  5.498888969421387\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  87\n",
            "Train Loss:  4.809238433837891\n",
            "Test Loss:  5.4978928565979\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  88\n",
            "Train Loss:  4.80064058303833\n",
            "Test Loss:  5.4969305992126465\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  89\n",
            "Train Loss:  4.792205333709717\n",
            "Test Loss:  5.496001243591309\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  90\n",
            "Train Loss:  4.783924102783203\n",
            "Test Loss:  5.49510383605957\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  91\n",
            "Train Loss:  4.775783538818359\n",
            "Test Loss:  5.494241714477539\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  92\n",
            "Train Loss:  4.767786502838135\n",
            "Test Loss:  5.493383407592773\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  93\n",
            "Train Loss:  4.759923934936523\n",
            "Test Loss:  5.492558479309082\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  94\n",
            "Train Loss:  4.7521867752075195\n",
            "Test Loss:  5.491762161254883\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  95\n",
            "Train Loss:  4.744588851928711\n",
            "Test Loss:  5.490981101989746\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  96\n",
            "Train Loss:  4.737119674682617\n",
            "Test Loss:  5.490229606628418\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  97\n",
            "Train Loss:  4.729775428771973\n",
            "Test Loss:  5.4895172119140625\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  98\n",
            "Train Loss:  4.7225661277771\n",
            "Test Loss:  5.4888386726379395\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  99\n",
            "Train Loss:  4.715473651885986\n",
            "Test Loss:  5.488182067871094\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  100\n",
            "Train Loss:  4.708486557006836\n",
            "Test Loss:  5.48756742477417\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  101\n",
            "Train Loss:  4.701610088348389\n",
            "Test Loss:  5.486990451812744\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  102\n",
            "Train Loss:  4.694842338562012\n",
            "Test Loss:  5.486452579498291\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  103\n",
            "Train Loss:  4.68817663192749\n",
            "Test Loss:  5.485957145690918\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  104\n",
            "Train Loss:  4.681613922119141\n",
            "Test Loss:  5.485475540161133\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  105\n",
            "Train Loss:  4.6751389503479\n",
            "Test Loss:  5.485019683837891\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  106\n",
            "Train Loss:  4.6687517166137695\n",
            "Test Loss:  5.484574317932129\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  107\n",
            "Train Loss:  4.662452697753906\n",
            "Test Loss:  5.4841485023498535\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  108\n",
            "Train Loss:  4.6562275886535645\n",
            "Test Loss:  5.483725547790527\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  109\n",
            "Train Loss:  4.650077819824219\n",
            "Test Loss:  5.48332405090332\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  110\n",
            "Train Loss:  4.643994331359863\n",
            "Test Loss:  5.482932090759277\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  111\n",
            "Train Loss:  4.637972831726074\n",
            "Test Loss:  5.482538223266602\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  112\n",
            "Train Loss:  4.63200569152832\n",
            "Test Loss:  5.482156753540039\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  113\n",
            "Train Loss:  4.626095771789551\n",
            "Test Loss:  5.481795787811279\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  114\n",
            "Train Loss:  4.620242595672607\n",
            "Test Loss:  5.481452465057373\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  115\n",
            "Train Loss:  4.614441871643066\n",
            "Test Loss:  5.481118202209473\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  116\n",
            "Train Loss:  4.608694076538086\n",
            "Test Loss:  5.480778694152832\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  117\n",
            "Train Loss:  4.602995872497559\n",
            "Test Loss:  5.480451583862305\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  118\n",
            "Train Loss:  4.597334861755371\n",
            "Test Loss:  5.480139255523682\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  119\n",
            "Train Loss:  4.591713905334473\n",
            "Test Loss:  5.479842662811279\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  120\n",
            "Train Loss:  4.586138725280762\n",
            "Test Loss:  5.479536056518555\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  121\n",
            "Train Loss:  4.580611228942871\n",
            "Test Loss:  5.479224681854248\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  122\n",
            "Train Loss:  4.575124263763428\n",
            "Test Loss:  5.478909969329834\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  123\n",
            "Train Loss:  4.569677352905273\n",
            "Test Loss:  5.478585243225098\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  124\n",
            "Train Loss:  4.56426477432251\n",
            "Test Loss:  5.478262901306152\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  125\n",
            "Train Loss:  4.558885097503662\n",
            "Test Loss:  5.477935791015625\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  126\n",
            "Train Loss:  4.553537368774414\n",
            "Test Loss:  5.477606296539307\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  127\n",
            "Train Loss:  4.548223495483398\n",
            "Test Loss:  5.477294921875\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  128\n",
            "Train Loss:  4.542943954467773\n",
            "Test Loss:  5.476968765258789\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  129\n",
            "Train Loss:  4.537700653076172\n",
            "Test Loss:  5.476653099060059\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  130\n",
            "Train Loss:  4.532487869262695\n",
            "Test Loss:  5.476348876953125\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  131\n",
            "Train Loss:  4.527298927307129\n",
            "Test Loss:  5.476044654846191\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  132\n",
            "Train Loss:  4.522134780883789\n",
            "Test Loss:  5.475746154785156\n",
            "Recall : 0.16285714285714287\n",
            "Epoch  133\n",
            "Train Loss:  4.517001152038574\n",
            "Test Loss:  5.475458145141602\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  134\n",
            "Train Loss:  4.511894226074219\n",
            "Test Loss:  5.475166320800781\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  135\n",
            "Train Loss:  4.506816864013672\n",
            "Test Loss:  5.474857330322266\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  136\n",
            "Train Loss:  4.501769542694092\n",
            "Test Loss:  5.47453498840332\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  137\n",
            "Train Loss:  4.4967498779296875\n",
            "Test Loss:  5.474209785461426\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  138\n",
            "Train Loss:  4.491761207580566\n",
            "Test Loss:  5.473886489868164\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  139\n",
            "Train Loss:  4.486800193786621\n",
            "Test Loss:  5.473566055297852\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  140\n",
            "Train Loss:  4.481864929199219\n",
            "Test Loss:  5.4732465744018555\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  141\n",
            "Train Loss:  4.476959228515625\n",
            "Test Loss:  5.472936153411865\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  142\n",
            "Train Loss:  4.472084999084473\n",
            "Test Loss:  5.472628593444824\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  143\n",
            "Train Loss:  4.467241287231445\n",
            "Test Loss:  5.472326278686523\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  144\n",
            "Train Loss:  4.462427616119385\n",
            "Test Loss:  5.4720354080200195\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  145\n",
            "Train Loss:  4.457650184631348\n",
            "Test Loss:  5.47174072265625\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  146\n",
            "Train Loss:  4.45290470123291\n",
            "Test Loss:  5.47146463394165\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  147\n",
            "Train Loss:  4.448195457458496\n",
            "Test Loss:  5.471200942993164\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  148\n",
            "Train Loss:  4.44351863861084\n",
            "Test Loss:  5.470938682556152\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  149\n",
            "Train Loss:  4.438873291015625\n",
            "Test Loss:  5.470672607421875\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  150\n",
            "Train Loss:  4.4342570304870605\n",
            "Test Loss:  5.4704084396362305\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  151\n",
            "Train Loss:  4.429670333862305\n",
            "Test Loss:  5.470136642456055\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  152\n",
            "Train Loss:  4.425114154815674\n",
            "Test Loss:  5.469856262207031\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  153\n",
            "Train Loss:  4.420590400695801\n",
            "Test Loss:  5.469581604003906\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  154\n",
            "Train Loss:  4.416101455688477\n",
            "Test Loss:  5.469318389892578\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  155\n",
            "Train Loss:  4.411647796630859\n",
            "Test Loss:  5.469078063964844\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  156\n",
            "Train Loss:  4.407232761383057\n",
            "Test Loss:  5.468845367431641\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  157\n",
            "Train Loss:  4.402849197387695\n",
            "Test Loss:  5.468628406524658\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  158\n",
            "Train Loss:  4.398496627807617\n",
            "Test Loss:  5.468433856964111\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  159\n",
            "Train Loss:  4.394179821014404\n",
            "Test Loss:  5.468255043029785\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  160\n",
            "Train Loss:  4.389898777008057\n",
            "Test Loss:  5.4680938720703125\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  161\n",
            "Train Loss:  4.3856520652771\n",
            "Test Loss:  5.467933654785156\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  162\n",
            "Train Loss:  4.381439208984375\n",
            "Test Loss:  5.467771530151367\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  163\n",
            "Train Loss:  4.377264022827148\n",
            "Test Loss:  5.467615127563477\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  164\n",
            "Train Loss:  4.3731255531311035\n",
            "Test Loss:  5.467457294464111\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  165\n",
            "Train Loss:  4.369025230407715\n",
            "Test Loss:  5.467312812805176\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  166\n",
            "Train Loss:  4.364958763122559\n",
            "Test Loss:  5.467169284820557\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  167\n",
            "Train Loss:  4.36092472076416\n",
            "Test Loss:  5.467036247253418\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  168\n",
            "Train Loss:  4.356924057006836\n",
            "Test Loss:  5.466913223266602\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  169\n",
            "Train Loss:  4.35295295715332\n",
            "Test Loss:  5.466792106628418\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  170\n",
            "Train Loss:  4.349018573760986\n",
            "Test Loss:  5.466672897338867\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  171\n",
            "Train Loss:  4.345110893249512\n",
            "Test Loss:  5.46656608581543\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  172\n",
            "Train Loss:  4.34123420715332\n",
            "Test Loss:  5.466464042663574\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  173\n",
            "Train Loss:  4.3373870849609375\n",
            "Test Loss:  5.466361999511719\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  174\n",
            "Train Loss:  4.333571434020996\n",
            "Test Loss:  5.46627140045166\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  175\n",
            "Train Loss:  4.329780578613281\n",
            "Test Loss:  5.466188907623291\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  176\n",
            "Train Loss:  4.3260178565979\n",
            "Test Loss:  5.466115474700928\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  177\n",
            "Train Loss:  4.3222832679748535\n",
            "Test Loss:  5.466053485870361\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  178\n",
            "Train Loss:  4.318581581115723\n",
            "Test Loss:  5.465994834899902\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  179\n",
            "Train Loss:  4.314909934997559\n",
            "Test Loss:  5.465946197509766\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  180\n",
            "Train Loss:  4.311263561248779\n",
            "Test Loss:  5.465907573699951\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  181\n",
            "Train Loss:  4.307642459869385\n",
            "Test Loss:  5.465876579284668\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  182\n",
            "Train Loss:  4.304042816162109\n",
            "Test Loss:  5.465847969055176\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  183\n",
            "Train Loss:  4.300465106964111\n",
            "Test Loss:  5.465827941894531\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  184\n",
            "Train Loss:  4.296913146972656\n",
            "Test Loss:  5.465816497802734\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  185\n",
            "Train Loss:  4.293386459350586\n",
            "Test Loss:  5.465811729431152\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  186\n",
            "Train Loss:  4.289886474609375\n",
            "Test Loss:  5.4658122062683105\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  187\n",
            "Train Loss:  4.286412239074707\n",
            "Test Loss:  5.465819358825684\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  188\n",
            "Train Loss:  4.282957077026367\n",
            "Test Loss:  5.4658308029174805\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  189\n",
            "Train Loss:  4.279525279998779\n",
            "Test Loss:  5.465836524963379\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  190\n",
            "Train Loss:  4.27611780166626\n",
            "Test Loss:  5.465829849243164\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  191\n",
            "Train Loss:  4.272730827331543\n",
            "Test Loss:  5.465808868408203\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  192\n",
            "Train Loss:  4.2693634033203125\n",
            "Test Loss:  5.465781211853027\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  193\n",
            "Train Loss:  4.266013145446777\n",
            "Test Loss:  5.465760231018066\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  194\n",
            "Train Loss:  4.262681007385254\n",
            "Test Loss:  5.465743064880371\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  195\n",
            "Train Loss:  4.259366035461426\n",
            "Test Loss:  5.465722560882568\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  196\n",
            "Train Loss:  4.256072521209717\n",
            "Test Loss:  5.465704917907715\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  197\n",
            "Train Loss:  4.252801895141602\n",
            "Test Loss:  5.465691089630127\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  198\n",
            "Train Loss:  4.249553680419922\n",
            "Test Loss:  5.465672492980957\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  199\n",
            "Train Loss:  4.2463178634643555\n",
            "Test Loss:  5.465659141540527\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  200\n",
            "Train Loss:  4.243100166320801\n",
            "Test Loss:  5.4656476974487305\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  201\n",
            "Train Loss:  4.239900588989258\n",
            "Test Loss:  5.465634346008301\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  202\n",
            "Train Loss:  4.236721038818359\n",
            "Test Loss:  5.4656219482421875\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  203\n",
            "Train Loss:  4.233556747436523\n",
            "Test Loss:  5.465603828430176\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  204\n",
            "Train Loss:  4.230411529541016\n",
            "Test Loss:  5.465581893920898\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  205\n",
            "Train Loss:  4.227282524108887\n",
            "Test Loss:  5.465548992156982\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  206\n",
            "Train Loss:  4.224173069000244\n",
            "Test Loss:  5.465508460998535\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  207\n",
            "Train Loss:  4.2210845947265625\n",
            "Test Loss:  5.465465545654297\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  208\n",
            "Train Loss:  4.218012809753418\n",
            "Test Loss:  5.465424537658691\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  209\n",
            "Train Loss:  4.2149577140808105\n",
            "Test Loss:  5.465389251708984\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  210\n",
            "Train Loss:  4.21191930770874\n",
            "Test Loss:  5.465350151062012\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  211\n",
            "Train Loss:  4.208897590637207\n",
            "Test Loss:  5.4653143882751465\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  212\n",
            "Train Loss:  4.2058939933776855\n",
            "Test Loss:  5.465277671813965\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  213\n",
            "Train Loss:  4.202901840209961\n",
            "Test Loss:  5.4652323722839355\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  214\n",
            "Train Loss:  4.199925422668457\n",
            "Test Loss:  5.465177536010742\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  215\n",
            "Train Loss:  4.196961402893066\n",
            "Test Loss:  5.465123176574707\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  216\n",
            "Train Loss:  4.1940107345581055\n",
            "Test Loss:  5.465066909790039\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  217\n",
            "Train Loss:  4.191073417663574\n",
            "Test Loss:  5.464996337890625\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  218\n",
            "Train Loss:  4.188148021697998\n",
            "Test Loss:  5.464923858642578\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  219\n",
            "Train Loss:  4.185238361358643\n",
            "Test Loss:  5.464844226837158\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  220\n",
            "Train Loss:  4.182343006134033\n",
            "Test Loss:  5.4647650718688965\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  221\n",
            "Train Loss:  4.179460525512695\n",
            "Test Loss:  5.4646806716918945\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  222\n",
            "Train Loss:  4.176592826843262\n",
            "Test Loss:  5.464591026306152\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  223\n",
            "Train Loss:  4.173741340637207\n",
            "Test Loss:  5.464499473571777\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  224\n",
            "Train Loss:  4.170906066894531\n",
            "Test Loss:  5.464404106140137\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  225\n",
            "Train Loss:  4.168087959289551\n",
            "Test Loss:  5.4643049240112305\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  226\n",
            "Train Loss:  4.165287017822266\n",
            "Test Loss:  5.464198112487793\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  227\n",
            "Train Loss:  4.162500381469727\n",
            "Test Loss:  5.464079856872559\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  228\n",
            "Train Loss:  4.15972900390625\n",
            "Test Loss:  5.463966369628906\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  229\n",
            "Train Loss:  4.156970977783203\n",
            "Test Loss:  5.463852882385254\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  230\n",
            "Train Loss:  4.154231071472168\n",
            "Test Loss:  5.463744163513184\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  231\n",
            "Train Loss:  4.151507377624512\n",
            "Test Loss:  5.463637351989746\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  232\n",
            "Train Loss:  4.148797512054443\n",
            "Test Loss:  5.463536262512207\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  233\n",
            "Train Loss:  4.146106243133545\n",
            "Test Loss:  5.463431358337402\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  234\n",
            "Train Loss:  4.143430709838867\n",
            "Test Loss:  5.463332176208496\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  235\n",
            "Train Loss:  4.140769958496094\n",
            "Test Loss:  5.46323299407959\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  236\n",
            "Train Loss:  4.138123512268066\n",
            "Test Loss:  5.463141441345215\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  237\n",
            "Train Loss:  4.135491371154785\n",
            "Test Loss:  5.463057994842529\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  238\n",
            "Train Loss:  4.132876396179199\n",
            "Test Loss:  5.46297550201416\n",
            "Recall : 0.16380952380952382\n",
            "Epoch  239\n",
            "Train Loss:  4.130278587341309\n",
            "Test Loss:  5.462890148162842\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  240\n",
            "Train Loss:  4.1276960372924805\n",
            "Test Loss:  5.462807655334473\n",
            "Recall : 0.1619047619047619\n",
            "Epoch  241\n",
            "Train Loss:  4.125131130218506\n",
            "Test Loss:  5.462726593017578\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  242\n",
            "Train Loss:  4.122584342956543\n",
            "Test Loss:  5.462649345397949\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  243\n",
            "Train Loss:  4.120054721832275\n",
            "Test Loss:  5.462577819824219\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  244\n",
            "Train Loss:  4.117542266845703\n",
            "Test Loss:  5.462510108947754\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  245\n",
            "Train Loss:  4.115044593811035\n",
            "Test Loss:  5.4624481201171875\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  246\n",
            "Train Loss:  4.112562656402588\n",
            "Test Loss:  5.462385177612305\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  247\n",
            "Train Loss:  4.110096454620361\n",
            "Test Loss:  5.462324619293213\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  248\n",
            "Train Loss:  4.107646465301514\n",
            "Test Loss:  5.462265968322754\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  249\n",
            "Train Loss:  4.1052093505859375\n",
            "Test Loss:  5.462210655212402\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  250\n",
            "Train Loss:  4.102788925170898\n",
            "Test Loss:  5.462158203125\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  251\n",
            "Train Loss:  4.1003804206848145\n",
            "Test Loss:  5.462105751037598\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  252\n",
            "Train Loss:  4.097986221313477\n",
            "Test Loss:  5.462052345275879\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  253\n",
            "Train Loss:  4.095605850219727\n",
            "Test Loss:  5.462002754211426\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  254\n",
            "Train Loss:  4.093240737915039\n",
            "Test Loss:  5.461952209472656\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  255\n",
            "Train Loss:  4.090891361236572\n",
            "Test Loss:  5.4619035720825195\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  256\n",
            "Train Loss:  4.088557720184326\n",
            "Test Loss:  5.461854934692383\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  257\n",
            "Train Loss:  4.086238384246826\n",
            "Test Loss:  5.461807727813721\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  258\n",
            "Train Loss:  4.08393669128418\n",
            "Test Loss:  5.461761474609375\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  259\n",
            "Train Loss:  4.0816521644592285\n",
            "Test Loss:  5.461716651916504\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  260\n",
            "Train Loss:  4.079381942749023\n",
            "Test Loss:  5.461674213409424\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  261\n",
            "Train Loss:  4.077124118804932\n",
            "Test Loss:  5.461637496948242\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  262\n",
            "Train Loss:  4.0748796463012695\n",
            "Test Loss:  5.461597442626953\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  263\n",
            "Train Loss:  4.0726494789123535\n",
            "Test Loss:  5.461553573608398\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  264\n",
            "Train Loss:  4.070430755615234\n",
            "Test Loss:  5.461503028869629\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  265\n",
            "Train Loss:  4.068228244781494\n",
            "Test Loss:  5.461453437805176\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  266\n",
            "Train Loss:  4.066037178039551\n",
            "Test Loss:  5.461408615112305\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  267\n",
            "Train Loss:  4.063859462738037\n",
            "Test Loss:  5.461365699768066\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  268\n",
            "Train Loss:  4.061695098876953\n",
            "Test Loss:  5.461322784423828\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  269\n",
            "Train Loss:  4.059543609619141\n",
            "Test Loss:  5.461282253265381\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  270\n",
            "Train Loss:  4.057403087615967\n",
            "Test Loss:  5.461245536804199\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  271\n",
            "Train Loss:  4.055275917053223\n",
            "Test Loss:  5.461209297180176\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  272\n",
            "Train Loss:  4.05316162109375\n",
            "Test Loss:  5.461176872253418\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  273\n",
            "Train Loss:  4.05106258392334\n",
            "Test Loss:  5.461145401000977\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  274\n",
            "Train Loss:  4.048977851867676\n",
            "Test Loss:  5.461112022399902\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  275\n",
            "Train Loss:  4.046907424926758\n",
            "Test Loss:  5.461081504821777\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  276\n",
            "Train Loss:  4.044849872589111\n",
            "Test Loss:  5.461054801940918\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  277\n",
            "Train Loss:  4.042804718017578\n",
            "Test Loss:  5.461027145385742\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  278\n",
            "Train Loss:  4.040772914886475\n",
            "Test Loss:  5.460995674133301\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  279\n",
            "Train Loss:  4.038750648498535\n",
            "Test Loss:  5.460967063903809\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  280\n",
            "Train Loss:  4.036742210388184\n",
            "Test Loss:  5.460941314697266\n",
            "Recall : 0.16476190476190475\n",
            "Epoch  281\n",
            "Train Loss:  4.0347418785095215\n",
            "Test Loss:  5.460918426513672\n",
            "Recall : 0.1657142857142857\n",
            "Epoch  282\n",
            "Train Loss:  4.03275203704834\n",
            "Test Loss:  5.460893630981445\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  283\n",
            "Train Loss:  4.030771255493164\n",
            "Test Loss:  5.460867404937744\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  284\n",
            "Train Loss:  4.028802871704102\n",
            "Test Loss:  5.460845470428467\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  285\n",
            "Train Loss:  4.026844024658203\n",
            "Test Loss:  5.460824012756348\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  286\n",
            "Train Loss:  4.024896144866943\n",
            "Test Loss:  5.460805892944336\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  287\n",
            "Train Loss:  4.022960186004639\n",
            "Test Loss:  5.460788726806641\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  288\n",
            "Train Loss:  4.021033763885498\n",
            "Test Loss:  5.4607696533203125\n",
            "Recall : 0.16666666666666666\n",
            "Epoch  289\n",
            "Train Loss:  4.01911735534668\n",
            "Test Loss:  5.46075439453125\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  290\n",
            "Train Loss:  4.017212390899658\n",
            "Test Loss:  5.4607439041137695\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  291\n",
            "Train Loss:  4.015315532684326\n",
            "Test Loss:  5.4607343673706055\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  292\n",
            "Train Loss:  4.013428688049316\n",
            "Test Loss:  5.460725784301758\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  293\n",
            "Train Loss:  4.011551856994629\n",
            "Test Loss:  5.460714340209961\n",
            "Recall : 0.1676190476190476\n",
            "Epoch  294\n",
            "Train Loss:  4.0096845626831055\n",
            "Test Loss:  5.460712432861328\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  295\n",
            "Train Loss:  4.007828712463379\n",
            "Test Loss:  5.460716724395752\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  296\n",
            "Train Loss:  4.005983829498291\n",
            "Test Loss:  5.460724830627441\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  297\n",
            "Train Loss:  4.004151821136475\n",
            "Test Loss:  5.460738182067871\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  298\n",
            "Train Loss:  4.002327919006348\n",
            "Test Loss:  5.460753440856934\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  299\n",
            "Train Loss:  4.00051736831665\n",
            "Test Loss:  5.460771560668945\n",
            "Recall : 0.16857142857142857\n",
            "Epoch  300\n",
            "Train Loss:  3.998715400695801\n",
            "Test Loss:  5.460789203643799\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  301\n",
            "Train Loss:  3.996922016143799\n",
            "Test Loss:  5.4608154296875\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  302\n",
            "Train Loss:  3.9951395988464355\n",
            "Test Loss:  5.460851192474365\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  303\n",
            "Train Loss:  3.993368148803711\n",
            "Test Loss:  5.460890769958496\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  304\n",
            "Train Loss:  3.991605520248413\n",
            "Test Loss:  5.46093225479126\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  305\n",
            "Train Loss:  3.9898533821105957\n",
            "Test Loss:  5.4609785079956055\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  306\n",
            "Train Loss:  3.9881110191345215\n",
            "Test Loss:  5.461026191711426\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  307\n",
            "Train Loss:  3.9863765239715576\n",
            "Test Loss:  5.461071968078613\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  308\n",
            "Train Loss:  3.9846503734588623\n",
            "Test Loss:  5.461119651794434\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  309\n",
            "Train Loss:  3.9829349517822266\n",
            "Test Loss:  5.461172103881836\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  310\n",
            "Train Loss:  3.981226682662964\n",
            "Test Loss:  5.461231708526611\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  311\n",
            "Train Loss:  3.979527473449707\n",
            "Test Loss:  5.461294174194336\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  312\n",
            "Train Loss:  3.9778380393981934\n",
            "Test Loss:  5.461362361907959\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  313\n",
            "Train Loss:  3.9761581420898438\n",
            "Test Loss:  5.461432456970215\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  314\n",
            "Train Loss:  3.974487781524658\n",
            "Test Loss:  5.461503028869629\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  315\n",
            "Train Loss:  3.9728236198425293\n",
            "Test Loss:  5.461575508117676\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  316\n",
            "Train Loss:  3.9711666107177734\n",
            "Test Loss:  5.461648941040039\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  317\n",
            "Train Loss:  3.969517469406128\n",
            "Test Loss:  5.461727142333984\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  318\n",
            "Train Loss:  3.967876434326172\n",
            "Test Loss:  5.46180534362793\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  319\n",
            "Train Loss:  3.966243267059326\n",
            "Test Loss:  5.461885452270508\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  320\n",
            "Train Loss:  3.9646177291870117\n",
            "Test Loss:  5.461966037750244\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  321\n",
            "Train Loss:  3.963001251220703\n",
            "Test Loss:  5.462042808532715\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  322\n",
            "Train Loss:  3.9613919258117676\n",
            "Test Loss:  5.462121963500977\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  323\n",
            "Train Loss:  3.959789276123047\n",
            "Test Loss:  5.462206840515137\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  324\n",
            "Train Loss:  3.958195209503174\n",
            "Test Loss:  5.462290287017822\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  325\n",
            "Train Loss:  3.9566094875335693\n",
            "Test Loss:  5.462373733520508\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  326\n",
            "Train Loss:  3.955031394958496\n",
            "Test Loss:  5.462457656860352\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  327\n",
            "Train Loss:  3.953460693359375\n",
            "Test Loss:  5.462543487548828\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  328\n",
            "Train Loss:  3.9518966674804688\n",
            "Test Loss:  5.46262788772583\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  329\n",
            "Train Loss:  3.9503397941589355\n",
            "Test Loss:  5.462712287902832\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  330\n",
            "Train Loss:  3.948788642883301\n",
            "Test Loss:  5.462798118591309\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  331\n",
            "Train Loss:  3.9472460746765137\n",
            "Test Loss:  5.462889194488525\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  332\n",
            "Train Loss:  3.9457101821899414\n",
            "Test Loss:  5.462980270385742\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  333\n",
            "Train Loss:  3.944180965423584\n",
            "Test Loss:  5.46307373046875\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  334\n",
            "Train Loss:  3.9426608085632324\n",
            "Test Loss:  5.463169574737549\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  335\n",
            "Train Loss:  3.941147565841675\n",
            "Test Loss:  5.463265419006348\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  336\n",
            "Train Loss:  3.9396376609802246\n",
            "Test Loss:  5.4633588790893555\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  337\n",
            "Train Loss:  3.9381351470947266\n",
            "Test Loss:  5.4634504318237305\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  338\n",
            "Train Loss:  3.936640977859497\n",
            "Test Loss:  5.463542938232422\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  339\n",
            "Train Loss:  3.935152530670166\n",
            "Test Loss:  5.46363639831543\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  340\n",
            "Train Loss:  3.9336702823638916\n",
            "Test Loss:  5.463732719421387\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  341\n",
            "Train Loss:  3.9321932792663574\n",
            "Test Loss:  5.463829517364502\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  342\n",
            "Train Loss:  3.9307210445404053\n",
            "Test Loss:  5.463928699493408\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  343\n",
            "Train Loss:  3.9292542934417725\n",
            "Test Loss:  5.464029312133789\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  344\n",
            "Train Loss:  3.927795648574829\n",
            "Test Loss:  5.464128494262695\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  345\n",
            "Train Loss:  3.9263429641723633\n",
            "Test Loss:  5.464228630065918\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  346\n",
            "Train Loss:  3.924895763397217\n",
            "Test Loss:  5.464330196380615\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  347\n",
            "Train Loss:  3.923454761505127\n",
            "Test Loss:  5.464427947998047\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  348\n",
            "Train Loss:  3.9220190048217773\n",
            "Test Loss:  5.464523792266846\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  349\n",
            "Train Loss:  3.920591115951538\n",
            "Test Loss:  5.464616775512695\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  350\n",
            "Train Loss:  3.919168710708618\n",
            "Test Loss:  5.464704990386963\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  351\n",
            "Train Loss:  3.917750835418701\n",
            "Test Loss:  5.464789390563965\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  352\n",
            "Train Loss:  3.916337013244629\n",
            "Test Loss:  5.464878559112549\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  353\n",
            "Train Loss:  3.9149298667907715\n",
            "Test Loss:  5.464967727661133\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  354\n",
            "Train Loss:  3.9135289192199707\n",
            "Test Loss:  5.465057373046875\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  355\n",
            "Train Loss:  3.9121336936950684\n",
            "Test Loss:  5.465142250061035\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  356\n",
            "Train Loss:  3.9107446670532227\n",
            "Test Loss:  5.465226173400879\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  357\n",
            "Train Loss:  3.909359931945801\n",
            "Test Loss:  5.465307235717773\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  358\n",
            "Train Loss:  3.9079813957214355\n",
            "Test Loss:  5.465386390686035\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  359\n",
            "Train Loss:  3.9066085815429688\n",
            "Test Loss:  5.465465545654297\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  360\n",
            "Train Loss:  3.905240535736084\n",
            "Test Loss:  5.465542793273926\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  361\n",
            "Train Loss:  3.9038777351379395\n",
            "Test Loss:  5.465620994567871\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  362\n",
            "Train Loss:  3.9025187492370605\n",
            "Test Loss:  5.465700149536133\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  363\n",
            "Train Loss:  3.9011669158935547\n",
            "Test Loss:  5.465776443481445\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  364\n",
            "Train Loss:  3.8998193740844727\n",
            "Test Loss:  5.465850830078125\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  365\n",
            "Train Loss:  3.898477554321289\n",
            "Test Loss:  5.465925693511963\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  366\n",
            "Train Loss:  3.8971407413482666\n",
            "Test Loss:  5.465996742248535\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  367\n",
            "Train Loss:  3.895810127258301\n",
            "Test Loss:  5.466068267822266\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  368\n",
            "Train Loss:  3.8944826126098633\n",
            "Test Loss:  5.466137886047363\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  369\n",
            "Train Loss:  3.8931615352630615\n",
            "Test Loss:  5.466207504272461\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  370\n",
            "Train Loss:  3.891843795776367\n",
            "Test Loss:  5.466276168823242\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  371\n",
            "Train Loss:  3.8905296325683594\n",
            "Test Loss:  5.466343879699707\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  372\n",
            "Train Loss:  3.88922119140625\n",
            "Test Loss:  5.466409683227539\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  373\n",
            "Train Loss:  3.8879175186157227\n",
            "Test Loss:  5.4664740562438965\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  374\n",
            "Train Loss:  3.886617422103882\n",
            "Test Loss:  5.466538429260254\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  375\n",
            "Train Loss:  3.8853235244750977\n",
            "Test Loss:  5.466606616973877\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  376\n",
            "Train Loss:  3.8840339183807373\n",
            "Test Loss:  5.466676235198975\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  377\n",
            "Train Loss:  3.882748603820801\n",
            "Test Loss:  5.466744422912598\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  378\n",
            "Train Loss:  3.881469249725342\n",
            "Test Loss:  5.4668121337890625\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  379\n",
            "Train Loss:  3.880194902420044\n",
            "Test Loss:  5.466880798339844\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  380\n",
            "Train Loss:  3.878925323486328\n",
            "Test Loss:  5.466948986053467\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  381\n",
            "Train Loss:  3.8776588439941406\n",
            "Test Loss:  5.467019557952881\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  382\n",
            "Train Loss:  3.876396656036377\n",
            "Test Loss:  5.4670915603637695\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  383\n",
            "Train Loss:  3.875138759613037\n",
            "Test Loss:  5.467169761657715\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  384\n",
            "Train Loss:  3.8738863468170166\n",
            "Test Loss:  5.467252254486084\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  385\n",
            "Train Loss:  3.8726377487182617\n",
            "Test Loss:  5.467340469360352\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  386\n",
            "Train Loss:  3.871392250061035\n",
            "Test Loss:  5.467430114746094\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  387\n",
            "Train Loss:  3.8701515197753906\n",
            "Test Loss:  5.467518329620361\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  388\n",
            "Train Loss:  3.868914842605591\n",
            "Test Loss:  5.46760368347168\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  389\n",
            "Train Loss:  3.8676815032958984\n",
            "Test Loss:  5.467685699462891\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  390\n",
            "Train Loss:  3.86645245552063\n",
            "Test Loss:  5.467764854431152\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  391\n",
            "Train Loss:  3.865227222442627\n",
            "Test Loss:  5.467846870422363\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  392\n",
            "Train Loss:  3.8640060424804688\n",
            "Test Loss:  5.467931270599365\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  393\n",
            "Train Loss:  3.862788200378418\n",
            "Test Loss:  5.468015670776367\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  394\n",
            "Train Loss:  3.861574172973633\n",
            "Test Loss:  5.468101978302002\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  395\n",
            "Train Loss:  3.860363245010376\n",
            "Test Loss:  5.4681901931762695\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  396\n",
            "Train Loss:  3.8591561317443848\n",
            "Test Loss:  5.46827507019043\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  397\n",
            "Train Loss:  3.8579535484313965\n",
            "Test Loss:  5.46835994720459\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  398\n",
            "Train Loss:  3.8567540645599365\n",
            "Test Loss:  5.468446731567383\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  399\n",
            "Train Loss:  3.855557441711426\n",
            "Test Loss:  5.46853494644165\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  400\n",
            "Train Loss:  3.8543646335601807\n",
            "Test Loss:  5.468625068664551\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  401\n",
            "Train Loss:  3.8531765937805176\n",
            "Test Loss:  5.468714237213135\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  402\n",
            "Train Loss:  3.851991653442383\n",
            "Test Loss:  5.468804359436035\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  403\n",
            "Train Loss:  3.850811719894409\n",
            "Test Loss:  5.468895435333252\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  404\n",
            "Train Loss:  3.849637508392334\n",
            "Test Loss:  5.46898889541626\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  405\n",
            "Train Loss:  3.848465919494629\n",
            "Test Loss:  5.469080448150635\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  406\n",
            "Train Loss:  3.8472981452941895\n",
            "Test Loss:  5.469173431396484\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  407\n",
            "Train Loss:  3.8461368083953857\n",
            "Test Loss:  5.469268798828125\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  408\n",
            "Train Loss:  3.8449788093566895\n",
            "Test Loss:  5.469365119934082\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  409\n",
            "Train Loss:  3.843822956085205\n",
            "Test Loss:  5.469463348388672\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  410\n",
            "Train Loss:  3.8426709175109863\n",
            "Test Loss:  5.469558238983154\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  411\n",
            "Train Loss:  3.841521978378296\n",
            "Test Loss:  5.469653129577637\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  412\n",
            "Train Loss:  3.84037446975708\n",
            "Test Loss:  5.469748497009277\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  413\n",
            "Train Loss:  3.8392302989959717\n",
            "Test Loss:  5.469843864440918\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  414\n",
            "Train Loss:  3.8380908966064453\n",
            "Test Loss:  5.469943046569824\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  415\n",
            "Train Loss:  3.836953639984131\n",
            "Test Loss:  5.470044136047363\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  416\n",
            "Train Loss:  3.835820198059082\n",
            "Test Loss:  5.470147132873535\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  417\n",
            "Train Loss:  3.8346915245056152\n",
            "Test Loss:  5.470247745513916\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  418\n",
            "Train Loss:  3.833564281463623\n",
            "Test Loss:  5.470351219177246\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  419\n",
            "Train Loss:  3.8324408531188965\n",
            "Test Loss:  5.470455169677734\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  420\n",
            "Train Loss:  3.831322193145752\n",
            "Test Loss:  5.470560550689697\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  421\n",
            "Train Loss:  3.830207347869873\n",
            "Test Loss:  5.470668792724609\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  422\n",
            "Train Loss:  3.8290977478027344\n",
            "Test Loss:  5.4707770347595215\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  423\n",
            "Train Loss:  3.8279905319213867\n",
            "Test Loss:  5.470886707305908\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  424\n",
            "Train Loss:  3.8268866539001465\n",
            "Test Loss:  5.470996379852295\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  425\n",
            "Train Loss:  3.825786590576172\n",
            "Test Loss:  5.47110652923584\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  426\n",
            "Train Loss:  3.8246889114379883\n",
            "Test Loss:  5.471216678619385\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  427\n",
            "Train Loss:  3.823594331741333\n",
            "Test Loss:  5.471325874328613\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  428\n",
            "Train Loss:  3.822500705718994\n",
            "Test Loss:  5.471433639526367\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  429\n",
            "Train Loss:  3.821411609649658\n",
            "Test Loss:  5.471540451049805\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  430\n",
            "Train Loss:  3.8203251361846924\n",
            "Test Loss:  5.471647262573242\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  431\n",
            "Train Loss:  3.819243907928467\n",
            "Test Loss:  5.471753120422363\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  432\n",
            "Train Loss:  3.818164825439453\n",
            "Test Loss:  5.471856117248535\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  433\n",
            "Train Loss:  3.8170900344848633\n",
            "Test Loss:  5.47196102142334\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  434\n",
            "Train Loss:  3.8160171508789062\n",
            "Test Loss:  5.472068786621094\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  435\n",
            "Train Loss:  3.8149478435516357\n",
            "Test Loss:  5.472175121307373\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  436\n",
            "Train Loss:  3.8138818740844727\n",
            "Test Loss:  5.472282409667969\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  437\n",
            "Train Loss:  3.812819480895996\n",
            "Test Loss:  5.472391128540039\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  438\n",
            "Train Loss:  3.811758518218994\n",
            "Test Loss:  5.472501754760742\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  439\n",
            "Train Loss:  3.810701608657837\n",
            "Test Loss:  5.472616672515869\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  440\n",
            "Train Loss:  3.809647560119629\n",
            "Test Loss:  5.4727325439453125\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  441\n",
            "Train Loss:  3.8085970878601074\n",
            "Test Loss:  5.472848892211914\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  442\n",
            "Train Loss:  3.807549238204956\n",
            "Test Loss:  5.472967624664307\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  443\n",
            "Train Loss:  3.806504964828491\n",
            "Test Loss:  5.473087310791016\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  444\n",
            "Train Loss:  3.8054630756378174\n",
            "Test Loss:  5.473208427429199\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  445\n",
            "Train Loss:  3.804422378540039\n",
            "Test Loss:  5.473328590393066\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  446\n",
            "Train Loss:  3.8033857345581055\n",
            "Test Loss:  5.473448276519775\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  447\n",
            "Train Loss:  3.802351236343384\n",
            "Test Loss:  5.473567962646484\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  448\n",
            "Train Loss:  3.801319122314453\n",
            "Test Loss:  5.473687171936035\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  449\n",
            "Train Loss:  3.8002893924713135\n",
            "Test Loss:  5.473811149597168\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  450\n",
            "Train Loss:  3.799262285232544\n",
            "Test Loss:  5.473936080932617\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  451\n",
            "Train Loss:  3.798239231109619\n",
            "Test Loss:  5.474061965942383\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  452\n",
            "Train Loss:  3.797219753265381\n",
            "Test Loss:  5.474186420440674\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  453\n",
            "Train Loss:  3.796203374862671\n",
            "Test Loss:  5.474311351776123\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  454\n",
            "Train Loss:  3.79518985748291\n",
            "Test Loss:  5.474433898925781\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  455\n",
            "Train Loss:  3.7941789627075195\n",
            "Test Loss:  5.474556922912598\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  456\n",
            "Train Loss:  3.7931714057922363\n",
            "Test Loss:  5.474678993225098\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  457\n",
            "Train Loss:  3.7921669483184814\n",
            "Test Loss:  5.474800109863281\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  458\n",
            "Train Loss:  3.7911651134490967\n",
            "Test Loss:  5.474924087524414\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  459\n",
            "Train Loss:  3.7901668548583984\n",
            "Test Loss:  5.475048065185547\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  460\n",
            "Train Loss:  3.7891716957092285\n",
            "Test Loss:  5.475173473358154\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  461\n",
            "Train Loss:  3.788180112838745\n",
            "Test Loss:  5.4753007888793945\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  462\n",
            "Train Loss:  3.787191152572632\n",
            "Test Loss:  5.475427627563477\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  463\n",
            "Train Loss:  3.786206007003784\n",
            "Test Loss:  5.475556373596191\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  464\n",
            "Train Loss:  3.785223960876465\n",
            "Test Loss:  5.47568416595459\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  465\n",
            "Train Loss:  3.784245014190674\n",
            "Test Loss:  5.475811958312988\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  466\n",
            "Train Loss:  3.7832677364349365\n",
            "Test Loss:  5.475942611694336\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  467\n",
            "Train Loss:  3.7822930812835693\n",
            "Test Loss:  5.476070404052734\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  468\n",
            "Train Loss:  3.781320095062256\n",
            "Test Loss:  5.4761962890625\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  469\n",
            "Train Loss:  3.7803492546081543\n",
            "Test Loss:  5.476322174072266\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  470\n",
            "Train Loss:  3.7793824672698975\n",
            "Test Loss:  5.476448059082031\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  471\n",
            "Train Loss:  3.7784175872802734\n",
            "Test Loss:  5.4765729904174805\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  472\n",
            "Train Loss:  3.777456283569336\n",
            "Test Loss:  5.476698875427246\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  473\n",
            "Train Loss:  3.776496410369873\n",
            "Test Loss:  5.4768266677856445\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  474\n",
            "Train Loss:  3.7755393981933594\n",
            "Test Loss:  5.476955413818359\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  475\n",
            "Train Loss:  3.7745847702026367\n",
            "Test Loss:  5.477083206176758\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  476\n",
            "Train Loss:  3.773632526397705\n",
            "Test Loss:  5.4772114753723145\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  477\n",
            "Train Loss:  3.7726821899414062\n",
            "Test Loss:  5.477339744567871\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  478\n",
            "Train Loss:  3.771735429763794\n",
            "Test Loss:  5.477468490600586\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  479\n",
            "Train Loss:  3.770792007446289\n",
            "Test Loss:  5.477595329284668\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  480\n",
            "Train Loss:  3.769853115081787\n",
            "Test Loss:  5.477720260620117\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  481\n",
            "Train Loss:  3.7689170837402344\n",
            "Test Loss:  5.477843284606934\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  482\n",
            "Train Loss:  3.767984390258789\n",
            "Test Loss:  5.477968215942383\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  483\n",
            "Train Loss:  3.7670507431030273\n",
            "Test Loss:  5.478091239929199\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  484\n",
            "Train Loss:  3.766120433807373\n",
            "Test Loss:  5.478213310241699\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  485\n",
            "Train Loss:  3.7651925086975098\n",
            "Test Loss:  5.478336334228516\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  486\n",
            "Train Loss:  3.7642669677734375\n",
            "Test Loss:  5.478458404541016\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  487\n",
            "Train Loss:  3.7633438110351562\n",
            "Test Loss:  5.478580474853516\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  488\n",
            "Train Loss:  3.762423276901245\n",
            "Test Loss:  5.478700637817383\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  489\n",
            "Train Loss:  3.7615041732788086\n",
            "Test Loss:  5.478820323944092\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  490\n",
            "Train Loss:  3.760586977005005\n",
            "Test Loss:  5.478940010070801\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  491\n",
            "Train Loss:  3.7596702575683594\n",
            "Test Loss:  5.479061603546143\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  492\n",
            "Train Loss:  3.7587571144104004\n",
            "Test Loss:  5.479183197021484\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  493\n",
            "Train Loss:  3.757845640182495\n",
            "Test Loss:  5.479304790496826\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  494\n",
            "Train Loss:  3.7569360733032227\n",
            "Test Loss:  5.479426383972168\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  495\n",
            "Train Loss:  3.7560296058654785\n",
            "Test Loss:  5.479548454284668\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  496\n",
            "Train Loss:  3.755126476287842\n",
            "Test Loss:  5.479668617248535\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  497\n",
            "Train Loss:  3.754225492477417\n",
            "Test Loss:  5.479789733886719\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  498\n",
            "Train Loss:  3.7533276081085205\n",
            "Test Loss:  5.479911804199219\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  499\n",
            "Train Loss:  3.7524337768554688\n",
            "Test Loss:  5.480032920837402\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  500\n",
            "Train Loss:  3.7515413761138916\n",
            "Test Loss:  5.480152606964111\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  501\n",
            "Train Loss:  3.750652313232422\n",
            "Test Loss:  5.48027229309082\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  502\n",
            "Train Loss:  3.749767303466797\n",
            "Test Loss:  5.480389595031738\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  503\n",
            "Train Loss:  3.748884677886963\n",
            "Test Loss:  5.48050594329834\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  504\n",
            "Train Loss:  3.748004198074341\n",
            "Test Loss:  5.480623245239258\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  505\n",
            "Train Loss:  3.747126579284668\n",
            "Test Loss:  5.480739593505859\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  506\n",
            "Train Loss:  3.746251106262207\n",
            "Test Loss:  5.480852127075195\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  507\n",
            "Train Loss:  3.745378017425537\n",
            "Test Loss:  5.480962753295898\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  508\n",
            "Train Loss:  3.7445068359375\n",
            "Test Loss:  5.481073379516602\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  509\n",
            "Train Loss:  3.743638515472412\n",
            "Test Loss:  5.481184482574463\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  510\n",
            "Train Loss:  3.7427730560302734\n",
            "Test Loss:  5.481297016143799\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  511\n",
            "Train Loss:  3.741912364959717\n",
            "Test Loss:  5.48140811920166\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  512\n",
            "Train Loss:  3.741053819656372\n",
            "Test Loss:  5.48151969909668\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  513\n",
            "Train Loss:  3.740199089050293\n",
            "Test Loss:  5.48163366317749\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  514\n",
            "Train Loss:  3.739346981048584\n",
            "Test Loss:  5.481747627258301\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  515\n",
            "Train Loss:  3.738497018814087\n",
            "Test Loss:  5.4818620681762695\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  516\n",
            "Train Loss:  3.73764967918396\n",
            "Test Loss:  5.481975555419922\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  517\n",
            "Train Loss:  3.7368054389953613\n",
            "Test Loss:  5.482088088989258\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  518\n",
            "Train Loss:  3.7359628677368164\n",
            "Test Loss:  5.482201099395752\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  519\n",
            "Train Loss:  3.7351231575012207\n",
            "Test Loss:  5.482314109802246\n",
            "Recall : 0.17523809523809525\n",
            "Epoch  520\n",
            "Train Loss:  3.7342848777770996\n",
            "Test Loss:  5.482429504394531\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  521\n",
            "Train Loss:  3.7334487438201904\n",
            "Test Loss:  5.482540130615234\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  522\n",
            "Train Loss:  3.7326138019561768\n",
            "Test Loss:  5.482651710510254\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  523\n",
            "Train Loss:  3.731780767440796\n",
            "Test Loss:  5.482763290405273\n",
            "Recall : 0.1742857142857143\n",
            "Epoch  524\n",
            "Train Loss:  3.7309513092041016\n",
            "Test Loss:  5.482874393463135\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  525\n",
            "Train Loss:  3.730123996734619\n",
            "Test Loss:  5.482985019683838\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  526\n",
            "Train Loss:  3.7293014526367188\n",
            "Test Loss:  5.483094215393066\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  527\n",
            "Train Loss:  3.728480100631714\n",
            "Test Loss:  5.483203887939453\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  528\n",
            "Train Loss:  3.7276620864868164\n",
            "Test Loss:  5.483315467834473\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  529\n",
            "Train Loss:  3.7268478870391846\n",
            "Test Loss:  5.483428001403809\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  530\n",
            "Train Loss:  3.726036787033081\n",
            "Test Loss:  5.4835381507873535\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  531\n",
            "Train Loss:  3.7252278327941895\n",
            "Test Loss:  5.483648300170898\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  532\n",
            "Train Loss:  3.724421977996826\n",
            "Test Loss:  5.483757019042969\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  533\n",
            "Train Loss:  3.723618984222412\n",
            "Test Loss:  5.4838666915893555\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  534\n",
            "Train Loss:  3.722818613052368\n",
            "Test Loss:  5.483975887298584\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  535\n",
            "Train Loss:  3.7220206260681152\n",
            "Test Loss:  5.4840826988220215\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  536\n",
            "Train Loss:  3.721226215362549\n",
            "Test Loss:  5.484189033508301\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  537\n",
            "Train Loss:  3.7204341888427734\n",
            "Test Loss:  5.484291076660156\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  538\n",
            "Train Loss:  3.7196459770202637\n",
            "Test Loss:  5.484393119812012\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  539\n",
            "Train Loss:  3.7188611030578613\n",
            "Test Loss:  5.484492301940918\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  540\n",
            "Train Loss:  3.7180795669555664\n",
            "Test Loss:  5.484591007232666\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  541\n",
            "Train Loss:  3.7173004150390625\n",
            "Test Loss:  5.484685897827148\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  542\n",
            "Train Loss:  3.7165236473083496\n",
            "Test Loss:  5.484783172607422\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  543\n",
            "Train Loss:  3.7157485485076904\n",
            "Test Loss:  5.48487663269043\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  544\n",
            "Train Loss:  3.714975595474243\n",
            "Test Loss:  5.4849700927734375\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  545\n",
            "Train Loss:  3.7142059803009033\n",
            "Test Loss:  5.485062599182129\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  546\n",
            "Train Loss:  3.71343994140625\n",
            "Test Loss:  5.4851555824279785\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  547\n",
            "Train Loss:  3.712674856185913\n",
            "Test Loss:  5.485248565673828\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  548\n",
            "Train Loss:  3.7119123935699463\n",
            "Test Loss:  5.4853434562683105\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  549\n",
            "Train Loss:  3.711153507232666\n",
            "Test Loss:  5.485435485839844\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  550\n",
            "Train Loss:  3.7103962898254395\n",
            "Test Loss:  5.4855265617370605\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  551\n",
            "Train Loss:  3.709641933441162\n",
            "Test Loss:  5.48561954498291\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  552\n",
            "Train Loss:  3.708890438079834\n",
            "Test Loss:  5.485709190368652\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  553\n",
            "Train Loss:  3.7081403732299805\n",
            "Test Loss:  5.485796928405762\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  554\n",
            "Train Loss:  3.707392692565918\n",
            "Test Loss:  5.485885143280029\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  555\n",
            "Train Loss:  3.7066473960876465\n",
            "Test Loss:  5.485971450805664\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  556\n",
            "Train Loss:  3.705904006958008\n",
            "Test Loss:  5.486057758331299\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  557\n",
            "Train Loss:  3.70516300201416\n",
            "Test Loss:  5.486144065856934\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  558\n",
            "Train Loss:  3.7044248580932617\n",
            "Test Loss:  5.486229419708252\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  559\n",
            "Train Loss:  3.7036893367767334\n",
            "Test Loss:  5.486314296722412\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  560\n",
            "Train Loss:  3.7029552459716797\n",
            "Test Loss:  5.486400604248047\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  561\n",
            "Train Loss:  3.7022247314453125\n",
            "Test Loss:  5.486485481262207\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  562\n",
            "Train Loss:  3.7014975547790527\n",
            "Test Loss:  5.486571311950684\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  563\n",
            "Train Loss:  3.7007737159729004\n",
            "Test Loss:  5.486657619476318\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  564\n",
            "Train Loss:  3.7000532150268555\n",
            "Test Loss:  5.486745834350586\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  565\n",
            "Train Loss:  3.6993350982666016\n",
            "Test Loss:  5.486833572387695\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  566\n",
            "Train Loss:  3.698619842529297\n",
            "Test Loss:  5.486920356750488\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  567\n",
            "Train Loss:  3.697906732559204\n",
            "Test Loss:  5.487008094787598\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  568\n",
            "Train Loss:  3.6971957683563232\n",
            "Test Loss:  5.487093925476074\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  569\n",
            "Train Loss:  3.6964874267578125\n",
            "Test Loss:  5.487178802490234\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  570\n",
            "Train Loss:  3.6957807540893555\n",
            "Test Loss:  5.487262725830078\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  571\n",
            "Train Loss:  3.6950745582580566\n",
            "Test Loss:  5.48734712600708\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  572\n",
            "Train Loss:  3.694371223449707\n",
            "Test Loss:  5.487430572509766\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  573\n",
            "Train Loss:  3.693669319152832\n",
            "Test Loss:  5.487514972686768\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  574\n",
            "Train Loss:  3.6929712295532227\n",
            "Test Loss:  5.487597465515137\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  575\n",
            "Train Loss:  3.692275047302246\n",
            "Test Loss:  5.487680435180664\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  576\n",
            "Train Loss:  3.6915812492370605\n",
            "Test Loss:  5.487762451171875\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  577\n",
            "Train Loss:  3.690890312194824\n",
            "Test Loss:  5.487845420837402\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  578\n",
            "Train Loss:  3.6902012825012207\n",
            "Test Loss:  5.487928867340088\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  579\n",
            "Train Loss:  3.689514636993408\n",
            "Test Loss:  5.488010883331299\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  580\n",
            "Train Loss:  3.688830852508545\n",
            "Test Loss:  5.488094329833984\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  581\n",
            "Train Loss:  3.688150405883789\n",
            "Test Loss:  5.48817777633667\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  582\n",
            "Train Loss:  3.687472343444824\n",
            "Test Loss:  5.4882612228393555\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  583\n",
            "Train Loss:  3.686796188354492\n",
            "Test Loss:  5.488343715667725\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  584\n",
            "Train Loss:  3.686123847961426\n",
            "Test Loss:  5.488425254821777\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  585\n",
            "Train Loss:  3.685452699661255\n",
            "Test Loss:  5.488504886627197\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  586\n",
            "Train Loss:  3.6847848892211914\n",
            "Test Loss:  5.488585472106934\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  587\n",
            "Train Loss:  3.6841182708740234\n",
            "Test Loss:  5.4886651039123535\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  588\n",
            "Train Loss:  3.683453321456909\n",
            "Test Loss:  5.488745212554932\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  589\n",
            "Train Loss:  3.6827902793884277\n",
            "Test Loss:  5.488824844360352\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  590\n",
            "Train Loss:  3.6821305751800537\n",
            "Test Loss:  5.488905429840088\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  591\n",
            "Train Loss:  3.6814732551574707\n",
            "Test Loss:  5.48898458480835\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  592\n",
            "Train Loss:  3.680818557739258\n",
            "Test Loss:  5.489065170288086\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  593\n",
            "Train Loss:  3.6801674365997314\n",
            "Test Loss:  5.489144325256348\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  594\n",
            "Train Loss:  3.6795177459716797\n",
            "Test Loss:  5.489223957061768\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  595\n",
            "Train Loss:  3.678870439529419\n",
            "Test Loss:  5.489305019378662\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  596\n",
            "Train Loss:  3.6782240867614746\n",
            "Test Loss:  5.489386081695557\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  597\n",
            "Train Loss:  3.6775810718536377\n",
            "Test Loss:  5.489468097686768\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  598\n",
            "Train Loss:  3.676940679550171\n",
            "Test Loss:  5.4895524978637695\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  599\n",
            "Train Loss:  3.6763017177581787\n",
            "Test Loss:  5.489636421203613\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  600\n",
            "Train Loss:  3.6756649017333984\n",
            "Test Loss:  5.489721298217773\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  601\n",
            "Train Loss:  3.6750307083129883\n",
            "Test Loss:  5.489805221557617\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  602\n",
            "Train Loss:  3.674398422241211\n",
            "Test Loss:  5.4898881912231445\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  603\n",
            "Train Loss:  3.673768997192383\n",
            "Test Loss:  5.489971160888672\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  604\n",
            "Train Loss:  3.6731410026550293\n",
            "Test Loss:  5.490056037902832\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  605\n",
            "Train Loss:  3.672515392303467\n",
            "Test Loss:  5.490140914916992\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  606\n",
            "Train Loss:  3.6718907356262207\n",
            "Test Loss:  5.490225791931152\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  607\n",
            "Train Loss:  3.671267509460449\n",
            "Test Loss:  5.490311145782471\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  608\n",
            "Train Loss:  3.6706461906433105\n",
            "Test Loss:  5.490394592285156\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  609\n",
            "Train Loss:  3.6700258255004883\n",
            "Test Loss:  5.490477561950684\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  610\n",
            "Train Loss:  3.6694083213806152\n",
            "Test Loss:  5.490561008453369\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  611\n",
            "Train Loss:  3.6687917709350586\n",
            "Test Loss:  5.490644454956055\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  612\n",
            "Train Loss:  3.6681771278381348\n",
            "Test Loss:  5.490728378295898\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  613\n",
            "Train Loss:  3.6675634384155273\n",
            "Test Loss:  5.490811347961426\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  614\n",
            "Train Loss:  3.6669511795043945\n",
            "Test Loss:  5.4908952713012695\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  615\n",
            "Train Loss:  3.666339874267578\n",
            "Test Loss:  5.490976333618164\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  616\n",
            "Train Loss:  3.6657309532165527\n",
            "Test Loss:  5.491055488586426\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  617\n",
            "Train Loss:  3.6651229858398438\n",
            "Test Loss:  5.491135597229004\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  618\n",
            "Train Loss:  3.6645169258117676\n",
            "Test Loss:  5.49121618270874\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  619\n",
            "Train Loss:  3.663912296295166\n",
            "Test Loss:  5.491296768188477\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  620\n",
            "Train Loss:  3.6633095741271973\n",
            "Test Loss:  5.4913787841796875\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  621\n",
            "Train Loss:  3.6627068519592285\n",
            "Test Loss:  5.491460800170898\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  622\n",
            "Train Loss:  3.662106990814209\n",
            "Test Loss:  5.491542816162109\n",
            "Recall : 0.17047619047619048\n",
            "Epoch  623\n",
            "Train Loss:  3.6615076065063477\n",
            "Test Loss:  5.491625785827637\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  624\n",
            "Train Loss:  3.660909414291382\n",
            "Test Loss:  5.4917097091674805\n",
            "Recall : 0.16952380952380952\n",
            "Epoch  625\n",
            "Train Loss:  3.6603124141693115\n",
            "Test Loss:  5.491793632507324\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  626\n",
            "Train Loss:  3.6597158908843994\n",
            "Test Loss:  5.491876602172852\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  627\n",
            "Train Loss:  3.659121036529541\n",
            "Test Loss:  5.491961479187012\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  628\n",
            "Train Loss:  3.6585264205932617\n",
            "Test Loss:  5.492046356201172\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  629\n",
            "Train Loss:  3.6579346656799316\n",
            "Test Loss:  5.492132663726807\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  630\n",
            "Train Loss:  3.6573433876037598\n",
            "Test Loss:  5.492218017578125\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  631\n",
            "Train Loss:  3.6567537784576416\n",
            "Test Loss:  5.492303848266602\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  632\n",
            "Train Loss:  3.656165838241577\n",
            "Test Loss:  5.492391109466553\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  633\n",
            "Train Loss:  3.655578136444092\n",
            "Test Loss:  5.492478847503662\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  634\n",
            "Train Loss:  3.6549923419952393\n",
            "Test Loss:  5.492566108703613\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  635\n",
            "Train Loss:  3.654407501220703\n",
            "Test Loss:  5.49265193939209\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  636\n",
            "Train Loss:  3.653823137283325\n",
            "Test Loss:  5.492740631103516\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  637\n",
            "Train Loss:  3.653240203857422\n",
            "Test Loss:  5.492828369140625\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  638\n",
            "Train Loss:  3.652657985687256\n",
            "Test Loss:  5.49291467666626\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  639\n",
            "Train Loss:  3.6520779132843018\n",
            "Test Loss:  5.493001937866211\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  640\n",
            "Train Loss:  3.651498794555664\n",
            "Test Loss:  5.493088722229004\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  641\n",
            "Train Loss:  3.65092134475708\n",
            "Test Loss:  5.493176460266113\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  642\n",
            "Train Loss:  3.650343894958496\n",
            "Test Loss:  5.493265151977539\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  643\n",
            "Train Loss:  3.649768352508545\n",
            "Test Loss:  5.493352890014648\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  644\n",
            "Train Loss:  3.649193286895752\n",
            "Test Loss:  5.493442535400391\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  645\n",
            "Train Loss:  3.648618221282959\n",
            "Test Loss:  5.493533134460449\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  646\n",
            "Train Loss:  3.6480443477630615\n",
            "Test Loss:  5.493621826171875\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  647\n",
            "Train Loss:  3.6474719047546387\n",
            "Test Loss:  5.493709087371826\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  648\n",
            "Train Loss:  3.646899700164795\n",
            "Test Loss:  5.493797302246094\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  649\n",
            "Train Loss:  3.646328926086426\n",
            "Test Loss:  5.493884563446045\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  650\n",
            "Train Loss:  3.6457576751708984\n",
            "Test Loss:  5.493971824645996\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  651\n",
            "Train Loss:  3.6451895236968994\n",
            "Test Loss:  5.494058609008789\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  652\n",
            "Train Loss:  3.6446218490600586\n",
            "Test Loss:  5.494144439697266\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  653\n",
            "Train Loss:  3.644054889678955\n",
            "Test Loss:  5.494231700897217\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  654\n",
            "Train Loss:  3.643489360809326\n",
            "Test Loss:  5.49431848526001\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  655\n",
            "Train Loss:  3.6429238319396973\n",
            "Test Loss:  5.494403839111328\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  656\n",
            "Train Loss:  3.6423583030700684\n",
            "Test Loss:  5.4944891929626465\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  657\n",
            "Train Loss:  3.641794443130493\n",
            "Test Loss:  5.494573593139648\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  658\n",
            "Train Loss:  3.6412322521209717\n",
            "Test Loss:  5.494660377502441\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  659\n",
            "Train Loss:  3.64067006111145\n",
            "Test Loss:  5.494744777679443\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  660\n",
            "Train Loss:  3.6401095390319824\n",
            "Test Loss:  5.494829177856445\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  661\n",
            "Train Loss:  3.639549493789673\n",
            "Test Loss:  5.4949140548706055\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  662\n",
            "Train Loss:  3.6389896869659424\n",
            "Test Loss:  5.494998931884766\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  663\n",
            "Train Loss:  3.638430595397949\n",
            "Test Loss:  5.495080947875977\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  664\n",
            "Train Loss:  3.6378722190856934\n",
            "Test Loss:  5.4951629638671875\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  665\n",
            "Train Loss:  3.637315273284912\n",
            "Test Loss:  5.495244026184082\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  666\n",
            "Train Loss:  3.636758327484131\n",
            "Test Loss:  5.495325088500977\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  667\n",
            "Train Loss:  3.6362035274505615\n",
            "Test Loss:  5.495406627655029\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  668\n",
            "Train Loss:  3.6356492042541504\n",
            "Test Loss:  5.495486259460449\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  669\n",
            "Train Loss:  3.63509464263916\n",
            "Test Loss:  5.495564937591553\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  670\n",
            "Train Loss:  3.6345412731170654\n",
            "Test Loss:  5.49564266204834\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  671\n",
            "Train Loss:  3.633988618850708\n",
            "Test Loss:  5.495720386505127\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  672\n",
            "Train Loss:  3.6334352493286133\n",
            "Test Loss:  5.495800018310547\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  673\n",
            "Train Loss:  3.6328835487365723\n",
            "Test Loss:  5.495880126953125\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  674\n",
            "Train Loss:  3.6323328018188477\n",
            "Test Loss:  5.495960235595703\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  675\n",
            "Train Loss:  3.631782293319702\n",
            "Test Loss:  5.4960408210754395\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  676\n",
            "Train Loss:  3.631232500076294\n",
            "Test Loss:  5.496120929718018\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  677\n",
            "Train Loss:  3.6306827068328857\n",
            "Test Loss:  5.49620246887207\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  678\n",
            "Train Loss:  3.6301345825195312\n",
            "Test Loss:  5.496280670166016\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  679\n",
            "Train Loss:  3.6295864582061768\n",
            "Test Loss:  5.49636173248291\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  680\n",
            "Train Loss:  3.6290390491485596\n",
            "Test Loss:  5.496440887451172\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  681\n",
            "Train Loss:  3.6284918785095215\n",
            "Test Loss:  5.496520042419434\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  682\n",
            "Train Loss:  3.6279456615448\n",
            "Test Loss:  5.496598720550537\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  683\n",
            "Train Loss:  3.6273996829986572\n",
            "Test Loss:  5.496677398681641\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  684\n",
            "Train Loss:  3.626854658126831\n",
            "Test Loss:  5.496756553649902\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  685\n",
            "Train Loss:  3.626310348510742\n",
            "Test Loss:  5.496833801269531\n",
            "Recall : 0.17142857142857143\n",
            "Epoch  686\n",
            "Train Loss:  3.6257662773132324\n",
            "Test Loss:  5.496912002563477\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  687\n",
            "Train Loss:  3.625223159790039\n",
            "Test Loss:  5.496988296508789\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  688\n",
            "Train Loss:  3.624680995941162\n",
            "Test Loss:  5.497067451477051\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  689\n",
            "Train Loss:  3.624138355255127\n",
            "Test Loss:  5.4971442222595215\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  690\n",
            "Train Loss:  3.6235971450805664\n",
            "Test Loss:  5.497221946716309\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  691\n",
            "Train Loss:  3.623055934906006\n",
            "Test Loss:  5.497298240661621\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  692\n",
            "Train Loss:  3.6225152015686035\n",
            "Test Loss:  5.497374057769775\n",
            "Recall : 0.17238095238095238\n",
            "Epoch  693\n",
            "Train Loss:  3.6219756603240967\n",
            "Test Loss:  5.497447967529297\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  694\n",
            "Train Loss:  3.621436595916748\n",
            "Test Loss:  5.49752140045166\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  695\n",
            "Train Loss:  3.6208972930908203\n",
            "Test Loss:  5.497591972351074\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  696\n",
            "Train Loss:  3.6203575134277344\n",
            "Test Loss:  5.497664451599121\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  697\n",
            "Train Loss:  3.619818687438965\n",
            "Test Loss:  5.497735023498535\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  698\n",
            "Train Loss:  3.6192803382873535\n",
            "Test Loss:  5.497802734375\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  699\n",
            "Train Loss:  3.618741989135742\n",
            "Test Loss:  5.497871398925781\n",
            "Recall : 0.17333333333333334\n",
            "Epoch  700\n",
            "Train Loss:  3.618203639984131\n",
            "Test Loss:  5.497939109802246\n",
            "Recall : 0.1742857142857143\n",
            "\n",
            "0.16802585034013687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_6PpfhzwtOX"
      },
      "source": [
        "torch.save(result,\"visual_ebds.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}