<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>positive-similarity.dataset API documentation</title>
<meta name="description" content="All our custom pytorch Dataset classes, the most important one is TTLDataset." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>positive-similarity.dataset</code></h1>
</header>
<section id="section-intro">
<p>All our custom pytorch Dataset classes, the most important one is TTLDataset.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;All our custom pytorch Dataset classes, the most important one is TTLDataset.&#34;&#34;&#34;

import os

import torch
import numpy as np

from skimage import io
from pathlib import Path
from typing import Tuple, Dict
from torch.utils.data import Dataset


class TTLDataset(Dataset):
    &#34;&#34;&#34;
    This is our pytorch TTL dataset, it is mainly used in the extracting part.
    &#34;&#34;&#34;
    def __init__(self, root_dir: str, transform=None, target_transform=None):
        &#34;&#34;&#34;
        Args:
            root_dir (str): Directory with all the images. left &amp; right
            transform (callable, optional): Optional transform to be applied on a sample.
            target_transform (callable, optional): Optional transform to be applied on a target (label).
        &#34;&#34;&#34;
        assert isinstance(root_dir, str)

        self.root_dir = Path(root_dir)
        (
            self.left_images,
            self.right_images,
        ) = self.check_directories_and_get_images_paths(self.root_dir)
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.right_images)

    def __getitem__(self, idx: int) -&gt; Tuple[Dict, str]:

        left_img_path = self.left_images[idx]
        right_img_path = self.right_images[idx]

        left_image = io.imread(left_img_path)
        right_image = io.imread(right_img_path)

        sample = {&#34;left&#34;: left_image, &#34;right&#34;: right_image}

        if self.transform:
            sample[&#34;left&#34;] = self.transform(sample[&#34;left&#34;])
            sample[&#34;right&#34;] = self.transform(sample[&#34;right&#34;])

        label = left_img_path.name
        if self.target_transform:
            label = self.target_transform(label)

        # same label for both and using name rather than stem to deal with the case of 2 imgs that
        # share the same name with diff extensions
        return (
            sample,
            label,
        )

    def check_directories_and_get_images_paths(self, root_dir):
        &#34;&#34;&#34;
        Ensure that the way the root_dir has two subdirs left &amp; right that contains the same number
        of images.
        This will not check that each pair is named the same way. 
        &#34;&#34;&#34;
        assert os.path.isdir(root_dir)

        _, dirs, _ = next(os.walk(root_dir))

        assert &#34;left&#34; in dirs
        assert &#34;right&#34; in dirs

        _, _, left_images = next(os.walk(root_dir / &#34;left&#34;))
        _, _, right_images = next(os.walk(root_dir / &#34;right&#34;))

        assert len(left_images) &gt; 0
        assert len(left_images) == len(right_images)

        return [root_dir / &#34;left&#34; / f for f in left_images], [
            root_dir / &#34;right&#34; / f for f in right_images
        ]


class SimpleDataset(Dataset):
    &#34;&#34;&#34;
    Dataset class to load images that are located in some directory.
    The assumed structure is the following:
        Dir/*.[img_exts]
    &#34;&#34;&#34;
    def __init__(self, root_dir: str, transform=None, target_transform=None):
        &#34;&#34;&#34;
        Args:
            root_dir (str): Directory with all the images. left &amp; right
            transform (callable, optional): Optional transform to be applied on a sample.
        &#34;&#34;&#34;
        assert isinstance(root_dir, str)

        self.root_dir = Path(root_dir)
        self.images = self.check_directories_and_get_images_paths(self.root_dir)
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx: int) -&gt; Tuple[np.ndarray, str]:

        img_path = self.images[idx]

        image = io.imread(img_path)
        label = img_path.name

        if self.transform:
            image = self.transform(image)

        if self.target_transform:
            label = self.target_transform(label)

        return (
            image,
            label,
        )

    def check_directories_and_get_images_paths(self, root_dir):
        assert os.path.isdir(root_dir)

        _, dirs, _ = next(os.walk(root_dir))

        assert len(dirs) == 0

        _, _, images = next(os.walk(root_dir))

        assert len(images) &gt; 0

        return [root_dir / f for f in images]


class EmbDataset(Dataset):
    &#34;&#34;&#34;
    This is was initally created to load the embeddings i.e the extracted features, to keep up with 
    the pytorch training classical style using a DataLoader.
    Nevertheless, we always load all the embeddings at once since they are light in memory.

    [Warning]: this is still doesn&#39;t support the case of Simple dataset, it assumes that the embds
    are serialized in a form of a dictionnary that contains the following keys:
        [&#39;left&#39;, &#39;right&#39;, &#39;left_name&#39;, &#39;right_name&#39;]
    &#34;&#34;&#34;
    def __init__(self, path: str, only_original=True):
        &#34;&#34;&#34;
        Args:
            path (str): the serialized file that contains the extracted embeddings.
            only_original (bool, optional): if is true, it means that we are going to use only the
            first half of the embeddings, and that is because of the way we constructed the TTLDataset
            when it is augmented, the features of the original images are located at the first half
            then followed by their augmented versions.
            In short, if you want to load all the embds, weather it contains augmented version or not
            use only_original=False, otherwise it will load only the first half.
        &#34;&#34;&#34;
        self.embds = self._load_embds(path, only_original)
        self.augmented = not only_original
        
        assert &#34;left&#34; in self.embds and &#34;left_name&#34; in self.embds
        assert &#34;right&#34; in self.embds and &#34;right_name&#34; in self.embds
        assert len(self.embds[&#34;left&#34;]) == len(self.embds[&#34;right&#34;]) and len(
            self.embds[&#34;left&#34;]
        ) == len(self.embds[&#34;left_name&#34;])
        assert len(self.embds[&#34;right&#34;]) == len(self.embds[&#34;right_name&#34;])

    def _load_embds(self, path: str, only_original : bool) -&gt; dict:
        e = np.load(path, allow_pickle=True).reshape(-1)[0]

        if &#39;left_ebds&#39; in e.keys():
            e[&#39;left&#39;] = e[&#39;left_ebds&#39;]
            e[&#39;right&#39;] = e[&#39;right_ebds&#39;]

        if only_original:
            length = len(e[&#39;left&#39;])
            e[&#39;left&#39;] = e[&#39;left&#39;][: length // 2]
            e[&#39;left_name&#39;] = e[&#39;left_name&#39;][: length // 2]
            e[&#39;right&#39;] = e[&#39;right&#39;][: length // 2]
            e[&#39;right_name&#39;] = e[&#39;right_name&#39;][: length // 2]

        return e

    def load_all_to_device(self, device):
        embds, _ = self[:]
        embds[&#39;left&#39;].to(device)
        embds[&#39;right&#39;].to(device)

        return embds

    def __getitem__(self, i):
        left, right = self.embds[&#34;left&#34;][i], self.embds[&#34;right&#34;][i]
        left, right = torch.from_numpy(left).float(), torch.from_numpy(right).float()

        return ({&#34;left&#34;: left, &#34;right&#34;: right}, self.embds[&#34;left_name&#34;][i])

    def __len__(self):
        return len(self.embds[&#34;left&#34;])</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="positive-similarity.dataset.EmbDataset"><code class="flex name class">
<span>class <span class="ident">EmbDataset</span></span>
<span>(</span><span>path: str, only_original=True)</span>
</code></dt>
<dd>
<div class="desc"><p>This is was initally created to load the embeddings i.e the extracted features, to keep up with
the pytorch training classical style using a DataLoader.
Nevertheless, we always load all the embeddings at once since they are light in memory.</p>
<p>[Warning]: this is still doesn't support the case of Simple dataset, it assumes that the embds
are serialized in a form of a dictionnary that contains the following keys:
['left', 'right', 'left_name', 'right_name']</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>the serialized file that contains the extracted embeddings.</dd>
<dt><strong><code>only_original</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>if is true, it means that we are going to use only the</dd>
</dl>
<p>first half of the embeddings, and that is because of the way we constructed the TTLDataset
when it is augmented, the features of the original images are located at the first half
then followed by their augmented versions.
In short, if you want to load all the embds, weather it contains augmented version or not
use only_original=False, otherwise it will load only the first half.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EmbDataset(Dataset):
    &#34;&#34;&#34;
    This is was initally created to load the embeddings i.e the extracted features, to keep up with 
    the pytorch training classical style using a DataLoader.
    Nevertheless, we always load all the embeddings at once since they are light in memory.

    [Warning]: this is still doesn&#39;t support the case of Simple dataset, it assumes that the embds
    are serialized in a form of a dictionnary that contains the following keys:
        [&#39;left&#39;, &#39;right&#39;, &#39;left_name&#39;, &#39;right_name&#39;]
    &#34;&#34;&#34;
    def __init__(self, path: str, only_original=True):
        &#34;&#34;&#34;
        Args:
            path (str): the serialized file that contains the extracted embeddings.
            only_original (bool, optional): if is true, it means that we are going to use only the
            first half of the embeddings, and that is because of the way we constructed the TTLDataset
            when it is augmented, the features of the original images are located at the first half
            then followed by their augmented versions.
            In short, if you want to load all the embds, weather it contains augmented version or not
            use only_original=False, otherwise it will load only the first half.
        &#34;&#34;&#34;
        self.embds = self._load_embds(path, only_original)
        self.augmented = not only_original
        
        assert &#34;left&#34; in self.embds and &#34;left_name&#34; in self.embds
        assert &#34;right&#34; in self.embds and &#34;right_name&#34; in self.embds
        assert len(self.embds[&#34;left&#34;]) == len(self.embds[&#34;right&#34;]) and len(
            self.embds[&#34;left&#34;]
        ) == len(self.embds[&#34;left_name&#34;])
        assert len(self.embds[&#34;right&#34;]) == len(self.embds[&#34;right_name&#34;])

    def _load_embds(self, path: str, only_original : bool) -&gt; dict:
        e = np.load(path, allow_pickle=True).reshape(-1)[0]

        if &#39;left_ebds&#39; in e.keys():
            e[&#39;left&#39;] = e[&#39;left_ebds&#39;]
            e[&#39;right&#39;] = e[&#39;right_ebds&#39;]

        if only_original:
            length = len(e[&#39;left&#39;])
            e[&#39;left&#39;] = e[&#39;left&#39;][: length // 2]
            e[&#39;left_name&#39;] = e[&#39;left_name&#39;][: length // 2]
            e[&#39;right&#39;] = e[&#39;right&#39;][: length // 2]
            e[&#39;right_name&#39;] = e[&#39;right_name&#39;][: length // 2]

        return e

    def load_all_to_device(self, device):
        embds, _ = self[:]
        embds[&#39;left&#39;].to(device)
        embds[&#39;right&#39;].to(device)

        return embds

    def __getitem__(self, i):
        left, right = self.embds[&#34;left&#34;][i], self.embds[&#34;right&#34;][i]
        left, right = torch.from_numpy(left).float(), torch.from_numpy(right).float()

        return ({&#34;left&#34;: left, &#34;right&#34;: right}, self.embds[&#34;left_name&#34;][i])

    def __len__(self):
        return len(self.embds[&#34;left&#34;])</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="positive-similarity.dataset.EmbDataset.load_all_to_device"><code class="name flex">
<span>def <span class="ident">load_all_to_device</span></span>(<span>self, device)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_all_to_device(self, device):
    embds, _ = self[:]
    embds[&#39;left&#39;].to(device)
    embds[&#39;right&#39;].to(device)

    return embds</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="positive-similarity.dataset.SimpleDataset"><code class="flex name class">
<span>class <span class="ident">SimpleDataset</span></span>
<span>(</span><span>root_dir: str, transform=None, target_transform=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Dataset class to load images that are located in some directory.
The assumed structure is the following:
Dir/*.[img_exts]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>root_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>Directory with all the images. left &amp; right</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>callable</code>, optional</dt>
<dd>Optional transform to be applied on a sample.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SimpleDataset(Dataset):
    &#34;&#34;&#34;
    Dataset class to load images that are located in some directory.
    The assumed structure is the following:
        Dir/*.[img_exts]
    &#34;&#34;&#34;
    def __init__(self, root_dir: str, transform=None, target_transform=None):
        &#34;&#34;&#34;
        Args:
            root_dir (str): Directory with all the images. left &amp; right
            transform (callable, optional): Optional transform to be applied on a sample.
        &#34;&#34;&#34;
        assert isinstance(root_dir, str)

        self.root_dir = Path(root_dir)
        self.images = self.check_directories_and_get_images_paths(self.root_dir)
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx: int) -&gt; Tuple[np.ndarray, str]:

        img_path = self.images[idx]

        image = io.imread(img_path)
        label = img_path.name

        if self.transform:
            image = self.transform(image)

        if self.target_transform:
            label = self.target_transform(label)

        return (
            image,
            label,
        )

    def check_directories_and_get_images_paths(self, root_dir):
        assert os.path.isdir(root_dir)

        _, dirs, _ = next(os.walk(root_dir))

        assert len(dirs) == 0

        _, _, images = next(os.walk(root_dir))

        assert len(images) &gt; 0

        return [root_dir / f for f in images]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="positive-similarity.dataset.SimpleDataset.check_directories_and_get_images_paths"><code class="name flex">
<span>def <span class="ident">check_directories_and_get_images_paths</span></span>(<span>self, root_dir)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_directories_and_get_images_paths(self, root_dir):
    assert os.path.isdir(root_dir)

    _, dirs, _ = next(os.walk(root_dir))

    assert len(dirs) == 0

    _, _, images = next(os.walk(root_dir))

    assert len(images) &gt; 0

    return [root_dir / f for f in images]</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="positive-similarity.dataset.TTLDataset"><code class="flex name class">
<span>class <span class="ident">TTLDataset</span></span>
<span>(</span><span>root_dir: str, transform=None, target_transform=None)</span>
</code></dt>
<dd>
<div class="desc"><p>This is our pytorch TTL dataset, it is mainly used in the extracting part.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>root_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>Directory with all the images. left &amp; right</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>callable</code>, optional</dt>
<dd>Optional transform to be applied on a sample.</dd>
<dt><strong><code>target_transform</code></strong> :&ensp;<code>callable</code>, optional</dt>
<dd>Optional transform to be applied on a target (label).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TTLDataset(Dataset):
    &#34;&#34;&#34;
    This is our pytorch TTL dataset, it is mainly used in the extracting part.
    &#34;&#34;&#34;
    def __init__(self, root_dir: str, transform=None, target_transform=None):
        &#34;&#34;&#34;
        Args:
            root_dir (str): Directory with all the images. left &amp; right
            transform (callable, optional): Optional transform to be applied on a sample.
            target_transform (callable, optional): Optional transform to be applied on a target (label).
        &#34;&#34;&#34;
        assert isinstance(root_dir, str)

        self.root_dir = Path(root_dir)
        (
            self.left_images,
            self.right_images,
        ) = self.check_directories_and_get_images_paths(self.root_dir)
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.right_images)

    def __getitem__(self, idx: int) -&gt; Tuple[Dict, str]:

        left_img_path = self.left_images[idx]
        right_img_path = self.right_images[idx]

        left_image = io.imread(left_img_path)
        right_image = io.imread(right_img_path)

        sample = {&#34;left&#34;: left_image, &#34;right&#34;: right_image}

        if self.transform:
            sample[&#34;left&#34;] = self.transform(sample[&#34;left&#34;])
            sample[&#34;right&#34;] = self.transform(sample[&#34;right&#34;])

        label = left_img_path.name
        if self.target_transform:
            label = self.target_transform(label)

        # same label for both and using name rather than stem to deal with the case of 2 imgs that
        # share the same name with diff extensions
        return (
            sample,
            label,
        )

    def check_directories_and_get_images_paths(self, root_dir):
        &#34;&#34;&#34;
        Ensure that the way the root_dir has two subdirs left &amp; right that contains the same number
        of images.
        This will not check that each pair is named the same way. 
        &#34;&#34;&#34;
        assert os.path.isdir(root_dir)

        _, dirs, _ = next(os.walk(root_dir))

        assert &#34;left&#34; in dirs
        assert &#34;right&#34; in dirs

        _, _, left_images = next(os.walk(root_dir / &#34;left&#34;))
        _, _, right_images = next(os.walk(root_dir / &#34;right&#34;))

        assert len(left_images) &gt; 0
        assert len(left_images) == len(right_images)

        return [root_dir / &#34;left&#34; / f for f in left_images], [
            root_dir / &#34;right&#34; / f for f in right_images
        ]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="positive-similarity.dataset.TTLDataset.check_directories_and_get_images_paths"><code class="name flex">
<span>def <span class="ident">check_directories_and_get_images_paths</span></span>(<span>self, root_dir)</span>
</code></dt>
<dd>
<div class="desc"><p>Ensure that the way the root_dir has two subdirs left &amp; right that contains the same number
of images.
This will not check that each pair is named the same way.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_directories_and_get_images_paths(self, root_dir):
    &#34;&#34;&#34;
    Ensure that the way the root_dir has two subdirs left &amp; right that contains the same number
    of images.
    This will not check that each pair is named the same way. 
    &#34;&#34;&#34;
    assert os.path.isdir(root_dir)

    _, dirs, _ = next(os.walk(root_dir))

    assert &#34;left&#34; in dirs
    assert &#34;right&#34; in dirs

    _, _, left_images = next(os.walk(root_dir / &#34;left&#34;))
    _, _, right_images = next(os.walk(root_dir / &#34;right&#34;))

    assert len(left_images) &gt; 0
    assert len(left_images) == len(right_images)

    return [root_dir / &#34;left&#34; / f for f in left_images], [
        root_dir / &#34;right&#34; / f for f in right_images
    ]</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="positive-similarity" href="index.html">positive-similarity</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="positive-similarity.dataset.EmbDataset" href="#positive-similarity.dataset.EmbDataset">EmbDataset</a></code></h4>
<ul class="">
<li><code><a title="positive-similarity.dataset.EmbDataset.load_all_to_device" href="#positive-similarity.dataset.EmbDataset.load_all_to_device">load_all_to_device</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="positive-similarity.dataset.SimpleDataset" href="#positive-similarity.dataset.SimpleDataset">SimpleDataset</a></code></h4>
<ul class="">
<li><code><a title="positive-similarity.dataset.SimpleDataset.check_directories_and_get_images_paths" href="#positive-similarity.dataset.SimpleDataset.check_directories_and_get_images_paths">check_directories_and_get_images_paths</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="positive-similarity.dataset.TTLDataset" href="#positive-similarity.dataset.TTLDataset">TTLDataset</a></code></h4>
<ul class="">
<li><code><a title="positive-similarity.dataset.TTLDataset.check_directories_and_get_images_paths" href="#positive-similarity.dataset.TTLDataset.check_directories_and_get_images_paths">check_directories_and_get_images_paths</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>